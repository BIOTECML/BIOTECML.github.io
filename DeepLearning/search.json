[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "MachineLearning",
    "section": "",
    "text": "Deep Learning\nEl padre moderno del concepto de Aprendizaje Profundo o Deep Learning fue el británico Geoffrey Hinton, que investigó sobre este campo en los años 80 del siglo XX. Sin embargo, no fue hasta 2010 que se volvió popular debido a su capacidad para resolver problemas complejos y mejorar la precisión de los resultados obtenidos mediante técnicas de aprendizaje automático. La idea principal que hay detrás del concepto de Aprendizaje Profundo es observar el cerebro humano e inspirarse en él para intentar reproducir de forma informática su comportamiento.\nEn la imagen inferior podemos observar una neurona real, que está compuesta principalmente de tres partes: soma (cuerpo celular), dendritas (canales de entrada) y axón (canal de salida). Descrito de una forma muy simplificada, las neuronas procesan y transmiten información por medios electroquímicos. Cuando una neurona recibe, a través de las dendritas, una cantidad de estímulos mayor a un cierto umbral, esta se despolariza excitando, a través del axón, a otras neuronas próximas conectadas a través de las sinapsis.\n\n\n\n\n\nEl aprendizaje profundo se centra en el uso de redes neuronales tanto para la representación como para el procesamiento de información. El funcionamiento se basa en la estructura biológica del sistema neuronal humano, de modo que el algoritmo es capaz de “aprender” y mejorar de manera autónoma a partir de los datos de entrada. Para reproducir el comportamiento del sistema neuronal biológico es necesario introducir los conceptos de neurona artificial y red neuronal artificial que veremos en el punto siguiente.\nGeneralmente, cuando se habla de aprendizaje automático (Machine Learning) y aprendizaje profundo (Deep Learning), se tiende a pensar que son términos intercambiables, pero esto no es cierto. Aunque ambos están relacionados con el campo de la inteligencia artificial (IA), existen diferencias significativas entre ellos. A continuación, se explican las principales diferencias entre estos dos tipos de aprendizaje:\n\nEl aprendizaje profundo se enfoca principalmente en el uso de redes neuronales profundas para procesar la información recibida, utilizando modelos muy complejos y difíciles de interpretar. En cambio, el aprendizaje automático utiliza una amplia variedad de algoritmos, algunos de los cuales son más simples y fáciles de interpretar, aunque en algunos casos también se utilizan redes neuronales y la complejidad de los modelos puede variar.\nGeneralmente, el aprendizaje profundo requiere una cantidad mayor de datos para poder entrenar los modelos de manera efectiva debido a la complejidad de las redes neuronales y su capacidad para capturar o elaborar patrones sobre los datos más complejos.\nEn cuanto a las características, el aprendizaje automático requiere que los usuarios las creen e identifiquen con precisión, mientras que el aprendizaje profundo las aprende y crea nuevas de forma automática.\nPor último, el aprendizaje profundo se suele aplicar a problemas que requieren una mayor precisión, como por ejemplo en diagnósticos médicos o en el procesamiento del lenguaje natural.\n\nA continuación se presenta un diagrama sobre la integración del aprendizaje profundo y el aprendizaje automático dentro de la inteligencia artificial.\n\n\n\n\n\nPor último, veamos los campos de aplicación más habitual del aprendizaje profundo haciendo uso de la redes neuronales artificiales, entre los que destacan:\n\nProcesamiento del lenguaje natural. Se utiliza en tareas como el filtrado de correos electrónicos para detectar los mensajes spam, en la predicción y autocompletado de palabras en textos, en chatbots para comprender lo que el usuario está solicitando y proporcionar una respuesta adecuada, y en traducciones de textos de un idioma a otro de manera automática y precisa.\nProcesamiento de imágenes. Es un área en la que el aprendizaje profundo ha logrado grandes avances. Entre las tareas más destacadas se encuentran la clasificación y detección de objetos en imágenes, así como la segmentación y síntesis de imágenes.\nDiagnósticos médicos. Los avances ayudan a los médicos a mejorar la precisión y rapidez de los diagnósticos, lo que puede llevar a una mejor atención médica y resultados para los pacientes. Se utiliza en la detección y diagnóstico de enfermedades, la identificación de patrones en imágenes médicas y la predicción de la progresión de enfermedades.\nReconocimiento facial y de voz. Se utiliza para tareas relacionadas con la interacción con el ser humano generalmente, como la verificación de la identidad, la detección de emociones y la transcripción de voz a texto.\nAsistentes virtuales. Los asistentes virtuales, como Alexa, Siri y ok google utilizan el aprendizaje profundo para comprender y responder a las solicitudes del usuario, como por ejemplo para reproducir la canción que este solicita, realizar una llamada telefónica o buscar información en la web.\n\nLos contenidos de esta parte se estructuran de la siguiente forma:\n\nIntroducción al deep learning y proceso de aprendizaje de una red neuronal.\nRedes multicapas densas para problemas de clasificación y regresión con Keras.\nRedes convolucionales para el análisis de imagenes con Keras."
  },
  {
    "objectID": "10_IntroDL.html#conceptos-fundamentales-del-dl",
    "href": "10_IntroDL.html#conceptos-fundamentales-del-dl",
    "title": "1  Introducción",
    "section": "1.1 Conceptos fundamentales del DL",
    "text": "1.1 Conceptos fundamentales del DL\nComenzamos con los conceptos matemáticos de neurona artificial y red neuronal.\n\n1.1.1 Neurona artificial\nPara poder modelizar de forma matemática el funcionamiento de una neurona es necesario conocer su funcionamiento biológico. De esta forma nos resultará posible construir la denominada neurona artificial que trata de replicar el funcionamiento de una neurona real. El comportamiento de una neurona se puede representar mediante este sencillo esquema:\n\nLa señal entra en el núcleo de la neurona vía las dendritas o través de otra neurona.\nLa conexión sináptica de cada dendrita puede tener una fuerza (peso) diferente y ajustable.\nEn el núcleo, la señal de todas las dendritas (inputs) se combina (generalmente de forma aditiva) en un único efecto.\nSi la señal combinada es más fuerte que un umbral dado, entonces la neurona se activa a lo largo del axón, en el caso contrario permanece quieta, es decir, en la realización más sencilla, la intensidad de la señal tiene dos niveles posibles: encendido o apagado, es decir, 1 o 0, en función del valor del umbral. No se necesitan valores intermedios.\nSi la neurona se ha activado, el terminal del axón se conecta a las dendritas de otras neuronas o produce un estímulo de salida.\n\nTraduciendo esto a una receta matemática, se asignan a las celdas de entrada los números \\(x_1,...,x_n\\) (punto de datos de entrada). La fuerza de las conexiones sinápticas se controla con los pesos \\(w_1,...,w_n\\). A continuación, la señal combinada se define como la suma ponderada:\n\\[s=\\sum_{i=1}^n x_iw_i\\]\nLa señal se convierte en un argumento de la función de activación (\\(f\\)), que, en el caso más sencillo, adopta la forma de la función de salto (step), es decir, cuando la señal combinada \\(s\\) es mayor que el sesgo (umbral) \\(b\\), la señal que pasa por el axón es 1. En el caso contrario, el valor de la señal generada es 0 (no hay activación):\n\\[f(s,b) =\n\\begin{cases}\n1 \\text{ para } s \\geq b \\\\\n0 \\text{ para } s < b \\\\\n\\end{cases}\\]\nEsta representeción matemática es precisamente lo que necesitamos para imitar el prototipo biológico.\nExiste una conveniente convención notacional que se utiliza con frecuencia. En lugar de separar el sesgo de los datos de entrada, podemos tratarlos todos uniformemente. La condición de activación puede transformarse trivialmente como:\n\\[s\\geq b \\rightarrow \\sum_{i=1}^n x_iw_i - b \\geq 0 \\rightarrow \\sum_{i=1}^n x_iw_i - x_0w_0 \\geq 0 \\rightarrow \\sum_{i=0}^n x_iw_i \\geq 0,\\]\ndonde \\(x_0 = 1\\) y \\(w_0 = -b\\). En otras palabras, podemos tratar el sesgo como un peso en la arista conectada a una celda adicional con la entrada siempre fija a 1:\n\\[f(s,b) =\n\\begin{cases}\n1 \\text{ para } s \\geq 0 \\\\\n0 \\text{ para } s < 0 \\\\\n\\end{cases}\\]\ncon \\(s=\\sum_{i=0}^n x_iw_i\\). En la figura siguiente viene representado el comportamiento de la neurona artificial:\n\n\n\n\n\nLas ponderaciones \\(w_0,w_1,...,w_n\\) se denominan generalmente hiperparámetros. Determinan la funcionalidad de la neurona artificial y pueden modificarse durante el proceso de aprendizaje (entrenamiento, que analizaremos más adelante). Sin embargo, se mantienen fijos cuando se utiliza la neurona entrenada en una muestra de datos de entrada concreta.\nUna propiedad esencial de las neuronas artificiales es la no linealidad de la función de activación, lo que permite la construcción de estructuras neuronales muy complejas con gran capacidad de aprendizaje.\nA continuación vamos a ver como podemos implementar una neurona artificial utilizando una función muy simple, donde fijaremos los valores de \\(x\\) y \\(w\\), así como el balor de \\(b\\) para la activación de la neurona. En primer lugar definimos la función salto de activación de la neurona.\n\n# Función de activación\nsalto = function(s)\n{\n  activ = ifelse(s>0,1,0)\n  return(activ)\n}\n\nRepresentamos la función de activación para una secuencia de valores de s:\n\n# Valores a evalaur\nsval = seq(-2,2,length=100)\n# Función de activación\nres = salto(sval)\nplot(sval,res,type=\"l\", xlab=\"s\",ylab=\"Activación\")\n\n\n\n\nFunción de activación\n\n\n\n\nDefinimos ahora nuestra neurona artificail teniendo en cuenta que dada la construcción matemática se debe fijar que \\(x_0 = 0\\) y \\(w_0 = -b\\).\n\n# Función de activación\nneurona = function(x,w,b,f=salto)\n{\n  # Neurona artificial\n  \n  # Entradas\n  #   x: array de entradas  [x1, x2,...,xn]\n  #   w: array de pesos [w1, w2,...,wn]\n  #   f: función de activación. Por defecto función de salto\n\n  # Return\n  #   signal = x.w\n  \n  x = c(0,x)\n  w = c(-1*b,w)\n  return(f(sum(x*w)))\n}\n\nPodemos ver el funcionamiento de nuestra neurona con un ejemplo de muestra. la nerurona se activará cuando el resultado sea igual a 1, y no lo hará si el resultado es igual a cero.\n\nx = c(2,1.5,-0.7)\nw = c(1,2.5,-0.2)\nb = 4\n# Evaluamos\nneurona(x, w, b)\n\n[1] 1\n\n\nEn este caso la neurona se ha activado. Si cambiamos los valores de \\(b\\) podríamos tener diferentes representaciones de la activación de la neurona.\n\n\n1.1.2 Red neuronal artificial\nLas redes neuronales artificiales (RNA) son modelos computacionales que procesan información imitando el funcionamiento de las neuronas biológicas. El objetivo de las RNA es ayudar a que los sistemas informáticos puedan funcionar tal como un cerebro humano en cuanto a aprendizaje y pensamiento. De esta idea parte el concepto de “inteligencia artificial”.\nLa forma más común de representar la estructura de una red neuronal es mediante el uso de capas (layers), formadas a su vez por neuronas (unidades, units o neurons). Cada neurona, realiza una operación sencilla y está conectada a las neuronas de la capa anterior y de la capa siguiente mediante pesos, cuya función es regular la información que se propaga de una neurona a otra.\nLas redes neuronales artificiales están conformadas por 3 tipos de nodos o neuronas:\n\nNodos de entrada: reciben la información desde el exterior de la red (input).\nNodos de salida: envían la información hacia el exterior de la red (output).\nNodos ocultos: transmiten la información entre los nodos de la red. Por lo tanto, se encuentran en el medio de los nodos de entrada y de salida y no tienen contacto con el exterior.\n\nLas RNA suelen estar conformadas por múltiples capas de nodos ocultos, a estas se les llaman “capas de aprendizaje”. A mayor cantidad de capas, mayor es la profundidad de la red y mayor es la capacidad de aprendizaje. En este contexto, los nodos de entrada reciben una serie de datos desde el exterior, estos datos son enviados al interior de la red hacia los nodos ocultos. Los nodos ocultos van procesando, modificando y transfiriendo la información de una capa a otra. Este proceso es lo que se conoce como “aprendizaje”, pues cada capa de nodos ocultos va aprendiendo de las capas más externas. Dicha secuencia de aprendizaje es lo que da origen al Deep Learning. De aquí la inseparable relación entre redes neuronales artificiales y Deep Learning.\nCuando las redes neuronales son entrenadas, cada red crea, modifica o elimina conexiones entre los nodos con el fin de dar respuestas más acertadas ante el problema que se busca resolver.\nEn este punto una red neuronal formada por una única neurona (neurona artificial) se caracteriza por:\n\n\n\n\n\n\nUna capa de entrada que recibe los datos en bruto, es decir, el valor de los predictores.\nUna capa oculta que recibe los valores de la capa de entrada, ponderados por los pesos.\nUna capa de salida que combina los valores que salen de la capa intermedia y cuya información se propaga a otra capa si la función de activación así lo determina.\n\nLas funciones de activación convierten el valor neto de entrada en un nuevo valor, combinación de los input, pesos y bias. Es gracias a combinar funciones de activación no lineales con múltiples capas que los modelos de redes son capaces de aprender relaciones no lineales. La gran mayoría de funciones de activación convierten el valor de entrada neto de la neurona en un valor dentro del rango (0, 1) o (-1, 1). Cuando el valor de activación de una neurona (salida de su función de activación) es cero, se dice que la neurona está inactiva, ya que no pasa ningún tipo de información a las siguientes neuronas.\nEl modelo de red neuronal con una única capa (single-layer perceptron), aunque supuso un gran avance en el campo del Machine Learning, solo es capaz de aprender patrones sencillos. Para superar esta limitación, los investigadores descubrieron que, combinando múltiples capas ocultas, la red puede aprender relaciones mucho más complejas entre los predictores y la variable respuesta. A esta estructura se le conoce como perceptrón multicapa o multilayer perceptron (MLP), y puede considerarse como el primer modelo de Deep Learning.\nLa estructura de un perceptón multicapa consta de varias capas de neuronas ocultas. Cada neurona está conectada a todas las neuronas de la capa anterior y a las de la capa posterior. Aunque no es estrictamente necesario, todas las neuronas que forman parte de una misma capa suelen emplear la misma función de activación.\nCombinando múltiples capas ocultas y funciones de activación no lineales los modelos de redes pueden aprender prácticamente cualquier patrón. De hecho, está demostrado que, con suficientes neuronas, un MLP es un aproximador universal para cualquier función. A continuación, se muestra la estructura de un MLP con tres capas ocultas con 6, 6, y 8 neuronas en cada una de ellas y con cuatro capas de salida o valores de predicción de la red:"
  },
  {
    "objectID": "10_IntroDL.html#tipos-redes-neuronales",
    "href": "10_IntroDL.html#tipos-redes-neuronales",
    "title": "1  Introducción",
    "section": "1.2 Tipos redes neuronales",
    "text": "1.2 Tipos redes neuronales\nDentro de las redes neuronales encontramos diferentes tipos, distinguiéndose estos por sus características y aplicaciones particulares. A continuación, detallamos las que vamos a desarrollar en próximos cuadernos:\n\nRedes neuronales monocapa. También conocidas como perceptrones simples, son las redes neuronales más simples y están compuestas por una única capa de neuronas que realizan una combinación lineal sobre las entradas. Una vez modificadas, las trasladan a una capa de neuronas de salida donde se aplica una función de activación para generar una salida. Este tipo de redes se utilizan cuando se pretende realizar una clasificación binaria o linealmente separable.\n\n\n\n\n\n\n\nRedes neuronales multicapa. Son una generalización de las anteriores, compuestas por dos o más capas de neuronas. En estas se introducen las capas ocultas, las cuales permiten que la red neuronal aprenda características más complejas de los datos de entrada y se combinan con la capa de entrada y la capa de salida para formar una arquitectura de red más compleja. En este caso no podemos especificar una aplicación concreta, pues se utilizan en una amplia variedad de aplicaciones en diversas áreas.\n\n\n\n\n\n\n\nRedes neuronales convolucionales (CNN). Son una variante de las redes neuronales multicapa en las que cada neurona no se une con todas y cada una de las capas siguientes, sino que solo lo hace con un subgrupo de estas. Con esto se consigue reducir el número de neuronas y la complejidad computacional necesarias para su ejecución. Se utilizan para tareas de clasificación y detección de objetos en imágenes.\nRedes neuronales recurrentes (RNN). Son redes neuronales que no tienen la típica estructura de capas, sino que permiten conexiones arbitrarias entre las neuronas, incluso pudiendo crear ciclos. Esto les permite tener memoria y retroalimentación de información, lo que las hace útiles en tareas que requieren un contexto o una memoria de largo plazo. Son especialmente útiles en tareas que involucren secuencias de datos, como el procesamiento del lenguaje natural y el reconocimiento de voz.\n\n\n\n\n\n\n\nRedes neuronales de base radial (RBF). Son redes neuronales multicapa que utilizan funciones radiales para calcular la distancia entre los datos y un conjunto de puntos denominados centros. La salida proporcionada consiste en una combinación lineal de las funciones de activación radiales utilizadas por las neuronas de manera individual. Se utilizan comúnmente en tareas de regresión y clasificación, siendo especialmente adecuadas en problemas de alta dimensionalidad."
  },
  {
    "objectID": "10_IntroDL.html#terminología-básica",
    "href": "10_IntroDL.html#terminología-básica",
    "title": "1  Introducción",
    "section": "1.3 Terminología básica",
    "text": "1.3 Terminología básica\n\nNeurona o perceptrón: unidad básica de procesamiento en una red neuronal que procesa información mediante la aplicación de pesos y umbrales o sesgos para producir una salida.\nCapa: conjunto de neuronas que procesan la información de entrada y realizan una transformación no lineal para extraer características relevantes que sean útiles para la tarea que se esté abordando. En una red neuronal profunda distinguimos tres tipos de capas, las de entrada, las ocultas y las de salida, cumpliendo cada una su función específica en el procesamiento de la información.\nFunción de activación: función que se aplica a la salida de una neurona o de un conjunto de neuronas y transmite la información generada por la combinación lineal de los pesos y las entradas. Esto permite que la red pueda aprender y modelar relaciones entre los datos de entrada y la salida deseada.\nPesos: parámetros ajustables que se utilizan en una red neuronal para transformar las entradas en salidas. Se utilizan para ponderar la importancia de cada entrada en la salida de la neurona y, durante el entrenamiento de la red, se ajustan mediante un algoritmo de optimización para minimizar la función de pérdida.\nÉpoca: ciclo completo a través de todo el conjunto de datos de entrenamiento a través de una red neuronal. Durante una época, la red neuronal procesa las entradas de entrenamiento y ajusta los pesos correspondientes.\nCaracterística: representación numérica de una variable, imagen, texto, sonido u otro tipo de dato. Se utiliza como entrada, y su objetivo es capturar información relevante y discriminativa que permita al modelo realizar una tarea específica.\nBatch o lote: cantidad de datos que se utilizan para entrenar una red neuronal en cada iteración de aprendizaje."
  },
  {
    "objectID": "10_IntroDL.html#el-perceptrón-lineal",
    "href": "10_IntroDL.html#el-perceptrón-lineal",
    "title": "1  Introducción",
    "section": "1.4 El perceptrón lineal",
    "text": "1.4 El perceptrón lineal\nAntes de profundizar más en el proceso de entrenamiento de una red neuronal, que trataremos en los temas siguientes, vamos a ver cómo la neurona artificial definida anteriormente se puede utilizar como un clasificador binario. Distinguimos dos situaciones:\n\nse conoce de partida la regla de clasificación,\nno se conoce de partida la regla de clasificación.\n\n\n1.4.1 Regla conocida\nPara empezar, generamos 100 datos de entrenamiento como puntos aleatorios en un cuadrado unidad. Así, las coordenadas del punto \\(x_1\\) y \\(x_2\\) se toman en el intervalo \\([0,1]\\). Definimos dos categorías: una para los puntos situados por encima de la línea \\(x_1=x_2\\) y otra para los puntos situados por debajo. Durante la generación, comprobamos si \\(x_2 > x_1\\) o no, y asignamos una etiqueta 1 o 0 en función de que se cumpla la condición de clasificación establecida. Estas etiquetas son las respuestas “verdaderas” de la clasificación.\nPara la regla de clasificación establecida tenemos por tanto que:\n\\[x_2 > x_1 \\rightarrow s=-x_1+x_2>0\\]\nque en términos de una neurona artificial con función de activación de salto nos proporciona los pesos:\n\\[w_0 = -b = 0, w_1 = -1, w_2 = 1\\]\n\n# Valores simulados\nx1 = runif(100, 0, 1)\nx2 = runif(100, 0, 1)\nx = cbind(x1, x2)\n\n# Parámetros de la neurona \nw = c(-1, 1)\nb = 0\n\n# Valores de activación\nvalor = c()\nfor (i in 1:length(x1))\n{\n  valor[i] = neurona(x[i,], w, b)\n}\n# Resultado\ndf = data.frame(x1=x1,x2=x2,activ=as.factor(valor))\n\nVeamos la representación gráfica de los puntos junto con el valor de activación. Además añadimos la recta que determina la regla de clasificación.\n\nggplot(df, aes(x1,x2,color=activ)) + \n  geom_point() +\n  geom_abline(intercept = 0, slope = 1) +\n  labs(color = \"Activación\") +\n  scale_color_discrete(labels=c(\"No\", \"Si\")) \n\n\n\n\nClasificación binaria lineal\n\n\n\n\nComo era de esperar la neurona artificial proporciona el resultado adecuado en términos de la regla de clasificación dado que las muestras son separables linealmente. El problema aparece cuando queremos resolver el problema de clasificación de dos clases cuando estas no son separables linealmente como podemos ver en la imagen siguiente donde introducimos los hiperplanos de separación \\(x_2=x_1\\) y \\(x_2=0.1*x_1+0.5\\), es decir la regla de clasificación vieen dada por la combinación de las regiones que determinan los hiperplanos.\n\n# Valores simulados\nx1 = runif(100, 0, 1)\nx2 = runif(100, 0, 1)\nx = cbind(x1, x2)\n\n# Valores de activación en función d elas regiones definidas\nvalor = 1*((x2>x1) & (x2>0.1*x1+0.5))\n# Resultado\ndf = data.frame(x1=x1,x2=x2,activ=as.factor(valor))\n# Grafico\nggplot(df, aes(x1,x2,color=activ)) + \n  geom_point() +\n  geom_abline(intercept = 0, slope = 1) +\n  geom_abline(intercept = 0.5, slope = 0.1) +\n  labs(color = \"Activación\") +\n  scale_color_discrete(labels=c(\"No\", \"Si\")) \n\n\n\n\nClasificación binaria no lineal\n\n\n\n\nEste problema se puede resolver fácilmente si consideramos que una parte de los datos son separados por una neurona y otra parte por otra, y así sucesivamente hasta conseguir separar los dos grupos de la forma más precisa posible. Podemos establecer tantas neuronas como sean necesarias para tener en cuenta todas las posibles ecuaciones lineales necesarias para separar los datos de ambas muestras.\nImaginemos ahora que tenemos más condiciones de este tipo: dos, tres, etc., en general \\(k\\) condiciones independientes. Tomando una conjunción de estas condiciones podemos construir regiones como se muestra, por ejemplo, en la figura siguiente:\n\n\n\n\n\nque no son más que regiones convexas en el plano obtenidas, de izquierda a derecha, con una condición de desigualdad, y una conjunción de 2, 3 o 4 condiciones de desigualdad, obteniéndose polígonos con las dos últimas. Claramente \\(k\\) condiciones de desigualdad se pueden imponer con \\(k\\) neuronas artificiales.\nEn la situación del ejemplo anterior utilizando la función de activación de salto tendríamos dos neuronas:\n\nNeurona 1 con pesos \\(w_0 =0, w_1=-1, w_2=1\\)\n\nNeurona 2 con pesos \\(w_0 =-0.5, w_1=-0.1, w_2=1\\)\n\nAhora sólo nos resta combinar la información de esas dos neuronas en una tercera para deteminar la clasificación de cada punto. Esta neurona final actúa como un operador lógico con cuatro posibilidades en función de la activación o no activación de las dos primeras neuronas. Podemos considerar esta neurona 3 con pesos \\(w_0=1.5, w_1=1, w_2=1\\) para reflejar el hecho de que combinamos las dos anteriores y que sólo una de las cuatro opciones lógicas nos activará esta última neurona. Las situaciones lógicas son:\n\nNo se activa la neurona 1 ni la neurona 2.\nSe activa la neurona 1 y no se activa la neurona 2.\nNo se activa la neurona 1 y se activa la neurona 2.\nSe activan ambas neuronas.\n\nSe pude crear ahora un función que evalué de acuerdo al algoritmo establecido con las dos neuronas construyendo así nuestra primera red neuronal.\nLas arquitecturas de redes para \\(k\\) = 1, 2, 3 ó 4 condiciones se muestran en la figura siguiente. Yendo de izquierda a derecha desde el segundo panel, tenemos redes con dos capas de neuronas y con neuronas en la capa intermedia, que proporcionan las condiciones de desigualdad, y una neurona en la capa de salida (ya que sólo debemos clasificar en dos grupos).\n\n\n\n\n\nEn la interpretación geométrica, la primera capa de neuronas representa los \\(k\\) semiplanos, y la neurona de la segunda capa corresponde a una región convexa con \\(k\\) lados. La situación se generaliza de forma obvia a los datos en más dimensiones. En ese caso tenemos más puntos negros en las entradas de la figura anterior. Geométricamente, para \\(n=3\\) tratamos con planos divisorios y poliedros convexos, y para \\(n>3\\) con hiperplanos divisores y polítopos convexos.\n\n\n1.4.2 Regla desconocida\nLlegados a este punto, puede parecer que los resultados que hemos obtenido en el punto anterior son bastante triviales. Esto se debe a que conocíamos la regla de clasificación y por tanto era posible obtener los pesos asociados con la neurona de la red. En situaciones reales disponemos de los datos de entrada pero se desconocen la regla o reglas de clasificación. En otras palabras, necesitamos encontrar la regla o reglas de clasificación correspondientes, lo que equivale a encontrar los pesos de las neuronas artificiales consideradas que nos permitan una mejor clasificación.\nEn el punto siguiente vemos el proceso de estimación de los pesos de la neurona artificial para el problema de clasificación binaria con una única neurona artificial. En próximos temas veremos como estimar los pesos en estructuras de redes con capas ocultas y donde incorporamos más de una neurona.\n\n1.4.2.1 Algoritmo perceptrón\nLa solución para el problema de clasificación binario pasa por disponer de un procedimiento algorítmico sistemático que funcione sin esfuerzo para ésta y cualquier otra situación similar. La respuesta es el ya mencionado algoritmo del perceptrón.\nEn la situación del ejemplo anterior, y antes de presentar el algoritmo de estimación de los pesos, observemos que la neurona artificial con algún conjunto de pesos \\(w_0, w_1,w_2\\) siempre da alguna respuesta para un punto de datos etiquetado, correcta o incorrecta. Consideramos el conjunto de datos inicial y vemos qué clasificación obtenemos cuando fijamos unos pesos que no se corresponden con los correspondientes con la regla de clasificación.\nLa idea general del algortimo perceptrón es utilizar las respuestas erróneas para ajustar inteligentemente, en pequeños pasos, los pesos, de forma que después de un número suficiente de iteraciones obtengamos todas las respuestas correctas para la muestra de entrenamiento.\nLa base del algoritmo (que estudiaremos con más detalle en el próximo cuaderno) se basa en el método del descenso del gradiente y viene dado por el siguiente proceso iterativo:\n\nSe hace una primera iteración con los pesos iniciales y se obtiene la clasificación con ellos.\nSi para un punto dado el resultado obtenido \\(y_0\\) es igual al valor verdadero \\(y_t\\) (la etiqueta), es decir, la respuesta es correcta, no hacemos nada. Sin embargo, si es incorrecta, cambiamos un poco los pesos, de forma que disminuya la probabilidad de obtener una respuesta errónea. Si consideramos \\(\\epsilon\\) (tasa de aprendizaje) como un valor pequeño que debemos fijar al inicio, y \\(x_i\\) como los inputs de la muestra \\(i\\) con \\(i=1,...,n\\).valor pequeño, entonces la regla iterativa viene dada por:\n\n\\[w_i \\rightarrow w_i + \\epsilon(y_t-y_0)x_i,\\]\n\nEl proceso se detiene cuando la diferencia de los pesos entre dos iteraciones seguidas está por debajo de un umbral prefijado.\n\nVeamos como funciona el algoritmo en la práctica. Supongamos que \\(x_i >0\\). Si la etiqueta predicha para dicha muestra es \\(y_t = 1\\) mientras que la etiqueta original era \\(y_0=0\\), el peso \\(w_i\\) se incrementa. Entonces \\(wx\\) se incrementa e \\(y_0=f(wx)\\) está más cerca de obtener el verdadero valor de 1 (ya que estamos utilizando la función de salto). Por otro lado, si la etiqueta \\(y_t=0\\) es menor que la respuesta encontrada \\(y_0=1\\), entonces el peso \\(w_i\\) decrece mientras que \\(wx\\) crece, e \\(y_0=f(wx)\\) esta más cerca de obtener el verdadero valor de 0. Si \\(x_i < 0\\) podemos ver que el funcionamiento es análogo. Cuando la respuesta es correcta, \\(y_t =y_0\\) entonces no es necesario cambiar los pesos.\nLa fórmula anterior puede utilizarse muchas veces para el mismo punto de la muestra de entrenamiento. A continuación, hacemos un bucle sobre todos los puntos de la muestra, y todo el procedimiento se puede seguir repitiendo en muchas rondas para obtener pesos estables (que no cambien más a medida que continuamos el procedimiento, o que cambien ligeramente).\nNormalmente, en este tipo de algoritmos la velocidad de aprendizaje \\(\\epsilon\\) disminuye en las rondas sucesivas. Esto es técnicamente muy importante, porque unas actualizaciones demasiado grandes podrían estropear la solución obtenida.\nGráficamente podemos ver el funcionamiento del algoritmo:"
  },
  {
    "objectID": "20_TrainDL.html#preprocesado-de-inputs",
    "href": "20_TrainDL.html#preprocesado-de-inputs",
    "title": "2  Entrenamiento de la red neuronal",
    "section": "2.1 Preprocesado de inputs",
    "text": "2.1 Preprocesado de inputs\nA la hora de entrenar modelos basados en redes neuronales es necesario realizar, al menos, dos tipos de transformaciones de los datos. Procedemos igual que en cualquier otro algoritmo de aprendizaje automático.\nCodificación (One hot ecoding) de las variables categóricas\nLa binarización (one-hot-encoding) consiste en crear nuevas variables dummy con cada uno de los niveles de las variables cualitativas. Por ejemplo, una variable llamada color que contenga los niveles rojo, verde y azul, se convertirá en tres nuevas variables (color_rojo, color_verde, color_azul), todas con el valor 0 excepto la que coincide con la observación, que toma el valor 1.\nEstandarización y escalado de variables numéricas\nCuando los predictores son numéricos, la escala en la que se miden, así como la magnitud de su varianza, pueden influir en gran medida en el modelo. Si no se igualan de alguna forma los predictores, aquellos que se midan en una escala mayor o que tengan más varianza dominarán el modelo aunque no sean los que más relación tengan con la variable respuesta. Existen principalmente dos estrategias para evitarlo:\n\nCentrado: consiste en restarle a cada valor la media del predictor al que pertenece. Si los datos están almacenados en un dataframe, el centrado se consigue restándole a cada valor la media de la columna en la que se encuentra. Como resultado de esta transformación, todos los predictores pasan a tener una media de cero, es decir, los valores se centran en torno al origen.\nNormalización (estandarización): consiste en transformar los datos de forma que todos los predictores estén aproximadamente en la misma escala. Las dos opciones habituales son:\n\nNormalización Z-score (StandardScaler): dividir cada predictor entre su desviación típica después de haber sido centrado, de esta forma, los datos pasan a tener una distribución normal.\nEstandarización max-min (MinMaxScaler): transformar los datos de forma que estén dentro del rango [0, 1]."
  },
  {
    "objectID": "20_TrainDL.html#funciones-de-activación",
    "href": "20_TrainDL.html#funciones-de-activación",
    "title": "2  Entrenamiento de la red neuronal",
    "section": "2.2 Funciones de activación",
    "text": "2.2 Funciones de activación\nComo ya vimos en el tema anterior, las funciones de activación controlan en gran medida qué información se propaga desde una capa a la siguiente (forward propagation). Estas funciones convierten el valor neto de entrada a la red neuronal, combinación de los inputs, pesos y sesgos, en un nuevo valor. En el cuaderno anterior ya vimos el comportamiento de la función de activación de salto, pero no es la única existente. En concreto, el uso de funciones de activación no lineales con múltiples capas es lo que permite que los modelos de redes sean capaces de aprender relaciones no lineales.\nLa gran mayoría de funciones de activación convierten el valor de entrada neto de la neurona en un valor dentro del rango (0, 1) o (-1, 1). Cuando el valor de activación de una neurona (salida de su función de activación) es cero, se dice que la neurona está inactiva, ya que no pasa ningún tipo de información a las siguientes neuronas. A continuación, se describen las funciones de activación más empleadas así como la derivada de dicha función que será utilizada en el proceso de entrenamiento de la red.\n\n2.2.1 Sigmoide\nLa función de activación sigmoide acepta un número como entrada y devuelve un número entre 0 y 1. Es fácil de usar y tiene todas las cualidades deseables de las funciones de activación: no linealidad, diferenciación continua, monotonicidad y un rango de salida establecido.\nSe utiliza principalmente en problemas de clasificación binaria, ya que su salida puede interpretarse como probabilidades, ya que nos proporciona la probabilidad de existencia de una clase determinada. Matemáticamente se define como:\n\\[sigmoid(s) = S(s) = \\frac{1}{1+e^{-s}}.\\] La derivada de la función viene dada por la expresión:\n\\[S'(s) = S(s)(1-S(s))\\]\nEntre las ventajas y desventajas del uso de esta función podemos mencionar:\n\nEs de naturaleza no lineal. Las combinaciones de esta función también son no lineales, y dará una activación analógica, a diferencia de la función de activación de salto. Además, esta función presenta un gradiente suave y es efectiva para el problema de clasificación.\nEl resultado de la función de activación siempre va a estar en el rango \\((0,1)\\) en comparación con \\((-∞, ∞)\\) de la función de activación lineal. Como resultado, hemos definido un rango para nuestras activaciones.\nLa función sigmoide da lugar a un problema de “gradientes evanescentes” (“Vanishing gradients”) y los sigmoides saturan y matan los gradientes. El problema de “gradientes evanescentes” es frecuente en el entrenamiento de redes neuronales. Dado que la función de activación tiene un rango de salida pequeño (de 0 a 1), un gran cambio en el input de la función de activación creará una pequeña modificación en la salida. Por lo tanto, la derivada también se vuelve pequeña. Estas funciones de activación sólo se utilizan en redes poco profundas con pocas capas. Cuando estas funciones de activación se aplican a una red multicapa, el gradiente puede llegar a ser demasiado pequeño para el entrenamiento esperado.\nSu resultado no está centrado en cero, y hace que las actualizaciones del gradiente fluctúen lejos en diferentes direcciones.\nEl valor de salida está entre cero y uno, por lo que dificulta la optimización.\nEn ocasiones la red se niega a aprender más o es extremadamente lenta.\n\n\n\n2.2.2 Tangente hiperbólica\nLa función tangente hiperbólica comprime un número real al rango [-1, 1]. Es no lineal, pero es diferente de la anterior (Sigmoid), y su salida está centrada en cero. Su definición formal es:\n\\[TanH(s) = \\frac{e^s-e^{-s}}{e^s+e^{-s}}\\]\nLa ventaja que tiene esta función de activación es que los inputs negativos se convierten en valores fuertemente negativos y los inputs positivos se convierten en valores fuertemente positivos. Los resultados tienden a los extremos. Al igual que en la función sigmoide, es diferenciable y monótona mientras que su derivada no lo es. Esta función de activación se utiliza principalmente para la clasificación entre dos clases, ya que si la tendencia es hacia uno de los lados la función lo arrastrará más aún para ese lado.\nLa derivada de la función viene dada por la expresión:\n\\[TanH'(s) = 1-Tanh^2(s)\\] Entre sus ventajas e inconvenientes podemos destacar:\n\nTanH también tiene el problema del gradiente evanescente, pero el gradiente es más fuerte en TanH que en sigmoide (las derivadas son más pronunciadas).\nTanH está centrada en cero, y los gradientes no tienen que moverse en una dirección específica.\n\n\n\n2.2.3 ReLU (Rectified linear Unit)\nReLU significa Unidad Lineal Rectificada y es una de las funciones de activación más utilizadas en las aplicaciones. Ha resuelto el problema del gradiente evanescente porque el valor máximo del gradiente de la función ReLU es uno. También resuelve el problema de la saturación de la neurona, ya que la pendiente nunca es cero para la función ReLU. El rango de ReLU está entre 0 e infinito.\nFormalmente se define como:\n\\[ReLU(s) = max\\{0,s\\}\\]\n¿Cuál es la diferencia de esta función con la de salto que la hace tan interesante? La clave está en que todos los valores negativos se vuelven cero, y eso significa que cualquier entrada negativa dada a la función de activación de ReLU convierte el valor en cero inmediatamente. Esto puede ayudar mucho en la simplificación computacional ya que todos los valores iguales a 0 son inmediatamente descartados (dichas neuronas son irrelevantes). A su vez esto puede disminuir la capacidad del modelo para ajustarse o entrenarse a partir de los datos correctamente. Es el motivo por el que su uso esta muy extendido en las redes convolucionales.\nEn este caso la derivada de la función ReLU toma el valor 1 si \\(s>0\\) y \\(0\\) en otro caso.\nEntre las ventajas e incovenientes de esta función podemos destacar:\n\nDado que sólo se activa un cierto número de neuronas, la función ReLU es mucho más eficiente desde el punto de vista computacional que las funciones sigmoide y TanH.\nReLU acelera la convergencia del descenso gradiente hacia el mínimo global de la función de pérdida gracias a su propiedad lineal y no saturante.\nUna de sus limitaciones es que sólo debe utilizarse dentro de las capas ocultas de un modelo de red neuronal artificial.\nAlgunos gradientes pueden ser frágiles durante el entrenamiento. En otras palabras, para activaciones en la región (\\(x<0\\)) de ReLU, el gradiente será 0 debido a lo cual los pesos no se ajustarán durante el descenso. Es decir, las neuronas que entren en ese estado dejarán de responder a las variaciones en la entrada (simplemente porque el gradiente es 0, nada cambia). A esto se le llama el problema del ReLU moribundo.\n\n\n\n2.2.4 Softmax\nLa función Softmax es una de las funciones estrella en la última capa de la red, ya que permite realizar una clasificación categórica multiclase.\nEs una combinación de muchos sigmoides. Al igual que la función sigmoide, devuelve una probabilidad, sólo que en este caso lo hace para cada clase/etiqueta. Más concretamente la función Softmax devuelve la probabilidad de la clase actual con respecto a las demás. Esto significa que también tiene en cuenta la posibilidad de que existan otras clases.\nSi \\(s_i\\) donde \\(i\\) identifica la clase \\(i\\) de un conjunto de \\(k\\) clases esta función se puede expresar como:\n\\[Softmax(s_i) = \\frac{exp(s_i)}{\\sum_{j=1}^k exp(s_j)}\\]\nEntre las ventajas e inconvenientes podemos destacar que:\n\nImita mejor la etiqueta codificada que los valores absolutos.\nSe perdería información si se utilizaran valores absolutos (módulo), pero la exponencial se encarga de esto por sí sola.\nDebería utilizarse también para tareas de clasificación y regresión multietiqueta.\n\n\n\n2.2.5 Otras funciones de activación\nExisten más funciones de activación pero hemos preferido centrarnos en estas porque son las de uso más habitual. Más adelante introduciremos nuevas funciones de activación cuando sea necesario."
  },
  {
    "objectID": "20_TrainDL.html#funciones-de-pérdida",
    "href": "20_TrainDL.html#funciones-de-pérdida",
    "title": "2  Entrenamiento de la red neuronal",
    "section": "2.3 Funciones de pérdida",
    "text": "2.3 Funciones de pérdida\nCuando se trabaja en un problema de aprendizaje automático o aprendizaje profundo se utilizan funciones de pérdida/coste para optimizar el modelo durante el entrenamiento. El objetivo es casi siempre minimizar la función de pérdida. Cuanto menor sea la pérdida, mejor será el modelo. En las redes neuronales este aspecto resulta muy relevante ya que la predición o salida de la red depende de la estructura de la red (nodos y capas ocultas). En este apartado se presenta la notación y las funciones utilizadas en las redes neuronales tanto para las tareas de clasificación como de regresión.\nPara ejemplificar supongamos que tenemos una red con una arquitectura \\([p,m,1]\\), es decir con \\(p\\) inputs, \\(m\\) neuronas artificiales en una única capa, y un nodo de salida. Consideramos:\n\n\\((X,y)\\) el conjunto de valores (inputs y respuesta) observados para \\(n\\) muestras, de forma que \\(x^{(i)}\\) e \\(y^{(i)}\\) son los inputs y respuesta de la muestra \\(i\\) con \\(i=1,...,n\\).\n\\(W\\) la matriz de pesos de la red.\n\\(f\\) la función de activación utilizada para obtener la respuesta para un input dado como\n\n\\[\\hat{y}^{(i)} = f(x^{(i)};W)\\]\nDefinimos entonces la función de pérdida (\\(L\\)) para una muestra específica como\n\\[L(\\hat{y}^{(i)}, y^{(i)})= L(f(x^{(i)};W), y^{(i)})\\]\nde forma que la pérdida empírica para el conjunto de muestras dado viene dada para una matriz de pesos \\(W\\) como\n\\[J(W)=\\frac{1}{n} \\sum_{i=1}^n L(f(x^{(i)};W), y^{(i)})\\]\nA continuación, veremos la expresión específica para la pérdida empírica en función del tipo de repuesta que tratamos de predecir con la red o tipo de tarea que deseamos resolver: clasificación binaria, regresión o clasificación múltiple.\n\n2.3.1 Clasificación binaria\nPara tareas de clasificación binaria donde la respuesta observada \\(y^{(i)}\\) para cada una de las muestras consideradas sólo toma valores 0 o 1, se define la pérdida de entropía cruzada binaria (“Binary Cross-Entropy”) como:\n\\[\\begin{eqnarray}\nJ(W) =&-\\frac{1}{n}\\sum_{i=1}^n \\left [ y^{(i)}log(f(x^{(i)};W)) + (1-y^{(i)})log(1-f(x^{(i)};W))\\right ]\\\\\n=&-\\frac{1}{n}\\sum_{i=1}^n \\left [ y^{(i)}log(p^{(i)}) + (1-y^{(i)})log(1-p^{(i)})\\right ]\n\\end{eqnarray}\\]\ndonde \\(p^{(i)} = f(x^{(i)};W)\\) es la probabilidad predicha de clasificación de la clase 1 mediante la red neuronal considerada con pesos estimados \\(W\\).\nLa principal ventaja de esta función de pérdida es que es diferenciable, pero entre las deventajas debemos destacar que tiene múltiples mínimos locales y que no es una medida de error muy intuitiva.\n\n\n2.3.2 Clasificación múltiple\nPara tareas de clasificación múltiple donde la respuesta observada \\(y^{(i)}\\) para cada una de las muestras consideradas puede tomar valores en el conjunto \\(\\{1, 2,...,M\\}\\), se define la pérdida de entropía cruzada binaria para clasificaciones múltiples (“Binary Cross Entropy for Multi-Class classification”) como:\n\\[\\begin{eqnarray}\nJ(W) =&-\\frac{1}{n}\\sum_{i=1}^n \\sum_{j=1}^M \\left [ y^{(i,j)}log(f(x^{(i)};W)) \\right ]\\\\\n&-\\frac{1}{n}\\sum_{i=1}^n \\sum_{j=1}^M \\left [ y^{(i,j)}log(p^{(i,j)}) \\right ]\n\\end{eqnarray}\\]\ndonde \\(y^{(i,j)}\\) es el elento \\(j\\) del vector \\((y^{(i,1)}, y^{(i,2)},..., y^{(i,M)})\\) que representa la codificación hot-encoding para la respuesta \\(y^{(i)}\\), y \\(p^{(i,j)}\\) representa la probabilidad predicha por la red neuronal de que la muestra \\(i\\) pertenezca a la clase \\(j\\).\n\n\n2.3.3 Predicción\nEn tareas de predicción podemos considerar diferentes funciones de pérdida.\n\n2.3.3.1 Error cuadrático medio\nEl error cuadrático medio o mean squared error (MSE) es la función de pérdida más sencilla y común para evaluar la solución obtenida en una tarea de predicción. Si \\(y^{(i)}\\) denota el valor real de la repuesta e \\(\\hat{y}^{(i)}\\) el valor predicho mediante la red considerada con pesos W, para calcular el MSE, se toma la diferencia entre el valor real y la predicción del modelo, se eleva al cuadrado y se calcula la media de todo el conjunto de datos:\n\\[\\begin{eqnarray}\nJ(W) =&-\\frac{1}{n}\\sum_{i=1}^n \\left ( y^{(i)}-f(x^{(i)};W) \\right )^2\\\\\n&-\\frac{1}{n}\\sum_{i=1}^n \\left ( y^{(i)}-\\hat{y}^{(i)} \\right )^2\n\\end{eqnarray}\\]\nLas principales ventajas de esta función de pérdida son que es muy fácil de interpretar, siempre es diferenciable y sólo tiene un mínimo local. Entre las desventajas podemos decir que el error está en unidades al cuadrado, y que es muy sensible a la presencia de observaciones anómalas.\n\n\n2.3.3.2 Error absoluto medio\nEl error absoluto medio o mean absolute error (MAE) es otra función de pérdida muy sencilla. Si \\(y^{(i)}\\) denota el valor real de la repuesta e \\(\\hat{y}^{(i)}\\) el valor predicho mediante la red considerada con pesos W, para calcular el MAE, se toma la diferencia en valor absoluto entre el valor real y la predicción del modelo, promediando para todo el conjunto de datos:\n\\[\\begin{eqnarray}\nJ(W) =&-\\frac{1}{n}\\sum_{i=1}^n  \\left |y^{(i)}-f(x^{(i)};W) \\right |\\\\\n&-\\frac{1}{n}\\sum_{i=1}^n \\left | y^{(i)}-\\hat{y}^{(i)} \\right |\n\\end{eqnarray}\\]\nLas principales ventajas de esta función de pérdida son que su resultado está en las mismas unidades que la variable respuesta, y que es insensible a observaciones anómalas. La principal desventaja es que la función de pérdida no es diferenciable y no se puede utilizar directamente en procesos de optimización."
  },
  {
    "objectID": "20_TrainDL.html#proceso-de-optimización",
    "href": "20_TrainDL.html#proceso-de-optimización",
    "title": "2  Entrenamiento de la red neuronal",
    "section": "2.4 Proceso de optimización",
    "text": "2.4 Proceso de optimización\nComo hemos visto en el punto anterior todas las funciones de pérdida dependen de los valores de los pesos \\(W\\) de la arquitectura de red considerada. Por tanto, para optimizar la arquitectura de dicha red es necesario obtener los valores de \\(W\\) que minimicen el error de predicción o clasificación dependiendo de la tarea de interés. En el cuaderno siguiente estudiaremos con detalle los algoritmos de optimización utilizados habitualmente, pero en este presentanmos las ideas generales. Distinguimos entre arquitecturas de redes con una única capa y otras con múltiples capas ocultas.\n\n2.4.1 Arquitectura de red con una capa oculta\nSupongamos que disponemos de \\(n\\) muestras con una arquitectura de red \\([p,m,1]\\) con matriz de datos \\((X,y)\\), \\(W\\) matriz de pesos, y \\(f\\) la función de activación. Independientemente de si la tarea es de clasificación o predicción, para obtener los valores óptimos de la matriz de pesos de la red, \\(W^*\\), debemos minimizar la función de pérdida empírica considerada con respecto a \\(W\\), es decir:\n\\[W^* = \\underset{W}{argmin} \\quad J(W)\\]\n\\[W^* = \\underset{W}{argmin} \\quad \\frac{1}{n} L(f(x^{(i)};W),y^{(i)})\\]\nPor tanto, para encontrar el óptimo queda claro que necesitamos la derivadas de la función de activación considerada.\n\n\n2.4.2 Arquitectura de red con múltiples capas ocultas\nSi tenemos una arquitectura de red con múltiples capas ocultas la matriz de pesos se organiza para las diferentes capas consideradas, es decir consideramos:\n\\[W = \\{W^{(0)}, W^{(1)},...\\}\\]\ndonde \\(W^{(i)}\\) es la matriz de pesos correspondiente a la capa oculta \\(i+1\\). Recordemos que el proceso de propagación hacia adelante utiliza la salida de una capa oculta para valorar la activación de la capa siguiente en función de los pesos de dicha capa. En esta situación el proceso de optimización viene dado por:\n\\[W^* = \\underset{W}{argmin} \\quad J(W)\\]\n\\[W^* = \\underset{W}{argmin} \\quad \\frac{1}{n} L(f(x^{(i)};W),y^{(i)})\\]\ndonde \\(W = \\{W^{(0)}, W^{(1)},...\\}\\).\nEn este caso el proceso de optimización resulta algo más complejo, ya que debemos enlazar las derivadas de las funciones de activación en cada una de las capas ocultas para obtener los pesos de la arquitectura de la red. Es lo que denominamos como algortimo de Backpropagation para combinar el proceso de optimización de las diferentes capas, mientras que utilizamos el método del gradiente descendente para estimar los pesos de una capa en específico."
  },
  {
    "objectID": "20_TrainDL.html#algoritmo-de-backpropagation",
    "href": "20_TrainDL.html#algoritmo-de-backpropagation",
    "title": "2  Entrenamiento de la red neuronal",
    "section": "2.5 Algoritmo de backpropagation",
    "text": "2.5 Algoritmo de backpropagation\nBackpropagation es el algoritmo que permite cuantificar la influencia que tiene cada peso y bias de la red en sus predicciones. Para conseguirlo, hace uso de la regla de la cadena (chain rule) para calcular el gradiente, que no es más que el vector formado por las derivadas parciales de una función.\nEn el caso de las redes, la derivada parcial del error respecto a un parámetro (peso o bias) mide cuanta “responsabilidad” ha tenido ese parámetro en el error cometido. Gracias a esto, se puede identificar qué pesos de la red hay que modificar para mejorarla.\nDe hecho el objetivo principal de este algoritmo es encontrar las derivadas de la pérdida o el error con respecto a cada peso de la red, y actualizar estos pesos en la dirección opuesta a sus derivadas respetadas, de modo que se muevan hacia los mínimos globales o locales de la función de coste o error.\nPara entender mejor el funcionamiento de este algoritmo, y ver cómo integrar los algortimos de optimización de pesos en el proceso, presentamos su funcionamiento teórico para una arquitectura de red con una capa oculta.\nPor simplicidad consideramos la red que viene representada en la figura siguiente:\n\n\n\n\n\ndonde tenemos una red con una única capa coculta, y con función de pérdida empírica para la matriz de pesos \\(W=\\{W1,W2\\}\\) dada por \\(J(W)\\). Como ya vimos en el cuaderno anterior el objetivo es encontrar los valores de \\(W\\) que minimizan la función de pérdida. Utilizando la regla de la cadena el proceso de optimización se puede escribir como:\n\\[\\frac{\\partial J(W)}{\\partial W1} = \\frac{\\partial J(W)}{\\partial \\hat{y}} \\frac{\\partial \\hat{y}}{\\partial Z} \\frac{\\partial Z}{\\partial W1}\\]\nEste proceso se repite para cada peso de la red utilizando los gradientes de capas posteriores.\nPor tanto, para resolver el entrenamiento del modelo es necesario determinar los gradientes anteriores actualizando los pesos de cada capa de la red para reducir la función de pérdida considerada."
  },
  {
    "objectID": "20_TrainDL.html#algoritmos-de-optimización",
    "href": "20_TrainDL.html#algoritmos-de-optimización",
    "title": "2  Entrenamiento de la red neuronal",
    "section": "2.6 Algoritmos de optimización",
    "text": "2.6 Algoritmos de optimización\nLos algoritmos optimizadores son métodos de optimización que ayudan a mejorar el rendimiento de un modelo de aprendizaje profundo. Estos algoritmos de optimización u optimizadores afectan en gran medida a la precisión y la velocidad de entrenamiento del modelo de aprendizaje profundo. Pero antes de nada, surge la pregunta de qué es un optimizador.\nMientras se entrena el modelo de aprendizaje profundo los optimizadores modifican los pesos de cada iteración (epoch) y minimizan la función de pérdida. Un optimizador es una función o un algoritmo que ajusta los atributos de la red neuronal, como los pesos y las tasas de aprendizaje. De este modo, ayuda a reducir la pérdida global y a mejorar la precisión. El problema de elegir los pesos adecuados para el modelo es una tarea de enormes proporciones, ya que un modelo de aprendizaje profundo suele constar de millones de parámetros. Esto plantea la necesidad de elegir un algoritmo de optimización adecuado para su aplicación. De ahí que la comprensión de estos algoritmos de aprendizaje automático sea necesaria para los científicos de datos antes de sumergirse a fondo en este campo.\nSe pueden utilizar diferentes optimizadores en el modelo de aprendizaje automático para cambiar sus pesos y su tasa de aprendizaje. Sin embargo, elegir el mejor optimizador depende de la aplicación. Como principiante, un mal pensamiento que nos viene a la mente es que probamos todas las posibilidades y elegimos la que muestra los mejores resultados. Esto puede estar bien al principio, pero cuando se trata de cientos de gigabytes de datos, incluso una sola epoch puede llevar un tiempo considerable. Así que elegir un algoritmo al azar puede resultar en una pérdida de tiempo.\nEste apartado cubrirá varios optimizadores de aprendizaje profundo, como Gradient Descent, Stochastic Gradient Descent, Mini-Batch Gradient Descent, Adagrad, RMSProp, AdaDelta, y Adam.\nAntes de continuar, recordemos algunos términos con los que nos debemos familiarizar:\n\nEpoch (Época) - Denota el número de veces que el algoritmo se ejecuta en todo el conjunto de datos de entrenamiento.\nBatch (Lote) - Número de muestras que se tomarán para actualizar los parámetros del modelo.\nLearning rate (Tasa de aprendizaje) - Es un parámetro que proporciona al modelo una escala de cuánto deben actualizarse los pesos del modelo.\n\n\n2.6.1 Descenso del gradiente\nEl algortimo de descenso del gradiente puede considerarse como el más famoso de todos los optimizadores. En concreto permite minimizar una función haciendo actualizaciones de sus parámetros en la dirección del valor negativo de su gradiente. Aplicado a las redes neuronales y, como ya vimos en el cuaderno de introducción a las redes neuronales, este algoritmo se implementa de la forma siguiente:\n\nFijamos unos pesos inciales \\(W\\) y evaluamos la función de pérdida correspondiente.\nHasta alcanzar convergencia, es decir, hasta alcanzar un mínimo local, procedemos de la siguiente forma fijando una tasa de aprendizaje \\(\\eta\\):\n\n\nCalcular el gradiente \\(\\frac{\\partial J(W)}{\\partial W_t}\\)\nActualizar los pesos mediante la expresión siguiente y reevaluar la función de pérdida\n\n\\[ W_{t+1} = W_t - \\eta  \\frac{\\partial J(W)}{\\partial W_t}\\]\n\nUna vez alcanzada la convergencia devolvemos los pesos de la última iteración y el valor de la función de pérdida corrrespondiente.\n\nEl algoritmo de descenso del gradiente funciona bien en la mayoría de situaciones pero, sin embargo, también tiene algunos inconvenientes:\n\nEs costoso calcular los gradientes si el tamaño de los datos es enorme.\nEl descenso de gradiente funciona bien para funciones convexas, pero no sabe qué distancia recorrer a lo largo del gradiente para funciones no convexas.\nHay que fijar una tasa de aprendizaje que puede afectar en gran medida al proceso de optimización, ya que en ocasiones puede ralentizar mucho el proceso o nos puede llevar a un mínimo local que no es óptimo.\n\nLa función siguiente nos permite ver el funcionamiento del descenso del gradiente para un learning rate y función específica.\n\n# Función para visualizar el algoritmo del gradiente descendente\nver_descenso_gradiente = function(learning_rate, f)\n{\n    # Visualización gráfica del método del descenso del gradiente\n\n    # learning_rate: ratio de aprendizaje\n    # f: función a optimizar\n\n    # return: solución gráfica del algoritmo\n    \n      # Número máximo de iteraciones\n      maximum_iterations = 1000\n      # Iteración actual\n      current_iteration = 0\n      # precisión de la solución\n      precision_value=1e-6\n      previous_step_size = 0.5\n      current_x_value = 1\n      h = 0.01\n      x_iterativo=c()\n      fx_iterativo=c()\n      while((previous_step_size>precision_value) & (current_iteration<maximum_iterations))\n      {\n            previous_x_value = current_x_value\n            #versión numérica\n            gradient_of_y=(f(current_x_value + h) - f(current_x_value - h))/(2*h)\n            current_x_value = current_x_value - learning_rate * gradient_of_y\n            x_iterativo = c(x_iterativo, current_x_value)\n            previous_step_size = abs(current_x_value - previous_x_value)\n            fx_iterativo = c(fx_iterativo, f(current_x_value))\n            current_iteration = current_iteration + 1\n        }\n        x = seq(-2, 5, length=100)\n        plot(x, f(x),\"l\", xlab=\"x\",ylab=\"f(x)\", main =paste(\"LR= \",learning_rate))\n        lines(x_iterativo, fx_iterativo,col=\"red\",lwd=3)\n        points(x_iterativo, fx_iterativo,col=\"red\",pch=16)\n}\n\nVeamos si el algoritmo es capaz de llegar al mínimo de la función \\(f(x) = x^2-6x+5\\)\n\n# Definimos la función objetivo\nf1x = function(x)\n{\n  return(x*x-6*x+5)\n}\n\n# Descenso del gradiente para diferentes tasas de aprendizaje\nlr =c(1,0.9,0.5,0.1,0.01,0.001, 0.0001,0.00001)\nfor(i in 1:length(lr))\n{\n  ver_descenso_gradiente(lr[i], f1x)\n}\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nDe los resultados obtenidos podemos ver que la tasa de aprendizaje juega un papel relevante en la convergencia del algoritmo, ya que en ocasiones necesitamos las 1000 iteraciones prefijadas y no alcanzamos el óptimo, mientras que en otras situaciones con pocas iteraciones somos capaces de alcanzar el óptimo. Incluso con una función tan sencilla como esta el algoritmo muestra comportamientos inadecuados.\n\n\n2.6.2 Descenso del gradiente estocástico\nAl final de la sección anterior, vimos que utilizar el descenso de gradiente podría no ser la mejor opción para encontrar el óptimo de la función. Para abordar el problema se plantea el algoritmo del descenso de gradiente estocástico. El término estocástico proviene de la aleatoriedad en la que se basa el algoritmo. En el descenso del gradiente estocástico, en lugar de tomar todo el conjunto de datos para cada iteración, seleccionamos aleatoriamente los lotes de datos. Esto significa que sólo tomamos unas pocas muestras del conjunto de datos.\nEl procedimiento consiste en seleccionar primero los parámetros iniciales y la tasa de aprendizaje para, a continuación, barajar aleatoriamente los datos en cada iteración para alcanzar un mínimo aproximado.\nDado que no utilizamos todo el conjunto de datos, el camino que recorre el algoritmo está lleno de ruido en comparación con el algoritmo del descenso del gradiente. Por lo tanto, SGD utiliza un mayor número de iteraciones para alcanzar los mínimos locales. Al aumentar el número de iteraciones, aumenta el tiempo total de cálculo. Pero incluso después de aumentar el número de iteraciones, el coste computacional sigue siendo menor que el del optimizador de descenso del gradiente.\nA continuación vemos la estructura del algoritmo:\n\nFijamos unos pesos inciales \\(W\\) y evaluamos la función de pérdida correspondiente.\nHasta alcanzar convergencia, es decir, hasta alcanzar un mínimo local, procedemos de la siguiente forma fijando una tasa de aprendizaje \\(\\eta\\):\n\n\nElegimos aleatoriamente un punto \\(i\\) de la muestra.\nCalcular el gradiente sobre dicho punto \\(\\frac{\\partial J_i(W)}{\\partial W_t}\\)\nActualizar los pesos\n\n\\[ W_{t+1} = W_{t} - \\eta  \\frac{\\partial J_i(W)}{\\partial W_t}\\]\n\nUna vez alcanzada la convergencia devolvemos los pesos de la última iteración y el valor de la función de pérdida correspondiente.\n\n\n\n2.6.3 Descenso del gradiente por mini lotes\nEn esta variante del algortimo de descenso del gradiente, en lugar de tomar todos los datos de entrenamiento, sólo se utiliza un subconjunto del conjunto de datos para calcular la función de pérdida. Dado que utilizamos un lote de datos en lugar de todo el conjunto de datos, se necesitan menos iteraciones. Por este motivo, el algoritmo de descenso del gradiente por mini lotes es más rápido que los algoritmos de descenso del gradiente anteriores. Además es más eficiente y robusto que las variantes anteriores del descenso del gradiente. Como el algoritmo utiliza el procesamiento por lotes, no es necesario cargar todos los datos de entrenamiento en la memoria, lo que hace que el proceso sea más eficiente de implementar. Además, la función de coste del algoritmo de descenso del gradiente contiene más variabilidad que las de los algortimos anteriores pero es más suave que la del algoritmo de descenso del gradiente estocástico. Por todo ello, el descenso del gradiente por mini lotes es ideal y proporciona un buen equilibrio entre velocidad y precisión.\nOtra ventaja importante es que la estructura del algoritmo permite la paralelización de cálculos, lo que permite acelerar todavía más el proceso de aprendizaje.\nA pesar de todo, el algoritmo de descenso del gradiente por mini lotes también tiene algunas desventajas. Necesita un hiperparámetro que es el “tamaño de mini lotes”, que debe ajustarse para lograr la precisión requerida. Aunque el tamaño de lote de 32 se considera adecuado para casi todos los casos. Además, en algunos casos, resulta en una precisión final pobre. Por ello, es necesario buscar también otras alternativas.\nA continuación vemos la estructura del algoritmo:\n\nFijamos unos pesos inciales \\(W\\) y evaluamos la función de pérdida correspondiente.\nHasta alcanzar convergencia, es decir, hasta alcanzar un mínimo local, procedemos de la siguiente forma fijando una tasa de aprendizaje \\(\\eta\\):\n\n\nElegimos aleatoriamente un lote de tamaño \\(B\\) de muestras.\nCalcular el gradiente como\n\n\\[\\frac{\\partial J_i(W)}{\\partial W_t} = \\frac{1}{B} \\sum_{k=1}^B \\frac{\\partial J_k(W)}{\\partial W_t}\\]\n\nActualizar los pesos\n\n\\[ W_{t+1} = W_{t} - \\eta  \\frac{\\partial J_i(W)}{\\partial W_t}\\]\n\nUna vez alcanzada la convergencia devolvemos los pesos de la última iteración y el valor de la función de pérdida corrrespondiente.\n\n\n\n2.6.4 Descenso del gradiente adaptativo (Adagrad)\nEl algoritmo de descenso del gradiente adaptativo es ligeramente diferente de otros algoritmos de descenso del gradiente. Esto se debe a que utiliza diferentes tasas de aprendizaje para cada iteración. El cambio en la tasa de aprendizaje depende de la diferencia en los parámetros durante el entrenamiento. Cuanto más cambian los parámetros, menos cambia la tasa de aprendizaje. Esta modificación es muy beneficiosa porque los conjuntos de datos del mundo real contienen características tanto dispersas como densas. Por lo tanto, es injusto tener el mismo valor de tasa de aprendizaje para todas las características.\nEl algoritmo Adagrad utiliza la siguiente fórmula para actualizar los pesos, donde \\(\\eta_t\\) denota las diferentes tasas de aprendizaje en cada iteración, \\(\\eta\\) es la tasa de aprendizaje inicial que actúa como una constante, y \\(\\epsilon\\) es un valor positivo pequeño para evitar la división por 0:\n\\[W_t = W_{t-1} - \\alpha_t \\frac{\\partial J(W)}{\\partial W_{t-1}}\\]\n\\[\\alpha_t = \\frac{\\eta}{\\sqrt{\\eta_t + \\epsilon}}\\]\nEl algoritmo completo queda de la forma siguiente:\n\nFijamos unos pesos inciales \\(W\\), una tasa de aprendizaje \\(\\eta\\), un valor de \\(\\epsilon\\) y evaluamos la función de pérdida correspondiente.\nHasta alcanzar convergencia, es decir, hasta alcanzar un mínimo local, procedemos de la siguiente forma en cada iteración \\(t\\):\n\n\nCalcular el gradiente\n\n\\[\\frac{\\partial J(W)}{\\partial W_{t}}\\]\n\nActualizar las tasas de aprendizaje \\(\\alpha_t\\)\n\n\\[\\alpha_{t+1} = \\frac{\\eta}{\\sqrt{\\eta_t + \\epsilon}}\\]\n\nActualizar los pesos\n\n\\[ W_{t+1} = W_{t} - \\alpha_t \\frac{\\partial J(W)}{\\partial W_{t}}\\]\n\nUna vez alcanzada la convergencia devolvemos los pesos de la última iteración y el valor de la función de pérdida corrrespondiente.\n\nLa ventaja de utilizar Adagrad es que elimina la necesidad de modificar manualmente la tasa de aprendizaje. Es más fiable que los algoritmos de descenso gradiente y sus variantes, y alcanza la convergencia a mayor velocidad.\nUn inconveniente del optimizador AdaGrad es que disminuye la tasa de aprendizaje de forma agresiva y monotónica. Puede llegar un momento en que la tasa de aprendizaje sea extremadamente pequeña. Esto se debe a que los gradientes al cuadrado en el denominador siguen acumulándose y, por tanto, la parte del denominador sigue aumentando. Debido a las pequeñas tasas de aprendizaje, el modelo acaba siendo incapaz de adquirir más conocimientos y, por tanto, la precisión del modelo se ve comprometida.\n\n\n2.6.5 RMS Prop\nRMS Prop es uno de los optimizadores más populares entre los entusiastas del aprendizaje profundo. Esto se debe quizás a que no ha sido publicado pero sigue siendo muy conocido en la comunidad. RMS Prop es idealmente una extensión del trabajo RPPROP. Resuelve el problema de los gradientes variables. El problema de los gradientes es que algunos son pequeños mientras que otros pueden ser enormes. Por lo tanto, definir una única tasa de aprendizaje puede no ser la mejor idea. RPPROP utiliza el signo del gradiente, adaptando el tamaño del paso individualmente para cada peso. En este algoritmo, primero se comparan los signos de los dos gradientes. Si tienen el mismo signo, vamos en la dirección correcta, aumentando el tamaño del paso en una pequeña fracción. Si tienen signos opuestos, debemos disminuir el tamaño del paso. Entonces limitamos el tamaño del paso y ya podemos pasar a la actualización del peso.\nEl problema con RPPROP es que no funciona bien con grandes conjuntos de datos y cuando queremos realizar actualizaciones en mini lotes. Por lo tanto, lograr la robustez de RPPROP y la eficiencia de los mini-lotes simultáneamente fue la principal motivación detrás del surgimiento de RMS Prop. RMS Prop es un avance en el optimizador AdaGrad, ya que reduce la tasa de aprendizaje monotónicamente decreciente.\nEl algoritmo se centra principalmente en acelerar el proceso de optimización disminuyendo el número de evaluaciones de la función para alcanzar el mínimo local. El algoritmo mantiene la media móvil de los gradientes al cuadrado para cada peso y divide el gradiente por la raíz cuadrada del cuadrado medio. La actualización de los pesos se obtiene como:\n\\[W_{t+1} = W_{t} - \\eta_t \\frac{\\partial J(W)}{\\partial W_t}\\]\ncon\n\\[\\eta_t = \\frac{\\eta}{\\sqrt{v_{t+1}}+\\epsilon}\\]\n\\[v_{t+1} = \\alpha v_t + \\left(1-\\alpha \\left[\\frac{\\partial J(W)}{\\partial W_t}\\right]^2\\right)\\]\ndonde \\(\\eta\\) es la taza global de aprendizaje, \\(\\epsilon\\) es un valor infinitesimal (del orden de \\(10^{-7}\\) o \\(10^{-8}\\)) para evitar errores de división por cero, y \\(v_{t+1}\\) es la estimación del segundo momento.\nEn términos más sencillos, si existe un parámetro debido al cual la función de coste oscila mucho, queremos penalizar la actualización de este parámetro. Supongamos que ha construido un modelo para clasificar una variedad de peces. El modelo se basa principalmente en el factor “color” para diferenciar los peces. Debido a esto, comete muchos errores. Lo que hace RMS Prop es penalizar el parámetro “color” para que pueda basarse también en otras características. Esto evita que el algoritmo se adapte demasiado rápido a los cambios en el parámetro “color” en comparación con otros parámetros. Este algoritmo tiene varias ventajas en comparación con las versiones anteriores de los algoritmos de descenso del gradiente. El algoritmo converge rápidamente y requiere menos ajustes que los algoritmos de descenso del gradiente y sus variantes.\nEl problema con RMS Prop es que la tasa de aprendizaje tiene que definirse manualmente, y el valor sugerido no funciona para todas las aplicaciones.\n\n\n2.6.6 AdaDelta\nAdaDelta puede considerarse una versión más robusta del optimizador AdaGrad. Se basa en el aprendizaje adaptativo y está diseñado para hacer frente a importantes inconvenientes del optimizador AdaGrad y RMS Prop. El principal problema de los dos optimizadores anteriores es que la tasa de aprendizaje inicial debe definirse manualmente. Otro problema es la tasa de aprendizaje decreciente, que llega a ser infinitesimalmente pequeña en algún momento. Debido a esto, un cierto número de iteraciones más tarde, el modelo ya no puede aprender nuevos conocimientos.\n\n\n2.6.7 Adam\nEl nombre Adam procede de adaptive moment estimation (estimación adaptativa del momento). Este algoritmo de optimización es una extensión del descenso del gradiente estocástico para actualizar los pesos de la red durante el entrenamiento. A diferencia de mantener una única tasa de aprendizaje durante el entrenamiento con el descenso del gradiente estocástico (SGD), el optimizador Adam actualiza la tasa de aprendizaje para cada peso de red individualmente. Los creadores del algoritmo de optimización Adam conocen las ventajas de los algoritmos AdaGrad y RMSProp, que también son extensiones de los algoritmos de descenso del gradiente estocástico. De ahí que los optimizadores Adam hereden las características de los algoritmos Adagrad y RMSProp. En Adam, en lugar de adaptar las tasas de aprendizaje basándose en el primer momento (media) como en RMS Prop, también utiliza el segundo momento de los gradientes. Nos referimos a la varianza no centrada por el segundo momento de los gradientes (no restamos la media).\nEl optimizador Adam tiene varias ventajas, por lo que se utiliza ampliamente. Se ha adaptado como punto de referencia para trabajos de aprendizaje profundo y se recomienda como algoritmo de optimización por defecto. Además, el algoritmo es fácil de implementar, tiene un tiempo de ejecución más rápido, bajos requisitos de memoria y requiere menos ajustes que cualquier otro algoritmo de optimización.\nLa actualización de los pesos viene dada por la expresión:\n\\[w_{t+1} = w_t - \\eta \\frac{m_t}{\\sqrt{v_{t+1} + \\epsilon}}\\]\ndonde\n\\[m_{t+1}  = \\beta m_t + (1-\\beta)\\frac{\\partial J(W)}{\\partial W_t}\\]\n\\[v_{t+1} = \\alpha v_t + (1-\\alpha)\\left[\\frac{\\partial J(W)}{\\partial W_t}\\right]^2\\]\ncon \\(v_{t+1}\\) es la estimación del segundo momento, y \\(m_{t+1}\\) es el promedio exponencial del momento.\n\n\n\n\n\n\nPara complemetar los aspectos teóricos de los diferentes algortimos de optimización y otros que no hemos presentado en este apartado se puede consultar el libro gratuito que aparece en este enlace http://d2l.ai/chapter_optimization/index.html.."
  },
  {
    "objectID": "20_TrainDL.html#hiperparámetros-de-la-red",
    "href": "20_TrainDL.html#hiperparámetros-de-la-red",
    "title": "2  Entrenamiento de la red neuronal",
    "section": "2.7 Hiperparámetros de la red",
    "text": "2.7 Hiperparámetros de la red\nLa gran “flexibilidad” que tienen las redes neuronales es un arma de doble filo. Por un lado, son capaces de generar modelos que aprenden relaciones muy complejas, sin embargo, sufren fácilmente el problema de sobreajuste (overfitting) lo que los incapacita al tratar de predecir nuevas observaciones. La forma de minimizar este problema y conseguir modelos útiles pasa por configurar de forma adecuada sus hiperparámetros.\n\n2.7.1 Número y tamaño de capas\nLa arquitectura de una red, el número de capas y el número de neuronas que forman parte de cada capa, determinan en gran medida la complejidad del modelo y con ello su potencial capacidad de aprendizaje.\nLas capas de entrada y salida son sencillas de establecer. La capa de entrada tiene tantas neuronas como predictores y la capa de salida tiene una neurona en problemas de regresión y tantas como clases en problemas de clasificación. En la mayoría de implementaciones, estos valores se establecen automáticamente en función del conjunto de entrenamiento. El usuario suele especificar únicamente el número de capas intermedias (ocultas) y el tamaño de las mismas.\nCuantas más neuronas y capas, mayor la complejidad de las relaciones que puede aprender el modelo. Sin embargo, dado que en cada neurona está conectada por pesos al resto de neuronas de las capas adyacentes, el número de parámetros a aprender aumenta y con ello el tiempo de entrenamiento.\n\n\n2.7.2 Ratio de aprendizaje\nEl learning rate o ratio de aprendizaje establece cómo de rápido pueden cambiar los parámetros de un modelo a medida que se optimiza (aprende). Este hiperparámetro es uno de los más complicados de establecer, ya que depende mucho de los datos e interacciona con el resto de hiperparámetros. Si el learning rate es muy grande, el proceso de optimización puede ir saltando de una región a otra sin que el modelo sea capaz de aprender. Si por el contrario, el learning rate es muy pequeño, el proceso de entrenamiento puede tardar demasiado y no llegar a completarse. Algunas de las recomendaciones heurísticas basadas en prueba y error son:\n\nUtilizar un learning rate lo más pequeño posible siempre y cuando el tiempo de entrenamiento no supere las limitaciones temporales disponibles.\nNo utilizar un valor constante de learning rate durante todo el proceso de entrenamiento. Por lo general, utilizar valores mayores al inicio y pequeños al final.\n\nDe hecho, el algoritmo de optimización establecido para el proceso de entrenamiento ya implementa las diferentes posibilidades de ratio de aprendizaje."
  },
  {
    "objectID": "20_TrainDL.html#regularización",
    "href": "20_TrainDL.html#regularización",
    "title": "2  Entrenamiento de la red neuronal",
    "section": "2.8 Regularización",
    "text": "2.8 Regularización\nLas redes neuronales pueden aprender a representar relaciones complejas entre las entradas y salidas de la red. Este poder de representación las ayuda a rendir mejor que los algoritmos tradicionales de aprendizaje automático en tareas de visión por ordenador y procesamiento del lenguaje natural. Sin embargo, uno de los retos asociados al entrenamiento de redes neuronales es el sobreajuste.\nCuando una red neuronal se adapta en exceso al conjunto de datos de entrenamiento, aprende una representación excesivamente compleja que modela el conjunto de datos de entrenamiento demasiado bien. Como resultado, su rendimiento es excepcional en el conjunto de datos de entrenamiento, pero su generalización a los datos de prueba es deficiente.\nLas técnicas de regularización ayudan a mejorar la capacidad de generalización de una red neuronal reduciendo el sobreajuste. Para ello, minimizan la complejidad innecesaria y exponen la red a datos más diversos. A continuación hacemos un repaso de las técnicas de regularización más habituales en el periodo de entrenamiento de la red.\n\n2.8.1 Parada temprana (early stopping)\nLa parada temprana es una de las técnicas de regularización más sencillas e intuitivas. Consiste en detener el entrenamiento de la red neuronal en una época anterior, de ahí su nombre.\nPero, ¿cómo y cuándo se detiene? A medida que se entrena la red neuronal durante muchas épocas, el error de entrenamiento disminuye.\nSi el error de entrenamiento es demasiado bajo y se acerca arbitrariamente a cero, la red se ajustará en exceso al conjunto de datos de entrenamiento. Una red neuronal de este tipo es un modelo de alta varianza que funciona mal en datos de prueba que nunca ha visto antes a pesar de su rendimiento casi perfecto en las muestras de entrenamiento.\nPor lo tanto, heurísticamente, si podemos evitar que la pérdida de entrenamiento sea arbitrariamente baja, es menos probable que el modelo se ajuste en exceso al conjunto de datos de entrenamiento y generalizará mejor.\n¿Cómo lo hacemos en la práctica?\n\n2.8.1.1 Métricas de validación\nUn método sencillo consiste en controlar métricas como el error de validación y la precisión de validación a medida que avanza el entrenamiento de la red neuronal, y utilizarlas para decidir cuándo parar.\nSi vemos que el error de validación no disminuye significativamente o aumenta en un intervalo de épocas, digamos p épocas, podemos detener el entrenamiento. También podemos reducir la tasa de aprendizaje y entrenar unas cuantas épocas más antes de parar. En la imagen siguiente (extraída de https://www.pinecone.io/learn/regularization-in-neural-networks/) podemos ver el cambio en las métricas y el punto de parada temprana.\n\n\n\n\n\nDe forma equivalente, se puede pensar en términos de la precisión de la red neuronal en los conjuntos de datos de entrenamiento y validación. Detenerse antes de tiempo cuando el error de validación empieza a aumentar (o deja de disminuir) equivale a detenerse cuando la precisión de validación empieza a disminuir.\n #### Monitorizando el cambio en el vector de pesos\nOtra forma de saber cuándo parar es controlar el cambio en los pesos de la red. Sean \\(w^{(t)}\\) y \\(w^{(t-k)}\\) los vectores de pesos en las épocas \\(t\\) y \\(t-k\\) respectivamente. Podemos calcular la norma l2 para la diferencia de los vectores anteriores y detener el entrenamiento cuando esta sea suficientemente pequeña, digamos una cantidad \\(epsilon\\), es decir:\n\\[||w^{(t)} - w^{(t-k)}|| < \\epsilon\\]\nPero este enfoque de utilizar la norma del vector diferencia no es muy fiable. ¿Por qué? Algunos pesos pueden haber cambiado mucho en las últimas k épocas, mientras que otros pueden haber sufrido cambios insignificantes. Por lo tanto, la norma del vector diferencia resultante puede ser pequeña a pesar del cambio drástico en ciertos componentes del vector peso.\nUn enfoque mejor es calcular el cambio en componentes individuales del vector de pesos. Si el cambio máximo (en todos los componentes) es inferior a \\(\\epsilon\\) podemos concluir que los pesos no están cambiando significativamente, por lo que podemos detener el entrenamiento de la red neuronal. Matemáticamente:\n\\[\\underset{i}{max} |w_i^{(t)} - w_i^{(t-k)}| < \\epsilon\\]\n\n\n\n2.8.2 Aumento de datos (data augmentation)\nEl aumento de datos es una técnica de regularización que ayuda a una red neuronal a generalizar mejor exponiéndola a un conjunto más diverso de ejemplos de entrenamiento. Como las redes neuronales profundas requieren un gran conjunto de datos de entrenamiento, el aumento de datos también es útil cuando no tenemos datos suficientes para entrenar una red neuronal.\nTomemos el ejemplo del aumento de datos de imágenes. Supongamos que tenemos un conjunto de datos con N ejemplos de entrenamiento en C clases. Podemos aplicar ciertas transformaciones a estas N imágenes para construir un conjunto de datos mayor.\n\n\n\n\n\n¿Qué es una transformación válida? Es cualquier operación que no altere la etiqueta original de los datos. Por ejemplo, un panda es un panda, esté mirando a la derecha o a la izquierda, situado cerca del centro de la imagen o en una de las esquinas.\nEn resumen: podemos aplicar cualquier transformación invariante de la etiqueta para realizar el aumento de datos. He aquí algunos ejemplos:\n\nTransformaciones del espacio de color, como el cambio de las intensidades de los píxeles.\nRotación y reflejo.\nInyección de ruido, distorsión y desenfoque.\n\nAdemás de las transformaciones básicas del espacio de color y de la imagen geométrica, existen nuevas técnicas de aumento de la imagen. Mixup es una técnica de regularización que utiliza una combinación convexa de entradas existentes para aumentar el conjunto de datos.\nSupongamos que \\(x_i\\) y \\(x_j\\) son muestras de entrada pertenecientes a las clases \\(i\\) y \\(j\\), respectivamente; \\(y_i\\) y \\(y_j\\) son los vectores unidireccionales correspondientes a las etiquetas de clase \\(i\\) y \\(j\\), respectivamente. Se puede formar forma una nueva imagen tomando una combinación convexa de \\(x_i\\) y \\(x_j\\):\n\\[\\begin{eqnarray}\n\\tilde{x} = &\\lambda x_i +(1-\\lambda)x_j\\\\\n\\tilde{y} = &\\lambda y_i +(1-\\lambda)y_j\\\\\n\\end{eqnarray}\\]\ncon \\(\\lambda \\in [0,1]\\).\nOtros métodos de aumento de datos son Cutout, CutMix y AugMix. Cutout implica la eliminación aleatoria de partes de una imagen de entrada durante el entrenamiento. CutMix sustituye las secciones eliminadas por partes de otra imagen. AugMix es una técnica de regularización que hace que una red neuronal sea robusta a los cambios de distribución. A diferencia de Mixup, que utiliza imágenes de dos clases diferentes, AugMix realiza una serie de transformaciones en la misma imagen y, a continuación, utiliza una composición de estas imágenes transformadas para obtener la imagen resultante.\n\n\n2.8.3 Penalización de pesos\nEn este caso actuamos como en otros muchos algoritmos de aprendiaje automático donde se añaden restricciones o penalizaciones sobre los coeficientes del modelo utilizado. En este caso se trata de introducir penalizaciones sobre los pesos de la red neuronal.\n\n2.8.3.1 Regularización L2\nLa idea detrás de este tipo de regularización es reducir el valor de los parámetros para que sean pequeños. Esta técnica introduce un término adicional de penalización en la función de coste original, añadiendo a su valor la suma de los cuadrados de los parámetros, es decir, consideramos una nueva función de coste que viene dada por:\n\\[J_2(W) = J(W) + \\lambda \\sum w_i^2\\]\nLa mala noticia es que este nuevo término puede ser alto; tanto que la red minimizaría la función de coste haciendo los parámetros muy cercanos a 0, lo que no sería nada conveniente. Es por ello que multiplicaremos ese sumando por una constante (\\(\\lambda\\)) pequeña, cuyo valor escogeremos de forma arbitraria (0.1, 0.01, …). La actualización de pesos en el proceso de entrenamiento de la red viene dado entonces (para SGD) por:\n\\[ W_{t+1} = W_{t} - \\eta  \\left[\\frac{\\partial J(W)}{\\partial W_t} +2\\lambda W_t\\right]\\]\nEl parámetro \\(\\lambda\\) controla la regularización, de forma que si deseamos más podemos aumentar el valor de \\(\\lambda\\).\n\n\n2.8.3.2 Regularización L1\nExiste otra técnica muy parecida a la anterior denominada regularización L1 donde los parámetros en el sumatorio del término de penalización no se elevan al cuadrado, sino que se usa su valor absoluto:\n\\[J_1(W) = J(W) + \\lambda \\sum |w_i|\\]\nde forma que la actualización de pesos viene dada por:\n\\[W_{t+1} = W_{t} - \\eta  \\left[\\frac{\\partial J(W)}{\\partial W_t} +\\lambda sgn(W_t)\\right]\\]\ndonde \\(sgn()\\) es la función signo.\nEsta variante empuja el valor de los parámetros hacia valores más pequeños, haciendo incluso que la influencia de algunas variables de entrada sea nula en la salida de la red, lo que supone una selección de variables automática. El resultado es una una mejor generalización, pero sólo hasta cierto punto (la elección del valor de λ cobra más importancia en este caso).\n\n\n2.8.3.3 Decaimiento de pesos (weight decay)\nEsta técnica podríamos decir que es idéntica a la regularización L2, pero aplicada en otro punto. En lugar de introducir la penalización como un sumando en la función de coste, la añadimos como un término extra en la fórmula de actualización de los pesos:\n\\[W_{t+1} = W_{t} - \\eta  \\left[\\frac{\\partial J(W)}{\\partial W_t} +\\lambda W_t\\right]\\]\nComo vemos esta actualización es prácticamente igual a la actualización de los pesos en la regularización L2, salvo que en este caso no aparece un 2 multiplicando en el término añadido.\n\n\n\n2.8.4 Drop out\nDrop out es uno de los tipos de técnicas de regularización más interesantes. También produce muy buenos resultados y, en consecuencia, es la técnica de regularización más utilizada en el campo del aprendizaje profundo.\nPara entender cómo funciona el abandono, conviene repasar el concepto de modelos de conjunto.\nEn el aprendizaje automático tradicional, los modelos de conjunto ayudan a reducir el sobreajuste y a mejorar el rendimiento del modelo. Para un problema de clasificación simple, podemos adoptar uno de los siguientes enfoques:\n\nEntrenar varios clasificadores para resolver la misma tarea.\nEntrenar diferentes instancias del mismo clasificador para diferentes subconjuntos del conjunto de datos de entrenamiento.\n\nPara un modelo de clasificación simple, una técnica de conjunto como el bagging implica entrenar el mismo clasificador en diferentes subconjuntos de datos de entrenamiento, muestreados con reemplazo. Supongamos que hay N instancias. En el momento de la prueba, cada clasificador pasa por la muestra de prueba y se utiliza un conjunto de sus predicciones.\nEn general, el rendimiento de un conjunto es al menos tan bueno como el de los modelos individuales; no puede ser peor que el de los modelos individuales.\nSi trasladáramos esta idea a las redes neuronales, podríamos intentar hacer lo siguiente (identificando al mismo tiempo las limitaciones de este enfoque):\n\nEntrenar varias redes neuronales con diferentes arquitecturas. Entrenar una red neuronal en diferentes subconjuntos de los datos de entrenamiento. Sin embargo, entrenar múltiples redes neuronales es prohibitivamente caro.\nIncluso si entrenamos N redes neuronales diferentes, ejecutar el punto de datos a través de cada uno de los N modelos -en el momento de la prueba- introduce una sobrecarga computacional sustancial.\n\nPara entender el drop out, digamos que la estructura de nuestra red neuronal es parecida a la que se muestra a continuación (red densa donde todas las neuronas están interconectadas):\n\n\n\n\n\n¿Qué hace drop out? En cada iteración, selecciona aleatoriamente algunos nodos y los elimina junto con todas sus conexiones entrantes y salientes, como se muestra a continuación\n\n\n\n\n\nAsí, cada iteración tiene un conjunto diferente de nodos, lo que da lugar a un conjunto diferente de resultados. También puede considerarse una técnica de conjunto en el aprendizaje automático. Los modelos de conjunto suelen funcionar mejor que un modelo único, ya que capturan más aleatoriedad. Del mismo modo, el abandono también funciona mejor que un modelo de red neuronal normal.\nCon un abandono de 0,5, hay un 50% de posibilidades de que cada neurona participe en el entrenamiento dentro de cada lote de entrenamiento. El resultado es una arquitectura de red ligeramente diferente para cada lote. Equivale a entrenar redes neuronales diferentes en subconjuntos diferentes de los datos de entrenamiento.\nEsta probabilidad de elegir cuántos nodos deben abandonarse es el hiperparámetro de la función de abandono. Como se ve en la imagen anterior, el drop out puede aplicarse tanto a las capas ocultas como a las capas de entrada.\nLa matriz de pesos se inicializa una vez al principio del entrenamiento. En general, para el lote k-ésimo, la retropropagación se produce sólo a lo largo de los caminos de las neuronas presentes para ese lote. Esto significa que sólo se actualizan los pesos correspondientes a las neuronas que están presentes.\nEn el momento de la prueba, todas las neuronas están presentes en la red. Entonces, ¿cómo tenemos en cuenta los abandonos durante el entrenamiento? Ponderamos la salida de cada neurona con la misma probabilidad p, proporcional a la fracción de tiempo que la neurona estuvo presente durante el entrenamiento.\n\n\n2.8.5 Normalización por lotes\nLa normalización en lotes consiste básicamente en añadir un paso extra, habitualmente entre las neuronas y la función de activación, con la idea de normalizar las activaciones de salida. Lo ideal es que la normalización se hiciera usando la media y la varianza de todo el conjunto de entrenamiento, pero si estamos aplicando el descenso del gradiente estocástico para entrenar la red, se usará la media y la varianza de cada mini-lote de entrada.\nNota: cada salida de cada neurona se normalizará de forma independiente, lo que quiere decir que en cada iteración se calculará la media y la varianza de cada salida para el mini-lote en curso.\nA continuación de la normalización se añaden 2 parámetros: un bias como sumando, y otra constante similar a un bias pero que aparece multiplicando cada activación. Esto se hace para que el rango de la entrada escale fácilmente hasta el rango de salida, lo que ayudará mucho a nuestra red a la hora de ajustar a los datos de entrada, y reducirá las oscilaciones de la función de coste. Como consecuencia de esto podremos aumentar la tasa de aprendizaje (no hay tanto riesgo de acabar en un mínimo local) y la convergencia hacia el mínimo global se producirá más rápidamente.\nLa normalización por lotes es más una técnica de ayuda al entrenamiento que una estrategia de regularización en sí misma. Esto último se logra realmente aplicando algo adicional conocido como momentum. La idea de este momentum es que cuando introduzcamos un nuevo mini-lote de entrada (N muestras procesadas en paralelo) no se usen una media y una desviación muy distintas a las de la iteración anterior, para lo que se tendrá en cuenta el histórico, y se elegirá una constante que pondere la importancia de los valores del mini-lote actual frente a los valores del anterior. Gracias a todo esto se conseguirá reducir el sobreajuste."
  },
  {
    "objectID": "30_RMDDL.html#qué-es-keras",
    "href": "30_RMDDL.html#qué-es-keras",
    "title": "3  Redes multicapa densas con Keras",
    "section": "3.1 ¿Qué es Keras?",
    "text": "3.1 ¿Qué es Keras?\nAunque las redes neuronales profundas están de moda, la complejidad de los principales marcos de trabajo ha sido una barrera para su uso por parte de los desarrolladores que se inician en el aprendizaje automático. Ha habido varias propuestas de APIs de alto nivel mejoradas y simplificadas para construir modelos de redes neuronales, todas las cuales tienden a parecer similares desde la distancia, pero muestran diferencias al examinarlas más de cerca.\nKeras es una de las principales API de redes neuronales de alto nivel. Está escrita en Python y admite múltiples motores de cálculo de redes neuronales backend, como TensorFlow, Theano o Microsoft Cognitive Toolkit. Proporciona una forma muy limpia y fácil de crear modelos de aprendizaje profundo. Keras no es un marco independiente, sino una interfaz para principiantes (API) para acceder y programar una variedad de marcos de Machine Learning. Theano, Microsoft Cognitive Toolkit y TensorFlow son algunos de los marcos soportados por Keras.\nKeras es relativamente fácil de aprender y trabajar con él, porque proporciona un frontend de Python con un alto nivel de abstracción mientras que tiene la opción de múltiples backend para fines de computación. Esto hace que Keras sea más lento que otros marcos de aprendizaje profundo, pero extremadamente amigable para los principiantes. Está integrado en TensorFlow y se puede utilizar para realizar desarrollos mucho más rápido, ya que proporciona módulos incorporados para todos los cálculos de redes neuronales. Al mismo tiempo, los cálculos que implican tensores, gráficos de cálculo, sesiones y otros, pueden hacerse a medida utilizando la API del núcleo de TensorFlow, lo que te proporciona una flexibilidad y un control total sobre tu aplicación y te permite implementar tus ideas en un tiempo relativamente corto.\n\n3.1.1 Características\nKeras tiene las siguientes características más destacadas:\n\nOfrece a los usuarios un marco de trabajo fácil de usar, junto con métodos y herramientas de creación de prototipos más rápidos.\nFunciona eficientemente tanto en la CPU como en la GPU, sin ningún tipo de contratiempo.\nOfrece una API consistente que proporciona la información necesaria cuando se produce un error.\nPuedes personalizar las funcionalidades de tu código hasta un gran punto. Incluso una pequeña personalización supone un gran cambio porque estas funcionalidades están profundamente integradas con el backend de bajo nivel.\nPermite trabajar tanto con redes neuronales convolucionales (CNN) como con redes neuronales recurrentes (RNN) para una variedad de aplicaciones como Visión Computacional y el análisis de series temporales, respectivamente.\nSu funcionalidad sin fisuras permite utilizar tanto CNN como RNN si es necesario.\nSoporta completamente arquitecturas de red arbitrarias, poniendo a disposición de los usuarios la posibilidad de compartir modelos y capas.\n\n\n\n3.1.2 Fundamentos\nKeras fue creado para ser amigable, modular, fácil de extender y para trabajar con Python. La API fue diseñada para seres humanos, no para máquinas, y sigue las mejores prácticas para reducir la carga cognitiva.\nLas capas neuronales, las funciones de coste, los optimizadores, los esquemas de inicialización, las funciones de activación y los esquemas de regularización son módulos independientes que se pueden combinar para crear nuevos modelos. Es sencillo añadir nuevos módulos, como nuevas clases y funciones. Los modelos se definen en código Python, no en archivos de configuración de modelos separados.\n\n\n3.1.3 ¿Por qué necesitamos Keras?\nEntre las características que podemos destacar de keras tenemos:\n\nEs una API que fue hecha para ser fácil de aprender para la gente. Keras fue hecho para ser simple. Ofrece APIs consistentes y simples, reduce las acciones requeridas para implementar código común y explica claramente los errores del usuario.\nEl tiempo de creación de prototipos en Keras es menor. Esto significa que tus ideas pueden ser implementadas y desplegadas en un tiempo más corto. Keras también proporciona una variedad de opciones de despliegue en función de las necesidades del usuario.\nLos lenguajes con un alto nivel de abstracción y características incorporadas son lentos y construir características personalizadas en ellos pueden ser difícil, pero Keras se ejecuta sobre TensorFlow y es relativamente rápido. Keras también está profundamente integrado con TensorFlow, por lo que puedes crear flujos de trabajo personalizados con facilidad.\nLa comunidad de investigadores de Keras es amplia y muy desarrollada. La documentación y la ayuda disponibles son mucho más extensas que las de otros marcos de Deep Learning.\nKeras es utilizado comercialmente por muchas empresas como Netflix, Uber, Square, Yelp, que han desplegado productos en el dominio público que se construyen utilizando Keras.\n\n\n\n3.1.4 ¿Cómo construir un modelo en keras?\nKeras es una biblioteca que trabaja con modelos. Proporciona los bloques de construcción para desarrollar modelos complejos de Deep Learning.\nA diferencia de los frameworks independientes, este software de código abierto no se ocupa de las operaciones simples de bajo nivel por sí mismo. En su lugar, utiliza las bibliotecas de los marcos de Machine Learning asociados para este fin. Estas actúan como una especie de motor backend para Keras.\nDado que la idea es ser modular, las capas deseadas para la red neuronal que se está desarrollando se conectan entre sí sin que el usuario de Keras tenga que entender o controlar el backend real del marco seleccionado.\nComo se ha mencionado anteriormente, Keras utiliza las tres herramientas TensorFlow, Theano y Microsoft Cognitive Toolkit. Estas tienen interfaces listas para usar que permiten un acceso rápido e intuitivo al respectivo backend.\nNo es necesario decidirse por un único framework porque se puede cambiar fácilmente entre los diferentes backends. También es posible elegir un backend diferente de las tres soluciones nombradas aquí. Solo tienes que especificarlo en el archivo de configuración, y tiene las siguientes tres funciones disponibles: placeholder, variable y función.\n\n\n3.1.5 Ventajas de utilizar Keras\nKeras ha sido una excelente adición a las herramientas existentes para el desarrollo de redes neuronales, ya que esta biblioteca de código abierto simplifica enormemente el proceso. La usabilidad es la clave aquí. Keras funciona como una interfaz diseñada explícitamente para los humanos y solo en segundo lugar para las máquinas.\nLas acciones del usuario se reducen al mínimo, y si aún así se producen errores, se proporciona una retroalimentación relevante para ayudar a corregirlos. Esto hace que sea comparativamente fácil de aprender a usar y permite un mayor nivel de productividad.\nA continuación, un resumen de algunas ventajas adicionales proporcionadas por Keras:\n\nAmplio soporte de plataforma para los modelos desarrollados. Los modelos desarrollados con Keras pueden ser fácilmente desplegados en diferentes plataformas.\nSoporte para múltiples motores de backend. Keras te da la libertad de elegir el backend que quieras y combinar múltiples backends. También puede transferir un modelo desarrollado a otro backend en cualquier momento.\nExtraordinario soporte multi-GPU. Cuando se utiliza Keras, el trabajo de computación para los procesos de Deep Learning desarrollados puede distribuirse fácilmente entre múltiples chips o tarjetas gráficas.\n\n\n\n3.1.6 ¿Quién utiliza keras?\nComo interfaz universal para las plataformas de Machine Learning, Keras se utiliza actualmente en una gran variedad de proyectos en el campo de la Inteligencia Artificial. A mediados de 2018, esta biblioteca ya contaba con más de 250.000 usuarios individuales, y este número ha aumentado mucho después desde su inclusión en el software TensorFlow.\nGracias a la libertad de elección del framework subyacente, la gratuidad de las licencias y su independencia de plataforma, Keras es la solución perfecta para todo tipo de aplicaciones profesionales de redes neuronales tanto en la industria como en la investigación. Por ejemplo, empresas conocidas como Netflix, Uber y Yelp, así como organizaciones como la NASA, y el Centro Europeo para la Investigación Nuclear (CERN), utilizan Keras o el paquete TensorFlow Keras en sus proyectos.\n\n\n3.1.7 Puesta en marcha de Keras\nPara la puesta en marcha del API Keras necesitamos ir instalando diferentes librerías. En este punto detallamos ese proceso que en muchas ocasiones es bastante lento. Una vez instaladas las libreías se cargaran como el resto de librerías de R.\nEn primer lugar debemos instalar la librería tensorflow:\n\nutils::install.packages(\"remotes\")\nremotes::install_github(\"rstudio/tensorflow\", force=TRUE)\n\nAhora instalamos la última vesión del interprete de python:\n\nreticulate::install_python()\n\nPonemos en marcha tensorflow\n\nlibrary(tensorflow)\ninstall_tensorflow(envname = \"r-tensorflow\")\n\nVirtual environment 'r-tensorflow' removed.\nUsing Python: /Users/javiermorales/.pyenv/versions/3.9.18/bin/python3.9\nCreating virtual environment 'r-tensorflow' ... \nDone!\nInstalling packages: pip, wheel, setuptools\nVirtual environment 'r-tensorflow' successfully created.\nUsing virtual environment 'r-tensorflow' ...\n\nInstallation complete.\n\n\nAhora comenzamos con la instalación y puesta en marcha de Keras\n\n#install.packages(\"keras\")\nlibrary(keras)\ninstall_keras()\n\nVirtual environment 'r-tensorflow' removed.\nUsing Python: /Users/javiermorales/.pyenv/versions/3.9.18/bin/python3.9\nCreating virtual environment 'r-tensorflow' ... \nDone!\nInstalling packages: pip, wheel, setuptools\nVirtual environment 'r-tensorflow' successfully created.\nUsing virtual environment 'r-tensorflow' ...\n\nInstallation complete.\n\n\nUna vez finalizado el proceso nos basta con cargar la librería keras para acceder a todos sus recursos. Cargamos todas las librería necesarias.\n\n# Paquetes anteriores\nlibrary(tidyverse)\nlibrary(sjPlot)\nlibrary(knitr) # para formatos de tablas\nlibrary(gridExtra)\nlibrary(ggpubr)\ntheme_set(theme_sjplot2())\nlibrary(mlr3verse)\nlibrary(tensorflow)\nlibrary(keras)"
  },
  {
    "objectID": "30_RMDDL.html#nuestras-primeras-redes-con-keras",
    "href": "30_RMDDL.html#nuestras-primeras-redes-con-keras",
    "title": "3  Redes multicapa densas con Keras",
    "section": "3.2 Nuestras primeras redes con Keras",
    "text": "3.2 Nuestras primeras redes con Keras\nDe la misma manera que cuando uno empieza a programar en un lenguaje nuevo existe la tradición de hacerlo con un print Hello World, en aprendizaje profundo se empieza por crear modelos para problemas de clasificación. Los ejemplos que presentamos nos permitirán adentrarnos paulatinamente en los conceptos básicos de las redes neuronales, reduciendo todo lo posible conceptos teóricos, con el objetivo de ofrecer al lector o lectora una visión global de un caso concreto para facilitar la lectura de los cuadernos posteriores, donde se profundiza en diferentes aspectos del área.\n\n3.2.1 Datos Iris\nLa base de datos iris consta de 50 muestras de cada una de las tres especies de Iris: Iris Setosa, Iris virginica e Iris versicolor. Se escogieron cuatro características de cada muestra: la longitud y el ancho de los sépalos y pétalos, en centímetros. El objetivo que se persigue es predecir la clase de especie (species) que es en función de sus características. Las variables contenidas en el banco de datos son:\n\nsepal_length: longitud del sépalo (en cm)\nsepal_width: anchura del sépalo (en cm)\npetal_length: longitud del pétalo (en cm)\npetal_width: anchura del pétalo (en cm)\nspecies: especie de la flor (Iris Setosa, Iris virginica e Iris versicolor)\n\nEl objetivo que se persigue es predecir la clase de especie (species) que es en función de sus características. Cargamos los datos y los preparamos para el análisis. COmo los datos están ordenos por especiedebeos barajarlos para evitar que al obtener la muestra de entrenamiento y validación tengamos sesgos de selección. Además debemos estandarizar las variables numéricas.\n\n# Cargamos datos\niris = read_rds(\"iris.rds\")\n# Barajamos los datos\niris = slice_sample(iris, n = nrow(iris))\nnombres = levels(iris$species)\n\n# Predictoras y respuesta\nX = dplyr::select(iris, -\"species\")\n# Codificamos la respuesta numéricamente y restamos 1 ya que los array  se inicializan en cero en python\ny = as.numeric(iris$species)-1\n\nCreamos la muestra de entrenamiento (80%) y validación (20%).\n\n# semilla para reproducibilidad\nset.seed(123)\n# Proporción muestra de entrenamiento\nnp = 0.8\n# Índices de la muestra de entrenamiento\nids_train = sample(nrow(iris), np*nrow(iris))\n# Muestras de entrenamiento y validación\nX_train_iris = X[ids_train,]\nX_test_iris = X[-ids_train,]\ny_train_iris = y[ids_train]\ny_test_iris = y[-ids_train]\n\nAhora estandarizamos a partir de la media y desviación típica de las predictoras en la muestra de entrenamiento.\n\n# Variables en el modelo\nnvari = ncol(X)\n############# Estandarización ###############\n# Medias\nmean_train = apply(X_train_iris, 2, mean)\n# Desviaciones típicas\nsd_train = apply(X_train_iris, 2, sd)\n# Estandarizamos muestra de entrenamiento\nXest_train_iris = scale(X_train_iris, mean_train, sd_train)\n# Estandarizamos muestra de validación\nXest_test_iris = scale(X_test_iris, mean_train, sd_train)\n\n\n3.2.1.1 Arquitectura de la red\nUna vez preparados los datos tenemos que definir la arquitectura de la red que vamos a utilizar. La estructura de datos principal en Keras es la clase Sequential que permite la creación de una red neuronal básica. En este caso, el modelo en Keras se considera como una secuencia de capas; cada una de ellas va «destilando» gradualmente los datos de entrada para obtener la salida deseada.\n\nmodelo_iris = keras_model_sequential()\n\nEl modelo creado en este momento es un contenedor, pues no contiene ningún tipo de información. Para ir introduciendo capas en la arquitectura de la red utilizamos el comando model.add donde identificamos las características de cada una de las capas ocultas que podemos ir considerando. Para empezar, la clase Dense nos permite definir una capa densa, es decir, una capa donde todas las entradas están conectadas con todas las salidas. Requiere los siguientes parámetros de entrada:\n\nunits: número entero que indica la dimensión de la capa de salida, es decir, el número de neuronas que se utilizan.\nactivation: función de activación que se aplica a la salida de la capa, es decir, si el modelo tiene un comportamiento lineal o si lo usamos para realizar, por ejemplo, una Regresión Logística o una Red Neuronal.\ninput_dim: tupla que indica el tamaño de los datos de entrada.\n\nTambién a menudo se indica la inicialización de los pesos como argumento de las capas Dense. Los valores iniciales deben ser adecuados para que el problema de optimización converja tan rápido como sea posible en el proceso de entrenamiento de la red. En el manual de Keras se pueden encontrar las diversas opciones de inicialización.\nEl número de capas necesarias no se sabe a priori, por lo que se suele establecer mediante un procedimiento de ensayo y error. Normalmente, la red necesaria será aquella que sea lo suficientemente grande para capturar la estructura y las dimensiones del problema. Siempre hay que tener en cuenta que la última capa de la red debe disponer de tantas neuronas como respuestas posibles de la respuesta. En este caso como la respuesta tiene tres clases, la última capa de la red debe tener tres neuronas. Además, dado que estamos en un problema de clasificación la función de activación a utilizar es softmax.\nEn este problema consideramos dos capas. En la primera definimos los datos de entrada con 20 neuronas artificiales y función de activación relu, y en la segunda tenemos la capa de salida. A continuación vemos el código necesario. Vamos a fijar la semilla inicial de los pesos de la red para poder reproducir los resultados. Para ello utilizamos la función initializer_glorot_normal que tiene por único parámetro el número aleatorio de inicio.\n\n# Fijamos semilla de los pesos iniciales para poder \ninicializador = initializer_glorot_normal(seed = 15)\n\nmodelo_iris %>% \n  layer_dense(units = 20, activation = 'relu', input_shape = c(ncol(Xest_test_iris)), kernel_initializer = inicializador) %>% \n  layer_dense(units = 3, activation = 'softmax', kernel_initializer = inicializador)\n\nPodemos ver ahora la arquitectura que hemos diseñado con:\n\nsummary(modelo_iris)\n\nModel: \"sequential\"\n________________________________________________________________________________\n Layer (type)                       Output Shape                    Param #     \n================================================================================\n dense_1 (Dense)                    (None, 20)                      100         \n dense (Dense)                      (None, 3)                       63          \n================================================================================\nTotal params: 163 (652.00 Byte)\nTrainable params: 163 (652.00 Byte)\nNon-trainable params: 0 (0.00 Byte)\n________________________________________________________________________________\n\n\nEl método muestra todas las capas del modelo, lo que incluye el nombre de cada capa (que se genera automáticamente, a menos que lo configuremos en un argumento al crear la capa), su forma de salida y su número de parámetros. La salida finaliza con el número total de parámetros, incluidos los parámetros entrenables y no entrenables.\n\n\n3.2.1.2 Proceso de aprendizaje\nA partir del modelo Sequential, podemos definir las capas del modelo de manera sencilla, tal como hemos avanzado en el apartado anterior. Una vez que tengamos nuestro modelo definido, debemos configurar cómo será su proceso de aprendizaje con el método compile(), con el que podemos especificar algunas propiedades a través de argumentos del método.\nEl primero de estos argumentos es la función de coste (loss function), que usaremos para evaluar el grado de error entre las salidas calculadas y las salidas deseadas de los datos de entrenamiento. Por otro lado, se especifica un optimizador que, como veremos, es la manera que tenemos de indicar los detalles del algoritmo de optimización que permite a la red neuronal calcular los pesos de los parámetros durante el entrenamiento a partir de los datos de entrada y la función de coste definida.\nFinalmente, debemos indicar la métrica que usaremos para monitorizar el proceso de aprendizaje (y prueba) de nuestra red neuronal. En este primer ejemplo solo tendremos en cuenta el porcentaje de casos correctamente clasificados (accuracy). Por ejemplo, en nuestro ejemplo podemos especificar los siguientes argumentos en el método compile() para probarlo:\n\nmodelo_iris %>% compile(\n  loss = 'sparse_categorical_crossentropy',\n  optimizer = optimizer_sgd(),\n  metrics = c('accuracy')\n)\n\nLa elección de la función de pérdida viene determinada en gran medida por el tipo de tarea o problema que se desea abordar. En la tabla siguiente tenemos un pequeño resumen de su uso:\n\n\n\n\n\n\n\n\nTipo de problema\nFunción de activación de la última capa\nFunción de pérdida\n\n\n\n\nClasificación múltiple con one-hot\nsoftmax\ncategorical_crossentropy\n\n\nClasificación múltiple con índice categoría\nsoftmax\nsparse_categorical_crossentropy\n\n\nRegresión de un valor arbitrario\n\nmse\n\n\nRegresión a valores en [0,1]\nsigmoid\nmse o binary_crossentropy\n\n\nClasificación binaria\nsigmoid\nbinary_crossentropy\n\n\n\nEn cuanto a los optimizadores disponibles en TensorFlow con la API Keras tenemos: SGD (descenso del gradiente estocástico), RMSprop, AdaGrad, Adadelta, Adam, Adamax, y Nadam. Estos optimizadores son variantes u optimizaciones del algoritmo de descenso del gradiente presentado, que usan hiperparámetros que explicaremos en próximos cuadernos. En la actualidad el algoritmo preferido es Adam ya que es el que proporciona mejores resultados de forma general.\nPara saber las métricas disponibles se puede consultar este enlace, mientars que para consultar los optimizadores disponibles se puede visitar esta página.\n\n\n3.2.1.3 Entrenamiento del modelo\nUna vez definido nuestro modelo y configurado su método de aprendizaje, este ya está listo para ser entrenado. Para ello, podemos entrenar o ajustar el modelo a los datos de entrenamiento de que disponemos invocando al método fit() del modelo. Los parámetros de entrada de esta función son los siguientes: * x: datos de entrada. * y: etiquetas de los datos de entrada. * batch_size: número de muestras que se utilizan en cada iteración del entrenamiento. Cuando la cantidad de datos es muy elevada (miles o millones) es conveniente usar un batch_size pequeño (de unos cuántos miles de datos) para evitar problemas de almacenamiento en la memoria del ordenador.\n\nepochs: número de veces que se itera sobre el conjunto de datos de entrenamiento completo durante el proceso de entrenamiento.\nverbose: indica el nivel de detalle de la información que se muestra en pantalla durante el entrenamiento. Si es 0 no se muestra nada, 1 se muestra una barra de progreso y 2 se muestra una línea por época.\n\nEl código siguiente configura el entrenamiento del modelo. Dado que el número de muestras es muy reducido no configuramos el batch_size.\nEl concepto de sobreajuste de un modelo (overfitting en inglés) se produce cuando el modelo obtenido se ajusta tanto a los ejemplos etiquetados de entrenamiento que no puede realizar las predicciones correctas en ejemplos de datos nuevos que nunca ha visto antes. En resumen, con overfitting o sobreajuste nos referimos a lo que le sucede a un modelo cuando este modela los datos de entrenamiento demasiado bien, aprendiendo detalles de estos que no son generales. Esto es debido a que sobre entrenamos nuestro modelo y este estará considerando como válidos solo los datos idénticos a los de nuestro conjunto de entrenamiento, incluidos sus defectos (también llamado ruido en nuestro contexto). Es decir, nos encontramos en la situación de que el modelo puede tener una baja tasa de error de clasificación para los datos de entrenamiento, pero no se generaliza bien a la población general de datos en los que estamos interesados.\nEs evidente que, en general, esta situación presenta un impacto negativo en la eficiencia del modelo cuando este se usa para inferencia con datos nuevos. Por ello, es muy importante evitar estar en esta situación; de aquí la utilidad de reservar una parte de datos de entrenamiento como datos de validación. Podemos añadir el porcentaje de datos de validación dentro de la muestra de entrenamiento dentro del ajuste del modelo con el parámetro validation_split. Como este banco de datos es muy pequeño vamos a prescindir por el momento de dicho parámetro, que si incorporaremos en modelos con un mayor número de muestras.\n\nhistory_iris = modelo_iris %>% \n  fit(Xest_train_iris, y_train_iris,  epochs = 20)\n\nEpoch 1/20\n4/4 - 1s - loss: 1.1106 - accuracy: 0.4417 - 555ms/epoch - 139ms/step\nEpoch 2/20\n4/4 - 0s - loss: 1.0732 - accuracy: 0.4417 - 35ms/epoch - 9ms/step\nEpoch 3/20\n4/4 - 0s - loss: 1.0386 - accuracy: 0.4500 - 10ms/epoch - 3ms/step\nEpoch 4/20\n4/4 - 0s - loss: 1.0058 - accuracy: 0.4583 - 9ms/epoch - 2ms/step\nEpoch 5/20\n4/4 - 0s - loss: 0.9752 - accuracy: 0.4667 - 9ms/epoch - 2ms/step\nEpoch 6/20\n4/4 - 0s - loss: 0.9466 - accuracy: 0.4667 - 9ms/epoch - 2ms/step\nEpoch 7/20\n4/4 - 0s - loss: 0.9198 - accuracy: 0.4833 - 13ms/epoch - 3ms/step\nEpoch 8/20\n4/4 - 0s - loss: 0.8947 - accuracy: 0.4833 - 9ms/epoch - 2ms/step\nEpoch 9/20\n4/4 - 0s - loss: 0.8717 - accuracy: 0.5083 - 10ms/epoch - 2ms/step\nEpoch 10/20\n4/4 - 0s - loss: 0.8498 - accuracy: 0.5500 - 11ms/epoch - 3ms/step\nEpoch 11/20\n4/4 - 0s - loss: 0.8293 - accuracy: 0.5500 - 10ms/epoch - 3ms/step\nEpoch 12/20\n4/4 - 0s - loss: 0.8098 - accuracy: 0.5917 - 9ms/epoch - 2ms/step\nEpoch 13/20\n4/4 - 0s - loss: 0.7913 - accuracy: 0.6083 - 9ms/epoch - 2ms/step\nEpoch 14/20\n4/4 - 0s - loss: 0.7741 - accuracy: 0.6250 - 9ms/epoch - 2ms/step\nEpoch 15/20\n4/4 - 0s - loss: 0.7574 - accuracy: 0.6333 - 10ms/epoch - 2ms/step\nEpoch 16/20\n4/4 - 0s - loss: 0.7421 - accuracy: 0.6417 - 10ms/epoch - 3ms/step\nEpoch 17/20\n4/4 - 0s - loss: 0.7275 - accuracy: 0.6500 - 9ms/epoch - 2ms/step\nEpoch 18/20\n4/4 - 0s - loss: 0.7140 - accuracy: 0.6750 - 9ms/epoch - 2ms/step\nEpoch 19/20\n4/4 - 0s - loss: 0.7011 - accuracy: 0.6917 - 9ms/epoch - 2ms/step\nEpoch 20/20\n4/4 - 0s - loss: 0.6887 - accuracy: 0.7000 - 9ms/epoch - 2ms/step\n\n\nEste método encuentra el valor de los parámetros de la red mediante el algoritmo iterativo de entrenamiento que hemos especificado en el argumento optimizer del método compile(). A grandes rasgos, en cada iteración de este algoritmo, este coge datos de entrenamiento de x_train, los pasa a través de la red neuronal (con los valores que en aquel momento tengan sus parámetros), compara el resultado obtenido con el esperado (indicado en y_train) y calcula la función de coste para guiar el proceso de ajuste de los parámetros del modelo. Intuitivamente consiste en aplicar el optimizador especificado anteriormente en el método compile() para calcular un nuevo valor de cada uno de los parámetros (pesos y sesgos) del modelo en cada iteración, de tal forma de que se reduzca el valor de la pérdida en siguientes iteraciones. Podemos ver la evolución de la función de pérdida y del porcentaje de clasificación correcta con el código siguiente.\nLos resultados finales del entrenamiento los podemos ver con:\n\nhistory_iris\n\n\nFinal epoch (plot to see history):\n    loss: 0.6887\naccuracy: 0.7 \n\n\nEl porcentaje de clasificación correcto conseguido no es excesivamente bueno para la muestra de entrenamiento. Aunque los resultados no son espectaculares comparados con otros métodos de clasificación para este conjunto de datos, debemos tener en cuenta que hemos probado una red neuronal muy sencilla con solo una capa oculta. Podemos analizar la evolución del proceso de aprendizaje representando gráficamente los resultados obtenidos:\n\nplot(history_iris) + ylim(0,1)\n\n\n\n\nProceso de aprendizaje. Datos Iris\n\n\n\n\nSe puede ver como el modelo converge rápidamente (valores de loss y accuracy estables desde la epoch 10 más o menos).\n\n\n3.2.1.4 Evaluación del modelo\nUna vez entrenada la red neuronal llega el momento de evaluar como se comporta con los datos de validación. Para esta tarea utilizamos el método evaluate(). Este nos devuelve el valor de la función de pérdida y el porcentaje de clasificación correcta. Veamos los resultados para nuestro banco de datos.\n\nmodelo_iris %>% tensorflow::evaluate(Xest_test_iris, y_test_iris)\n\n1/1 - 0s - loss: 0.7027 - accuracy: 0.6667 - 175ms/epoch - 175ms/step\n\n\n     loss  accuracy \n0.7026886 0.6666667 \n\n\n¿ Qué porcentaje de clasificación correcta alcanzamos para la muestra de validación?¿Cómo lo interpretamos?.\nUna herramienta muy utilizada en el aprendizaje automático para evaluar el rendimiento de modelos de clasificación es la matriz de confusión que contabiliza las predicciones en comparación con los valores reales. Usamos esta tabla para entender mejor cómo de bien o de mal el modelo se comporta, y es muy útil para mostrar de forma explícita cuándo una clase es confundida con otra. Para poder obtener la matriz de confusión es necesario obtener las predicciones del modelo para la muestra de validación y compararla con los datos originales. En el código siguiente se muestra como obtener dichos valores. Las funciones utilizadas devuelven valores numéricos que convertimos en factor con las etiquetas de los nombres de la especies consideradas.\n\n# probabilidades de clasificación de cada muestra en cada especie \nprediccion = modelo_iris %>% predict(Xest_test_iris)\n\n1/1 - 0s - 105ms/epoch - 105ms/step\n\n# predicción del modelo\npr_modelo = factor((prediccion %>% k_argmax())$numpy(), levels = 0:(length(nombres)-1), labels = nombres)\n# valores originales\npr_test = factor(y_test_iris, levels = 0:0:(length(nombres)-1), labels = nombres)\n\nEn los problemas de clasificación el objetivo es predecir correctamente la categoría de clasificación de cada observación. Así pues, las métricas naturales para evaluar estos modelos estarán basadas en contabilizar las coincidencias entre la clasificación correcta y la conseguida o predicha con el modelo.\nSe pueden obtener muchas métricas relacionadas con la matriz de confusión entre las que destaca el porcentaje de clasificación correcta ponderado que es el utilizado cuando las categorias de la respuesta están desequilibradas, es decir, sus tamaños son muy diferentes. Para obtener la matriz de confusión utilizamos la librería cvms que dispone de la función confusion_matrix que nos permite seleccionar entre las métricas siguientes:\n\n\n\nMetric\nName\nDefault\n\n\n\n\nBalanced Accuracy\n“Balanced Accuracy”\nEnabled\n\n\nAccuracy\n“Accuracy”\nDisabled\n\n\nWeighted Accuracy\n“Weighted Accuracy”\nDisabled\n\n\nF1\n“F1”\nEnabled\n\n\nSensitivity\n“Sensitivity”\nEnabled\n\n\nSpecificity\n“Specificity”\nEnabled\n\n\nPositive Predictive Value\n“Pos Pred Value”\nEnabled\n\n\nNegative Predictive Value\n“Neg Pred Value”\nEnabled\n\n\nKappa\n“Kappa”\nEnabled\n\n\nMatthews Correlation Coefficient\n“MCC”\nEnabled\n\n\nDetection Rate\n“Detection Rate”\nEnabled\n\n\nDetection Prevalence\n“Detection Prevalence”\nEnabled\n\n\nPrevalence\n“Prevalence”\nEnabled\n\n\nFalse Negative Rate\n“False Neg Rate”\nDisabled\n\n\nFalse Positive Rate\n“False Pos Rate”\nDisabled\n\n\nFalse Discovery Rate\n“False Discovery Rate”\nDisabled\n\n\nFalse Omission Rate\n“False Omission Rate”\nDisabled\n\n\nThreat Score\n“Threat Score”\nDisabled\n\n\n\nEn este caso utilizamos como métrica el porcentaje de clasificación correcta ponderada. En primer lugar mostramos los resultados globales, el resultado para la métrica de interés, y la representación gráfica de la matriz de confusión.\n\nlibrary(cvms)\ncm <- confusion_matrix(pr_test, pr_modelo,\n  metrics = list(\"Weighted Accuracy\" = TRUE)\n)\n# Matriz de confusión\ncm$Table\n\n[[1]]\n                 Target\nPrediction        Iris-setosa Iris-versicolor Iris-virginica\n  Iris-setosa              10               1              0\n  Iris-versicolor           0               2              1\n  Iris-virginica            0               8              8\n\n\nPodemos acceder a la métrica de interés con:\n\n# Global\ncm$`Weighted Accuracy`\n\n[1] 0.7766667\n\n# individuales para cada clase\ncm[[3]][[1]][,c(\"Class\", \"Balanced Accuracy\",\"Accuracy\")]\n\n# A tibble: 3 × 3\n  Class           `Balanced Accuracy` Accuracy\n  <chr>                         <dbl>    <dbl>\n1 Iris-setosa                   0.975    0.967\n2 Iris-versicolor               0.565    0.667\n3 Iris-virginica                0.754    0.7  \n\n\n¿Cómo interpretamos los resultados obtenidos de forma global y particular?. Veamos la matriz de confusión para detectar donde se producen las discrepancias en la clasificación:\n\nplot_confusion_matrix(cm$`Confusion Matrix`[[1]])\n\n\n\n\nMatriz de confusión. Datos Iris\n\n\n\n\n¿que podemos comentar sobre la matriz de confusión?\nPara finalizar vamos a representar la clasificación individual de cada una de las muestras de validación. Para esta faena creamos una función que nos proporciona un dataframe con los datos necesarios para el análisis individual de cada sujeto a partir de la matriz de las predicciones obtenida anteriormente.\n\ngenera_dat_indiv = function(dfpred, clases, eti_test){\n  # Función para generar banco de datos para el análisis individual de la predicción\n  \n  # Valores de entrada\n  #   dfpred: matriz numérica con las predicciones de cada clase\n  #   clases: etiquetas con los nombres de las clases\n  #   eti_test: etiquetas de la respuesta en la muestra de test\n  \n  # Valores de salida\n  #   dataframe con columnas: \n  #      sample: sujeto (repetido tantas veces como clases)\n  #      class: clase \n  #      probability: probabilidad predicha de la clase\n  #      target: clase observada  (repetido tantas veces como clases)\n  #      coincidencia: vector para saber cuando coinciden clase original y predicha\n  #      max: probabilidad máxima observada asignada a la clase predicha \n  \n  # Número de muestras\n  nval = nrow(dfpred)\n  # Número de clases \n  nclases = length(clases)\n  # Convertimos data.frame y asignamos nombres a las columnas\n  df = as.data.frame(dfpred)\n  colnames(df) = clases\n  # Añadimos el sujeto\n  df[\"sample\"] = 1:nval\n  # preparamos los datos para el gráfico desdoblando el data frame\n  pred_gr = df %>%\n  pivot_longer(\n    cols = !sample, \n    names_to = \"class\", \n    values_to = \"probability\"\n  )\n  # Añadimos target\n  pred_gr[\"target\"] = rep(eti_test, each = nclases)\n  # máximo de probabilidad\n  pred_gr[\"max\"] = rep(apply(df[,1:nclases],1,max), each = nclases)\n  # condiciones lógicas para selección de casos\n  sel1 = (pred_gr[\"class\"] == pred_gr[\"target\"])      # igualdad entre clase observada y predicha\n  sel2 = (pred_gr[\"probability\"] == pred_gr[\"max\"])   # posición donde registrar probabilidad máxima\n  # Identifica muestras en als que la clasificación coincide con el target\n  pred_gr[\"coincidencia\"] = ((sel1 == TRUE) & (sel2 == TRUE))\n  # Calculo de probabilidad máxima asiganda a la categoria predicha\n  pred_gr[\"max\"] = pred_gr[\"max\"]*sel2\n  return(pred_gr)\n}\n\nObtenemos los datos con la función anterior e identificamos las muestras en las que la predicción no coincide con el valor observado:\n\n# Datos\ndatos_pred = genera_dat_indiv(prediccion, nombres, pr_test)\n# datos de observaciones que no coinciden\ndatos_pred[(datos_pred$max>0) & (datos_pred$coincidencia == FALSE), c(\"sample\", \"class\", \"probability\", \"target\")]\n\n# A tibble: 10 × 4\n   sample class           probability target         \n    <int> <chr>                 <dbl> <fct>          \n 1      4 Iris-virginica        0.392 Iris-versicolor\n 2      5 Iris-virginica        0.644 Iris-versicolor\n 3      7 Iris-virginica        0.498 Iris-versicolor\n 4     15 Iris-virginica        0.503 Iris-versicolor\n 5     17 Iris-setosa           0.363 Iris-versicolor\n 6     19 Iris-virginica        0.429 Iris-versicolor\n 7     20 Iris-virginica        0.443 Iris-versicolor\n 8     22 Iris-versicolor       0.461 Iris-virginica \n 9     26 Iris-virginica        0.414 Iris-versicolor\n10     28 Iris-virginica        0.445 Iris-versicolor\n\n\nAhora podemos representar el comportamiento de cada muestra mediante un gráfico de barras con las probabilidades de clasificación de cada clase. Para hacer esto definimos una función donde debemos incorporar los datos de predicción que hemos preparado antes y el índice de la muestra que queremos representar. La función representa mediante barras azules las probabilidades de asignación, barra de color verde a la probabilidad más alta cuando la predicción de clase coincide con el original, y en color rojo a la probabilidad más alta cuando la predicción de clase no coincide con el original.\n\ngrafica_clf = function(datos,idx)\n{\n  # Datos de un sujeto\n  dfsel = datos[datos$sample==idx,]\n  # Gráfico\n  if(sum(dfsel$coincidencia)==1)\n  {\n  ggplot(dfsel, aes(class, probability)) + \n      geom_bar(stat=\"identity\", fill = \"blue\") +\n      scale_y_continuous(breaks = seq(0,1,0.1), limits=c(0,1)) +\n      geom_bar(aes(target, max), fill=\"red\", stat=\"identity\") +\n      geom_bar(aes(target[coincidencia], max[coincidencia]), fill=\"green\", stat=\"identity\", na.rm = TRUE) +\n      theme(legend.position = \"none\")\n  }\n  else{\n  ggplot(dfsel, aes(class, probability)) + \n      geom_bar(stat=\"identity\", fill = \"blue\") +\n      scale_y_continuous(breaks = seq(0,1,0.1), limits=c(0,1)) +\n      geom_bar(aes(target, max), fill=\"red\", stat=\"identity\") +\n      theme(legend.position = \"none\")    \n  }\n}\n\nRepresentamos todas las muestras:\n\ngraf = list()\nfor (i in 1:length(y_test_iris))\n{\n  graf[[i]] = grafica_clf(datos_pred, i)\n}\nggarrange(plotlist=graf,ncol=5,nrow=6)\n\n\n\n\nClasificación. Datos Iris\n\n\n\n\n¿Qué muestras son clasificadas de forma incorrecta?\n\n\n3.2.1.5 Validación del modelo\nComo ya hemos visto, la solución obtenida depende de la muestra de entrenamiento y de las semillas prefijadas en el periodo de entrenamiento. Sin embargo, en las tareas de aprendizaje automático resulta necesario conocer la validez del modelo obtenido, y más concretamente la estabilidad de la solución propuesta utilizando métodos de validación cruzada.\nLos dos modelos de validación cruzada más habituales son Hold-out validation y K-fold cross-validation. Dado que el número de muestras de entrenamiento suele ser bastante elevado en los modelos de redes neuronales consideramos que el segundo de los métodos de validación puede resultar más adecuado porque además conseguimos acelerar el proceso de convergencia.\nEste método de validación consiste en dividir los datos en K particiones de igual tamaño. Para cada partición i, se entrena un modelo en las K - 1 particiones restantes y se evalúa en la partición i. La puntuación final es la media de las K puntuaciones obtenidas. Podemos estudiar así la variabilidad de la evaluación en las k particiones. Este método es útil cuando el rendimiento del modelo muestra una variación significativa en función de la división entrenamiento-prueba. Para realizar este proceso debemos establecer un procedimiento secuencial para la creación de los diferentes fold de datos, y considerar un función que nos permita explicitar el modelo de red (arquitectura y proceso de aprendizaje) que será el miso para todos los folds. En primer lugar vemos la función para estabecer el modelo que define la arquitectura de red y proceso de aprendizaje que vamos a utilizar. Por el momento la función no tiene ningún parámetro.\n\n# Función para la definición del modelo\nbuild_model = function()\n{\n  # Arquitectura del modelo\n  inicializador = initializer_glorot_normal(seed = 15)\n  modelo = keras_model_sequential() %>% \n    layer_dense(units = 20, activation = 'relu', input_shape = 4, kernel_initializer = inicializador) %>% \n    layer_dense(units = 3, activation = 'softmax', kernel_initializer = inicializador)\n  # Proceso de aprendizaje\n  modelo %>% compile(\n    loss = 'sparse_categorical_crossentropy',\n    optimizer = optimizer_sgd(),\n    metrics = c('accuracy')\n  )\n  # Devolvemos el modelo configurado\n  return(modelo)\n}\n\nPodemos ver como funciona la función con el código siguiente:\n\nmodelo = build_model()\nsummary(modelo)\n\nModel: \"sequential_1\"\n________________________________________________________________________________\n Layer (type)                       Output Shape                    Param #     \n================================================================================\n dense_3 (Dense)                    (None, 20)                      100         \n dense_2 (Dense)                    (None, 3)                       63          \n================================================================================\nTotal params: 163 (652.00 Byte)\nTrainable params: 163 (652.00 Byte)\nNon-trainable params: 0 (0.00 Byte)\n________________________________________________________________________________\n\n\nEl modelo es el mismo que hemos utilizado en el análisis del ejemplo. En este primer ejmeplo vamos a considerar \\(k=5\\) folds lo que supone que dividimos nuestra muestra original en 5 subconjuntos de 30 muestras, de forma que en cada iteración tenemos 30 observaciones para la muestra de validación y 120 para el entrenamiento. Definimos a continuación el proceso de entrenamiento y la evaluación del modelo para cada uno de los folds. Consideramos accuray y weight accuray como las métricas de valoración del modelo.\n\n# Establecemos número de folds\nfolds = 5\n# Tamaño de cada fold\nnfolds = nrow(iris)/folds\n# Variable que codifica cada fold\ncodfold = rep(1:folds,rep(nfolds, folds))\n# Generamos data frame con valores originales y el código del fold\ndf = cbind(iris, codfold)\n\nEn primer lugar vamos a verificar si todos los folds contienen valores de todas las clases que deseamos predecir, ya que sino el proceso de evaluación podría dar errores. Si esto ocurre se puede aumentar el tamaño del fold para evitar este problema.\n\ndf %>% group_by(codfold) %>% summarise(conteo = n_distinct(species))\n\n# A tibble: 5 × 2\n  codfold conteo\n    <int>  <int>\n1       1      3\n2       2      3\n3       3      3\n4       4      3\n5       5      3\n\n\nTodos los folds contienen observaciones de la tres especies. Definimos ahora un bucle que nos permite realizar el proceso de validación.\n\n# Predictoras y respuesta\nX_iris = dplyr::select(df, -c(\"species\",\"codfold\"))\n# Codificamos la respuesta numéricamente y restamos 1 ya los array  se incializan en ceor en python\ny_iris = as.numeric(df$species)-1\n\n# Inicializamos los vectores donde almacenamos las métricas de validación de los sucesivos modelos\nacc_mod = c()\nwacc_mod = c()\nmetricas = c()\n\n# Bucle para cada fold\nfor(i in 1:folds)\n{\n  # Índice para la muestra de test\n  test = (nfolds*(i-1) +1):(nfolds*i)\n  # Muestras de entrenamiento y test\n  xtrain = X_iris[-test,]\n  xtest = X_iris[test,]\n  ytrain = y_iris[-test]\n  ytest = y_iris[test]\n  # Estandarización\n  # Medias\n  mean_train = apply(xtrain, 2, mean)\n  # Desviaciones típicas\n  sd_train = apply(xtrain, 2, sd)\n  # Estandarizamos muestra de entrenamiento\n  xtrain = scale(xtrain, mean_train, sd_train)\n  # Estandarizamos muestra de validación\n  xtest = scale(xtest, mean_train, sd_train)\n  \n  # Modelo de red\n  modelo = build_model()\n  cat(\"Comienza el entrenamiento para el fold \", i, \"\\n\")\n  # Entrenamiento del modelo\n  history = modelo %>%  fit(xtrain, ytrain,  batch_size = 50, epochs = 10, verbose = FALSE)\n  # Evaluación del modelo\n  acc_mod[i] = (modelo %>% tensorflow::evaluate(xtest, ytest))[2]\n  # Predicción con el modelo\n  prediccion = modelo %>% predict(xtest)\n  # predicción del modelo\n  pr_modelo = factor((prediccion %>% k_argmax())$numpy(), levels = 0:(length(nombres)-1))\n  pr_test = factor(ytest, levels = 0:(length(nombres)-1))\n  wacc_mod[i] = confusion_matrix(pr_test, pr_modelo, metrics = list(\"Weighted Accuracy\" = TRUE))$`Weighted Accuracy`\n  metricas = rbind(metricas,c(i, acc_mod[i],wacc_mod[i]))\n  }\n\nComienza el entrenamiento para el fold  1 \n1/1 - 0s - loss: 1.0110 - accuracy: 0.3333 - 128ms/epoch - 128ms/step\n1/1 - 0s - 57ms/epoch - 57ms/step\nComienza el entrenamiento para el fold  2 \n1/1 - 0s - loss: 0.7185 - accuracy: 0.6333 - 127ms/epoch - 127ms/step\n1/1 - 0s - 44ms/epoch - 44ms/step\nComienza el entrenamiento para el fold  3 \n1/1 - 0s - loss: 0.9221 - accuracy: 0.5000 - 114ms/epoch - 114ms/step\n1/1 - 0s - 45ms/epoch - 45ms/step\nComienza el entrenamiento para el fold  4 \n1/1 - 0s - loss: 0.8709 - accuracy: 0.5333 - 130ms/epoch - 130ms/step\n1/1 - 0s - 68ms/epoch - 68ms/step\nComienza el entrenamiento para el fold  5 \n1/1 - 0s - loss: 0.9695 - accuracy: 0.4333 - 124ms/epoch - 124ms/step\n1/1 - 0s - 200ms/epoch - 200ms/step\n\ncolnames(metricas) = c(\"Fold\",\"Acc\",\"WAcc\")\nmetricas\n\n     Fold       Acc      WAcc\n[1,]    1 0.3333333 0.4966667\n[2,]    2 0.6333333 0.8266667\n[3,]    3 0.5000000 0.6700000\n[4,]    4 0.5333334 0.6877778\n[5,]    5 0.4333333 0.5733333\n\n\nDefinimos ahora una función para el análisis descriptivo de cada una de las métricas. la función proporciona la media, desviación típica, y los percentiles asociados.\n\ndescribe = function(dat)\n{\n  ds = data.frame(media = mean(dat), dt = sd(dat), \n                  p05 = quantile(dat, 0.05),\n                  p25 = quantile(dat, 0.25),\n                  p50 = quantile(dat, 0.50),\n                  p75 = quantile(dat, 0.75),\n                  p95 = quantile(dat, 0.95))\n  row.names(ds) = \"\"\n  return(ds)\n}\n\nVeamos los resultados:\n\n# Accuracy\ndescribe(metricas[,2])\n\n     media        dt       p05       p25 p50       p75       p95\n 0.4866667 0.1120516 0.3533333 0.4333333 0.5 0.5333334 0.6133333\n\n# WAccuracy\ndescribe(metricas[,3])\n\n     media        dt   p05       p25  p50       p75       p95\n 0.6508889 0.1249232 0.512 0.5733333 0.67 0.6877778 0.7988889\n\n\n¿Cómo interpretamos los resultados obtenidos para ambas métricas?\n\n\n\n3.2.2 Datos Digits\nEste conjunto de datos trata el problema de reconocimiento de números escritos a mano. El conjunto de datos MNIST está formado por imágenes de dígitos escritos a mano. Este conjunto de datos contiene 60000 muestras para entrenar el modelo y 1000 adicionales para testearlo, y es ideal para adentrarse por primera vez en técnicas de reconocimiento de patrones sin tener que dedicar mucho tiempo al preproceso y formateado de datos. Ambos son muy importantes y costosos en el análisis de datos, y de especial complejidad cuando se está trabajando con imágenes. Este conjunto de datos solo requiere pequeñas transformaciones que comentaremos a continuación. El conjunto de imágenes, originales en blanco y negro, han sido normalizadas a 20 x 20 píxeles, y conservan su relación de aspecto. En este caso, es importante notar que las imágenes contienen niveles de grises como resultado de la técnica de anti-aliasing, usada en el algoritmo de normalización (reducir la resolución de todas las imágenes). Posteriormente, las imágenes se han centrado en 28 x 28 píxeles -se calcula el centro de masa de estos y se traslada la imagen con el fin de posicionar este punto en el centro del campo de 28 x 28-. Estas imágenes, de entrada, se representan en una matriz con las intensidades de cada uno de los 28 x 28 píxeles con valores entre [0, 255]. Además, el conjunto de datos dispone de una etiqueta para cada una de las imágenes, que indica qué dígito representa (entre el 0 y el 9), es decir, a qué clase corresponde. En este ejemplo, vamos a representar esta etiqueta con un vector de 1 0 posiciones, donde la posición correspondiente al dígito que representa la imagen contiene un 1, y el resto son 0.\nEn primer lugar cargamos los datos que se encuentra disponibles dentro de la librería Keras. Este objeto contiene dos listas mnist$train y mnist$test. Estas a su vez contienen dos elementos, 2 arrays, mnist$train$x con las imágenes y mnist$train$y con las etiquetas de cada una, o dicho de otra forma, el número que aparece en la imagen.\n\n# Cargamos datos\nmnist <- keras::dataset_mnist()\n# División de muestras entrenamiento y validación\nx_train <- mnist$train$x\ny_train <- mnist$train$y\nx_test <- mnist$test$x\ny_test <- mnist$test$y\n# Etiquetas\netiquetas = 0:9\n\nPodemos acceder a la matriz de inputs correspondiente al primer elemento de la muestra de entrenamiento y al target correspondiente con:\n\n# Input\nx_train[1,,]\n\n      [,1] [,2] [,3] [,4] [,5] [,6] [,7] [,8] [,9] [,10] [,11] [,12] [,13]\n [1,]    0    0    0    0    0    0    0    0    0     0     0     0     0\n [2,]    0    0    0    0    0    0    0    0    0     0     0     0     0\n [3,]    0    0    0    0    0    0    0    0    0     0     0     0     0\n [4,]    0    0    0    0    0    0    0    0    0     0     0     0     0\n [5,]    0    0    0    0    0    0    0    0    0     0     0     0     0\n [6,]    0    0    0    0    0    0    0    0    0     0     0     0     3\n [7,]    0    0    0    0    0    0    0    0   30    36    94   154   170\n [8,]    0    0    0    0    0    0    0   49  238   253   253   253   253\n [9,]    0    0    0    0    0    0    0   18  219   253   253   253   253\n[10,]    0    0    0    0    0    0    0    0   80   156   107   253   253\n[11,]    0    0    0    0    0    0    0    0    0    14     1   154   253\n[12,]    0    0    0    0    0    0    0    0    0     0     0   139   253\n[13,]    0    0    0    0    0    0    0    0    0     0     0    11   190\n[14,]    0    0    0    0    0    0    0    0    0     0     0     0    35\n[15,]    0    0    0    0    0    0    0    0    0     0     0     0     0\n[16,]    0    0    0    0    0    0    0    0    0     0     0     0     0\n[17,]    0    0    0    0    0    0    0    0    0     0     0     0     0\n[18,]    0    0    0    0    0    0    0    0    0     0     0     0     0\n[19,]    0    0    0    0    0    0    0    0    0     0     0     0     0\n[20,]    0    0    0    0    0    0    0    0    0     0     0     0    39\n[21,]    0    0    0    0    0    0    0    0    0     0    24   114   221\n[22,]    0    0    0    0    0    0    0    0   23    66   213   253   253\n[23,]    0    0    0    0    0    0   18  171  219   253   253   253   253\n[24,]    0    0    0    0   55  172  226  253  253   253   253   244   133\n[25,]    0    0    0    0  136  253  253  253  212   135   132    16     0\n[26,]    0    0    0    0    0    0    0    0    0     0     0     0     0\n[27,]    0    0    0    0    0    0    0    0    0     0     0     0     0\n[28,]    0    0    0    0    0    0    0    0    0     0     0     0     0\n      [,14] [,15] [,16] [,17] [,18] [,19] [,20] [,21] [,22] [,23] [,24] [,25]\n [1,]     0     0     0     0     0     0     0     0     0     0     0     0\n [2,]     0     0     0     0     0     0     0     0     0     0     0     0\n [3,]     0     0     0     0     0     0     0     0     0     0     0     0\n [4,]     0     0     0     0     0     0     0     0     0     0     0     0\n [5,]     0     0     0     0     0     0     0     0     0     0     0     0\n [6,]    18    18    18   126   136   175    26   166   255   247   127     0\n [7,]   253   253   253   253   253   225   172   253   242   195    64     0\n [8,]   253   253   253   253   251    93    82    82    56    39     0     0\n [9,]   253   198   182   247   241     0     0     0     0     0     0     0\n[10,]   205    11     0    43   154     0     0     0     0     0     0     0\n[11,]    90     0     0     0     0     0     0     0     0     0     0     0\n[12,]   190     2     0     0     0     0     0     0     0     0     0     0\n[13,]   253    70     0     0     0     0     0     0     0     0     0     0\n[14,]   241   225   160   108     1     0     0     0     0     0     0     0\n[15,]    81   240   253   253   119    25     0     0     0     0     0     0\n[16,]     0    45   186   253   253   150    27     0     0     0     0     0\n[17,]     0     0    16    93   252   253   187     0     0     0     0     0\n[18,]     0     0     0     0   249   253   249    64     0     0     0     0\n[19,]     0    46   130   183   253   253   207     2     0     0     0     0\n[20,]   148   229   253   253   253   250   182     0     0     0     0     0\n[21,]   253   253   253   253   201    78     0     0     0     0     0     0\n[22,]   253   253   198    81     2     0     0     0     0     0     0     0\n[23,]   195    80     9     0     0     0     0     0     0     0     0     0\n[24,]    11     0     0     0     0     0     0     0     0     0     0     0\n[25,]     0     0     0     0     0     0     0     0     0     0     0     0\n[26,]     0     0     0     0     0     0     0     0     0     0     0     0\n[27,]     0     0     0     0     0     0     0     0     0     0     0     0\n[28,]     0     0     0     0     0     0     0     0     0     0     0     0\n      [,26] [,27] [,28]\n [1,]     0     0     0\n [2,]     0     0     0\n [3,]     0     0     0\n [4,]     0     0     0\n [5,]     0     0     0\n [6,]     0     0     0\n [7,]     0     0     0\n [8,]     0     0     0\n [9,]     0     0     0\n[10,]     0     0     0\n[11,]     0     0     0\n[12,]     0     0     0\n[13,]     0     0     0\n[14,]     0     0     0\n[15,]     0     0     0\n[16,]     0     0     0\n[17,]     0     0     0\n[18,]     0     0     0\n[19,]     0     0     0\n[20,]     0     0     0\n[21,]     0     0     0\n[22,]     0     0     0\n[23,]     0     0     0\n[24,]     0     0     0\n[25,]     0     0     0\n[26,]     0     0     0\n[27,]     0     0     0\n[28,]     0     0     0\n\n# Target\ny_train[1]\n\n[1] 5\n\n\nAhora definimos una función que nos permite representar gráficamente la información contenida en cada uno de los elementos de entrenamiento.\n\npinta_digit = function(datos, idx)\n{\n  ## Valores de entrada\n  #    datos: matriz de datos de inputs\n  #    idx: muestra seleccionada\n  ## Valores de salida\n  #    gráfico de intensidad en escala de grises de la información contenida en la muestra idx de la matriz de inputs  \n  datos[idx, , ] %>%\n    #transformar a dataframe\n    as.data.frame() %>%\n    # agregar el ide de la columna\n    # para identificar la posición de cada pixel\n    rowid_to_column(var = \"y\") %>%\n    # reshape del dataframe\n    gather(\"x\", \"value\", -y) %>%\n    # volviendo la variable x numerica\n    mutate(x = parse_number(x)) %>%\n    # gráfico de tiles\n    ggplot(aes(x = x, y = y, fill = value)) + \n      geom_tile(show.legend = FALSE) +\n      scale_y_reverse() +\n      scale_fill_gradient(low = \"white\", high = \"black\") +\n      theme_void() \n}\n\nVeamos su funcionamiento sobre la primera muestra de la matriz de inputs de entrenamiento\n\npinta_digit(x_train, 1)\n\n\n\n\nEl resultado se corresponde con el valor etiquetado en ytrain[1] que es un 5. Representamos la información de los 100 primeras muestras de entrenamiento\n\n# Realizamos los gráficos y los cargamos en una lista\ngr = list()\nfor(i in 1:100)\n{\n  gr[[i]] = pinta_digit(x_train, i)\n}\n# Representamos todos los gráficos\nggarrange(plotlist=gr, ncol = 10, nrow = 10)\n\n\n\n\nVeamos con que dígito se corresponde cada uno de ellos:\n\ny_train[1:100]\n\n  [1] 5 0 4 1 9 2 1 3 1 4 3 5 3 6 1 7 2 8 6 9 4 0 9 1 1 2 4 3 2 7 3 8 6 9 0 5 6\n [38] 0 7 6 1 8 7 9 3 9 8 5 9 3 3 0 7 4 9 8 0 9 4 1 4 4 6 0 4 5 6 1 0 0 1 7 1 6\n [75] 3 0 2 1 1 7 9 0 2 6 7 8 3 9 0 4 6 7 4 6 8 0 7 8 3 1\n\n\n\n3.2.2.1 Arquitectura de la red\nAntes de comenzar a describir la arquitectura de la red neuronal para este ejemplo vamos a normalizar los inputs a la escala 0-1 para facilitar que la red converja más rápidamente.\n\n# Reescalamos para tener entradas en el intervalo 0-1\nx_train <- x_train / 255\nx_test <- x_test / 255\n\nPara definir la arquitectura de la red en este caso debemos tener en cuenta que el input de cada muestra es una matriz (array) de dimensiones 28x28 y no un cevtor como en el primer ejemplo. Para facilitar el trabajo de la red neuronal lo más habitual es introducir para cada muestra un vector de inputs, por lo que es necesario reconvertir la entrada en un vector. Esto se puede hacer de dos formas:\n\nConvertir la matriz 28x28 en una vector con 784 elementos mediante la función array_reshape.\nIntroducir en la arquitectura una capa de preprocesado layer_faltten que convierte la matriz de input en un vector de forma automática.\n\nEn este caso vamos a optar por esta opción para la manipulación de datos. Luego se especifican dos capas dense, en la primera se establece la cantidad de nodos o neuronas de la red y la función de activación. En este caso se usa una de las más comunes, la función de activación ReLU.\nEn la segunda capa dense, la capa del output, se especifican los nodos de salida, uno por cada categoría probable, y al tratarse de números del 0 al 9 se especifican 10, El segundo argumento de esta capa hace que el resultado del modelo sea un array con 10 valores de probabilidad que suma uno. En este caso el nodo de la categoría que tenga el mayor score termina siendo la predicción.\n\ninicializador = initializer_glorot_normal(seed = 15)\n\nmodelo_digits = keras_model_sequential() %>% \n    layer_flatten(input_shape = c(28, 28)) %>% \n    layer_dense(units = 32, activation = \"relu\", kernel_initializer = inicializador) %>% \n    layer_dense(10, activation = \"softmax\", kernel_initializer = inicializador)\n\nVeamos el número de parámetros de este modelo\n\nsummary(modelo_digits)\n\nModel: \"sequential_7\"\n________________________________________________________________________________\n Layer (type)                       Output Shape                    Param #     \n================================================================================\n flatten (Flatten)                  (None, 784)                     0           \n dense_15 (Dense)                   (None, 32)                      25120       \n dense_14 (Dense)                   (None, 10)                      330         \n================================================================================\nTotal params: 25450 (99.41 KB)\nTrainable params: 25450 (99.41 KB)\nNon-trainable params: 0 (0.00 Byte)\n________________________________________________________________________________\n\n\nEl número de parámetros es 25450 a pesar de la sencillez de la red.\n\n\n3.2.2.2 Proceso de aprendizaje\nDefinimos ahora el proceso de aprendizaje con la misma configuración que en el ejemplo anterior\n\nmodelo_digits %>% compile(\n  loss = 'sparse_categorical_crossentropy',\n  optimizer = optimizer_sgd(),\n  metrics = c('accuracy')\n)\n\n\n\n3.2.2.3 Entrenamiento del modelo\nPara el proceso de entrenamiento consideramos batch_size de 50 y 10 epochs. En este caso hay un número bastante grande de muestras de entrenamiento y es necesario hacer bloques para que el algoritmo pueda estimar los parámetros de la red.\n\nhistory_digits = modelo_digits %>% \n  fit(x_train, y_train, batch_size = 50, epochs = 10)\n\nEpoch 1/10\n1200/1200 - 3s - loss: 0.8719 - accuracy: 0.7737 - 3s/epoch - 2ms/step\nEpoch 2/10\n1200/1200 - 2s - loss: 0.4072 - accuracy: 0.8886 - 2s/epoch - 2ms/step\nEpoch 3/10\n1200/1200 - 2s - loss: 0.3470 - accuracy: 0.9019 - 2s/epoch - 2ms/step\nEpoch 4/10\n1200/1200 - 2s - loss: 0.3174 - accuracy: 0.9093 - 2s/epoch - 2ms/step\nEpoch 5/10\n1200/1200 - 2s - loss: 0.2978 - accuracy: 0.9153 - 2s/epoch - 2ms/step\nEpoch 6/10\n1200/1200 - 2s - loss: 0.2825 - accuracy: 0.9195 - 2s/epoch - 2ms/step\nEpoch 7/10\n1200/1200 - 2s - loss: 0.2698 - accuracy: 0.9231 - 2s/epoch - 2ms/step\nEpoch 8/10\n1200/1200 - 2s - loss: 0.2587 - accuracy: 0.9264 - 2s/epoch - 2ms/step\nEpoch 9/10\n1200/1200 - 2s - loss: 0.2487 - accuracy: 0.9297 - 2s/epoch - 2ms/step\nEpoch 10/10\n1200/1200 - 2s - loss: 0.2398 - accuracy: 0.9315 - 2s/epoch - 2ms/step\n\n\nLos resultados finales del entrenamiento los podemos ver con:\n\nhistory_digits\n\n\nFinal epoch (plot to see history):\n    loss: 0.2398\naccuracy: 0.9315 \n\n\nEl porcentaje de clasificación correcta es muy alta incluso con una red tan sencilla. Vemos los resultados del proceso iterativa gráficamente\n\nplot(history_digits) + ylim(0,1)\n\n\n\n\nProceso de aprendizaje. Datos Iris\n\n\n\n\n¿qué podemos decir?\n\n\n3.2.2.4 Evaluación del modelo\nUna vez entrenada la red neuronal llega el momento de evaluar como se comporta con los datos de validación. Veamos los resultados para nuestro banco de datos.\n\nmodelo_digits %>% tensorflow::evaluate(x_test, y_test)\n\n313/313 - 0s - loss: 0.2310 - accuracy: 0.9335 - 449ms/epoch - 1ms/step\n\n\n     loss  accuracy \n0.2309539 0.9335000 \n\n\n¿Cómo interpretamos el valor obtenido?\nObtenemos ahora las predicciones asociadas para conseguir la matriz de confusión y la métrica de interés.\n\n# probabilidades de clasificación de cada muestra en cada especie \nprediccion = modelo_digits %>% predict(x_test)\n\n313/313 - 0s - 335ms/epoch - 1ms/step\n\n# predicción del modelo\npr_modelo = factor((prediccion %>% k_argmax())$numpy(), levels = 0:(length(etiquetas)-1))\npr_test = factor(y_test, levels = 0:(length(etiquetas)-1))\n# matriz de confusion\ncm <- confusion_matrix(y_test, pr_modelo, metrics = list(\"Weighted Accuracy\" = TRUE))\n# Matriz de confusión\ncm$Table\n\n[[1]]\n          Target\nPrediction    0    1    2    3    4    5    6    7    8    9\n         0  962    0    7    3    1   10   10    1    6   10\n         1    0 1115    7    1    2    3    3   10    8    8\n         2    2    2  943   24    7    5    4   27    4    1\n         3    1    2   16  917    0   32    1    2   18   11\n         4    0    0    9    1  922    7    9    5    8   32\n         5    2    1    1   23    0  786    7    0   14    4\n         6   10    4   11    2   10   21  922    0   14    1\n         7    1    2   10   10    3    5    0  954   10   10\n         8    1    9   25   18    4   15    2    3  888    6\n         9    1    0    3   11   33    8    0   26    4  926\n\n# Métrica global\ncm$`Weighted Accuracy`\n\n[1] 0.9867928\n\n# individuales para cada clase\ncm[[3]][[1]][,c(\"Class\", \"Balanced Accuracy\",\"Accuracy\")]\n\n# A tibble: 10 × 3\n   Class `Balanced Accuracy` Accuracy\n   <chr>               <dbl>    <dbl>\n 1 0                   0.988    0.993\n 2 1                   0.989    0.994\n 3 2                   0.953    0.984\n 4 3                   0.949    0.982\n 5 4                   0.966    0.987\n 6 5                   0.938    0.984\n 7 6                   0.977    0.989\n 8 7                   0.961    0.988\n 9 8                   0.951    0.983\n10 9                   0.954    0.983\n\n\n\nplot_confusion_matrix(cm$`Confusion Matrix`[[1]])\n\n\n\n\nMatriz de confusión\n\n\n\n\n¿Qué podemos comentar de la matriz de confusión obtenida?\nVisualizamos el análisis individual de la clasificación para las primeras muestras de test igual que hicimos con el ejemplo de iris. En primer lugar obtenemos los datos para la representación gráfica.\n\n# Datos\ndatos_pred = genera_dat_indiv(prediccion, etiquetas, pr_test)\n# datos de observaciones que no coinciden\ndatos_pred[(datos_pred$max>0) & (datos_pred$coincidencia == FALSE), c(\"sample\", \"class\", \"probability\", \"target\")]\n\n# A tibble: 665 × 4\n   sample class probability target\n    <int> <chr>       <dbl> <fct> \n 1      9 6           0.976 5     \n 2     34 6           0.664 4     \n 3     64 2           0.620 3     \n 4     93 4           0.396 9     \n 5    125 4           0.616 7     \n 6    150 9           0.574 2     \n 7    194 3           0.320 9     \n 8    196 8           0.292 3     \n 9    212 7           0.464 5     \n10    234 7           0.553 8     \n# ℹ 655 more rows\n\n\nRepresentamos las 16 primeras muestras de tests:\n\nngraf = 16\ngraf = list()\nfor (i in 1:ngraf)\n{\n  graf[[i]] = grafica_clf(datos_pred, i)\n}\nggarrange(plotlist=graf, ncol = 4, nrow = 4)\n\n\n\n\nClasificación. Datos Iris\n\n\n\n\n¿qué podemos decir de los gráficos obtenidos?\n\n\n3.2.2.5 Validación del modelo\nEn este caso el proceso de validación es similar al del ejemplo anterior seleccionando los folds sobre las matrices de inputs y el vector de target combinando tanto los datos de entrenamiento como los de test. El código siguiente nos permite combinar ambos conjuntos en uno solo tanto en los inputs como en el output.\n\n# Calculamos dimensiones\ndm_train = dim(x_train)[1]\ndm_test = dim(x_test)[1]\ndm = dm_train + dm_test\n# matriz de inputs completo\nx_digits = array(0, dim= c(dm, 28, 28))\nx_digits[1:dm_train,,] = x_train\nx_digits[(dm_train+1):dm,,] = x_test\n# vector de output completo\ny_digits = c(y_train, y_test)\n# Barajamos los datos: \nset.seed(123)\norder = slice_sample(as.data.frame(1:length(y_digits)),n=length(y_digits))$`1:length(y_digits)`\n# Reordenamos los datos\nx_digits = x_digits[order,,]\ny_digits = y_digits[order]\n\nEn primer lugar generamos la función que nos permite establecer la arquitectura de la red:\n\n# Función para la definición del modelo\nbuild_model_digits = function()\n{\n  # Arquitectura del modelo\n  modelo = keras_model_sequential() %>% \n      layer_flatten(input_shape = c(28, 28)) %>% \n      layer_dense(units = 32, activation = \"relu\", kernel_initializer = inicializador) %>% \n      layer_dense(10, activation = \"softmax\", kernel_initializer = inicializador)\n  modelo %>% compile(\n    loss = 'sparse_categorical_crossentropy',\n    optimizer = optimizer_sgd(),\n    metrics = c('accuracy')\n  )\n  # Devolvemos el modelo configurado\n  return(modelo)\n}\n\nAhora debemos establecer el número de folds y el tamaño de cada uno de ellos. En este caso optamos por \\(k=7\\) folds para mantener los tamaños de las muestras de entrenamiento y validación que hemos utilizado en el modelo de partida.\n\n# Inicializamos los vectores donde almacenamos las métricas de validación de los sucesivos modelos\nacc_mod = c()\nwacc_mod = c()\nmetricas = c()\n\n# Establecemos número de folds\nfolds = 7\n# Tamaño de cada fold\nnfolds = length(y_digits)/folds\n\n# Bucle pra cada fold\nfor(i in 1:folds)\n{\n  # Índice para la muestra de test\n  test = (nfolds*(i-1) +1):(nfolds*i)\n  # Muestras de entrenamiento y test\n  xtrain = x_digits[-test,,]\n  xtest = x_digits[test,,]\n  ytrain = y_digits[-test]\n  ytest = y_digits[test]\n    # Modelo de red\n  modelo = build_model_digits()\n  cat(\"Comienza el entrenamiento para el fold \", i, \"\\n\")\n  # Entrenamiento del modelo\n  history = modelo %>%  fit(xtrain, ytrain,  batch_size = 50, epochs = 10, verbose = FALSE)\n  # Evaluación del modelo\n  acc_mod[i] = (modelo %>% tensorflow::evaluate(xtest, ytest))[2]\n  # Predicción con el modelo\n  prediccion = modelo %>% predict(xtest)\n  # predicción del modelo\n  pr_modelo = factor((prediccion %>% k_argmax())$numpy(), levels = 0:(length(etiquetas)-1))\n  pr_test = factor(y_test, levels = 0:(length(etiquetas)-1))\n  wacc_mod[i] = confusion_matrix(pr_test, pr_modelo, metrics = list(\"Weighted Accuracy\" = TRUE))$`Weighted Accuracy`\n  metricas = rbind(metricas, c(i,acc_mod[i],wacc_mod[i]))\n  }\n\nComienza el entrenamiento para el fold  1 \n313/313 - 0s - loss: 0.2513 - accuracy: 0.9276 - 411ms/epoch - 1ms/step\n313/313 - 0s - 297ms/epoch - 948us/step\nComienza el entrenamiento para el fold  2 \n313/313 - 0s - loss: 0.2438 - accuracy: 0.9282 - 406ms/epoch - 1ms/step\n313/313 - 0s - 292ms/epoch - 933us/step\nComienza el entrenamiento para el fold  3 \n313/313 - 0s - loss: 0.2468 - accuracy: 0.9261 - 443ms/epoch - 1ms/step\n313/313 - 0s - 323ms/epoch - 1ms/step\nComienza el entrenamiento para el fold  4 \n313/313 - 0s - loss: 0.2371 - accuracy: 0.9312 - 399ms/epoch - 1ms/step\n313/313 - 0s - 289ms/epoch - 924us/step\nComienza el entrenamiento para el fold  5 \n313/313 - 0s - loss: 0.2366 - accuracy: 0.9309 - 394ms/epoch - 1ms/step\n313/313 - 0s - 299ms/epoch - 956us/step\nComienza el entrenamiento para el fold  6 \n313/313 - 0s - loss: 0.2434 - accuracy: 0.9319 - 396ms/epoch - 1ms/step\n313/313 - 0s - 294ms/epoch - 939us/step\nComienza el entrenamiento para el fold  7 \n313/313 - 0s - loss: 0.2468 - accuracy: 0.9335 - 419ms/epoch - 1ms/step\n313/313 - 0s - 288ms/epoch - 920us/step\n\ncolnames(metricas) = c(\"Fold\",\"Acc\",\"WAcc\")\nmetricas\n\n     Fold    Acc      WAcc\n[1,]    1 0.9276 0.8199056\n[2,]    2 0.9282 0.8190394\n[3,]    3 0.9261 0.8193737\n[4,]    4 0.9312 0.8190675\n[5,]    5 0.9309 0.8186953\n[6,]    6 0.9319 0.8205304\n[7,]    7 0.9335 0.8204387\n\n\nVeamos los resultados:\n\n# Accuracy\ndescribe(metricas[,2])\n\n     media          dt     p05    p25    p50     p75     p95\n 0.9299143 0.002654191 0.92655 0.9279 0.9309 0.93155 0.93302\n\n# WAccuracy\ndescribe(metricas[,3])\n\n     media           dt       p05       p25       p50       p75       p95\n 0.8195787 0.0007218941 0.8187985 0.8190534 0.8193737 0.8201722 0.8205029\n\n\n¿Cómo interpretamos los resultados obtenidos para ambas métricas?"
  },
  {
    "objectID": "30_RMDDL.html#parámetros-e-hiperparámetros-de-la-red",
    "href": "30_RMDDL.html#parámetros-e-hiperparámetros-de-la-red",
    "title": "3  Redes multicapa densas con Keras",
    "section": "3.3 Parámetros e hiperparámetros de la red",
    "text": "3.3 Parámetros e hiperparámetros de la red\n¿Cuál es la diferencia entre un parámetro del modelo y un hiperparámetro? Los parámetros del modelo son internos a la red neuronal, por ejemplo, los pesos de las neuronas. Se estiman o aprenden automáticamente a partir de las muestras de entrenamiento. Estos parámetros también se utilizan para hacer predicciones en un modelo ya entrenado que se encuentra en producción.\nEn cambio, los hiperparámetros son parámetros externos al modelo en sí mismo, establecidos por el programador de la red neuronal; por ejemplo, podemos aumentar el número de epochs (veces que se usan todos los datos de entrenamiento), agregar más neuronas en una capa o agregar más capas, seleccionar qué función de activación usar o el tamaño de lote utilizado en el entrenamiento. Los hiperparámetros tienen un gran impacto en la precisión de una red neuronal y puede haber diferentes valores óptimos para diferentes hiperparámetros; descubrir esos valores no es algo trivial.\nLa forma más sencilla de seleccionar hiperparámetros para un modelo de red neuronal es «búsqueda manual»; en otras palabras, prueba y error. De todas maneras, están apareciendo algoritmos y métodos de optimización para descubrir los mejores hiperparámetros. Es importante mencionar que actualmente existen ya propuestas para ayudar al programador en este paso de búsqueda de hiperparámetros. En ellas se intenta automatizar este proceso: Hyperopt, Kopt, Talos o GPflowOpt. También en el escenario del Cloud Computing hay ya alguna propuesta, como Google Cloud.\nEn este apartado vamos a analizar el efecto de los hiperparámetros de la red que se establecen antes del proceso de entrenamiento de la red (antes de optimizar los pesos y sesgos), por lo que elegir sus valores adecuados deviene un paso esencial para conseguir un buen modelo. En primer lugar hacemos una revisión teórica de los conceptos más relevantes, para centrarnos más tarde es los aspectos prácticos de su aplicación y análisis.\n\n3.3.1 Grupos de hiperparámetros\nA grandes rasgos, los hiperparámetros de un modelo de red neuronal se pueden clasificar en dos grandes grupos:\n\nHiperparámetros a nivel de estructura y topología de la red neuronal: número de capas, número de neuronas por capa, sus funciones de activación, inicialización de los pesos, etc.\nHiperparámetros a nivel de algoritmo de aprendizaje: epochs, batch size, learning rate, etc.\n\nPara empezar veremos el efecto que tienen sobre las métricas de evaluación del modelo los hiperpárametros del segundo punto, y posteriormente veremos de forma introductoria el efecto de los del primer grupo.\nPara ver el efecto de los cambios de los hiperparámetros vamos a utilizar el banco de datos digits.\n\n3.3.1.1 A nivel de estructura y topologia\nComo el resultado del modelo obtenido en el punto anterior ya era bastante bueno vamos a considerar que la arquitectura de red mantiene el mismo número de capas pero vamos a ir modificando el tamaño de la capa intermedia y la función de activación. Analizamos el comportamiento de la red comparando el porcentaje global de clasificación correcta para cada red. Antes de mostrar el bucle de evaluación definimos una función para cargar cada modelo con parámetros el tamaño de la capa y la función de activación.\n\nbuild_model_digits = function(size, factiv)\n{\n# Función para la definición del modelo (arquitectura y proceso de aprendizaje)\n\n  #  Valores de entrada\n  #   size: número de neuronas en la capa input\n  #   factiv: función de activación de la capa input  \n  \n  # Valores de salida\n  #   modelo: modelo configurado\n  \n  # Arquitectura del modelo\n  modelo = keras_model_sequential() %>% \n      layer_flatten(input_shape = c(28, 28)) %>% \n      layer_dense(units = size, activation = factiv, kernel_initializer = inicializador) %>% \n      layer_dense(10, activation = 'softmax', kernel_initializer = inicializador)\n  # Proceso de aprendizaje\n  modelo %>% compile(\n    loss = 'sparse_categorical_crossentropy',\n    optimizer = optimizer_sgd(),\n    metrics = c('accuracy'))\nreturn(modelo)\n}\n\nPara la evaluación vamos a considerar que el número de neuronas es 16, 32, 64, y que las funciones de activación son relu, sigmoid, y tanh. A continuación se muestra el bucle de evaluación para todas las combinaciones prediseñadas.\n\n# Neuronas\nneuronas = c(16, 32, 64)\nfactiv = c('relu', 'sigmoid', 'tanh')\n# Lista donde almacenamos la accuracy de cada modelo\ncomparativa = c()\n\n\n# Bucle de evaluación\nfor (i in neuronas)\n{\n  for (j in factiv)\n  {\n    modelo = build_model_digits(i, j)\n    # Entrenamiento\n    history = modelo %>%  fit(x_train, y_train, batch_size = 50, epochs = 10)  \n    # Evaluación\n    valor = (modelo %>% tensorflow::evaluate(x_test, y_test))[2]\n    comparativa = rbind(comparativa,c(i,j,valor))\n  }\n}\n\nEpoch 1/10\n1200/1200 - 2s - loss: 0.9445 - accuracy: 0.7454 - 2s/epoch - 2ms/step\nEpoch 2/10\n1200/1200 - 2s - loss: 0.4372 - accuracy: 0.8816 - 2s/epoch - 2ms/step\nEpoch 3/10\n1200/1200 - 2s - loss: 0.3665 - accuracy: 0.8980 - 2s/epoch - 1ms/step\nEpoch 4/10\n1200/1200 - 2s - loss: 0.3348 - accuracy: 0.9046 - 2s/epoch - 1ms/step\nEpoch 5/10\n1200/1200 - 2s - loss: 0.3135 - accuracy: 0.9107 - 2s/epoch - 1ms/step\nEpoch 6/10\n1200/1200 - 2s - loss: 0.2981 - accuracy: 0.9147 - 2s/epoch - 2ms/step\nEpoch 7/10\n1200/1200 - 2s - loss: 0.2858 - accuracy: 0.9179 - 2s/epoch - 2ms/step\nEpoch 8/10\n1200/1200 - 2s - loss: 0.2758 - accuracy: 0.9212 - 2s/epoch - 2ms/step\nEpoch 9/10\n1200/1200 - 2s - loss: 0.2670 - accuracy: 0.9234 - 2s/epoch - 1ms/step\nEpoch 10/10\n1200/1200 - 2s - loss: 0.2592 - accuracy: 0.9258 - 2s/epoch - 2ms/step\n313/313 - 0s - loss: 0.2539 - accuracy: 0.9288 - 392ms/epoch - 1ms/step\nEpoch 1/10\n1200/1200 - 2s - loss: 1.9313 - accuracy: 0.5092 - 2s/epoch - 2ms/step\nEpoch 2/10\n1200/1200 - 2s - loss: 1.3834 - accuracy: 0.6990 - 2s/epoch - 2ms/step\nEpoch 3/10\n1200/1200 - 2s - loss: 1.0529 - accuracy: 0.7770 - 2s/epoch - 2ms/step\nEpoch 4/10\n1200/1200 - 2s - loss: 0.8528 - accuracy: 0.8195 - 2s/epoch - 2ms/step\nEpoch 5/10\n1200/1200 - 2s - loss: 0.7269 - accuracy: 0.8416 - 2s/epoch - 2ms/step\nEpoch 6/10\n1200/1200 - 2s - loss: 0.6422 - accuracy: 0.8566 - 2s/epoch - 2ms/step\nEpoch 7/10\n1200/1200 - 2s - loss: 0.5816 - accuracy: 0.8663 - 2s/epoch - 2ms/step\nEpoch 8/10\n1200/1200 - 2s - loss: 0.5360 - accuracy: 0.8735 - 2s/epoch - 1ms/step\nEpoch 9/10\n1200/1200 - 2s - loss: 0.5006 - accuracy: 0.8801 - 2s/epoch - 2ms/step\nEpoch 10/10\n1200/1200 - 2s - loss: 0.4723 - accuracy: 0.8845 - 2s/epoch - 2ms/step\n313/313 - 0s - loss: 0.4483 - accuracy: 0.8912 - 403ms/epoch - 1ms/step\nEpoch 1/10\n1200/1200 - 3s - loss: 1.0311 - accuracy: 0.7459 - 3s/epoch - 3ms/step\nEpoch 2/10\n1200/1200 - 2s - loss: 0.5428 - accuracy: 0.8727 - 2s/epoch - 2ms/step\nEpoch 3/10\n1200/1200 - 2s - loss: 0.4302 - accuracy: 0.8912 - 2s/epoch - 2ms/step\nEpoch 4/10\n1200/1200 - 2s - loss: 0.3788 - accuracy: 0.9004 - 2s/epoch - 2ms/step\nEpoch 5/10\n1200/1200 - 2s - loss: 0.3485 - accuracy: 0.9060 - 2s/epoch - 2ms/step\nEpoch 6/10\n1200/1200 - 2s - loss: 0.3272 - accuracy: 0.9101 - 2s/epoch - 2ms/step\nEpoch 7/10\n1200/1200 - 2s - loss: 0.3116 - accuracy: 0.9143 - 2s/epoch - 2ms/step\nEpoch 8/10\n1200/1200 - 2s - loss: 0.2990 - accuracy: 0.9169 - 2s/epoch - 2ms/step\nEpoch 9/10\n1200/1200 - 2s - loss: 0.2886 - accuracy: 0.9198 - 2s/epoch - 2ms/step\nEpoch 10/10\n1200/1200 - 2s - loss: 0.2796 - accuracy: 0.9224 - 2s/epoch - 2ms/step\n313/313 - 0s - loss: 0.2758 - accuracy: 0.9248 - 405ms/epoch - 1ms/step\nEpoch 1/10\n1200/1200 - 2s - loss: 0.8705 - accuracy: 0.7729 - 2s/epoch - 2ms/step\nEpoch 2/10\n1200/1200 - 2s - loss: 0.4073 - accuracy: 0.8877 - 2s/epoch - 2ms/step\nEpoch 3/10\n1200/1200 - 2s - loss: 0.3472 - accuracy: 0.9023 - 2s/epoch - 2ms/step\nEpoch 4/10\n1200/1200 - 2s - loss: 0.3177 - accuracy: 0.9095 - 2s/epoch - 2ms/step\nEpoch 5/10\n1200/1200 - 2s - loss: 0.2981 - accuracy: 0.9153 - 2s/epoch - 2ms/step\nEpoch 6/10\n1200/1200 - 2s - loss: 0.2830 - accuracy: 0.9188 - 2s/epoch - 2ms/step\nEpoch 7/10\n1200/1200 - 2s - loss: 0.2706 - accuracy: 0.9230 - 2s/epoch - 2ms/step\nEpoch 8/10\n1200/1200 - 2s - loss: 0.2595 - accuracy: 0.9266 - 2s/epoch - 2ms/step\nEpoch 9/10\n1200/1200 - 2s - loss: 0.2495 - accuracy: 0.9292 - 2s/epoch - 2ms/step\nEpoch 10/10\n1200/1200 - 2s - loss: 0.2404 - accuracy: 0.9318 - 2s/epoch - 2ms/step\n313/313 - 0s - loss: 0.2324 - accuracy: 0.9322 - 447ms/epoch - 1ms/step\nEpoch 1/10\n1200/1200 - 2s - loss: 1.8485 - accuracy: 0.5701 - 2s/epoch - 2ms/step\nEpoch 2/10\n1200/1200 - 2s - loss: 1.1923 - accuracy: 0.7631 - 2s/epoch - 2ms/step\nEpoch 3/10\n1200/1200 - 2s - loss: 0.8613 - accuracy: 0.8284 - 2s/epoch - 2ms/step\nEpoch 4/10\n1200/1200 - 2s - loss: 0.6939 - accuracy: 0.8503 - 2s/epoch - 2ms/step\nEpoch 5/10\n1200/1200 - 2s - loss: 0.5967 - accuracy: 0.8639 - 2s/epoch - 2ms/step\nEpoch 6/10\n1200/1200 - 2s - loss: 0.5333 - accuracy: 0.8729 - 2s/epoch - 2ms/step\nEpoch 7/10\n1200/1200 - 2s - loss: 0.4886 - accuracy: 0.8800 - 2s/epoch - 2ms/step\nEpoch 8/10\n1200/1200 - 2s - loss: 0.4554 - accuracy: 0.8852 - 2s/epoch - 2ms/step\nEpoch 9/10\n1200/1200 - 2s - loss: 0.4297 - accuracy: 0.8896 - 2s/epoch - 2ms/step\nEpoch 10/10\n1200/1200 - 2s - loss: 0.4092 - accuracy: 0.8929 - 2s/epoch - 2ms/step\n313/313 - 0s - loss: 0.3851 - accuracy: 0.8993 - 408ms/epoch - 1ms/step\nEpoch 1/10\n1200/1200 - 2s - loss: 0.8926 - accuracy: 0.7859 - 2s/epoch - 2ms/step\nEpoch 2/10\n1200/1200 - 2s - loss: 0.4658 - accuracy: 0.8809 - 2s/epoch - 2ms/step\nEpoch 3/10\n1200/1200 - 2s - loss: 0.3829 - accuracy: 0.8974 - 2s/epoch - 2ms/step\nEpoch 4/10\n1200/1200 - 2s - loss: 0.3422 - accuracy: 0.9061 - 2s/epoch - 2ms/step\nEpoch 5/10\n1200/1200 - 2s - loss: 0.3160 - accuracy: 0.9119 - 2s/epoch - 2ms/step\nEpoch 6/10\n1200/1200 - 2s - loss: 0.2968 - accuracy: 0.9172 - 2s/epoch - 2ms/step\nEpoch 7/10\n1200/1200 - 2s - loss: 0.2819 - accuracy: 0.9207 - 2s/epoch - 2ms/step\nEpoch 8/10\n1200/1200 - 2s - loss: 0.2693 - accuracy: 0.9249 - 2s/epoch - 2ms/step\nEpoch 9/10\n1200/1200 - 2s - loss: 0.2583 - accuracy: 0.9271 - 2s/epoch - 2ms/step\nEpoch 10/10\n1200/1200 - 2s - loss: 0.2489 - accuracy: 0.9302 - 2s/epoch - 2ms/step\n313/313 - 0s - loss: 0.2414 - accuracy: 0.9319 - 412ms/epoch - 1ms/step\nEpoch 1/10\n1200/1200 - 3s - loss: 0.8202 - accuracy: 0.7931 - 3s/epoch - 2ms/step\nEpoch 2/10\n1200/1200 - 2s - loss: 0.3919 - accuracy: 0.8924 - 2s/epoch - 2ms/step\nEpoch 3/10\n1200/1200 - 2s - loss: 0.3318 - accuracy: 0.9065 - 2s/epoch - 2ms/step\nEpoch 4/10\n1200/1200 - 2s - loss: 0.3002 - accuracy: 0.9152 - 2s/epoch - 2ms/step\nEpoch 5/10\n1200/1200 - 2s - loss: 0.2779 - accuracy: 0.9215 - 2s/epoch - 2ms/step\nEpoch 6/10\n1200/1200 - 2s - loss: 0.2603 - accuracy: 0.9265 - 2s/epoch - 2ms/step\nEpoch 7/10\n1200/1200 - 2s - loss: 0.2457 - accuracy: 0.9315 - 2s/epoch - 2ms/step\nEpoch 8/10\n1200/1200 - 2s - loss: 0.2333 - accuracy: 0.9343 - 2s/epoch - 2ms/step\nEpoch 9/10\n1200/1200 - 2s - loss: 0.2222 - accuracy: 0.9379 - 2s/epoch - 2ms/step\nEpoch 10/10\n1200/1200 - 2s - loss: 0.2124 - accuracy: 0.9407 - 2s/epoch - 2ms/step\n313/313 - 0s - loss: 0.2070 - accuracy: 0.9402 - 432ms/epoch - 1ms/step\nEpoch 1/10\n1200/1200 - 3s - loss: 1.7629 - accuracy: 0.6190 - 3s/epoch - 2ms/step\nEpoch 2/10\n1200/1200 - 2s - loss: 1.0283 - accuracy: 0.7999 - 2s/epoch - 2ms/step\nEpoch 3/10\n1200/1200 - 2s - loss: 0.7349 - accuracy: 0.8404 - 2s/epoch - 2ms/step\nEpoch 4/10\n1200/1200 - 2s - loss: 0.6013 - accuracy: 0.8596 - 2s/epoch - 2ms/step\nEpoch 5/10\n1200/1200 - 2s - loss: 0.5253 - accuracy: 0.8713 - 2s/epoch - 2ms/step\nEpoch 6/10\n1200/1200 - 2s - loss: 0.4760 - accuracy: 0.8797 - 2s/epoch - 2ms/step\nEpoch 7/10\n1200/1200 - 2s - loss: 0.4413 - accuracy: 0.8863 - 2s/epoch - 2ms/step\nEpoch 8/10\n1200/1200 - 2s - loss: 0.4156 - accuracy: 0.8911 - 2s/epoch - 2ms/step\nEpoch 9/10\n1200/1200 - 2s - loss: 0.3957 - accuracy: 0.8946 - 2s/epoch - 2ms/step\nEpoch 10/10\n1200/1200 - 2s - loss: 0.3798 - accuracy: 0.8974 - 2s/epoch - 2ms/step\n313/313 - 0s - loss: 0.3563 - accuracy: 0.9030 - 452ms/epoch - 1ms/step\nEpoch 1/10\n1200/1200 - 3s - loss: 0.8045 - accuracy: 0.7999 - 3s/epoch - 2ms/step\nEpoch 2/10\n1200/1200 - 2s - loss: 0.4242 - accuracy: 0.8869 - 2s/epoch - 2ms/step\nEpoch 3/10\n1200/1200 - 2s - loss: 0.3590 - accuracy: 0.9007 - 2s/epoch - 2ms/step\nEpoch 4/10\n1200/1200 - 2s - loss: 0.3253 - accuracy: 0.9083 - 2s/epoch - 2ms/step\nEpoch 5/10\n1200/1200 - 2s - loss: 0.3022 - accuracy: 0.9141 - 2s/epoch - 2ms/step\nEpoch 6/10\n1200/1200 - 2s - loss: 0.2844 - accuracy: 0.9195 - 2s/epoch - 2ms/step\nEpoch 7/10\n1200/1200 - 2s - loss: 0.2698 - accuracy: 0.9233 - 2s/epoch - 2ms/step\nEpoch 8/10\n1200/1200 - 2s - loss: 0.2573 - accuracy: 0.9265 - 2s/epoch - 2ms/step\nEpoch 9/10\n1200/1200 - 2s - loss: 0.2461 - accuracy: 0.9298 - 2s/epoch - 2ms/step\nEpoch 10/10\n1200/1200 - 2s - loss: 0.2364 - accuracy: 0.9331 - 2s/epoch - 2ms/step\n313/313 - 0s - loss: 0.2269 - accuracy: 0.9345 - 447ms/epoch - 1ms/step\n\n# Data Frame de resultados\ncolnames(comparativa) = c(\"Size\", \"Factiv\", \"Accuracy\")\ncomparativa\n\n      Size Factiv    Accuracy           \n [1,] \"16\" \"relu\"    \"0.928799986839294\"\n [2,] \"16\" \"sigmoid\" \"0.891200006008148\"\n [3,] \"16\" \"tanh\"    \"0.924799978733063\"\n [4,] \"32\" \"relu\"    \"0.932200014591217\"\n [5,] \"32\" \"sigmoid\" \"0.8992999792099\"  \n [6,] \"32\" \"tanh\"    \"0.931900024414062\"\n [7,] \"64\" \"relu\"    \"0.940199971199036\"\n [8,] \"64\" \"sigmoid\" \"0.902999997138977\"\n [9,] \"64\" \"tanh\"    \"0.934499979019165\"\n\n\nAunque hay que tomar los resultados con cautela, ya que solo entrenamos cada red una única vez, parece claro que las funciones de activación sigmoid y tanh proporcionan mejores resultados que la utilizada inicialmente. No se aprecian muchas diferencias en cuanto al número de neuronas, ya que incluso con 16 neuronas el modelo parece funcionar bastante bien.\n\n\n3.3.1.2 A nivel de algoritmo de aprendizaje\nEn este punto vamos a estudiar el efecto del número de epochs, el batch size y el learning rate sobre las métricas de evaluación de la red neuronal utilizada para modelizar los dos bancos de datos propuestos.\nNúmero de epochs\nEl número de épocas (epochs) nos indica el número de veces que los datos de entrenamiento han pasado por la red neuronal en el proceso de entrenamiento. Es importante determinar un valor adecuado de este hiperparámentro. Un número alto de épocas provoca que el modelo se ajuste en exceso a los datos y puede tener problemas de generalización en el conjunto de datos de prueba y validación, como veremos más adelante, así como problemas de vanishing gradients y exploding gradient.\nUn valor menor al óptimo de épocas puede limitar el potencial del modelo, en el sentido de que este no llegue a entrenarse lo suficiente por no haber visto suficientes datos y, por tanto, no haga buenas predicciones.\nNormalmente, se prueban diferentes valores en función del tiempo y los recursos computacionales que se tenga. Una buena pista es incrementar el número de epochs hasta que la métrica de precisión con los datos de validación empiece a decrecer, incluso cuando la precisión de los datos de entrenamiento continúe incrementándose (es cuando detectamos un potencial sobreajuste u overfitting).\nBatch size\nYa hemos explicado anteriormente que podemos particionar los datos de entrenamiento en lotes (batches) para pasarlos por la red. En Keras, como hemos visto, el batch_size es argumento en el método fit(), que indica el tamaño de estos lotes en una iteración del entrenamiento para actualizar el gradiente. El tamaño óptimo dependerá de muchos factores, entre ellos de la capacidad de memoria del ordenador que usemos para hacer los cálculos. Como ocurre con el número de epochs deberemos buscar sobre un rango de posibles valores. Lo habitual es comenzar con un valor grande e ir reduciéndolo. Podemos considerar por ejemplo los valores 128, 64, 32, 16, 8, 4, 2 y evaluar los modelos correspondientes.\nLearnig rate\nComo ya vimos anteriormente los algoritmos de optimización usados en el proceso de configuración del aprendizaje de la red neuronal multiplican la magnitud del gradiente por un escalar conocido como learning rate. Por ejemplo, si la magnitud del gradiente es 1.5 y el learning rate es 0.01, entonces el algoritmo del gradiente descendiente seleccionará el siguiente punto a 0.015 de distancia del punto anterior.\nEl valor adecuado de este hiperparámetro es muy dependiente del problema en cuestión. En general, si este es demasiado grande, se están dando pasos enormes que podrían ser buenos para ir rápido en el proceso de aprendizaje, pero sus actualizaciones pueden terminar llevándolo a ubicaciones completamente aleatorias en la curva, saltándose el mínimo. Esto podría dificultar el proceso de aprendizaje porque al buscar el siguiente punto perpetuamente rebota al azar en el fondo del «pozo» sin llegar a encontrar el valor mínimo deseado.\nContrariamente, si la tasa de aprendizaje es demasiado pequeña, se harán avances constantes pero pequeños, generando así una mejor oportunidad de llegar a un mínimo local de la función de pérdida. Sin embargo, esto puede provocar que el proceso de aprendizaje sea extremadamente lento. En general, una buena regla es -si nuestro modelo de aprendizaje no funciona- disminuir la learning rate. Si sabemos que el gradiente de la función de pérdida (loss) es pequeño, es más seguro probar con learning rates que compensen el gradiente.\nAhora bien, la mejor tasa de aprendizaje en general es aquella que disminuye a medida que el modelo se acerca a una solución. Para conseguir este efecto, disponemos de otro hiperparámetro, el weight_decay, una especie de decaimiento del rango de aprendizaje que se usa para disminuir el learning rate a medida que van pasando epochs. Esto permite que el aprendizaje avance más rápido al principio con learning rates más grandes y, a medida que se avanza, se vayan haciendo ajustes cada vez más pequeños para facilitar que converja el proceso de entrenamiento al mínimo de la función de pérdida.\nEl valor de la tasa de aprendizaje depende también del optimizador utilizado. Por poner algún ejemplo, para el optimizador de descenso del gradiente estocástico, un learning rate de 0.1 generalmente funciona bien, mientras que para el optimizador Adam es mejor un learning rate entre 0.001 y 0.01. Pero se recomienda probar siempre varios valores. También puede usar el parámetro de weight_decay para lograr la convergencia.\nAplicación al banco de datos digits\nComo el banco de datos es tan grande (y para no ralentizar mucho el proceso de computación) vamos a mantener fijo el número de epochs, pero probaremos diferentes configuraciones del algoritmo de aprendizaje y el learning rate.\n\n# Configuraciones de búsqueda\ntasa = c(0.001, 0.01, 0.1)\nbloque = c(16, 32, 64)\n\nEn cuanto a los algoritmos de aprendizaje consideramos: SGD, ADAM, y RMSprop. Para cada uno de los algoritmos deberemos definir una función de configuración del modelo diferente. Comenzamos con `SGD pero vamos a reducir el número de neuronas en la capa oculta para facilitar el tiempo de computación. Tengamos en cuenta que solamente estamos probando configuraciones para ver el efecto que tiene sobre el resultado fina y no en la búsqueda de la mejor solución, ya que este ejemplo se ha estuado con mucho de talle y se encuentran publicadas las soluciones óptimasl.\n\nbuild_model_digits_2 = function(tasa)\n{\n# Función para la definición del modelo (arquitectura y proceso de aprendizaje)\n\n  #  Valores de entrada\n  #   tasa: tasa de aprendizaje\n  \n  # Valores de salida\n  #   modelo: modelo configurado\n  \n  # Arquitectura del modelo\n  modelo = keras_model_sequential() %>% \n      layer_flatten(input_shape = c(28, 28)) %>% \n      layer_dense(units = 8, activation = 'relu', kernel_initializer = inicializador) %>% \n      layer_dense(10, activation = 'softmax', kernel_initializer = inicializador)\n  # Proceso de aprendizaje\n  modelo %>% compile(\n    loss = 'sparse_categorical_crossentropy',\n    optimizer = optimizer_sgd(learning_rate = tasa),\n    metrics = c('accuracy'))\nreturn(modelo)\n}\n\nAhora planteamos el bucle para este algoritmo\n\n# Lista donde almacenamos la accuracy de cada modelo\ncomparativa = c()\n\n# Bucle de evaluación\nfor (i in tasa)\n{\n  for (j in bloque)\n  {\n    modelo = build_model_digits_2(i)\n    # Entrenamiento\n    history = modelo %>%  fit(x_train, y_train, batch_size = j, epochs = 10)  \n    # Evaluación\n    valor = (modelo %>% tensorflow::evaluate(x_test, y_test))[2]\n    comparativa = rbind(comparativa, c(i,j,valor))\n  }\n}\n\nEpoch 1/10\n3750/3750 - 6s - loss: 1.8871 - accuracy: 0.3396 - 6s/epoch - 2ms/step\nEpoch 2/10\n3750/3750 - 5s - loss: 1.3594 - accuracy: 0.5942 - 5s/epoch - 1ms/step\nEpoch 3/10\n3750/3750 - 5s - loss: 1.0800 - accuracy: 0.6814 - 5s/epoch - 1ms/step\nEpoch 4/10\n3750/3750 - 5s - loss: 0.8668 - accuracy: 0.7338 - 5s/epoch - 1ms/step\nEpoch 5/10\n3750/3750 - 5s - loss: 0.7075 - accuracy: 0.7836 - 5s/epoch - 1ms/step\nEpoch 6/10\n3750/3750 - 6s - loss: 0.6127 - accuracy: 0.8178 - 6s/epoch - 1ms/step\nEpoch 7/10\n3750/3750 - 5s - loss: 0.5526 - accuracy: 0.8371 - 5s/epoch - 1ms/step\nEpoch 8/10\n3750/3750 - 5s - loss: 0.5116 - accuracy: 0.8509 - 5s/epoch - 1ms/step\nEpoch 9/10\n3750/3750 - 5s - loss: 0.4820 - accuracy: 0.8597 - 5s/epoch - 1ms/step\nEpoch 10/10\n3750/3750 - 5s - loss: 0.4596 - accuracy: 0.8671 - 5s/epoch - 1ms/step\n313/313 - 0s - loss: 0.4343 - accuracy: 0.8711 - 418ms/epoch - 1ms/step\nEpoch 1/10\n1875/1875 - 3s - loss: 2.0874 - accuracy: 0.2335 - 3s/epoch - 2ms/step\nEpoch 2/10\n1875/1875 - 3s - loss: 1.6877 - accuracy: 0.4426 - 3s/epoch - 1ms/step\nEpoch 3/10\n1875/1875 - 3s - loss: 1.4358 - accuracy: 0.5670 - 3s/epoch - 1ms/step\nEpoch 4/10\n1875/1875 - 3s - loss: 1.2769 - accuracy: 0.6283 - 3s/epoch - 1ms/step\nEpoch 5/10\n1875/1875 - 3s - loss: 1.1642 - accuracy: 0.6579 - 3s/epoch - 1ms/step\nEpoch 6/10\n1875/1875 - 3s - loss: 1.0653 - accuracy: 0.6839 - 3s/epoch - 2ms/step\nEpoch 7/10\n1875/1875 - 3s - loss: 0.9689 - accuracy: 0.7086 - 3s/epoch - 1ms/step\nEpoch 8/10\n1875/1875 - 3s - loss: 0.8799 - accuracy: 0.7328 - 3s/epoch - 1ms/step\nEpoch 9/10\n1875/1875 - 3s - loss: 0.7943 - accuracy: 0.7620 - 3s/epoch - 1ms/step\nEpoch 10/10\n1875/1875 - 3s - loss: 0.7204 - accuracy: 0.7867 - 3s/epoch - 1ms/step\n313/313 - 0s - loss: 0.6713 - accuracy: 0.8012 - 391ms/epoch - 1ms/step\nEpoch 1/10\n938/938 - 2s - loss: 2.2144 - accuracy: 0.1432 - 2s/epoch - 2ms/step\nEpoch 2/10\n938/938 - 1s - loss: 1.9638 - accuracy: 0.3133 - 1s/epoch - 2ms/step\nEpoch 3/10\n938/938 - 1s - loss: 1.7713 - accuracy: 0.4136 - 1s/epoch - 2ms/step\nEpoch 4/10\n938/938 - 2s - loss: 1.6156 - accuracy: 0.4683 - 2s/epoch - 2ms/step\nEpoch 5/10\n938/938 - 2s - loss: 1.4894 - accuracy: 0.5404 - 2s/epoch - 2ms/step\nEpoch 6/10\n938/938 - 2s - loss: 1.3912 - accuracy: 0.5914 - 2s/epoch - 2ms/step\nEpoch 7/10\n938/938 - 1s - loss: 1.3128 - accuracy: 0.6170 - 1s/epoch - 2ms/step\nEpoch 8/10\n938/938 - 1s - loss: 1.2478 - accuracy: 0.6359 - 1s/epoch - 2ms/step\nEpoch 9/10\n938/938 - 1s - loss: 1.1921 - accuracy: 0.6512 - 1s/epoch - 2ms/step\nEpoch 10/10\n938/938 - 1s - loss: 1.1432 - accuracy: 0.6635 - 1s/epoch - 2ms/step\n313/313 - 0s - loss: 1.0998 - accuracy: 0.6783 - 440ms/epoch - 1ms/step\nEpoch 1/10\n3750/3750 - 5s - loss: 0.8675 - accuracy: 0.7259 - 5s/epoch - 1ms/step\nEpoch 2/10\n3750/3750 - 5s - loss: 0.4062 - accuracy: 0.8837 - 5s/epoch - 1ms/step\nEpoch 3/10\n3750/3750 - 6s - loss: 0.3594 - accuracy: 0.8977 - 6s/epoch - 1ms/step\nEpoch 4/10\n3750/3750 - 5s - loss: 0.3393 - accuracy: 0.9037 - 5s/epoch - 1ms/step\nEpoch 5/10\n3750/3750 - 5s - loss: 0.3273 - accuracy: 0.9069 - 5s/epoch - 1ms/step\nEpoch 6/10\n3750/3750 - 5s - loss: 0.3187 - accuracy: 0.9090 - 5s/epoch - 1ms/step\nEpoch 7/10\n3750/3750 - 5s - loss: 0.3120 - accuracy: 0.9115 - 5s/epoch - 1ms/step\nEpoch 8/10\n3750/3750 - 5s - loss: 0.3059 - accuracy: 0.9139 - 5s/epoch - 1ms/step\nEpoch 9/10\n3750/3750 - 5s - loss: 0.3017 - accuracy: 0.9142 - 5s/epoch - 1ms/step\nEpoch 10/10\n3750/3750 - 5s - loss: 0.2978 - accuracy: 0.9164 - 5s/epoch - 1ms/step\n313/313 - 0s - loss: 0.2975 - accuracy: 0.9142 - 384ms/epoch - 1ms/step\nEpoch 1/10\n1875/1875 - 3s - loss: 1.2226 - accuracy: 0.6165 - 3s/epoch - 2ms/step\nEpoch 2/10\n1875/1875 - 3s - loss: 0.5586 - accuracy: 0.8367 - 3s/epoch - 1ms/step\nEpoch 3/10\n1875/1875 - 3s - loss: 0.4303 - accuracy: 0.8764 - 3s/epoch - 1ms/step\nEpoch 4/10\n1875/1875 - 3s - loss: 0.3878 - accuracy: 0.8897 - 3s/epoch - 1ms/step\nEpoch 5/10\n1875/1875 - 3s - loss: 0.3657 - accuracy: 0.8962 - 3s/epoch - 1ms/step\nEpoch 6/10\n1875/1875 - 3s - loss: 0.3517 - accuracy: 0.9000 - 3s/epoch - 1ms/step\nEpoch 7/10\n1875/1875 - 3s - loss: 0.3421 - accuracy: 0.9029 - 3s/epoch - 1ms/step\nEpoch 8/10\n1875/1875 - 3s - loss: 0.3348 - accuracy: 0.9050 - 3s/epoch - 1ms/step\nEpoch 9/10\n1875/1875 - 3s - loss: 0.3291 - accuracy: 0.9064 - 3s/epoch - 1ms/step\nEpoch 10/10\n1875/1875 - 3s - loss: 0.3238 - accuracy: 0.9079 - 3s/epoch - 1ms/step\n313/313 - 0s - loss: 0.3224 - accuracy: 0.9072 - 403ms/epoch - 1ms/step\nEpoch 1/10\n938/938 - 2s - loss: 1.5042 - accuracy: 0.5091 - 2s/epoch - 2ms/step\nEpoch 2/10\n938/938 - 1s - loss: 0.7718 - accuracy: 0.7615 - 1s/epoch - 2ms/step\nEpoch 3/10\n938/938 - 1s - loss: 0.5538 - accuracy: 0.8367 - 1s/epoch - 2ms/step\nEpoch 4/10\n938/938 - 2s - loss: 0.4696 - accuracy: 0.8638 - 2s/epoch - 2ms/step\nEpoch 5/10\n938/938 - 2s - loss: 0.4272 - accuracy: 0.8770 - 2s/epoch - 2ms/step\nEpoch 6/10\n938/938 - 1s - loss: 0.4017 - accuracy: 0.8848 - 1s/epoch - 2ms/step\nEpoch 7/10\n938/938 - 1s - loss: 0.3842 - accuracy: 0.8901 - 1s/epoch - 2ms/step\nEpoch 8/10\n938/938 - 2s - loss: 0.3716 - accuracy: 0.8933 - 2s/epoch - 2ms/step\nEpoch 9/10\n938/938 - 2s - loss: 0.3615 - accuracy: 0.8966 - 2s/epoch - 2ms/step\nEpoch 10/10\n938/938 - 2s - loss: 0.3540 - accuracy: 0.8994 - 2s/epoch - 2ms/step\n313/313 - 0s - loss: 0.3441 - accuracy: 0.8995 - 412ms/epoch - 1ms/step\nEpoch 1/10\n3750/3750 - 6s - loss: 0.5623 - accuracy: 0.8305 - 6s/epoch - 2ms/step\nEpoch 2/10\n3750/3750 - 5s - loss: 0.4304 - accuracy: 0.8753 - 5s/epoch - 1ms/step\nEpoch 3/10\n3750/3750 - 5s - loss: 0.3732 - accuracy: 0.8928 - 5s/epoch - 1ms/step\nEpoch 4/10\n3750/3750 - 5s - loss: 0.3284 - accuracy: 0.9047 - 5s/epoch - 1ms/step\nEpoch 5/10\n3750/3750 - 5s - loss: 0.3144 - accuracy: 0.9097 - 5s/epoch - 1ms/step\nEpoch 6/10\n3750/3750 - 5s - loss: 0.3026 - accuracy: 0.9129 - 5s/epoch - 1ms/step\nEpoch 7/10\n3750/3750 - 5s - loss: 0.2952 - accuracy: 0.9151 - 5s/epoch - 1ms/step\nEpoch 8/10\n3750/3750 - 5s - loss: 0.2928 - accuracy: 0.9157 - 5s/epoch - 1ms/step\nEpoch 9/10\n3750/3750 - 5s - loss: 0.2881 - accuracy: 0.9152 - 5s/epoch - 1ms/step\nEpoch 10/10\n3750/3750 - 5s - loss: 0.2852 - accuracy: 0.9172 - 5s/epoch - 1ms/step\n313/313 - 0s - loss: 0.2921 - accuracy: 0.9146 - 408ms/epoch - 1ms/step\nEpoch 1/10\n1875/1875 - 3s - loss: 0.4974 - accuracy: 0.8501 - 3s/epoch - 2ms/step\nEpoch 2/10\n1875/1875 - 3s - loss: 0.3529 - accuracy: 0.8969 - 3s/epoch - 1ms/step\nEpoch 3/10\n1875/1875 - 3s - loss: 0.3295 - accuracy: 0.9049 - 3s/epoch - 1ms/step\nEpoch 4/10\n1875/1875 - 3s - loss: 0.3184 - accuracy: 0.9075 - 3s/epoch - 1ms/step\nEpoch 5/10\n1875/1875 - 3s - loss: 0.3091 - accuracy: 0.9090 - 3s/epoch - 2ms/step\nEpoch 6/10\n1875/1875 - 3s - loss: 0.2907 - accuracy: 0.9153 - 3s/epoch - 1ms/step\nEpoch 7/10\n1875/1875 - 3s - loss: 0.2763 - accuracy: 0.9197 - 3s/epoch - 2ms/step\nEpoch 8/10\n1875/1875 - 3s - loss: 0.2639 - accuracy: 0.9228 - 3s/epoch - 1ms/step\nEpoch 9/10\n1875/1875 - 3s - loss: 0.2559 - accuracy: 0.9262 - 3s/epoch - 2ms/step\nEpoch 10/10\n1875/1875 - 3s - loss: 0.2505 - accuracy: 0.9261 - 3s/epoch - 1ms/step\n313/313 - 0s - loss: 0.2580 - accuracy: 0.9252 - 398ms/epoch - 1ms/step\nEpoch 1/10\n938/938 - 2s - loss: 0.5808 - accuracy: 0.8199 - 2s/epoch - 2ms/step\nEpoch 2/10\n938/938 - 1s - loss: 0.3552 - accuracy: 0.8968 - 1s/epoch - 2ms/step\nEpoch 3/10\n938/938 - 1s - loss: 0.3301 - accuracy: 0.9065 - 1s/epoch - 2ms/step\nEpoch 4/10\n938/938 - 2s - loss: 0.3194 - accuracy: 0.9095 - 2s/epoch - 2ms/step\nEpoch 5/10\n938/938 - 1s - loss: 0.3118 - accuracy: 0.9115 - 1s/epoch - 2ms/step\nEpoch 6/10\n938/938 - 2s - loss: 0.3051 - accuracy: 0.9141 - 2s/epoch - 2ms/step\nEpoch 7/10\n938/938 - 2s - loss: 0.3000 - accuracy: 0.9147 - 2s/epoch - 2ms/step\nEpoch 8/10\n938/938 - 2s - loss: 0.2972 - accuracy: 0.9168 - 2s/epoch - 2ms/step\nEpoch 9/10\n938/938 - 1s - loss: 0.2939 - accuracy: 0.9160 - 1s/epoch - 2ms/step\nEpoch 10/10\n938/938 - 2s - loss: 0.2897 - accuracy: 0.9181 - 2s/epoch - 2ms/step\n313/313 - 0s - loss: 0.3008 - accuracy: 0.9097 - 396ms/epoch - 1ms/step\n\n# Data Frame de resultados\ncolnames(comparativa) = c(\"lr\", \"Factiv\", \"Accuracy\")\ncomparativa\n\n         lr Factiv Accuracy\n [1,] 0.001     16   0.8711\n [2,] 0.001     32   0.8012\n [3,] 0.001     64   0.6783\n [4,] 0.010     16   0.9142\n [5,] 0.010     32   0.9072\n [6,] 0.010     64   0.8995\n [7,] 0.100     16   0.9146\n [8,] 0.100     32   0.9252\n [9,] 0.100     64   0.9097\n\n\n¿qué conclusiones podemos extraer de este estudio? Se deja para el lector en completar los estudios para los otros dos algoritmos de aprendizaje."
  },
  {
    "objectID": "30_RMDDL.html#sobreajuste-e-infraajuste",
    "href": "30_RMDDL.html#sobreajuste-e-infraajuste",
    "title": "3  Redes multicapa densas con Keras",
    "section": "3.4 Sobreajuste e infraajuste",
    "text": "3.4 Sobreajuste e infraajuste\nEl concepto de sobreajuste de un modelo (overfitting en inglés) se produce cuando el modelo obtenido se ajusta tanto a los ejemplos etiquetados de entrenamiento que no puede realizar las predicciones correctas en ejemplos de datos nuevos que nunca ha visto antes.\nEn resumen, con overfitting o sobreajuste nos referimos a lo que le sucede a un modelo cuando este modela los datos de entrenamiento demasiado bien, aprendiendo detalles de estos que no son generales. Esto es debido a que sobreentrenamos nuestro modelo y este estará considerando como válidos solo los datos idénticos a los de nuestro conjunto de entrenamiento, incluidos sus defectos (también llamado ruido en nuestro contexto). Es decir, nos encontramos en la situación de que el modelo puede tener una baja tasa de error de clasificación para los datos de entrenamiento, pero no se generaliza bien a la población general de datos en los que estamos interesados.\nEs evidente que, en general, esta situación presenta un impacto negativo en la eficiencia del modelo cuando este se usa para inferencia con datos nuevos. Por ello, es muy importante evitar estar en esta situación; de aquí la utilidad de reservar una parte de datos de entrenamiento como datos de validación.\nPodemos añadir el porcentaje de datos de validación dentro de la muestra de entrenamiento dentro del ajuste del modelo con el parámetro validation_split mediante:\nmodel.fit(train_data, train_labels, epochs=epochs, validation_split=0.2)\nde forma que cada época reservamos el 20% de los datos de entrenamiento para validar el modelo.\nLos datos de validación del modelo se usan para probar y evaluar diferentes opciones de hiperparámetros para minimizar la situación de overfitting, como el número de epochs con las que entrenar el modelo, el ratio de aprendizaje o la mejor arquitectura de red, por poner algunos ejemplos.\nEntrenamos por ejemplo el modelo de digits reservando un 20% para validación:\n\n# Arquitectura del modelo\nmodelo_digits = keras_model_sequential() %>% \n      layer_flatten(input_shape = c(28, 28)) %>% \n      layer_dense(units = 32, activation = 'relu', kernel_initializer = inicializador) %>% \n      layer_dense(10, activation = 'softmax', kernel_initializer = inicializador)\n# Proceso de aprendizaje\n  modelo_digits %>% compile(\n    loss = 'sparse_categorical_crossentropy',\n    optimizer = optimizer_sgd(),\n    metrics = c('accuracy'))\n# Entrenamiento\nhistory_digits = modelo_digits %>% \n  fit(x_train, y_train, batch_size = 50, epochs = 10, validation_split = 0.2)\n\nEpoch 1/10\n960/960 - 2s - loss: 0.9715 - accuracy: 0.7476 - val_loss: 0.4797 - val_accuracy: 0.8804 - 2s/epoch - 3ms/step\nEpoch 2/10\n960/960 - 2s - loss: 0.4447 - accuracy: 0.8802 - val_loss: 0.3678 - val_accuracy: 0.9001 - 2s/epoch - 2ms/step\nEpoch 3/10\n960/960 - 2s - loss: 0.3725 - accuracy: 0.8956 - val_loss: 0.3290 - val_accuracy: 0.9093 - 2s/epoch - 2ms/step\nEpoch 4/10\n960/960 - 2s - loss: 0.3387 - accuracy: 0.9039 - val_loss: 0.3066 - val_accuracy: 0.9147 - 2s/epoch - 2ms/step\nEpoch 5/10\n960/960 - 2s - loss: 0.3168 - accuracy: 0.9094 - val_loss: 0.2910 - val_accuracy: 0.9182 - 2s/epoch - 2ms/step\nEpoch 6/10\n960/960 - 2s - loss: 0.3009 - accuracy: 0.9141 - val_loss: 0.2815 - val_accuracy: 0.9207 - 2s/epoch - 2ms/step\nEpoch 7/10\n960/960 - 2s - loss: 0.2877 - accuracy: 0.9183 - val_loss: 0.2697 - val_accuracy: 0.9237 - 2s/epoch - 2ms/step\nEpoch 8/10\n960/960 - 2s - loss: 0.2763 - accuracy: 0.9209 - val_loss: 0.2608 - val_accuracy: 0.9265 - 2s/epoch - 2ms/step\nEpoch 9/10\n960/960 - 2s - loss: 0.2662 - accuracy: 0.9245 - val_loss: 0.2547 - val_accuracy: 0.9268 - 2s/epoch - 2ms/step\nEpoch 10/10\n960/960 - 2s - loss: 0.2571 - accuracy: 0.9273 - val_loss: 0.2474 - val_accuracy: 0.9294 - 2s/epoch - 2ms/step\n\n# Evaluación\nmodelo_digits %>% tensorflow::evaluate(x_test, y_test)\n\n313/313 - 0s - loss: 0.2477 - accuracy: 0.9300 - 413ms/epoch - 1ms/step\n\n\n     loss  accuracy \n0.2477478 0.9300000 \n\n\nVeamos gráficamente al evolución del proceso iterativo:\n\nplot(history_digits) + ylim(0,1)\n\n\n\n\nLos resultados con la muestra reservada para validación son comparables con los resultados de entrenamiento indicando que no parece producirse sobreajuste ni infrajuste. A continuación vemos diferentes modificaciones que se pueden introducir en el modelo para reducir cualquiera de esos dos efectos, aunque los estudiaremos con más detalle en el tema siguiente donde introduciremos diferentes casos prácticos de redes neuronales densas aplicadas a otro problemas de clasificación y regresión.\n\n3.4.1 Reduciendo el tamaño de la red\nLa forma más sencilla de evitar el sobreajuste es reducir el tamaño del modelo: el número de parámetros aprendibles en el modelo (que viene determinado por el número de capas y el número de unidades por capa). En el aprendizaje profundo, el número de parámetros aprendibles en un modelo suele denominarse capacidad del modelo.\nIntuitivamente, un modelo con más parámetros tiene más capacidad de memorización y, por lo tanto, puede aprender fácilmente y obtener un modelo perfecto entre las muestras de entrenamiento y sus objetivos, pero sin ningún poder de generalización. Por ejemplo, un modelo con 500.000 parámetros binarios podría aprender fácilmente la clase de cada dígito del conjunto de entrenamiento MNIST sólo necesitaríamos 10 parámetros binarios para cada uno de los 50.000 dígitos. Pero un modelo así sería inútil para clasificar nuevas muestras de dígitos.\nPor otro lado, si la red tiene recursos de memorización limitados, no podrá aprender fácilmente; por tanto, para minimizar su pérdida, tendrá que recurrir al aprendizaje de modelos más complejos. Al mismo tiempo, hay que tener en cuenta que hay que utilizar modelos que tengan suficientes parámetros para que no se ajusten mal.\nDesgraciadamente, no existe una fórmula mágica para determinar el número correcto de capas o el tamaño adecuado de cada capa. Se deben evaluar una serie de arquitecturas diferentes (en su conjunto de validación, no en su conjunto de prueba, por supuesto) con el fin de encontrar el tamaño correcto del modelo para los datos. El flujo de trabajo general para encontrar un tamaño de modelo adecuado consiste en empezar con relativamente pocas capas y parámetros, e ir aumentando el tamaño de las capas o añadiendo nuevas capas hasta que se observe una disminución del rendimiento con respecto a la pérdida de validación.\n\n\n3.4.2 Regularización de parámetros\nDados unos datos de entrenamiento y una arquitectura de red, múltiples conjuntos de valores de los pesos (múltiples modelos) podrían explicar los datos. Un modelo simple en este contexto es un modelo en el que la distribución de los valores de los parámetros tiene menos entropía (o un modelo con menos parámetros). Por tanto, una forma común de mitigar el sobreajuste es poner restricciones a la complejidad de una red obligando a sus pesos a tomar sólo valores pequeños, lo que hace que la distribución de los valores de los pesos sea más regular. Esto se llama regularización de pesos, y se hace añadiendo a la función de pérdida de la red un coste asociado a tener pesos grandes.\nEste coste puede ser de dos tipos:\n\nRegularización L1. El coste añadido es proporcional al valor absoluto de los coeficientes de peso (la norma L1 de los pesos).\nRegularización L2. El coste añadido es proporcional al cuadrado del valor de los coeficientes de peso (la norma L2 de los pesos). En el contexto de las redes neuronales, la regularización L2 también se denomina decaimiento de los pesos.\n\nEn Keras, la regularización de peso se añade pasando instancias de regularizador de peso a las capas como argumentos de palabra clave. Más concretamente debemos definir un regularizador de pesos con las funciones kernel_regularizer=regularizer_l2(value) y kernel_regularizer=regularizer_l1(value), donde si value toma el valor 0.001 implica que cada coeficiente de la matriz de pesos de la capa sumará 0.001*weight_coefficient_value a la pérdida total de la red.\nTenga en cuenta que como esta penalización sólo se añade en el momento del entrenamiento, la pérdida de esta red será mucho mayor durante el entrenamiento que en el momento de la validación.\n\n\n3.4.3 Añadiendo abandono (dropout)\nEl dropout es una de las técnicas de regularización de redes neuronales más eficaces y utilizadas, desarrollada por Geoff Hinton y sus alumnos de la Universidad de Toronto. El dropout, aplicado a una capa, consiste en eliminar aleatoriamente (poner a cero) un número de características de salida de la capa durante el entrenamiento. Supongamos que una capa determinada devuelve normalmente un vector [0.2, 0.5, 1.3, 0.8, 1.1] para una determinada muestra de entrada durante el entrenamiento. Después de aplicar el abandono, este vector tendrá algunas entradas cero distribuidas al azar: por ejemplo, [0, 0.5, 1.3, 0, 1.1]. La tasa de abandono es la fracción de las características que se reducen a cero; normalmente se establece entre 0,2 y 0,5. En el momento de la prueba, no se eliminan las unidades; en su lugar, los valores de salida de la capa se reducen en un factor igual a la tasa de eliminación, para equilibrar el hecho de que hay más unidades activas que en el momento del entrenamiento.\nEn Keras, puedes introducir dropout en una red a través de la capa Dropout, que se aplica a la salida de la capa justo antes de ella:\nmodel.add(layers.Dropout(0.5))\nEn este caso no pasamos por el 50% de las neuronas consideradas. Vamos a ver el efecto de esta capa sobre la red para el banco de datos digits. Como solo tenemos una capa intermedia dense colocamos ahí la capa dropout. para comparar los resultados vamos a justar un modelo sin dropout y otro con un dropout del 50% y comparemos la evolución de la pérdida entre ambos modelos.\n\ninicializador = initializer_glorot_normal(seed = 15)\n# Arquitectura del modelo sin dropout\nmodelo_digits_sdr = keras_model_sequential() %>% \n      layer_flatten(input_shape = c(28, 28)) %>% \n      layer_dense(units = 32, activation = 'relu', kernel_initializer = inicializador) %>% \n      layer_dense(10, activation = 'softmax', kernel_initializer = inicializador)\n# Proceso de aprendizaje\n  modelo_digits_sdr %>% compile(\n    loss = 'sparse_categorical_crossentropy',\n    optimizer = optimizer_sgd(),\n    metrics = c('accuracy'))\n# Entrenamiento\nhistory_digits_sdr = modelo_digits_sdr %>% \n  fit(x_train, y_train, batch_size = 50, epochs = 10, validation_split=0.2)\n\nEpoch 1/10\n960/960 - 2s - loss: 0.9752 - accuracy: 0.7448 - val_loss: 0.4816 - val_accuracy: 0.8821 - 2s/epoch - 3ms/step\nEpoch 2/10\n960/960 - 2s - loss: 0.4460 - accuracy: 0.8796 - val_loss: 0.3688 - val_accuracy: 0.8986 - 2s/epoch - 2ms/step\nEpoch 3/10\n960/960 - 2s - loss: 0.3730 - accuracy: 0.8950 - val_loss: 0.3294 - val_accuracy: 0.9086 - 2s/epoch - 2ms/step\nEpoch 4/10\n960/960 - 2s - loss: 0.3391 - accuracy: 0.9035 - val_loss: 0.3099 - val_accuracy: 0.9134 - 2s/epoch - 2ms/step\nEpoch 5/10\n960/960 - 2s - loss: 0.3174 - accuracy: 0.9098 - val_loss: 0.2916 - val_accuracy: 0.9191 - 2s/epoch - 2ms/step\nEpoch 6/10\n960/960 - 2s - loss: 0.3011 - accuracy: 0.9136 - val_loss: 0.2802 - val_accuracy: 0.9213 - 2s/epoch - 2ms/step\nEpoch 7/10\n960/960 - 2s - loss: 0.2879 - accuracy: 0.9180 - val_loss: 0.2703 - val_accuracy: 0.9237 - 2s/epoch - 2ms/step\nEpoch 8/10\n960/960 - 2s - loss: 0.2763 - accuracy: 0.9213 - val_loss: 0.2618 - val_accuracy: 0.9260 - 2s/epoch - 2ms/step\nEpoch 9/10\n960/960 - 2s - loss: 0.2664 - accuracy: 0.9245 - val_loss: 0.2537 - val_accuracy: 0.9280 - 2s/epoch - 2ms/step\nEpoch 10/10\n960/960 - 2s - loss: 0.2572 - accuracy: 0.9272 - val_loss: 0.2468 - val_accuracy: 0.9302 - 2s/epoch - 2ms/step\n\n\nModelo con Dropout\n\ninicializador = initializer_glorot_normal(seed = 15)\n# Arquitectura del modelo sin dropout\nmodelo_digits_dr = keras_model_sequential() %>% \n      layer_flatten(input_shape = c(28, 28)) %>% \n      layer_dense(units = 32, activation = 'relu', kernel_initializer = inicializador) %>% \n      layer_dropout(0.5) %>%\n      layer_dense(10, activation = 'softmax', kernel_initializer = inicializador)\n# Proceso de aprendizaje\n  modelo_digits_dr %>% compile(\n    loss = 'sparse_categorical_crossentropy',\n    optimizer = optimizer_sgd(),\n    metrics = c('accuracy'))\n# Entrenamiento\nhistory_digits_dr = modelo_digits_dr %>% \n  fit(x_train, y_train, batch_size = 50, epochs = 10, validation_split=0.2)\n\nEpoch 1/10\n960/960 - 3s - loss: 1.4090 - accuracy: 0.5387 - val_loss: 0.6724 - val_accuracy: 0.8639 - 3s/epoch - 3ms/step\nEpoch 2/10\n960/960 - 2s - loss: 0.8923 - accuracy: 0.7176 - val_loss: 0.4855 - val_accuracy: 0.8867 - 2s/epoch - 2ms/step\nEpoch 3/10\n960/960 - 2s - loss: 0.7631 - accuracy: 0.7626 - val_loss: 0.4153 - val_accuracy: 0.8947 - 2s/epoch - 2ms/step\nEpoch 4/10\n960/960 - 2s - loss: 0.7004 - accuracy: 0.7809 - val_loss: 0.3762 - val_accuracy: 0.9029 - 2s/epoch - 2ms/step\nEpoch 5/10\n960/960 - 2s - loss: 0.6590 - accuracy: 0.7948 - val_loss: 0.3491 - val_accuracy: 0.9068 - 2s/epoch - 2ms/step\nEpoch 6/10\n960/960 - 2s - loss: 0.6342 - accuracy: 0.8020 - val_loss: 0.3323 - val_accuracy: 0.9107 - 2s/epoch - 2ms/step\nEpoch 7/10\n960/960 - 2s - loss: 0.6082 - accuracy: 0.8120 - val_loss: 0.3181 - val_accuracy: 0.9149 - 2s/epoch - 2ms/step\nEpoch 8/10\n960/960 - 2s - loss: 0.5894 - accuracy: 0.8162 - val_loss: 0.3070 - val_accuracy: 0.9163 - 2s/epoch - 2ms/step\nEpoch 9/10\n960/960 - 2s - loss: 0.5801 - accuracy: 0.8188 - val_loss: 0.2970 - val_accuracy: 0.9195 - 2s/epoch - 2ms/step\nEpoch 10/10\n960/960 - 2s - loss: 0.5631 - accuracy: 0.8236 - val_loss: 0.2866 - val_accuracy: 0.9204 - 2s/epoch - 2ms/step\n\n\nComparamos ahora los valores de la muestra de validación durante el proceso de entrenamiento para ambos modelos.\n\npar(mfrow=c(1, 2))\nvl1 = history_digits_sdr$metrics$val_accuracy\nvl2 = history_digits_dr$metrics$val_accuracy \nplot(vl1, type =\"l\"\n     ,xlab = \"Epoch\", ylab = \"Validation Accuracy\", col = 1, ylim =c(min(vl1,vl2), max(vl1,vl2)))\nlines(vl2, col = 2)\nlegend(\"topleft\", legend=c(\"Sin Dropout\", \"50% Dropout\"), lty = c(1,1), col = c(1,2))\n\nvl1 = history_digits_sdr$metrics$val_loss\nvl2 = history_digits_dr$metrics$val_loss \nplot(vl1, type =\"l\"\n     ,xlab = \"Epoch\", ylab = \"Validation loss\", col = 1,\n     ylim = c(0, max(vl1, vl2)))\nlines(vl2, col = 2)\nlegend(\"topright\", legend=c(\"Sin Dropout\", \"50% Dropout\"), lty = c(1,1), col = c(1,2))\n\n\n\n\nEn este caso el dropout no mejora los resultados del modelo completo, ya que la red tiene mucha información de entrada y es capaz de aprender con gran precisión. Más adelante veremos otros ejemplos donde la red contiene menos información de entrenamiento y el efecto del dropout si resulta relevante.\n\n\n3.4.4 Parada temprana (early stopping)\nEn general, uno de los motivos del sobreajuste es que realizamos más epochs de las requeridas. Keras nos permite controlar que no nos excedemos de epochs de manera automática mediante callbacks.\nBásicamente consiste en añadir un callback EarlyStopping como argumento en el método fit() que, automáticamente, para el entrenamiento cuando las métricas de la función de pérdida, para los datos de validación no mejoran. Al callback EarlyStopping le indicamos con el argumento monitor qué métrica debe tener en cuenta y, con el argumento patience, cuántas epochs se deben considerar para verificar la mejora. Por ejemplo si deseamos usar la pérdida con 3 epochs debemos escribir:\nearly_stop = callback_early_stoppingg(monitor = 'loss', patience = 3)\nhistory = model.fit(train_data, train_labels, epochs,\n    validation_split, callbacks=list(early_stop))\nSi definimos la validacíón durante el entrenamiento (lo que es habitual) podemos usar como métrica val_loss. tambien podemos obviar el parámetro patience para que el entrenamiento se detenga entre dos iteraciones consecutivas.\nEn el tema siguiente nos enfrentamos a diferentes bancos de datos donde utilizaremos redes densas para problemas de clasificación y regresión, y pondremos en práctica todos los conceptos vistos en este tema."
  },
  {
    "objectID": "40_AplMD.html#conjuntos-de-datos",
    "href": "40_AplMD.html#conjuntos-de-datos",
    "title": "4  Aplicaciones Redes multicapa densas",
    "section": "4.1 Conjuntos de datos",
    "text": "4.1 Conjuntos de datos\nVamos a trabajar con cuatro bancos de datos: dos enfocados en problemas de regresión y los otros dos en problemas de clasificación. En cada uno de ellos se establece el objetivo que se persigue, los inputs o predictoras consideradas, la presencia o no de observaciones anómalas, y el código necesario para la carga de datos.\n\n4.1.1 Diabetes\nEn un estudio sobre la diabetes se obtuvieron diez variables basales, edad, sexo, índice de masa corporal, presión arterial media y seis mediciones de suero sanguíneo para 442 pacientes diabéticos, así como la respuesta de interés, una medida cuantitativa de la progresión de la enfermedad un año después de la entrada al estudio.\nCaracterísticas del banco de datos:\n\nTarget: Y (progresión de la enfermedad)\nValores perdidos: no\nNúmero de registros: 442\nNúmero de inputs: 10\n\nVariables contenidas:\n\nAGE: edad (en años)\nSEX: sexo (1 = Hombre, 2 = Mujer)\nBMI: índice de masa corporal\nBP: promedio de la presión sanguínea\nS1: colesterol sérico total\nS2: lipoproteínas de baja densidad\nS3: lipoproteínas de alta densidad\nS4: colesterol total\nS5: registro del nivel de triglicéridos en suero\nS6: nivel de azúcar en sangre\n\n\nurl = \"https://raw.githubusercontent.com/ia4legos/MachineLearning/main/data/diabetes.tab.txt\"\ndiabetes = read_delim(url, col_types = \"dfddddddddd\")\n# Estructura de los datos\nstr(diabetes)\n\nspc_tbl_ [442 × 11] (S3: spec_tbl_df/tbl_df/tbl/data.frame)\n $ AGE: num [1:442] 59 48 72 24 50 23 36 66 60 29 ...\n $ SEX: Factor w/ 2 levels \"2\",\"1\": 1 2 1 2 2 2 1 1 1 2 ...\n $ BMI: num [1:442] 32.1 21.6 30.5 25.3 23 22.6 22 26.2 32.1 30 ...\n $ BP : num [1:442] 101 87 93 84 101 89 90 114 83 85 ...\n $ S1 : num [1:442] 157 183 156 198 192 139 160 255 179 180 ...\n $ S2 : num [1:442] 93.2 103.2 93.6 131.4 125.4 ...\n $ S3 : num [1:442] 38 70 41 40 52 61 50 56 42 43 ...\n $ S4 : num [1:442] 4 3 4 5 4 2 3 4.55 4 4 ...\n $ S5 : num [1:442] 4.86 3.89 4.67 4.89 4.29 ...\n $ S6 : num [1:442] 87 69 85 89 80 68 82 92 94 88 ...\n $ Y  : num [1:442] 151 75 141 206 135 97 138 63 110 310 ...\n - attr(*, \"spec\")=\n  .. cols(\n  ..   AGE = col_double(),\n  ..   SEX = col_factor(levels = NULL, ordered = FALSE, include_na = FALSE),\n  ..   BMI = col_double(),\n  ..   BP = col_double(),\n  ..   S1 = col_double(),\n  ..   S2 = col_double(),\n  ..   S3 = col_double(),\n  ..   S4 = col_double(),\n  ..   S5 = col_double(),\n  ..   S6 = col_double(),\n  ..   Y = col_double()\n  .. )\n - attr(*, \"problems\")=<externalptr> \n\n\n\n\n4.1.2 Qsar\nEste conjunto de datos se utilizó para desarrollar modelos QSAR de regresión cuantitativa para predecir la toxicidad acuática aguda hacia el pez Pimephales promelas (pececillo de cabeza plana) sobre un conjunto de 908 sustancias químicas. Como variable a predecir se consideraron los datos de la LC50, que es la concentración que provoca la muerte del 50% de sujetos sometidas a prueba durante 48 horas.\nCaracterísticas del banco de datos:\n\nTarget: LC50\nValores perdidos: no\n\nVariables contenidas:\n\nTPSA (propiedades moleculares),\nSAacc (propiedades moleculares),\nH-050 (fragmentos centrados en átomos),\nMLOGP (propiedades moleculares),\nRDCHI (índices de conectividad),\nGATS1p (autocorrelaciones 2D),\nnN (índices constitucionales),\nC-040 (fragmentos centrados en átomos),\nLC50\n\n\nurl = \"https://raw.githubusercontent.com/jmsocuellamos/DatosBIOTEC/master/CaseStudies/Qsar/qsar_aquatic_toxicity.csv\"\nqsar = read_csv(url)\n\n\n\n4.1.3 Water potability\nEl agua potable es el derecho humano más básico y un factor importante para la salud. El conjunto de datos Water potability, tiene por objetivo estudiar la potabilidad del agua utilizando varias propiedades químicas debido a su importancia como cuestión de salud y desarrollo a nivel nacional, regional y local. En algunas regiones, se ha demostrado que las inversiones en abastecimiento de agua y saneamiento pueden producir un beneficio económico neto, ya que la reducción de los efectos adversos para la salud y los costes de la atención sanitaria superan los costes de las intervenciones.\nCaracterísticas del banco de datos:\n\nTarget: potability\nValores perdidos: sí (variables ph, Sulfate y Trihalomethanes)\nNúmero de registros: 3276\nNúmero de variables: 10\n\nVariables contenidas:\n\npH: valor del pH.\nHardness: dureza o capacidad del agua para precipitar el jabón causado por el calcio y el magnesio.\nSolids: sólidos disueltos totales (en partes por millón)\nChloramines: cantidad de cloraminas (en partes por millón)\nSulfate: cantidad de sulfatos disueltos (en mg/L)\nConductivity: conductividad eléctrica del agua (en μS/cm)\nOrganic_carbon: cantidad de carbono orgánico (en partes por millón)\nTrihalomethanes: cantidad de trihalometanos (en μg/L)\nTurbidity: medida de la propiedad de emisión de luz del agua en NTU.\nPotability: indica si el agua es segura para el consumo humano (1 = potable y 0 = no potable)\n\n\nurl = \"https://raw.githubusercontent.com/ia4legos/MachineLearning/main/data/water_potability.csv\"\nwaterpot = read_csv(url)\n# Estructura de los datos\nstr(waterpot)\n\nspc_tbl_ [3,276 × 10] (S3: spec_tbl_df/tbl_df/tbl/data.frame)\n $ ph             : num [1:3276] NA 3.72 8.1 8.32 9.09 ...\n $ Hardness       : num [1:3276] 205 129 224 214 181 ...\n $ Solids         : num [1:3276] 20791 18630 19910 22018 17979 ...\n $ Chloramines    : num [1:3276] 7.3 6.64 9.28 8.06 6.55 ...\n $ Sulfate        : num [1:3276] 369 NA NA 357 310 ...\n $ Conductivity   : num [1:3276] 564 593 419 363 398 ...\n $ Organic_carbon : num [1:3276] 10.4 15.2 16.9 18.4 11.6 ...\n $ Trihalomethanes: num [1:3276] 87 56.3 66.4 100.3 32 ...\n $ Turbidity      : num [1:3276] 2.96 4.5 3.06 4.63 4.08 ...\n $ Potability     : num [1:3276] 0 0 0 0 0 0 0 0 0 0 ...\n - attr(*, \"spec\")=\n  .. cols(\n  ..   ph = col_double(),\n  ..   Hardness = col_double(),\n  ..   Solids = col_double(),\n  ..   Chloramines = col_double(),\n  ..   Sulfate = col_double(),\n  ..   Conductivity = col_double(),\n  ..   Organic_carbon = col_double(),\n  ..   Trihalomethanes = col_double(),\n  ..   Turbidity = col_double(),\n  ..   Potability = col_double()\n  .. )\n - attr(*, \"problems\")=<externalptr> \n\n\n\n\n4.1.4 Breast Cancer Wisconsin\nEn esta base de datos se recoge información sobre los cánceres de mama en la ciudad de Wisconsin. Las características de la base de datos se calculan a partir de una imagen digitalizada de un aspiración de aguja fina (FNA) de una masa mamaria. Describen las características de los núcleos celulares presentes en la imagen y el objetivo que se persigue es clasificar un tumor como benigno o maligno en función de las variables predictoras.\nCaracterísticas del banco de datos:\n\nVariable respuesta: diagnosis\nValores perdidos: no\nNúmero de registros: 569\nNúmero de variables: 32\n\nVariables contenidas:\n\nid: identificador.\ndiagnosis: diagnóstico de tejidos mamarios (M = maligno, B = benigno)\nradius_mean: media de las distancias del centro a los puntos del perímetro.\ntexture_mean: desviación estándar de los valores de la escala de grises.\nperimeter_mean:tamaño medio del tumor central.\narea_mean:\nsmoothness_mean: media de variación local en longitudes de radio\ncompactness_mean: (media de perímetro)^2 / área - 1,0\nconcavity_mean: media de gravedad de las porciones cóncavas del contorno.\nconcave points_mean: media para el número de porciones cóncavas del contorno.\nsymmetry_mean:\nfractal_dimension_mean: media para “aproximación de la costa” - 1.\nradius_se: error estándar para la media de distancias desde el centro hasta los puntos en el perímetro.\ntexture_se: error estándar para la desviación estándar de los valores de escala de grises.\nperimeter_se:\narea_se:\nsmoothness_se: error estándar para la variación local en las longitudes del radio.\ncompactness_se: (error estándar para perímetro)^2 / área - 1,0.\nconcavity_se: error estándar para la gravedad de las partes cóncavas del contorno.\nconcave points_se: error estándar para el número de porciones cóncavas del contorno.\nsymmetry_se:\nfractal_dimension_se: error estándar para “aproximación de la costa” - 1.\nradius_worst: “peor” o mayor valor medio para la media de distancias desde el centro hasta los puntos del perímetro (en cm).\ntexture_worst: “peor” o mayor valor medio para la desviación estándar de los valores de escala de grises.\nperimeter_worst:\narea_worst:\nsmoothness_worst: “peor” o mayor valor medio para la variación local en longitudes de radio.\ncompactness_worst: “peor” o mayor valor medio para el perímetro^2 / área - 1,0.\nconcavity_worst: “peor” o mayor valor medio para la gravedad de las porciones cóncavas del contorno.\nconcave points_worst: “peor” o mayor valor medio para el número de porciones cóncavas del contorno.\nsymmetry_worst:\nfractal_dimension_worst: “peor” o mayor valor medio para “aproximación de la costa” - 1.\n\n\nurl = \"https://raw.githubusercontent.com/ia4legos/MachineLearning/main/data/cancer.csv\"\nbreastcancer = read_csv(url, col_types = \"ccdddddddddddddddddddddddddddddd\")\n# Estructura de los datos\nstr(breastcancer)\n\nspc_tbl_ [569 × 32] (S3: spec_tbl_df/tbl_df/tbl/data.frame)\n $ id                     : chr [1:569] \"842302\" \"842517\" \"84300903\" \"84348301\" ...\n $ diagnosis              : chr [1:569] \"M\" \"M\" \"M\" \"M\" ...\n $ radius_mean            : num [1:569] 18 20.6 19.7 11.4 20.3 ...\n $ texture_mean           : num [1:569] 10.4 17.8 21.2 20.4 14.3 ...\n $ perimeter_mean         : num [1:569] 122.8 132.9 130 77.6 135.1 ...\n $ area_mean              : num [1:569] 1001 1326 1203 386 1297 ...\n $ smoothness_mean        : num [1:569] 0.1184 0.0847 0.1096 0.1425 0.1003 ...\n $ compactness_mean       : num [1:569] 0.2776 0.0786 0.1599 0.2839 0.1328 ...\n $ concavity_mean         : num [1:569] 0.3001 0.0869 0.1974 0.2414 0.198 ...\n $ concave_points_mean    : num [1:569] 0.1471 0.0702 0.1279 0.1052 0.1043 ...\n $ symmetry_mean          : num [1:569] 0.242 0.181 0.207 0.26 0.181 ...\n $ fractal_dimension_mean : num [1:569] 0.0787 0.0567 0.06 0.0974 0.0588 ...\n $ radius_se              : num [1:569] 1.095 0.543 0.746 0.496 0.757 ...\n $ texture_se             : num [1:569] 0.905 0.734 0.787 1.156 0.781 ...\n $ perimeter_se           : num [1:569] 8.59 3.4 4.58 3.44 5.44 ...\n $ area_se                : num [1:569] 153.4 74.1 94 27.2 94.4 ...\n $ smoothness_se          : num [1:569] 0.0064 0.00522 0.00615 0.00911 0.01149 ...\n $ compactness_se         : num [1:569] 0.049 0.0131 0.0401 0.0746 0.0246 ...\n $ concavity_se           : num [1:569] 0.0537 0.0186 0.0383 0.0566 0.0569 ...\n $ concave_points_se      : num [1:569] 0.0159 0.0134 0.0206 0.0187 0.0188 ...\n $ symmetry_se            : num [1:569] 0.03 0.0139 0.0225 0.0596 0.0176 ...\n $ fractal_dimension_se   : num [1:569] 0.00619 0.00353 0.00457 0.00921 0.00511 ...\n $ radius_worst           : num [1:569] 25.4 25 23.6 14.9 22.5 ...\n $ texture_worst          : num [1:569] 17.3 23.4 25.5 26.5 16.7 ...\n $ perimeter_worst        : num [1:569] 184.6 158.8 152.5 98.9 152.2 ...\n $ area_worst             : num [1:569] 2019 1956 1709 568 1575 ...\n $ smoothness_worst       : num [1:569] 0.162 0.124 0.144 0.21 0.137 ...\n $ compactness_worst      : num [1:569] 0.666 0.187 0.424 0.866 0.205 ...\n $ concavity_worst        : num [1:569] 0.712 0.242 0.45 0.687 0.4 ...\n $ concave_points_worst   : num [1:569] 0.265 0.186 0.243 0.258 0.163 ...\n $ symmetry_worst         : num [1:569] 0.46 0.275 0.361 0.664 0.236 ...\n $ fractal_dimension_worst: num [1:569] 0.1189 0.089 0.0876 0.173 0.0768 ...\n - attr(*, \"spec\")=\n  .. cols(\n  ..   id = col_character(),\n  ..   diagnosis = col_character(),\n  ..   radius_mean = col_double(),\n  ..   texture_mean = col_double(),\n  ..   perimeter_mean = col_double(),\n  ..   area_mean = col_double(),\n  ..   smoothness_mean = col_double(),\n  ..   compactness_mean = col_double(),\n  ..   concavity_mean = col_double(),\n  ..   concave_points_mean = col_double(),\n  ..   symmetry_mean = col_double(),\n  ..   fractal_dimension_mean = col_double(),\n  ..   radius_se = col_double(),\n  ..   texture_se = col_double(),\n  ..   perimeter_se = col_double(),\n  ..   area_se = col_double(),\n  ..   smoothness_se = col_double(),\n  ..   compactness_se = col_double(),\n  ..   concavity_se = col_double(),\n  ..   concave_points_se = col_double(),\n  ..   symmetry_se = col_double(),\n  ..   fractal_dimension_se = col_double(),\n  ..   radius_worst = col_double(),\n  ..   texture_worst = col_double(),\n  ..   perimeter_worst = col_double(),\n  ..   area_worst = col_double(),\n  ..   smoothness_worst = col_double(),\n  ..   compactness_worst = col_double(),\n  ..   concavity_worst = col_double(),\n  ..   concave_points_worst = col_double(),\n  ..   symmetry_worst = col_double(),\n  ..   fractal_dimension_worst = col_double()\n  .. )\n - attr(*, \"problems\")=<externalptr>"
  },
  {
    "objectID": "40_AplMD.html#análisis-de-los-ejemplos",
    "href": "40_AplMD.html#análisis-de-los-ejemplos",
    "title": "4  Aplicaciones Redes multicapa densas",
    "section": "4.2 Análisis de los ejemplos",
    "text": "4.2 Análisis de los ejemplos\nPara el análisis de cada uno de los ejemplos seguimos siempre el mismo procedimiento:\n\nPreprocesado de los datos y preparación de los datos de muestra y entrenamiento.\nModelo basal de red neuronal.\nExploración de mejoras del modelo basal.\n\n\n4.2.1 Diabetes\nNos enfrentamos aquí a nuestro primer banco de datos cuya objetivo es predecir la progresión de la enfermedad (variable numérica) en función del conjunto de predictoras.\n\n4.2.1.1 Preprocesado\nEn el preprocesado de los datos debemos identificar la presencia o no de valores faltantes para imputar los correspondientes valores, así como codificar los inputs o predictoras de tipo factor. Posteriormente establecemos las matrices de inputs y vector de outputs, y dividimos el conjunto de datos en muestra y validación, y estandarizamos los inputs numéricos.\nEn primer lugar establecemos la presencia o no de valores faltantes en nuestro conjunto de datos con el código siguiente:\n\n# Valoramos a existencia de valores pérdidos\napply(is.na(diabetes),2,sum)\n\nAGE SEX BMI  BP  S1  S2  S3  S4  S5  S6   Y \n  0   0   0   0   0   0   0   0   0   0   0 \n\n\nGeneramos ahora la matriz de inputs y el vector de outputs, identificando los tipos de cada una de ellas y codificamos los inputs categóricos para convertirlos en entradas numéricas. En este caso solo tenemos la variable SEX. Como los valores de entrada son 1 (Hombres) y 2 (Mujeres) codificaremos 0-1 donde el 0 hace referencia a los hombres y 1 a las mujeres.\n\n# Output\ny_diabetes = diabetes$Y\n# Matriz de inputs\nX_diabetes = dplyr::select(diabetes, -c(\"Y\"))\n# Tipo de input\ntipos = sapply(X_diabetes,class)\n# Conjunto de numéricas\nXnum = X_diabetes[,names(X_diabetes)[tipos == \"numeric\"]]\n########## Recodificación factor ########\n# Codificación 0-1\nX_diabetes$SEX_cod = as.numeric(X_diabetes$SEX) - 1\n\nEstablecemos ahora la división en muestras de entrenamiento (80%) y validación (20%), y estandarizamos los inputs numéricos. Para ello seleccionamos la columnas correspondientes con la variable tipos que acabamos de definir.\n\n####### División de muestras #############\n# semilla para reproducibilidad\nset.seed(123)\n# Proporción muestra de entrenamiento\nnp = 0.8\n# número de muestras\nmuestras = nrow(diabetes)\n# Índices de la muestra de entrenamiento para la selección\nids_train = sample(muestras, np*muestras)\n# Identificamos entrenamiento y validación matriz numéricas\nxtrain = Xnum[ids_train,]\nxtest = Xnum[-ids_train,]\n######## Estandarización #################\n# Medias\nmean_train = apply(xtrain, 2, mean)\n# Desviaciones típicas\nsd_train = apply(xtrain, 2, sd)\n# Estandarizamos muestra de entrenamiento\nxtrain_est = scale(xtrain, mean_train, sd_train)\n# Estandarizamos muestra de validación\nxtest_est = scale(xtest, mean_train, sd_train)\n# Muestras de entrenamiento y validación\nxtrain_diabetes = cbind(xtrain_est, X_diabetes$SEX_cod[ids_train])\nxtest_diabetes = cbind(xtest_est, X_diabetes$SEX_cod[-ids_train])\nytrain_diabetes = y_diabetes[ids_train]\nytest_diabetes = y_diabetes[-ids_train]\n# Número de inputs\ninputs = ncol(xtrain_diabetes)\n\nUna vez establecidas las muestras de entrenamiento y validación realizamos un pequeño análisis descriptivo para analizar el comportamiento de los inputs en cada conjunto. Tratamos de ver si la división establecida puede generar algún tipo de sesgo en los resultados de la red neuronal.\n\n## Variables numéricas\ndata.frame(\"Media Entrenamiento\" = apply(xtrain_diabetes[,-10], 2, mean),\n           \"Media Validación\" = apply(xtest_diabetes[,-10], 2, mean)     \n           )\n\n    Media.Entrenamiento Media.Validación\nAGE        1.355376e-16      0.066388850\nBMI        3.049895e-16      0.082392072\nBP        -1.013833e-16      0.004494473\nS1        -1.368985e-16      0.151572062\nS2         1.932122e-17      0.058142653\nS3         2.710708e-16      0.139454280\nS4         3.162031e-16      0.018667633\nS5        -3.399504e-17      0.134118151\nS6        -4.357467e-16     -0.034787479\n\n## Variables factor\ndata.frame(\"Entrenamiento\" = table(xtrain_diabetes[,10])/nrow(xtrain_diabetes),\n           \"Validación\" = table(xtest_diabetes[,10])/nrow(xtest_diabetes))\n\n  Entrenamiento.Var1 Entrenamiento.Freq Validación.Var1 Validación.Freq\n1                  0           0.470255               0       0.4606742\n2                  1           0.529745               1       0.5393258\n\n\nA la vista de los resultados la muestra parece bastante equilibrada y podemos pasar a establecer nuestra primera red neuronal para esta tarea de regresión.\n\n\n4.2.1.2 Nuestra primera RN\nLa mayor diferencia entre los modelos de redes estudiados en el tema anterior y este primer modelo es que la capa de salida sólo tiene una neurona dado que estamos en una tarea de regresión y no necesita función de activación. En cuanto al resto del modelo vamos a considerar dos capas ocultas con 16 neuronas respectivamente, y con función de activación relu.\nPara el proceso de aprendizaje utilizamos el algoritmo rmsprop con pérdida mse y utilizando como métrica mean_squared_logarithmic_error, es decir el logaritmo del error cuadrático medio. Finalmente para el entrenamiento consideramos 200 epochs para asegurar convergencia (la muestra no es muy grande y el proceso es muy rápido), un batch_size de 24, y con un 30% para la validación en el proceso de entrenamiento. Se pueden consultar todas las funciones de pérdida y métricas de aprendizaje en los enlaces: loss, metrics.\n\n# Fijamos semilla de los pesos iniciales para poder \ninicializador = initializer_glorot_normal(seed = 15)\n# Arquitectura de red\nmod1 = keras_model_sequential() %>%  \n  layer_dense(units = 16, activation = 'relu', input_shape = dim(xtrain_diabetes)[[2]], kernel_initializer = inicializador) %>% \n  layer_dense(units = 16, activation = 'relu', kernel_initializer = inicializador) %>% \n  layer_dense(units = 1, kernel_initializer = inicializador)\nsummary(mod1)\n\nModel: \"sequential\"\n________________________________________________________________________________\n Layer (type)                       Output Shape                    Param #     \n================================================================================\n dense_2 (Dense)                    (None, 16)                      176         \n dense_1 (Dense)                    (None, 16)                      272         \n dense (Dense)                      (None, 1)                       17          \n================================================================================\nTotal params: 465 (1.82 KB)\nTrainable params: 465 (1.82 KB)\nNon-trainable params: 0 (0.00 Byte)\n________________________________________________________________________________\n\n# Proceso de aprendizaje\nmod1 %>% compile(loss = 'mse', optimizer = optimizer_rmsprop(), metrics = c('mean_squared_logarithmic_error')\n)\n# Entrenamiento del modelo\n# Colocamos verbose=0 para no presentar todo el proceso iterativo  \nhistory_mod1 = mod1 %>% fit(xtrain_diabetes, ytrain_diabetes, batch_size = 24, \n                            epochs = 200, validation_split=0.3, verbose = 0)\n\nAnalizamos el proceso iterativo de convergencia de la red neuronal:\n\nplot(history_mod1)\n\n\n\n\nEl modelo parece mostrar un buen comportamiento tanto en la función de pérdida como en la métríca de evaluación. Ambas muestras se comportan de forma casi idéntica y tenemos convergencia desde la epoch 60 o 70. Parece razonable que un reajuste de la arquitectura de la red (menos neuronas o añadir alguna capa más) podría llevarnos a un modelo más eficiente. Evaluamos la métrica sobre la muestra de validación:\n\nmod1 %>% tensorflow::evaluate(xtest_diabetes, ytest_diabetes)\n\n3/3 - 0s - loss: 3180.7302 - mean_squared_logarithmic_error: 0.1763 - 33ms/epoch - 11ms/step\n\n\n                          loss mean_squared_logarithmic_error \n                    3180.73022                        0.17632 \n\n\nEl valor de la métrica es 0.1773 que es relativamente pequeño. Para evaluar la capacidad predictiva del modelo obtenemos la predicción y comparamos los resultados con los valores observados:\n\n# predicción de la evolución de la enfermedad\nprediccion = mod1 %>% predict(xtest_diabetes)\n\n3/3 - 0s - 79ms/epoch - 26ms/step\n\ndf = data.frame(pred = prediccion, ori = ytest_diabetes)\n# gráfico\nggplot(df, aes(ori, prediccion)) + \n  geom_point() +  \n  geom_abline(intercept = 0, slope = 1, col = \"blue\")\n\n\n\n\nLa linea azul de referencia indica el ajuste perfecto, de forma que el modelo propuesto proporciona una buena solución. Tomaremos este modelo como nuestro modelo basal sobre el que iremos añadiendo modificaciones con el objeto de conseguir un modelo de predicción más preciso sin caer en el problema del sobreajuste.\n\n\n4.2.1.3 Actualizando nuestra red neuronal\nEn este punto proponemos diferentes modificaciones de la red anterior empezando por los parámetros que pretenden controlar el sobreajuste (early stopping y drop-out). En concreto, fijamos un drop out del 50% en cada capa intermedia.\n\n# Fijamos semilla de los pesos iniciales para poder \ninicializador = initializer_glorot_normal(seed = 15)\n# callback early stopping\nearly_stop = callback_early_stopping(monitor = 'val_loss')\n# Arquitectura de red\nmod1 = keras_model_sequential() %>%  \n  layer_dense(units = 16, activation = 'relu', input_shape = dim(xtrain_diabetes)[[2]], kernel_initializer = inicializador) %>% \n  layer_dense(units = 16, activation = 'relu', kernel_initializer = inicializador) %>% \n  layer_dense(units = 1, kernel_initializer = inicializador)\nsummary(mod1)\n\nModel: \"sequential_1\"\n________________________________________________________________________________\n Layer (type)                       Output Shape                    Param #     \n================================================================================\n dense_5 (Dense)                    (None, 16)                      176         \n dense_4 (Dense)                    (None, 16)                      272         \n dense_3 (Dense)                    (None, 1)                       17          \n================================================================================\nTotal params: 465 (1.82 KB)\nTrainable params: 465 (1.82 KB)\nNon-trainable params: 0 (0.00 Byte)\n________________________________________________________________________________\n\n# Proceso de aprendizaje\nmod1 %>% compile(loss = 'mse', optimizer = optimizer_rmsprop(), metrics = c('mean_squared_logarithmic_error')\n)\n# Entrenamiento del modelo\n# Eliminamos verbose para ver donde se detiene el proceo iterativono presentar todo el proceso iterativo  \nhistory_mod1 = mod1 %>% fit(xtrain_diabetes, ytrain_diabetes, batch_size = 24, epochs = 200, \n                            validation_split=0.3, verbose = 0, callbacks=list(early_stop))\n\nRepresentamos gráficamente el proceso iterativo para verificar si el modeo se ha detenido antes de alcanzar las 200 evaluaciones.\n\nplot(history_mod1)\n\n\n\n\nPodemos ver como el modelo se detiene antes de alcanzar las 125 evaluaciones. Añadimos ahora las capas de dropout al 50% antes de evaluar la capacidad predictiva del modelo:\n\n# Fijamos semilla de los pesos iniciales para poder \ninicializador = initializer_glorot_normal(seed = 15)\n# callback early stopping\nearly_stop = callback_early_stopping(monitor = 'val_loss')\n# Arquitectura de red\nmod2 = keras_model_sequential() %>%  \n  layer_dense(units = 16, activation = 'relu', input_shape = dim(xtrain_diabetes)[[2]], kernel_initializer = inicializador) %>% \n  layer_dropout(0.5) %>%\n  layer_dense(units = 16, activation = 'relu', kernel_initializer = inicializador) %>% \n  layer_dropout(0.5) %>%\n  layer_dense(units = 1, kernel_initializer = inicializador)\nsummary(mod1)\n\nModel: \"sequential_1\"\n________________________________________________________________________________\n Layer (type)                       Output Shape                    Param #     \n================================================================================\n dense_5 (Dense)                    (None, 16)                      176         \n dense_4 (Dense)                    (None, 16)                      272         \n dense_3 (Dense)                    (None, 1)                       17          \n================================================================================\nTotal params: 465 (1.82 KB)\nTrainable params: 465 (1.82 KB)\nNon-trainable params: 0 (0.00 Byte)\n________________________________________________________________________________\n\n# Proceso de aprendizaje\nmod2 %>% compile(loss = 'mse', optimizer = optimizer_rmsprop(), metrics = c('mean_squared_logarithmic_error')\n)\n# Entrenamiento del modelo\n# Eliminamos verbose para ver donde se detiene el proceo iterativono presentar todo el proceso iterativo  \nhistory_mod2 = mod2 %>% fit(xtrain_diabetes, ytrain_diabetes, batch_size = 24, epochs = 200, \n                            validation_split=0.3, verbose = 0, callbacks=list(early_stop))\n\nEn primer lugar evaluamos ambos modelos sobre la muestra de validación.\n\nmod1 %>% tensorflow::evaluate(xtest_diabetes, ytest_diabetes, verbose = 2)\n\n3/3 - 0s - loss: 3628.7610 - mean_squared_logarithmic_error: 0.1949 - 30ms/epoch - 10ms/step\n\n\n                          loss mean_squared_logarithmic_error \n                  3628.7609863                      0.1949135 \n\nmod2 %>% tensorflow::evaluate(xtest_diabetes, ytest_diabetes, verbose = 2)\n\n3/3 - 0s - loss: 5484.3213 - mean_squared_logarithmic_error: 0.2841 - 29ms/epoch - 10ms/step\n\n\n                          loss mean_squared_logarithmic_error \n                  5484.3212891                      0.2840641 \n\n\nSe puede ver que el modelo sin dropout proporcione mejores valores en las métricas de validación pero los resultados son bastante similares. Podemos analizar más su comportamiento con el gráfico siguiente:\n\nmse1 = history_mod1$metrics$val_loss\nmse2 = history_mod2$metrics$val_loss\nlmse1 = history_mod1$metrics$val_mean_squared_logarithmic_error\nlmse2 = history_mod2$metrics$val_mean_squared_logarithmic_error\n\npar(mfrow=c(1,2))\nplot(mse1, type = \"l\", col = 1, lwd = 1.5, xlim= c(1,200), xlab=\"Epoch\", ylab=\"Value\", \n     main =\"validation MSE\")\nlines(mse2, col =2, lwd = 1.5)\nlegend(\"topright\", legend=c(\"Sin Dropout\", \"50% Dropout\"), lty = c(1,1), col = c(1,2))\n\nplot(lmse1, type = \"l\", col = 1, lwd = 1.5, xlim= c(1,200), xlab=\"Epoch\", ylab=\"Value\", \n     main =\"validation log(MSE)\")\nlines(lmse2, col =2, lwd = 1.5)\nlegend(\"topright\", legend=c(\"Sin Dropout\", \"50% Dropout\"), lty = c(1,1), col = c(1,2))\n\n\n\n\nRealmente ambas soluciones son bastante semejantes con lo que podríamos optar por cualquiera de ellas. Si queremos protegernos frente al problema de sobre estimación podemos optar por la opción con dropout que en términos de las métricas proporciona resultados casi idénticos. En este caso optamos por la opción sin dropout para seguir explorando posibilidades de la red y por que el ajuste del modelo es tan rápido que no nos hace falta saltar neuronas en las diferentes capas.\nPasamos ahora a estudiar el efecto que sobre el modelo tienen los cambios en el learning rate y el batch size. En concreto consideramos valores 0.0001, 0.001, 0.01, 0.1, y 1 para el learning rate, y 8, 16, 32 y 64 para el batch size. En primer lugar definimos la arquitectura del modelo en función del learning rate:\n\nbuild_model = function(lr, ninputs)\n{\n# Función para la definición del modelo (arquitectura y proceso de aprendizaje)\n\n  #  Valores de entrada\n  #   tasa: tasa de aprendizaje\n  #   ninuts: número de inputs\n  \n  # Valores de salida\n  #   modelo: modelo configurado\n  \n  # Fijamos semilla de los pesos iniciales para poder \n  inicializador = initializer_glorot_normal(seed = 15)\n  # Arquitectura de red\n  mod = keras_model_sequential() %>%  \n    layer_dense(units = 16, activation = 'relu', input_shape = ninputs, kernel_initializer = inicializador) %>% \n    layer_dense(units = 16, activation = 'relu', kernel_initializer = inicializador) %>% \n    layer_dense(units = 1, kernel_initializer = inicializador)\n  # Proceso de aprendizaje\n  mod %>% compile(loss = 'mse', optimizer = optimizer_rmsprop(learning_rate = lr), metrics = c('mean_squared_logarithmic_error')\n  )\n  # Devolvemos el modelo configurado\n  return(mod)\n}\n\nAhora planteamos el bucle de evaluación del learning rate y batch size. En early stopping añadimos patience igual a 5 para estabilizar la solución:\n\n# Lista donde almacenamos la métrica de evaluación de cada modelo\ncomparativa = c()\nlr = c(0.0001, 0.001, 0.01, 0.1, 1)\nbs = c(8, 16, 32, 64)\n\n# Bucle de evaluación\nfor (i in lr)\n{\n  for (j in bs)\n  {\n    modelo = build_model(lr = i, ninputs = dim(xtrain_diabetes)[[2]])\n    # callback early stopping\n    early_stop = callback_early_stopping(monitor = 'val_loss', patience = 5)\n    # Entrenamiento\n    history = modelo %>%  fit(xtrain_diabetes, ytrain_diabetes, batch_size = j, epochs = 200, \n                            validation_split=0.3, verbose = 0, callbacks=list(early_stop))\n    # Evaluación\n    valor = (modelo %>% tensorflow::evaluate(xtest_diabetes, ytest_diabetes, verbose = 0))[2]\n    comparativa = rbind(comparativa, c(i,j,valor))\n  }\n}\n# Data Frame de resultados\ncolnames(comparativa) = c(\"lr\", \"Bs\", \"logMSE\")\n# Mejor combinación\nvalores = comparativa[which.min(comparativa[,3]),]\nvalores\n\n       lr        Bs    logMSE \n0.1000000 8.0000000 0.1452594 \n\n\nReajustamos el modelo óptimo:\n\n# Fijamos semilla de los pesos iniciales para poder \ninicializador = initializer_glorot_normal(seed = 15)\n# Arquitectura de red\nmod = keras_model_sequential() %>%  \n    layer_dense(units = 16, activation = 'relu', input_shape = dim(xtrain_diabetes)[[2]], kernel_initializer = inicializador) %>% \n    layer_dense(units = 16, activation = 'relu', kernel_initializer = inicializador) %>% \n    layer_dense(units = 1, kernel_initializer = inicializador)\n# Proceso de aprendizaje\nmod %>% compile(loss = 'mse', optimizer = optimizer_rmsprop(learning_rate = valores[1]), metrics = c('mean_squared_logarithmic_error'))\n# callback early stopping\nearly_stop = callback_early_stopping(monitor = 'val_loss', patience = 5)\n# Entrenamiento\nhistory = mod %>%  fit(xtrain_diabetes, ytrain_diabetes, batch_size = valores[2], epochs = 200, validation_split=0.3, verbose = 0, callbacks=list(early_stop))\nplot(history)\n\n\n\n\nEl modelo estabiliza la solución sobre la epoch 50. Por último representamos los valores predichos por el modelo frente a los valores observados:\n\n# predicción de la evolución de la enfermedad\nprediccion = mod %>% predict(xtest_diabetes)\n\n3/3 - 0s - 57ms/epoch - 19ms/step\n\ndf = data.frame(pred = prediccion, ori = ytest_diabetes)\n# gráfico\nggplot(df, aes(ori, prediccion)) + \n  geom_point() +  \n  geom_abline(intercept = 0, slope = 1, col = \"blue\")\n\n\n\n\nAunque podríamos seguir haciendo pruebas en nuestra arquitectura de red vamos a tomar esta como definitiva y procedemos con el estudio de validación para valorar el cambio en los resultados cuando iteramos las muestras de entrenamiento y validación. A continuación vemos el algoritmo de validación cruzada con \\(k=10\\) folds y estudiamos la métrica de validación del modelo.\nEn primer lugar definimos la función que nos permite evaluar el modelo de red establecido para una división de entrenamiento y test específica:\n\nbuild_model = function(xtrain, ytrain, xtest, ytest)\n{  \n  # Función para evaluar una red neuronal en función la muestra de netrenamiento y división \n  \n  # Valores de entrada\n  #   xtrain: inputs de entrenamiento\n  #   ytrain: target de entrenamiento\n  #   xtest: inputs de validación\n  #   ytest: target de validación\n  \n  # Resultado\n  #   La función devuelve la evaluación de la métrica de interés en las muestras de validación  \n   \n  # Cuerpo de la función\n  # Fijamos semilla de los pesos iniciales para poder \n  inicializador = initializer_glorot_normal(seed = 15)\n  # Arquitectura de red\n  mod = keras_model_sequential() %>%  \n      layer_dense(units = 16, activation = 'relu', input_shape = dim(xtrain)[[2]], kernel_initializer = inicializador) %>% \n      layer_dense(units = 16, activation = 'relu', kernel_initializer = inicializador) %>% \n      layer_dense(units = 1, kernel_initializer = inicializador)\n  # Proceso de aprendizaje\n  mod %>% compile(loss = 'mse', optimizer = optimizer_rmsprop(learning_rate = 0.01), \n                  metrics = c('mean_squared_logarithmic_error'))\n  # callback early stopping\n  early_stop = callback_early_stopping(monitor = 'val_loss', patience = 5)\n  # Entrenamiento\n  history = mod %>%  fit(xtrain, ytrain, batch_size = 64, epochs = 200, \n                         validation_split = 0.3, verbose = 0, callbacks = list(early_stop))\n  # Evaluación del modelo\n  valor = (mod %>% tensorflow::evaluate(xtest, ytest))[2]\n  return(valor)\n}\n\nProcedemos ahora con el bucle de evaluación de cada uno de los folds considerados.\n\n# vector donde almacenamos la métrica de cada modelo\nmetrica = c()\n# Seleccionamos variables numéricas\nXnum = X_diabetes[,-c(2,11)]\n# Seleccionamos variables categóricas\nXcat = X_diabetes[,11]\n# Establecemos número de folds\nfolds = 10\n# Número de muestras\nn = nrow(diabetes)\n# Tamaño de cada fold\nnfolds = floor(n/folds)+1\n\n# Bucle pra cada fold\nfor(i in 1:folds)\n{\n  # Índice para la muestra de test\n  test = (nfolds*(i-1) +1):min(n, (nfolds*i))\n  # Selección inicial de entrenamiento y test para variables numéricas\n  dfnum_train = Xnum[-test,]\n  dfnum_test = Xnum[test,]\n  ###############################\n  # Estandarización de numéricas\n  ###############################\n  # Medias\n  mean_train = apply(dfnum_train, 2, mean)\n  # Desviaciones típicas\n  sd_train = apply(dfnum_train, 2, sd)\n  # Estandarizamos muestra de entrenamiento\n  xtrain_est = scale(dfnum_train, mean_train, sd_train)\n  # Estandarizamos muestra de validación\n  xtest_est = scale(dfnum_test, mean_train, sd_train)\n  #####################################\n  # Matrices de entrenamiento y test\n  #####################################\n  xtrain = cbind(xtrain_est, X_diabetes$SEX_cod[-test])\n  xtest = cbind(xtest_est, X_diabetes$SEX_cod[test])\n  ytrain = y_diabetes[-test]\n  ytest = y_diabetes[test]\n  #####################################\n  # Evaluación del modelo\n  #####################################\n  cat(\"Comienza el entrenamiento para el fold \", i, \"\\n\")\n  res = build_model(xtrain, ytrain, xtest, ytest)\n  metrica = c(metrica, res)\n}\n\nComienza el entrenamiento para el fold  1 \n2/2 - 0s - loss: 3443.1267 - mean_squared_logarithmic_error: 0.1920 - 37ms/epoch - 19ms/step\nComienza el entrenamiento para el fold  2 \n2/2 - 0s - loss: 2547.6919 - mean_squared_logarithmic_error: 0.2057 - 23ms/epoch - 12ms/step\nComienza el entrenamiento para el fold  3 \n2/2 - 0s - loss: 3490.7598 - mean_squared_logarithmic_error: 0.1617 - 29ms/epoch - 14ms/step\nComienza el entrenamiento para el fold  4 \n2/2 - 0s - loss: 2609.2722 - mean_squared_logarithmic_error: 0.1373 - 25ms/epoch - 12ms/step\nComienza el entrenamiento para el fold  5 \n2/2 - 0s - loss: 3539.8403 - mean_squared_logarithmic_error: 0.1747 - 23ms/epoch - 12ms/step\nComienza el entrenamiento para el fold  6 \n2/2 - 0s - loss: 2684.8792 - mean_squared_logarithmic_error: 0.1758 - 22ms/epoch - 11ms/step\nComienza el entrenamiento para el fold  7 \n2/2 - 0s - loss: 3580.5659 - mean_squared_logarithmic_error: 0.1944 - 22ms/epoch - 11ms/step\nComienza el entrenamiento para el fold  8 \n2/2 - 0s - loss: 2978.9531 - mean_squared_logarithmic_error: 0.1153 - 23ms/epoch - 11ms/step\nComienza el entrenamiento para el fold  9 \n2/2 - 0s - loss: 4252.6426 - mean_squared_logarithmic_error: 0.2079 - 23ms/epoch - 12ms/step\nComienza el entrenamiento para el fold  10 \n2/2 - 0s - loss: 1879.3577 - mean_squared_logarithmic_error: 0.1500 - 23ms/epoch - 11ms/step\n\n\nAhora definimos una función que nos proporciona el descriptivo de las métricas\n\nimp_descrip = function(m)\n{\n  cat(\"N            : \", length(m),\"\\n\")\n  cat(\"Media        : \", round(mean(m),3),\"\\n\")\n  cat(\"SD           : \", round(sd(m),3),\"\\n\")\n  cat(\"Mínimo       : \", round(min(m),3),\"\\n\")\n  cat(\"Percentil 25 : \", round(quantile(m, 0.25),3),\"\\n\")\n  cat(\"Percentil 75 : \", round(quantile(m, 0.75),3),\"\\n\")\n  cat(\"Máximo       : \", round(max(m),3),\"\\n\")\n}\n\nVeamos los resultados para el análisis de validación realizado:\n\nimp_descrip(metrica)\n\nN            :  10 \nMedia        :  0.171 \nSD           :  0.03 \nMínimo       :  0.115 \nPercentil 25 :  0.153 \nPercentil 75 :  0.194 \nMáximo       :  0.208 \n\n\n¿qué podemos decir sobre los resultados obtenidos?\n\n\n\n4.2.2 Qsar\nNos enfrentamos aquí a un banco de datos cuya objetivo es predecir la lD50 en función del conjunto de predictoras de tipo numérico.\n\n4.2.2.1 Preprocesado\nEn el preprocesado de los datos debemos identificar la presencia o no de valores faltantes, establecer la matriz de inputs y vector de outputs, dividir el conjunto de datos en muestra y validación, y estandarizar los inputs numéricos.\nEn primer lugar establecemos la presencia o no de valores faltantes en nuestro conjunto de datos con el código siguiente:\n\n# Valoramos a existencia de valores pérdidos\napply(is.na(qsar),2,sum)\n\n  TPSA  SAacc  H-050  MLOGP  RDCHI GATS1p     nN  C-040   LC50 \n     0      0      0      0      0      0      0      0      0 \n\n\nDado que no hay valores ausentes seguimos con el resto de pasos del preprocesamiento. Obtenemos la matriz de inputs y outpit, dividimos la muestra y estandarizamos.\n\n####### nombres variables #######\nnombres = names(qsar)\n######## Matriz de inputs #########\nX_qsar = qsar[,nombres[nombres != \"LC50\"]]\n######## Vector de output #########\ny_qsar = qsar$LC50\n# número de muestras total\nmuestras = nrow(qsar)\n# semilla para reproducibilidad\nset.seed(123)\n# Proporción tamaño de entrenamiento \nnp = 0.8\n# indices de la muestra de entrenamiento\nids_train = sample(muestras, size = np*muestras)\n\n####### División de muestras #############\n# Matriz de inputs\nxtrain = X_qsar[ids_train,]\nxtest = X_qsar[-ids_train,]\n\n######## Estandarización #################\n# Medias\nmean_train = apply(xtrain, 2, mean)\n# Desviaciones típicas\nsd_train = apply(xtrain, 2, sd)\n# Estandarizamos muestra de entrenamiento\nxtrain_qsar = scale(xtrain, mean_train, sd_train)\n# Estandarizamos muestra de validación\nxtest_qsar = scale(xtest, mean_train, sd_train)\n# Muestras de entrenamiento y validación para output\nytrain_qsar = y_qsar[ids_train]\nytest_qsar = y_qsar[-ids_train]\n# Número de inputs\nninputs = ncol(xtrain_qsar)\n\n\n\n4.2.2.2 Nuestra primera red neuronal\nConsideramos una arquitectura de red con dos capas ocultas con 16 neuronas respectivamente, y con función de activación relu. Para el proceso de aprendizaje utilizamos el algoritmo rmsprop con pérdida mse y utilizando como métrica mean_squared_logarithmic_error, es decir el logaritmo del error cuadrático medio. Finalmente para el entrenamiento consideramos 200 epochs para asegurar convergencia (la muestra no es muy grande y el proceso es muy rápido), un batch_size de 24, y con un 20% para la validación en el proceso de entrenamiento.\n\n# Fijamos semilla de los pesos iniciales para poder \ninicializador = initializer_glorot_normal(seed = 15)\n# Arquitectura de red\nmod1 = keras_model_sequential() %>%  \n  layer_dense(units = 16, activation = 'relu', input_shape = ninputs, kernel_initializer = inicializador) %>% \n  layer_dense(units = 16, activation = 'relu', kernel_initializer = inicializador) %>% \n  layer_dense(units = 1, kernel_initializer = inicializador)\nsummary(mod1)\n\nModel: \"sequential_34\"\n________________________________________________________________________________\n Layer (type)                       Output Shape                    Param #     \n================================================================================\n dense_104 (Dense)                  (None, 16)                      144         \n dense_103 (Dense)                  (None, 16)                      272         \n dense_102 (Dense)                  (None, 1)                       17          \n================================================================================\nTotal params: 433 (1.69 KB)\nTrainable params: 433 (1.69 KB)\nNon-trainable params: 0 (0.00 Byte)\n________________________________________________________________________________\n\n# Proceso de aprendizaje\nmod1 %>% compile(loss = 'mse', optimizer = optimizer_rmsprop(), metrics = c('mean_squared_logarithmic_error'))\n# Entrenamiento del modelo\n# Colocamos verbose=0 para no presentar todo el proceso iterativo  \nhistory_mod1 = mod1 %>% fit(xtrain_qsar, ytrain_qsar, batch_size = 24, \n                            epochs = 200, validation_split=0.2, verbose = 0)\n\nAnalizamos el proceso iterativo de convergencia de la red neuronal:\n\nplot(history_mod1)\n\n\n\n\nEl proceso converge en pocas epochs con unos resultados muy buenos. Evaluamos los resultados en al muestra de test, construímos la predicción asociada con el modelo y la representamos con respecto al target observado.\n\n# Evaluación muestra de test\neval = mod1 %>% tensorflow::evaluate(xtest_qsar, ytest_qsar)\n\n4/4 - 0s - loss: 1.2088 - mean_squared_logarithmic_error: 0.0583 - 31ms/epoch - 8ms/step\n\ncat(\"Evaluación del modelo en la muestra de test: \", eval)\n\nEvaluación del modelo en la muestra de test:  1.208754 0.05825111\n\n# predicción de la evolución de la enfermedad\nprediccion = mod1 %>% predict(xtest_qsar)\n\n4/4 - 0s - 59ms/epoch - 15ms/step\n\ndf = data.frame(pred = prediccion, ori = ytest_qsar)\n# gráfico\nggplot(df, aes(ori, prediccion)) + \n  geom_point() +  \n  geom_abline(intercept = 0, slope = 1, col = \"blue\")\n\n\n\n\nEl gráfico de dispersión muestra el buen comportamiento de los valores predichos.\n\n\n4.2.2.3 Actualizando nuestra red neuronal\nAl no apreciarse problemas de sobreaprendizaje podríamos quedarnos con este modelo como modelo final. Sin embargo, para simplificar el modelo de red vamos a considerar algunas modificaciones. en primer lugar vamos a reducir el número de epochs a la mitad y comparamos los resultados.\n\n# Fijamos semilla de los pesos iniciales para poder \ninicializador = initializer_glorot_normal(seed = 15)\n# Arquitectura de red\nmod2 = keras_model_sequential() %>%  \n  layer_dense(units = 16, activation = 'relu', input_shape = ninputs, kernel_initializer = inicializador) %>% \n  layer_dense(units = 16, activation = 'relu', kernel_initializer = inicializador) %>% \n  layer_dense(units = 1, kernel_initializer = inicializador)\n# Proceso de aprendizaje\nmod2 %>% compile(loss = 'mse', optimizer = optimizer_rmsprop(), metrics = c('mean_squared_logarithmic_error'))\n# Entrenamiento del modelo\n# Colocamos verbose=0 para no presentar todo el proceso iterativo  \nhistory_mod2 = mod2 %>% fit(xtrain_qsar, ytrain_qsar, batch_size = 24, \n                            epochs = 100, validation_split=0.2, verbose = 0)\n# Evaluación muestra de test\neval = mod2 %>% tensorflow::evaluate(xtest_qsar, ytest_qsar)\n\n4/4 - 0s - loss: 1.2551 - mean_squared_logarithmic_error: 0.0560 - 25ms/epoch - 6ms/step\n\ncat(\"Evaluación del modelo en la muestra de test: \", eval)\n\nEvaluación del modelo en la muestra de test:  1.255135 0.05602086\n\n\nEl valor de la métrica para la muestra de test 0.0566 que es inferior al de la red anterior que era 0.0592 mostrando que la reducción de epochs mejora incluos la solución del modelo anterior. Podemos intentar ahora simplificar la red considerando una única capa oculta.\n\n# Fijamos semilla de los pesos iniciales para poder \ninicializador = initializer_glorot_normal(seed = 15)\n# Arquitectura de red\nmod3 = keras_model_sequential() %>%  \n  layer_dense(units = 16, activation = 'relu', input_shape = ninputs, kernel_initializer = inicializador) %>% \n  layer_dense(units = 1, kernel_initializer = inicializador)\n# Proceso de aprendizaje\nmod3 %>% compile(loss = 'mse', optimizer = optimizer_rmsprop(), metrics = c('mean_squared_logarithmic_error'))\n# Entrenamiento del modelo\n# Colocamos verbose=0 para no presentar todo el proceso iterativo  \nhistory_mod3 = mod3 %>% fit(xtrain_qsar, ytrain_qsar, batch_size = 24, \n                            epochs = 100, validation_split=0.2, verbose = 0)\n# Evaluación muestra de test\neval = mod3 %>% tensorflow::evaluate(xtest_qsar, ytest_qsar)\n\n4/4 - 0s - loss: 1.3601 - mean_squared_logarithmic_error: 0.0560 - 29ms/epoch - 7ms/step\n\ncat(\"Evaluación del modelo en la muestra de test: \", eval)\n\nEvaluación del modelo en la muestra de test:  1.360115 0.05598298\n\n\nLa métrica del modelo es inferior al anterior, de forma que trabajar con un modelo más sencillo produce mejores resultados. Veamos que ocurre si reducimos ahora el número de neuronas.\n\n# Fijamos semilla de los pesos iniciales para poder \ninicializador = initializer_glorot_normal(seed = 15)\n# Arquitectura de red\nmod4 = keras_model_sequential() %>%  \n  layer_dense(units = 8, activation = 'relu', input_shape = ninputs, kernel_initializer = inicializador) %>% \n  layer_dense(units = 1, kernel_initializer = inicializador)\n# Proceso de aprendizaje\nmod4 %>% compile(loss = 'mse', optimizer = optimizer_rmsprop(), metrics = c('mean_squared_logarithmic_error'))\n# Entrenamiento del modelo\n# Colocamos verbose=0 para no presentar todo el proceso iterativo  \nhistory_mod4 = mod4 %>% fit(xtrain_qsar, ytrain_qsar, batch_size = 24, \n                            epochs = 100, validation_split=0.2, verbose = 0)\n# Evaluación muestra de test\neval = mod4 %>% tensorflow::evaluate(xtest_qsar, ytest_qsar)\n\n4/4 - 0s - loss: 1.5103 - mean_squared_logarithmic_error: 0.0639 - 30ms/epoch - 8ms/step\n\ncat(\"Evaluación del modelo en la muestra de test: \", eval)\n\nEvaluación del modelo en la muestra de test:  1.510266 0.06386463\n\n\nEn este caso la solución empeora con loq ue reducir el número de neuronas produce un modelo con peror poder de predicción. Otras opciones pasarían por seguir modificando las características de la red para ver si podemos reducir el valo de la métrica de evaluación. Obtenemos la predicción para el mejor modleo encontrado hasta ahora y repreentamos de nuevo frente a los valores observados.\n\n# Evaluación muestra de test\neval = mod3 %>% tensorflow::evaluate(xtest_qsar, ytest_qsar)\n\n4/4 - 0s - loss: 1.3601 - mean_squared_logarithmic_error: 0.0560 - 42ms/epoch - 10ms/step\n\ncat(\"Evaluación del modelo en la muestra de test: \", eval)\n\nEvaluación del modelo en la muestra de test:  1.360115 0.05598298\n\n# predicción de la evolución de la enfermedad\nprediccion = mod3 %>% predict(xtest_qsar)\n\n4/4 - 0s - 55ms/epoch - 14ms/step\n\ndf = data.frame(pred = prediccion, ori = ytest_qsar)\n# gráfico\nggplot(df, aes(ori, prediccion)) + \n  geom_point() +  \n  geom_abline(intercept = 0, slope = 1, col = \"blue\")\n\n\n\n\nComo era de esperar la solución es muy similar a la presentada antes, ya que la mejora en la métrica de evalaución no es suficente apra producir una solución muy diferente.\n\n\n\n4.2.3 Water potability\nEn este caso nos enfrentamos a un problema de clasificación binario (agua potable o no potable) con un conjunto de predictoras de tipo numérico donde tenemos valores ausentes en algunas de ellas.\n\n4.2.3.1 Preprocesado\nEn el preprocesado de los datos debemos identificar la presencia o no de valores faltantes para imputar los correspondientes valores, establecer las matrices de inputs y vector de outputs, dividir el conjunto de datos en muestra y validación, y estandarizar los inputs numéricos.\nEn primer lugar valoramos la presencia de valores faltantes:\n\n# Valoramos a existencia de valores perdidos\napply(is.na(waterpot),2,sum)\n\n             ph        Hardness          Solids     Chloramines         Sulfate \n            491               0               0               0             781 \n   Conductivity  Organic_carbon Trihalomethanes       Turbidity      Potability \n              0               0             162               0               0 \n\n\nDado que se detectan valores ausentes en tres de los inputs podemos optar por dos soluciones:\n\nEliminar todas las muestras que contiene al menos un valor ausente, que en este caso no resulta razonable ya que el tamaño del banco de datos pasaría de 3276 a 2011.\nImputar los valores ausentes con un valor adecuado. En este optamos por imputar con la mediana del resto de valores de la variable de interés.\n\nVeamos como realizar el proceso de imputación de forma rápida y sencilla. Básicamente se trata de identificar las posiciones donde se encuentran los valores ausentes y sustituir dichos valores por la mediana de esa variable.\nNo se detectan valores ausentes por lo que podemos establecer la matriz global de inputs y vector completo de output:\n\n# Proceso de imputación en cada variable\nwaterpot[is.na(waterpot$ph),\"ph\"] = median(waterpot$ph, na.rm = T)\nwaterpot[is.na(waterpot$Sulfate),\"Sulfate\"] = median(waterpot$Sulfate, na.rm = T)\nwaterpot[is.na(waterpot$Trihalomethanes),\"Trihalomethanes\"] = median(waterpot$Trihalomethanes, na.rm = T)\n# Valoramos de nuevo la presencia de valores ausentes\napply(is.na(waterpot),2,sum)\n\n             ph        Hardness          Solids     Chloramines         Sulfate \n              0               0               0               0               0 \n   Conductivity  Organic_carbon Trihalomethanes       Turbidity      Potability \n              0               0               0               0               0 \n\n\nAhora podemos seguir con el preprocesado. En concreto dividimos en muestra de entrenamiento y validación, para proceder posteriormente con la estandarización. Sin embargo la división en este caso debe mantener el porcentaje de 0-1 de la respuesta en la muestra de entrenamiento para no introducir sesgos de selección y ajuste durante el entrenamiento, ya que los tamaños originales no están equilibrados. Creamos la matriz de inputs y vector de target en primer lugar.\n\n####### nombres variables #######\nnombres = names(waterpot)\n######## Matriz de inputs #########\nX_waterpot = waterpot[,nombres[nombres != \"Potability\"]]\n######## Vector de output #########\ny_waterpot = waterpot$Potability\n\nPara poder muestrear de acuerdo a los tamaños originales de la variable Potability creamos un vector de pesos asociado con la proporción inicial de cada nivel de la respuesta. Veamos como realizar este proceso:\n\n# número de muestras total\nmuestras = nrow(waterpot)\n# semilla para reproducibilidad\nset.seed(123)\n\n######### muestreo de índices de entrenamiento ######\n# 1. Obtenemos los pesos de cada categoría de la respuesta\ntabla = table(waterpot$Potability)\nprop = as.vector(tabla/sum(tabla))\n# 2. Generamos el vector de pesos asociado ca cada muestra\npesos = rep(0, nrow(waterpot))\npesos[waterpot$Potability == 0] = prop[1]\npesos[waterpot$Potability == 1] = prop[2]\n# 3. Proporción muestra de entrenamiento\nnp = 0.8\n# 4. Indices para la muestra de entrenamiento\nids_train = sample(muestras, size = np*muestras, prob = pesos)\n\nEn primer lugar verificamos si se mantienen las proporciones de reparto de cada clase en la muestra de entrenamiento:\n\n# Reparto en la población original\ntabla = table(waterpot$Potability)\nprop = as.vector(tabla/sum(tabla))\nprop\n\n[1] 0.6098901 0.3901099\n\n# Reparto en la muestra de entrenamiento\ntabla = table(waterpot$Potability[ids_train])\nprop = as.vector(tabla/sum(tabla))\nprop\n\n[1] 0.6557252 0.3442748\n\n\nPodemos ver que los porcentajes son muy similares con lo que podemos proceder con la división de muestras de entrenamiento y validación\n\n####### División de muestras #############\n\n# Matriz de inputs\nxtrain = X_waterpot[ids_train,]\nxtest = X_waterpot[-ids_train,]\n\n######## Estandarización #################\n# Medias\nmean_train = apply(xtrain, 2, mean)\n# Desviaciones típicas\nsd_train = apply(xtrain, 2, sd)\n# Estandarizamos muestra de entrenamiento\nxtrain_waterpot = scale(xtrain, mean_train, sd_train)\n# Estandarizamos muestra de validación\nxtest_waterpot = scale(xtest, mean_train, sd_train)\n# Muestras de entrenamiento y validación para output\nytrain_waterpot = y_waterpot[ids_train]\nytest_waterpot = y_waterpot[-ids_train]\n# Número de inputs\nninputs = ncol(xtrain_waterpot)\n\nUna vez preprocesados los datos vamos a establecer nuestra primera red neuronal.\n\n\n4.2.3.2 Nuestra primera red neuronal\nTenemos un problema de clasificación con dos posibles resultados por lo que debemos adaptar la arquitectura de nuestra red a esta situación. En este caso consideramos dos capas ocultas con 16 neuronas y con función de activación relu, mientras que consideramos la activación sigmoid en la capa de salida. En el proceso de aprendizaje consideramos como función de perdida binary_crossentropy y algoritmo de optmización sgd. En cuanto a la métrica para validar la capacidad de clasificación del algoritmo podemos utilizar la habitual (accuracy) o alguna de las ue viene recogidas en este enlace para variables respuesta con dos categorías. A modo de prueba vamos a usar AUC que nos porporciona el área bajo la curva ROC. Recordemos que cuanto más cerca a 1 se encuentre este valor mejor será la clasificación.\nFinalmente para el entrenamiento consideramos 200 epochs, un batch_size de 16, y con un 20% para la validación en el proceso de entrenamiento.\n\n# Fijamos semilla de los pesos iniciales para poder \ninicializador = initializer_glorot_normal(seed = 15)\n# Arquitectura de red\nmod1 = keras_model_sequential() %>%  \n  layer_dense(units = 32, activation = 'relu', input_shape = ninputs, kernel_initializer = inicializador) %>% \n  layer_dense(units = 32, activation = 'relu', input_shape = ninputs, kernel_initializer = inicializador) %>% \n  layer_dense(units = 1, activation = 'sigmoid', kernel_initializer = inicializador)\n# Proceso de aprendizaje\nmod1 %>% compile(loss = 'binary_crossentropy', optimizer = optimizer_sgd(), metrics = c('AUC')\n)\n# Entrenamiento del modelo\nhistory_mod1 = mod1 %>% fit(xtrain_waterpot, ytrain_waterpot, batch_size = 16, \n                            epochs = 200, validation_split = 0.2, verbose = 0)\nplot(history_mod1)\n\n\n\n\nEl análisis del gráfico muestra que no hemos alcanzado convergencia y que se produce cierto efecto de sobre estimación con el modelo propuesto. Parece obvio que demos modificar la red propuesta apra conseguir resultados más estables. Realizamos el proceso de evaluación del modelo para tener un punto de partida de comparación con el resto de modelos que propondremos a continuación.\n\n# Evaluación de la capacidad clasificadora\ncat(\"Métricas para la muestra de test\")\n\nMétricas para la muestra de test\n\nmod1 %>% tensorflow::evaluate(xtest_waterpot, ytest_waterpot)\n\n21/21 - 0s - loss: 0.8077 - auc: 0.6553 - 43ms/epoch - 2ms/step\n\n\n     loss       auc \n0.8076965 0.6552669 \n\ncat(\"\\n\")\n# probabilidades de clasificación de cada muestra \nprediccion = mod1 %>% predict(xtest_waterpot)\n\n21/21 - 0s - 72ms/epoch - 3ms/step\n\n# predicción del modelo\npr_modelo = as.vector(prediccion %>% `>`(0.5) %>% k_cast(\"int32\"))\n\n# Matriz de confusión\ncm = confusion_matrix(ytest_waterpot, pr_modelo)\n# Gráfico\nplot_confusion_matrix(cm$`Confusion Matrix`[[1]])\n\n\n\n\n\n\n4.2.3.3 Actualizando nuestra red neuronal\nEn primer lugar consideramos la solución más sencilla que consiste en reducir el número de capas ocultas. En concreto consideramos una sola con las mismas especificaciones que en el modelo anterior.\n\n# Fijamos semilla de los pesos iniciales para poder \ninicializador = initializer_glorot_normal(seed = 15)\n# Arquitectura de red\nmod2 = keras_model_sequential() %>%  \n  layer_dense(units = 32, activation = 'relu', input_shape = ninputs, kernel_initializer = inicializador) %>% \n  layer_dense(units = 1, activation = 'sigmoid', kernel_initializer = inicializador)\n# Proceso de aprendizaje\nmod2 %>% compile(loss = 'binary_crossentropy', optimizer = optimizer_sgd(), metrics = c('AUC')\n)\n# Entrenamiento del modelo\nhistory_mod2 = mod2 %>% fit(xtrain_waterpot, ytrain_waterpot, batch_size = 16, \n                            epochs = 200, validation_split = 0.2, verbose = 0)\n\nDefinimos ahora una función que nos permite comparar ambas soluciones:\n\ncompara_history = function(m1, m2)\n{\n  # Función que nos permite compara las historys de dos arquitecturas de red.\n  # en concreto evaluamos la loss y el auc\n  \n  # Parámetros de entrada\n  #   m1: history del modelo 1\n  #   m2: history del modelo 2\n  \n  # Resultado\n  #   gráfico comparativo de loss y auc \n  \n  h1m = m1$metrics\n  h2m = m2$metrics\n  minimoloss = min(h1m$loss, h1m$val_loss, h2m$loss, h2m$val_loss)\n  maximoloss = max(h1m$loss, h1m$val_loss, h2m$loss, h2m$val_loss)\n  minimoauc = min(h1m$auc, h1m$val_auc, h2m$auc, h2m$val_auc)\n  maximoauc = max(h1m$auc, h1m$val_auc, h2m$auc, h2m$val_auc)\n\n  par(mfrow=c(1,2))\n  plot(h1m$loss, type = \"l\", xlab = \"Epoch\", ylab = \"loss\", \n     ylim = c(minimoloss, maximoloss))\n  lines(h2m$loss, col = 2)\n  lines(h1m$val_loss, lty = 2)\n  lines(h2m$val_loss, lty = 2, col = 2)\n  legend(\"topright\", legend=c(\"M1 loss\", \"M2 loss\", \"M1 val-loss\", \"M2 val-loss\"), \n       lty = rep(1:2,rep(2,2)), col = rep(1:2,2))\n\n  plot(h1m$auc, type = \"l\", xlab = \"Epoch\", ylab = \"AUC\", \n     ylim = c(minimoauc, maximoauc))\n  lines(h2m$auc, col = 2)\n  lines(h1m$val_auc, lty = 2)\n  lines(h2m$val_auc, lty = 2, col = 2)\n  legend(\"bottomright\", legend=c(\"M1 AUC\", \"M2 AUC\", \"M1 val-AUC\", \"M2 val-AUC\"), \n       lty = rep(1:2,rep(2,2)), col = rep(1:2,2))\n}\n\n\ncompara_history(history_mod1, history_mod2)\n\n\n\n\nEl segundo planteado parece mejorar algo el problema de sobreajuste, aunque no soluciona el problema del todo. Veamos que ocurre si reducimos el número de neuronas. En concreto vamos a pasar de 32 a 8.\n\n# Fijamos semilla de los pesos iniciales para poder \ninicializador = initializer_glorot_normal(seed = 15)\n# Arquitectura de red\nmod3 = keras_model_sequential() %>%  \n  layer_dense(units = 8, activation = 'relu', input_shape = ninputs, kernel_initializer = inicializador) %>% \n  layer_dense(units = 1, activation = 'sigmoid', kernel_initializer = inicializador)\n# Proceso de aprendizaje\nmod3 %>% compile(loss = 'binary_crossentropy', optimizer = optimizer_sgd(), metrics = c('AUC')\n)\n# Entrenamiento del modelo\nhistory_mod3 = mod3 %>% fit(xtrain_waterpot, ytrain_waterpot, batch_size = 16, \n                            epochs = 200, validation_split = 0.2, verbose = 0)\n\nComparamos las soluciones de los dos últimos modelos:\n\ncompara_history(history_mod2, history_mod3)\n\n\n\n\nLa solución es muy similar a la anterior por lo tanto para obtener mejores resultados utilizamos la solución con 32 neuronas. Antes de pasar valorar diferentes opciones sobre el proceso de optimización valoramos lo que ocurre si introducimos una capa de dropout del 20%.\n\n# Fijamos semilla de los pesos iniciales para poder \ninicializador = initializer_glorot_normal(seed = 15)\n# Arquitectura de red\nmod4 = keras_model_sequential() %>%  \n  layer_dense(units = 32, activation = 'relu', input_shape = ninputs, kernel_initializer = inicializador) %>% \n  layer_dropout(0.2) %>%\n  layer_dense(units = 1, activation = 'sigmoid', kernel_initializer = inicializador)\n# Proceso de aprendizaje\nmod4 %>% compile(loss = 'binary_crossentropy', optimizer = optimizer_sgd(), metrics = c('AUC')\n)\n# Entrenamiento del modelo\nhistory_mod4 = mod4 %>% fit(xtrain_waterpot, ytrain_waterpot, batch_size = 16, \n                            epochs = 200, validation_split = 0.2, verbose = 0)\n\nComparamos las soluciones de ambos modelos\n\ncompara_history(history_mod2, history_mod4)\n\n\n\n\nEl modelo es mucho más estable con lo que vamos a pasar a introducir mejoras sobre el proceso de optimización. En primer lugar vamos a considerar diferentes algoritmos de aprendizaje y learning rate. En concreto consideramos los algoritmos rmsprop y ADAM con tasas de aprendizaje 0.0001, 0.001, 0.01, y 0.1. Definimos una función con la arquitectura del modelo para cada algortimo de optimización antes de introducir el bucle de evaluación de todas las tasas de aprendiaje.\n\nbuild_model_sgd = function(lr)\n{\n  # Fijamos semilla de los pesos iniciales para poder \n  inicializador = initializer_glorot_normal(seed = 15)\n  # Arquitectura de red\n  mod = keras_model_sequential() %>%  \n    layer_dense(units = 32, activation = 'relu', input_shape = ninputs, kernel_initializer = inicializador) %>% \n    layer_dropout(0.2) %>%\n    layer_dense(units = 1, activation = 'sigmoid', kernel_initializer = inicializador)\n  # Proceso de aprendizaje\n  mod %>% compile(loss = 'binary_crossentropy', optimizer = optimizer_sgd(learning_rate = lr), metrics = c('AUC'))\n  # Entrenamiento de los modelos\n  h1 = mod %>% fit(xtrain_waterpot, ytrain_waterpot, batch_size = 16, epochs = 200, validation_split = 0.2, verbose = 0)\n  # Evaluación\n  eval = (mod %>% tensorflow::evaluate(xtest_waterpot, ytest_waterpot, verbose = 2))[2]\nreturn (eval) \n}\n\nbuild_model_rmsprop = function(lr)\n{\n  # Fijamos semilla de los pesos iniciales para poder \n  inicializador = initializer_glorot_normal(seed = 15)\n  # Arquitectura de red\n  mod = keras_model_sequential() %>%  \n    layer_dense(units = 32, activation = 'relu', input_shape = ninputs, kernel_initializer = inicializador) %>% \n    layer_dropout(0.2) %>%\n    layer_dense(units = 1, activation = 'sigmoid', kernel_initializer = inicializador)\n  # Proceso de aprendizaje\n  mod %>% compile(loss = 'binary_crossentropy', optimizer = optimizer_rmsprop(learning_rate = lr), metrics = c('AUC'))\n  # Entrenamiento de los modelos\n  h1 = mod %>% fit(xtrain_waterpot, ytrain_waterpot, batch_size = 16, epochs = 200, validation_split = 0.2, verbose = 0)\n  # Evaluación\n  eval = (mod %>% tensorflow::evaluate(xtest_waterpot, ytest_waterpot, verbose = 2))[2]\nreturn (eval) \n}\n\nbuild_model_adam = function(lr)\n{\n  # Fijamos semilla de los pesos iniciales para poder \n  inicializador = initializer_glorot_normal(seed = 15)\n  # Arquitectura de red\n  mod = keras_model_sequential() %>%  \n    layer_dense(units = 32, activation = 'relu', input_shape = ninputs, kernel_initializer = inicializador) %>% \n    layer_dropout(0.2) %>%\n    layer_dense(units = 1, activation = 'sigmoid', kernel_initializer = inicializador)\n  # Proceso de aprendizaje\n  mod %>% compile(loss = 'binary_crossentropy', optimizer = optimizer_adam(learning_rate = lr), metrics = c('AUC'))\n  # Entrenamiento de los modelos\n  h1 = mod %>% fit(xtrain_waterpot, ytrain_waterpot, batch_size = 16, epochs = 200, validation_split = 0.2, verbose = 0)\n  # Evaluación\n  eval = (mod %>% tensorflow::evaluate(xtest_waterpot, ytest_waterpot, verbose = 2))[2]\nreturn (eval) \n}\n\nVeamos ahora el bucle con todos los algoritmos y tasas de aprendizaje propuestas:\n\n# evaluación AUC de cada modelo sobre la muestra de validación\neval_auc_sgd = c()\neval_auc_rmsprop = c()\neval_auc_adam = c()\n\nlr = c(0.0001, 0.001, 0.01, 0.1)\n\nfor (i in 1:4)\n{\n  # Evaluación\n  eval_auc_sgd[i] = build_model_sgd(lr[i])\n  eval_auc_rmsprop[i] = build_model_rmsprop(lr[i])\n  eval_auc_adam[i] = build_model_adam(lr[i])  \n}\n\n21/21 - 0s - loss: 0.8722 - auc: 0.4855 - 43ms/epoch - 2ms/step\n21/21 - 0s - loss: 0.7524 - auc: 0.6562 - 71ms/epoch - 3ms/step\n21/21 - 0s - loss: 0.7484 - auc: 0.6583 - 42ms/epoch - 2ms/step\n21/21 - 0s - loss: 0.7930 - auc: 0.5560 - 42ms/epoch - 2ms/step\n21/21 - 0s - loss: 0.7528 - auc: 0.6611 - 43ms/epoch - 2ms/step\n21/21 - 0s - loss: 0.7541 - auc: 0.6570 - 49ms/epoch - 2ms/step\n21/21 - 0s - loss: 0.7479 - auc: 0.6688 - 42ms/epoch - 2ms/step\n21/21 - 0s - loss: 0.9565 - auc: 0.6428 - 42ms/epoch - 2ms/step\n21/21 - 0s - loss: 0.8481 - auc: 0.6634 - 44ms/epoch - 2ms/step\n21/21 - 0s - loss: 0.7656 - auc: 0.6605 - 42ms/epoch - 2ms/step\n21/21 - 0s - loss: 0.9907 - auc: 0.5833 - 44ms/epoch - 2ms/step\n21/21 - 0s - loss: 0.7707 - auc: 0.5000 - 43ms/epoch - 2ms/step\n\neval_auc_sgd\n\n[1] 0.4854673 0.5559508 0.6687547 0.6605243\n\neval_auc_rmsprop\n\n[1] 0.6562500 0.6610752 0.6427669 0.5832589\n\neval_auc_adam\n\n[1] 0.6583444 0.6569719 0.6633929 0.5000000\n\n\nLos tres algoritmos proporcionan soluciones muy similares, siendo el valor de \\(\\lambda\\) igual a 0.01 el que parece funcionar mejor, aunque en cualquier caso la solución obtenida parece bastante mala.\nEn este caso dejamos para el lector el análisis de validación del modelo conseguido finalmente. Utilizar k = 10 folds para dicho análisis.\n\n\n\n4.2.4 Breast Cancer Wisconsin\nAntes de comenzar con el preprocesado de los datos hya dos tareas que debemos realizar: eliminar la variable id que identifica las muestras y codificar como 0-1 el target de interés. En este caso codificamos como M = 1 y estudiamos la proporción de cada clase para saber si el diseño esta equilibrado.\n\n#  Eliminación id\nbreastcancer = dplyr::select(breastcancer, -\"id\")\n# Recodificación diagnosis\nbreastcancer[\"diagnosis\"] = 1*(breastcancer[\"diagnosis\"] == \"M\")\n# Tabla\ntabla = table(breastcancer[\"diagnosis\"])\nprop = tabla/sum(tabla)\nprop\n\ndiagnosis\n        0         1 \n0.6274165 0.3725835 \n\n\nClaramente el diseño está desequilibrado y deberemos tener en cuenta este aspecto en la división de muestras de entrenamiento y validación como en el ejemplo anterior. En este caso no tenemos inputs de tipo factor por lo que no es necesario ningún tipo de codificación.\n\n4.2.4.1 Preprocesado\nEn el preprocesado de los datos debemos identificar la presencia o no de valores faltantes para imputar los correspondientes valores, establecer las matrices de inputs y vector de outputs, dividir el conjunto de datos en muestra y validación, y estandarizar los inputs numéricos.\nEn primer lugar valoramos la presencia de valores faltantes:\n\n# Valoramos a existencia de valores perdidos\napply(is.na(breastcancer),2,sum)\n\n              diagnosis             radius_mean            texture_mean \n                      0                       0                       0 \n         perimeter_mean               area_mean         smoothness_mean \n                      0                       0                       0 \n       compactness_mean          concavity_mean     concave_points_mean \n                      0                       0                       0 \n          symmetry_mean  fractal_dimension_mean               radius_se \n                      0                       0                       0 \n             texture_se            perimeter_se                 area_se \n                      0                       0                       0 \n          smoothness_se          compactness_se            concavity_se \n                      0                       0                       0 \n      concave_points_se             symmetry_se    fractal_dimension_se \n                      0                       0                       0 \n           radius_worst           texture_worst         perimeter_worst \n                      0                       0                       0 \n             area_worst        smoothness_worst       compactness_worst \n                      0                       0                       0 \n        concavity_worst    concave_points_worst          symmetry_worst \n                      0                       0                       0 \nfractal_dimension_worst \n                      0 \n\n\nNo existen valores faltantes por lo que podemos proceder con la división de muestras y estandarización. En primer lugar identificamos la matriz de inputs y vector de output.\n\n####### nombres variables #######\nnombres = names(breastcancer)\n######## Matriz de inputs #########\nX_breastcancer = breastcancer[,nombres[nombres != \"diagnosis\"]]\n######## Vector de output #########\ny_breastcancer = breastcancer$diagnosis\n\nProcedemos ahora con la estandarización:\n\n# número de muestras total\nmuestras = nrow(breastcancer)\n# semilla para reproducibilidad\nset.seed(123)\n\n######### muestreo de índices de entrenamiento ######\n# 1. Generamos el vector de pesos asociado ca cada muestra\npesos = rep(0, muestras)\npesos[breastcancer$diagnosis == 0] = prop[1]\npesos[breastcancer$diagnosis == 1] = prop[2]\n# 2. Proporción muestra de entrenamiento\nnp = 0.8\n# 3. Indices para la muestra de entrenamiento\nids_train = sample(muestras, size = np*muestras, prob = pesos)\n\nVerificamos si se mantienen las proporciones de reparto de cada clase en la muestra de entrenamiento:\n\n# Reparto en la población original\nprop\n\ndiagnosis\n        0         1 \n0.6274165 0.3725835 \n\n# Reparto en la muestra de entrenamiento\ntabla = table(breastcancer$diagnosis[ids_train])\nprop = as.vector(tabla/sum(tabla))\nprop\n\n[1] 0.6901099 0.3098901\n\n\nPodemos ver que los porcentajes son muy similares con lo que podemos proceder con la división de muestras de entrenamiento y validación\n\n####### División de muestras #############\n\n# Matriz de inputs\nxtrain = X_breastcancer[ids_train,]\nxtest = X_breastcancer[-ids_train,]\n\n######## Estandarización #################\n# Medias\nmean_train = apply(xtrain, 2, mean)\n# Desviaciones típicas\nsd_train = apply(xtrain, 2, sd)\n# Estandarizamos muestra de entrenamiento\nxtrain_breastcancer = scale(xtrain, mean_train, sd_train)\n# Estandarizamos muestra de validación\nxtest_breastcancer = scale(xtest, mean_train, sd_train)\n# Muestras de entrenamiento y validación para output\nytrain_breastcancer = y_breastcancer[ids_train]\nytest_breastcancer = y_breastcancer[-ids_train]\n# Número de inputs\nninputs = ncol(xtrain_breastcancer)\n\n\n\n4.2.4.2 Nuestra primera red neuronal\nTenemos un problema de clasificación con dos posibles resultados por lo que utilizaremos una arquitectura similar al del ejemplo anterior. Consideramos dos capas ocultas con 16 neuronas y con función de activación relu, mientras que consideramos la activación sigmoid en la capa de salida. En el proceso de aprendizaje consideramos como función de perdida binary_crossentropy y algoritmo de optmización sgd. En cuanto a la métrica para validar la capacidad de clasificación volvemos a utilizar AUC.\n\n# Fijamos semilla de los pesos iniciales para poder \ninicializador = initializer_glorot_normal(seed = 15)\n# Arquitectura de red\nmod1 = keras_model_sequential() %>%  \n  layer_dense(units = 32, activation = 'relu', input_shape = ninputs, kernel_initializer = inicializador) %>% \n  layer_dense(units = 32, activation = 'relu', input_shape = ninputs, kernel_initializer = inicializador) %>% \n  layer_dense(units = 1, activation = 'sigmoid', kernel_initializer = inicializador)\n# Proceso de aprendizaje\nmod1 %>% compile(loss = 'binary_crossentropy', optimizer = optimizer_sgd(), metrics = c('AUC')\n)\n# Entrenamiento del modelo\nhistory_mod1 = mod1 %>% fit(xtrain_breastcancer, ytrain_breastcancer, batch_size = 16, \n                            epochs = 200, validation_split = 0.2, verbose = 0)\nplot(history_mod1)\n\n\n\n\nEl algoritmo converge rápidamente y además con unos resultados bastante buenos. Evaluamos lo resultados sobre la muestra de validación:\n\nmod1 %>% tensorflow::evaluate(xtest_breastcancer, ytest_breastcancer, verbose = 2)\n\n4/4 - 0s - loss: 0.0956 - auc: 0.9975 - 29ms/epoch - 7ms/step\n\n\n      loss        auc \n0.09562495 0.99754339 \n\n\nEl valor del AUC es prácticamente 1 indicando que el modelo nos proporciona una clasificación casi perfecta. Evaluamos la matriz de confusión asociada con el modelo planteado.\n\n# probabilidades de clasificación de cada muestra \nprediccion = mod1 %>% predict(xtest_breastcancer)\n\n4/4 - 0s - 60ms/epoch - 15ms/step\n\n# predicción del modelo\npr_modelo = as.vector(prediccion %>% `>`(0.5) %>% k_cast(\"int32\"))\n\n# Matriz de confusión\ncm = confusion_matrix(ytest_breastcancer, pr_modelo)\ncm$`Balanced Accuracy`\n\n[1] 0.9788732\n\n# Gráfico\nplot_confusion_matrix(cm$`Confusion Matrix`[[1]])\n\n\n\n\nEl modelo solo proporciona un 2.6% de errores de clasificación indicando como benignos muestras etiquetadas con tumores malignos. Para evitar posibles de sobre estimación y reducir la complejidad de la red vamos a probar diferentes configuraciones en el punto siguiente\n\n\n4.2.4.3 Actualizando nuestra red neuronal\nEn primer lugar consideramos la solución más sencilla que consiste en reducir el número de capas ocultas. En concreto consideramos una sola con las mismas especificaciones que en el modelo anterior.\n\n# Fijamos semilla de los pesos iniciales para poder \ninicializador = initializer_glorot_normal(seed = 15)\n# Arquitectura de red\nmod2 = keras_model_sequential() %>%  \n  layer_dense(units = 32, activation = 'relu', input_shape = ninputs, kernel_initializer = inicializador) %>% \n  layer_dense(units = 1, activation = 'sigmoid', kernel_initializer = inicializador)\n# Proceso de aprendizaje\nmod2 %>% compile(loss = 'binary_crossentropy', optimizer = optimizer_sgd(), metrics = c('AUC')\n)\n# Entrenamiento del modelo\nhistory_mod2 = mod2 %>% fit(xtrain_breastcancer, ytrain_breastcancer, batch_size = 16, \n                            epochs = 200, validation_split = 0.2, verbose = 0)\n\nComparamos ambas soluciones\n\ncompara_history(history_mod1, history_mod2)\n\n\n\n\nEl segundo modelo proporciona una perdida ligeramente superior pero los resultados para el AUC son muy similares. Añadimos early stopping sobre el número de epochs para el segundo modelo para ver su efecto sobre la solución final.\n\n# Fijamos semilla de los pesos iniciales para poder \ninicializador = initializer_glorot_normal(seed = 15)\n# callback early stopping\nearly_stop = callback_early_stopping(monitor = 'val_loss')\n# Arquitectura de red\nmod3 = keras_model_sequential() %>%  \n  layer_dense(units = 32, activation = 'relu', input_shape = ninputs, kernel_initializer = inicializador) %>% \n  layer_dense(units = 1, activation = 'sigmoid', kernel_initializer = inicializador)\n# Proceso de aprendizaje\nmod3 %>% compile(loss = 'binary_crossentropy', optimizer = optimizer_sgd(), metrics = c('AUC')\n)\n# Entrenamiento del modelo\nhistory_mod3 = mod3 %>% fit(xtrain_breastcancer, ytrain_breastcancer, batch_size = 16, \n                            epochs = 200, validation_split = 0.2, verbose = 0, callbacks=list(early_stop))\nplot(history_mod3)\n\n\n\n\nEl algoritmo no se detiene antes de llegar al límite de epochs establecidos. Estudiamos la clasificación obtenida con este modelo:\n\n# probabilidades de clasificación de cada muestra \nprediccion = mod2 %>% predict(xtest_breastcancer)\n\n4/4 - 0s - 69ms/epoch - 17ms/step\n\n# predicción del modelo\npr_modelo = as.vector(prediccion %>% `>`(0.5) %>% k_cast(\"int32\"))\n# Matriz de confusión\ncm = confusion_matrix(ytest_breastcancer, pr_modelo)\ncm$`Balanced Accuracy`\n\n[1] 0.9788732\n\n# Gráfico\nplot_confusion_matrix(cm$`Confusion Matrix`[[1]])\n\n\n\n\nEste modelo parece bastante bueno produciendo solo un 2.6% de errores. Aunque podemos seguir explorando otras posibilidades de modelización, las mejoras que podmeos conseguir son bastante reducidas a nivel de décimas en el porcentaje de clasificación correcta. Procedemos con el análisis de validación cruzada con \\(k=10\\) folds.\nEn primer lugar definimos la función que nos evalúa el modelo propuesto en función de la muestra de entrenamiento y validación.\n\nbuild_model = function(xtrain, ytrain, xtest, ytest)\n{\n  # A partir de las muestars de entrenamiento y test esta función proporciona la \n  # evalaución del modelo de red propuesto.\n  \n  # Fijamos semilla de los pesos iniciales para poder \n  inicializador = initializer_glorot_normal(seed = 15)\n  # callback early stopping\n  early_stop = callback_early_stopping(monitor = 'val_loss')\n  # Arquitectura de red\n  mod = keras_model_sequential() %>%  \n    layer_dense(units = 32, activation = 'relu', input_shape = ninputs, kernel_initializer = inicializador) %>% \n    layer_dense(units = 1, activation = 'sigmoid', kernel_initializer = inicializador)\n  # Proceso de aprendizaje\n  mod %>% compile(loss = 'binary_crossentropy', optimizer = optimizer_sgd(), metrics = c('AUC'))\n  # Entrenamiento del modelo\n  history_mod = mod %>% fit(xtrain, ytrain, batch_size = 16, \n                            epochs = 200, validation_split = 0.2, verbose = 0, callbacks=list(early_stop))  \n  # Evaluación del modelo\n  eval = (mod %>% tensorflow::evaluate(xtest, ytest, verbose = 2))[2]\n  return(eval)\n}\n\nProcedemos ahora con el bucle de evaluación de cada uno de los folds considerados.\n\n# vector donde almacenamos la métrica de cada modelo\nmetrica = c()\n# Establecemos número de folds\nfolds = 10\n# Número de muestras\nn = nrow(breastcancer)\n# Tamaño de cada fold\nnfolds = floor(n/folds)+1\n\n# Bucle pra cada fold\nfor(i in 1:folds)\n{\n  # Índice para la muestra de test\n  test = (nfolds*(i-1) +1):min(n, (nfolds*i))\n  # Selección inicial de entrenamiento y test para variables numéricas\n  dfnum_train = X_breastcancer[-test,]\n  dfnum_test = X_breastcancer[test,]\n  ###################################\n  # Estadísticos para estandarización\n  ##################################\n  # Medias\n  mean_train = apply(dfnum_train, 2, mean)\n  # Desviaciones típicas\n  sd_train = apply(dfnum_train, 2, sd)\n  #####################################\n  # Matrices de entrenamiento y test\n  #####################################  \n  # Estandarizamos muestra de entrenamiento\n  xtrain = scale(dfnum_train, mean_train, sd_train)\n  # Estandarizamos muestra de validación\n  xtest = scale(dfnum_test, mean_train, sd_train)\n  ytrain = y_breastcancer[-test]\n  ytest = y_breastcancer[test]\n  #####################################\n  # Evaluación del modelo\n  #####################################\n  cat(\"Comienza el entrenamiento para el fold \", i, \"\\n\")\n  res = build_model(xtrain, ytrain, xtest, ytest)\n  metrica = c(metrica, res)\n}\n\nComienza el entrenamiento para el fold  1 \n2/2 - 0s - loss: 0.0964 - auc: 0.9980 - 26ms/epoch - 13ms/step\nComienza el entrenamiento para el fold  2 \n2/2 - 0s - loss: 0.1030 - auc: 0.9909 - 26ms/epoch - 13ms/step\nComienza el entrenamiento para el fold  3 \n2/2 - 0s - loss: 0.1144 - auc: 0.9907 - 28ms/epoch - 14ms/step\nComienza el entrenamiento para el fold  4 \n2/2 - 0s - loss: 0.0872 - auc: 0.9988 - 28ms/epoch - 14ms/step\nComienza el entrenamiento para el fold  5 \n2/2 - 0s - loss: 0.0690 - auc: 0.9963 - 32ms/epoch - 16ms/step\nComienza el entrenamiento para el fold  6 \n2/2 - 0s - loss: 0.1360 - auc: 0.9509 - 25ms/epoch - 12ms/step\nComienza el entrenamiento para el fold  7 \n2/2 - 0s - loss: 0.0477 - auc: 1.0000 - 25ms/epoch - 13ms/step\nComienza el entrenamiento para el fold  8 \n2/2 - 0s - loss: 0.0828 - auc: 0.9983 - 25ms/epoch - 13ms/step\nComienza el entrenamiento para el fold  9 \n2/2 - 0s - loss: 0.0707 - auc: 1.0000 - 25ms/epoch - 13ms/step\nComienza el entrenamiento para el fold  10 \n2/2 - 0s - loss: 0.1238 - auc: 0.9973 - 27ms/epoch - 14ms/step\n\n\nRealizamos el análisis descriptivo de la métrica evaluada.\n\nimp_descrip(metrica)\n\nN            :  10 \nMedia        :  0.992 \nSD           :  0.015 \nMínimo       :  0.951 \nPercentil 25 :  0.992 \nPercentil 75 :  0.999 \nMáximo       :  1 \n\n\nEL valor medio del AUC para los 10 folds se sitúa en el 0.99 con una desviación típica de 0.016. Hay mucha precisión y los valores indican que el modelo clasifica casi de forma perfecta. El modelo propuesto nos puede servir para identificar el tipo de tumor de cáncer de mama en función de los inputs considerados."
  },
  {
    "objectID": "50_ConvNN.html#cómo-aprende-una-res-convolucional",
    "href": "50_ConvNN.html#cómo-aprende-una-res-convolucional",
    "title": "5  Redes convolucionales",
    "section": "5.1 ¿Cómo aprende una res convolucional?",
    "text": "5.1 ¿Cómo aprende una res convolucional?\nLas Redes neuronales Convolucionales aprenden a reconocer una diversidad de objetos dentro de imágenes, pero para ello necesitan “entrenarse” de previo con una cantidad importante de “muestras” de cada objeto, y a su vez, poder generalizarlo. Nuestra red va a poder reconocer por ejemplo un cierto tipo de célula porque ya la ha “visto” anteriormente muchas veces, pero no solo buscará células semejantes sino que podrá inferir imagenes que no conozca pero que relaciona y en donde podrían existir similitudes, y esta es la parte inteligente del conocimiento.\nEl reconocimiento de imagénes comienza por la pixelización de una imagen:\n\n\n\n\n\nPodemos hacer los mismo utilizando la descomposición RGB del color:"
  },
  {
    "objectID": "50_ConvNN.html#aspecto-matemáticos-de-las-convoluciones",
    "href": "50_ConvNN.html#aspecto-matemáticos-de-las-convoluciones",
    "title": "5  Redes convolucionales",
    "section": "5.2 Aspecto matemáticos de las convoluciones",
    "text": "5.2 Aspecto matemáticos de las convoluciones\nAntes de meternos de lleno con las redes, necesitamos comprender bien el concepto de convolución. La convolución es un operador matemático que se define como la integral del producto de dos funciones (\\(f\\) y \\(g\\)) donde una de ellas está desplazada una distancia \\(t\\):\n\\[(f*g)(t) =\\int_{-\\infty}^{\\infty} f(x)g(t-x)dx\\]\nNosotros vamos a adaptar este operador a una versión bidimensional y discreta:\n\\[(f*g)(i,j) = \\sum_{-\\infty}^{\\infty} \\sum_{-\\infty}^{\\infty} f(x,y)g(i-x,j-y)\\]\n¿Y para qué nos va a servir? Antes habíamos dicho que nuestro cerebro integraba simples estímulos visuales procedentes de cada fotorreceptor de la retina para producir elementos de información cada vez más compleja y elaborada para permitir luego su reconocimiento. Es como decir que para reconocer una cara nuestro sistema visual registra primero fragmentos de la imagen como pupilas, comisuras de labios, lóbulos de orejas… para luego formar ojos, bocas, orejas… para, finalmente, formar caras. Bueno, pues con la operación de convolución vamos a hacer algo así.\nPartamos de una imagen cualquiera, tomémosla en escala de grises para que sea algo más sencilla. Por ahora solo tenemos píxeles. ¿Cuáles serían las características más sencillas que podríamos encontrar? Quizá serían las características que encontraríamos en regiones de tamaño 3×3 de la imagen. ¿Qué cabe en una región tan pequeña? Podríamos encontrar un borde vertical, un borde horizontal, una esquina, un punto… cosas así.\nEn esta situación consideramos como \\(g\\) nuestra imagen. Para ejempificar consideramos una imagen en blanco y negro en una cuadrícula 6x6 como la siguiente:\n\n\n\n\n\ndonde identificamos cada cuadrícula con 0 si hay imagen y con 255 las cuadrículas en blanco (intensidad de píxel), lo que nos porporciona la forma que vemos en la imagen anterior.\nEn primer lugar vamos a tratar de establecer un detector de bordes verticales, es decir queremos identificar las casilla que se encentran en las filas 1 a 5 de la columna 2. Para ello consideramos la función \\(f\\) que denominmos como kernel con la forma:\n\n\n\n\n\ny supongamos que queremos calcular la convolución en las coordenadas (2,1) de la imagen (\\(g\\)) mediante el kernel \\(f\\). Gráficamente se vería como la superposición del kernel sobre la imagen en esas coordendas y multiplicar celda a celda sus correspondientes valores para, finalmente, sumarlo todo. El resultado obtenido es:\n El resultado que nos devuelve es 765. Es decir, un valor alto, lo que nos permite identificar el borde vertical de la imagen. Si aplicamos el kernel en las posiciones (1,1), (2,1), (3,1), (4,1), y (5,1) podemos identificar todo el borde vertical de la imagen. De froma algo simialr podemos identificar los bordes horizontales con un kernel:\narray([[1., 1., 1.],\n       [0., 0., 0.],\n       [-1., -1., -1.]])\ny los bordes diagonales con un kernel:\narray([[2., 1., 0.],\n       [1., 0., -1.],\n       [0., -1., -2.]])\nEstos kernels se puden generalizar a diferentes tipos de imágenes y bordes. La convolución en su versión bidimensional y discretaen estas situaciones se podría definir como:\n\\[conv2D(i,j) = \\sum_{y=0}^{2} \\sum_{x=0}^{2} kernel(x,y)imagen(i+x,j+y)\\] ## Componentes básicos de una red neuronal\nAhora que tenemos una visión intuitiva sobre cómo clasifican una imagen las redes neuronales convolucionales, vamos a trabajar con el banco de datos DIGITS para mostrar su funcionamiento. A partir de él, introduciremos las dos capas que definen a las redes neuronales convolucionales, que pueden expresarse como grupos de neuronas especializadas en dos operaciones: convolución y pooling.\n\n5.2.1 Operación de convolución\nLa diferencia fundamental entre una capa densamente conectada y una capa especializada en la operación de convolución, que llamaremos capa convolucional, es que la capa densa aprende patrones globales en su espacio global de entrada, mientras que la capa convolucional aprende patrones locales dentro de la imagen en pequeñas ventanas de dos dimensiones.\nDe manera intuitiva, podríamos decir que el propósito principal de una capa convolucional es detectar características o rasgos visuales en las imágenes, como aristas, líneas, gotas de color, etc. Esta es una propiedad muy interesante porque una vez aprendida una característica en un punto concreto de la imagen, la puede reconocer después en cualquier parte de la misma. En cambio, una red neuronal densamente conectada tiene que aprender el patrón nuevamente si este aparece en una nueva localización de la imagen.\nOtra característica importante es que las capas convolucionales pueden aprender jerarquías espaciales de patrones. Por ejemplo, una primera capa convolucional puede aprender elementos básicos como aristas, y una segunda capa convolucional puede aprender patrones compuestos de elementos básicos aprendidos en la capa anterior. Y así sucesivamente hasta ir aprendiendo patrones muy complejos. Esto permite que las redes neuronales convolucionales aprendan eficientemente conceptos visuales cada vez más complejos y abstractos.\nEn general, las capas convoluciones operan sobre tensores 3D, llamados mapas de características (feature maps en inglés), con dos ejes espaciales de altura y anchura (height y width), además de un eje de canal (channels) también llamado profundidad (depth). Para una imagen de color RGB, la dimensión del eje depth es 3, pues la imagen tiene tres canales: rojo, verde y azul (red, green y blue). Para una imagen en blanco y negro, como es el caso de los dígitos MNIST, la dimensión del eje depth es 1 (nivel de gris).\nEn el caso de MNIST, como entrada en nuestra red neuronal podemos pensar en un espacio de neuronas de dos dimensiones 28 x 28, que transformaremos en un tensor 3D (heíght = 28, width = 28, depth = 1 ), aunque la tercera dimensión en este caso sea de tamaño 1. Una primera capa de neuronas ocultas conectadas a las neuronas de la capa de entrada que hemos comentado realizarán las operaciones convolucionales que acabamos de describir. Pero, como hemos avanzado, no se conectan todas las neuronas de entrada con todas las neuronas de este primer nivel de neuronas ocultas (como en el caso de las redes neuronales densamente conectadas); solo se hace por pequeñas zonas localizadas del espacio de las neuronas de entrada que almacenan los píxeles de la imagen. Visualmente, se podría representar tal como se muestra en la figura siguiente:\n\n\n\n\n\nEn el caso de nuestro ejemplo, cada neurona de la capa oculta será conectada a una pequeña región de 5 x 5 neuronas (es decir, 25 neuronas) de la capa de entrada (de 28 x 28). Intuitivamente, se puede pensar en una ventana del tamaño de 5 x 5 que va recorriendo toda la capa de 28 x 28 que contiene la imagen.\nEsta ventana va deslizándose a lo largo de toda la capa de neuronas. Por cada posición de la ventana hay una neurona en la capa oculta que procesa esta información. La ventana empieza en la esquina superior izquierda de la imagen, y esto le da la información necesaria a la primera neurona de la capa oculta.\n\n\n\n\n\nA continuación, la ventana se desliza una posición hacia la derecha para «conectar» las 5 x 5 neuronas de la capa de entrada incluidas en esta ventana con la segunda neurona de la capa oculta. Y así, sucesivamente, va recorriendo todo el espacio de la capa de entrada, de izquierda a derecha y de arriba abajo.\nAnalizando un poco el ejemplo concreto que hemos propuesto, observemos que si tenemos una entrada de 28 x 28 píxeles y una ventana de 5 x 5, nos define un espacio de 24 x 24 neuronas en la primera capa oculta, debido a que la ventana solo se puede desplazar 23 neuronas hacia la derecha y 23 hacia abajo antes de chocar con el lado derecho (o inferior) de la imagen de entrada.\nQuisiéramos hacer notar al lector o lectora que el supuesto que hemos hecho es que la ventana hace movimientos de avance de 1 píxel en cada paso, tanto en horizontal como en vertical, cuando empieza una nueva fila. Por ello, en cada paso la nueva ventana se solapa con la anterior, excepto en esta línea de píxeles que hemos avanzado. Pero, como veremos en la siguiente sección, en redes neuronales convolucionales se pueden usar diferentes longitudes de pasos de avance (el parámetro llamado stride). En las redes neuronales onvolucionales también se puede aplicar una técnica de relleno de ceros alrededor del margen de la imagen para mejorar el resultado del barrido que se realiza con la ventana que se va deslizando. El parámetro para definir este relleno recibe el nombre de padding, el cual también se presentará con más detalle en la siguiente sección.\nEn nuestro caso de estudio, y siguiendo el formalismo ya presentado previamente, para «conectar» cada neurona de la capa oculta con las 25 neuronas que le corresponden de la capa de entrada usaremos un valor de sesgo b y una matriz de pesos W de tamaño 5 x 5, que llamaremos filtro (o kernel y filteren inglés). El valor de cada punto de la capa oculta corresponde al producto escalar entre el filtro y el conjunto de 25 neuronas (5 x 5) de la capa de entrada.\nAhora bien, lo particular y muy importante de las redes convolucionales es que se usa el mismo filtro (la misma matriz W de pesos y el mismo sesgo b) para todas las neuronas de la capa oculta: en nuestro caso para las 24 x 24 neuronas (576 neuronas en total) de la primera capa oculta. En este caso concreto, esta compartición reduce de manera drástica el número de parámetros que tendría una red neuronal si no la hiciéramos: pasa de 14400 parámetros que tendrían que ser ajustados (5 x 5 x 24 x 24) a 25 (5 x 5) parámetros más los sesgos b.\nEsta matriz de pesos W, compartida con el sesgo b, es similar a los filtros que usamos para retocar imágenes, que en nuestro caso sirven para buscar características locales en pequeños grupos de entradas.\nEn resumen, una convolución es el tratamiento de una matriz de entrada por otra que llamamos filtro. Pero un filtro definido por una matriz W y un sesgo b solo permiten detectar una característica concreta en una imagen. Por tanto, para poder realizar el reconocimiento de imágenes se propone usar varios filtros a la vez, uno para cada característica que queramos detectar. Por eso una capa convolucional completa en una red neuronal convolucional incluye varios filtros.\nUna manera habitual de representar visualmente esta capa convolucional es la que se muestra en la figura siguiente, donde se visualiza que la capa convolucional está compuesta por varios filtros. En nuestro ejemplo proponemos 32 filtros, donde cada filtro se define con una matriz W de pesos compartida de 5 x 5 y un sesgo b. En este ejemplo, la primera capa convolucional recibe un tensor de entrada de tamaño (28, 28, 1) y genera una salida de tamaño (24, 24, 32), un tensor 3D que contiene las 32 salidas de 24 x 24 píxeles resultado de computar los 32 filtros sobre la entrada.\n\n\n\n\n\n\n\n5.2.2 Operación de pooling\nAdemás de las capas convolucionales que acabamos de describir, las redes neuronales convolucionales acompañan a la capa de convolución con unas capas de pooling -que podríamos traducir por agrupación-, que suelen ser aplicadas inmediatamente después de las capas convolucionales. Una primera aproximación para entender para qué sirven estas capas es considerar que las capas de pooling hacen una simplificación de la información recogida por la capa convolucional y crean una versión condensada de la información contenida en esta capa.\nEn nuestro ejemplo de dígitos MNIST, vamos a escoger una ventana de 2 x 2 sobre la capa convolucional y vamos a sintetizar la información en un punto en la capa de pooling. Visualmente, se puede expresar como en la figura siguiente.\n\n\n\n\n\nHay varias maneras de condensar la información, pero una habitual y que usaremos es la conocida como max-pooling. Como valor, se queda con el valor máximo de los que había en la ventana de entrada de 2 x 2 que, en nuestro caso, ha «troceado» en 12 x 12 ventanas la capa de pooling. En este caso, se divide por 4 el tamaño de la salida de la capa de pooling en relación a la capa convolucional donde se aplica el pooling, y queda con tamaño de 12 x 12.\nTambién se puede utilizar average-pooling en lugar de max-pooling, donde cada grupo de puntos de entrada se transforma en el valor promedio del grupo de puntos, en vez de su valor máximo. Pero, en general, el max-pooling tiende a funcionar muy bien.\nEs interesante remarcar que con la transformación de poo/ing mantenemos la relación espacial. Para verlo visualmente, cojamos el siguiente ejemplo de una matriz de 12 x 12 donde tenemos representado un 7 (imaginemos que los píxeles por los que pasamos por encima contienen un 1 y el resto O; no lo hemos añadido al dibujo para simplificar su visualización). Esto se representa visualmente en la figura siguiente. Si aplicamos una operación de max-pooling con una ventana de 2 x 2 (lo representamos en la matriz central que divide el espacio en un mosaico con regiones del tamaño de la ventana), obtenemos una matriz de 6 x 6 donde se mantiene una representación que nos recuerda sin ninguna duda al número 7 (lo podemos ver en la figura de la derecha, donde hemos marcado en blanco los ceros y en negro los puntos con valor 1 ).\n Como hemos mencionado anteriormente, la capa convolucional alberga más de un filtro y, por tanto, como aplicamos el max-pooling a cada uno de estos filtros separadamente, la capa de pooling contendrá tantos filtros de pooling como filtros convolucionales había, tal como se representa en la figura siguiente\n\n\n\n\n\nLa capa convolucíonal alberga 32 filtros y al aplicar el max-pooling a cada uno de ellos separadamente, la capa de pooling contendrá tantos filtros de pooling como filtros convolucionales.\nDado que teníamos un espacio de 24 x 24 neuronas en cada filtro convolucional, después de hacer el pooling tenemos 12 x 12 neuronas, que corresponden a las 12 x 12 regiones de tamaño 2 x 2 que aparecen al dividir el espacio de neuronas del espacio del filtro de la capa convolucional y este por los 32 filtros convolucionales."
  },
  {
    "objectID": "50_ConvNN.html#implementación-de-modelos-básicos-en-keras",
    "href": "50_ConvNN.html#implementación-de-modelos-básicos-en-keras",
    "title": "5  Redes convolucionales",
    "section": "5.3 Implementación de modelos básicos en Keras",
    "text": "5.3 Implementación de modelos básicos en Keras\nVeamos cómo se puede programar este ejemplo de red neuronal convolucional que hemos presentado en Keras. Como hemos comentado, hay varios valores a concretar para parametrizar las capas de convolución y pooling. En nuestro caso, usaremos un modelo simplificado con un stride de 1 en cada dimensión (tamaño del paso con el que desliza la ventana) y un padding de O (en este caso no hay relleno de ceros alrededor de la imagen). Ambos hiperparámetros los presentaremos en la siguiente sección. El pooling que aplicaremos será un max-pooling como el descrito anteriormente con una ventana de 2x2.\nEn primer lugar cargamos los datos Digits:\n\n# Cargamos datos\nmnist <- keras::dataset_mnist()\n# División de muestras entrenamiento y validación\nx_train <- mnist$train$x\ny_train <- mnist$train$y\nx_test <- mnist$test$x\ny_test <- mnist$test$y\n# Reescalamos para tener entradas en el intervalo 0-1\nx_train <- x_train / 255\nx_test <- x_test / 255\n# Etiquetas\netiquetas = 0:9\n\nPasamos a implementar nuestra primera red neuronal convolucional, que consistirá en una convolución seguida de un max-pooling. En nuestro caso, tendremos 32 filtros, usaremos una ventana de 5 x 5 para la capa convolucional y una ventana de 2 x 2 para la capa de pooling. Usaremos, por ejemplo, la función de activación ReLU. En este caso, estamos configurando una red neuronal convolucional para procesar un tensor de entrada de tamaño (28, 28, 1 ), que es el tamaño de las imágenes MNIST (el tercer parámetro es el canal de color que, en nuestro caso, es 1), y lo especificamos mediante el valor del argumento input_ shape= (28, 28, 1) en nuestra primera capa. Veamos cómo es el código de Keras:\n\n# Arquitectura de red\nmod = keras_model_sequential() %>%  \n  layer_conv_2d(filters = 32, kernel_size = c(5, 5), activation='relu', input_shape=c(28, 28, 1)) %>% \n  layer_max_pooling_2d(pool_size = c(2, 2)) \nsummary(mod)\n\nModel: \"sequential\"\n________________________________________________________________________________\n Layer (type)                       Output Shape                    Param #     \n================================================================================\n conv2d (Conv2D)                    (None, 24, 24, 32)              832         \n max_pooling2d (MaxPooling2D)       (None, 12, 12, 32)              0           \n================================================================================\nTotal params: 832 (3.25 KB)\nTrainable params: 832 (3.25 KB)\nNon-trainable params: 0 (0.00 Byte)\n________________________________________________________________________________\n\n\nEl número de parámetros de la capa conv2D corresponde a la matriz de pesos W de 5 x 5; y un sesgo b para cada uno de los filtros es 832 parámetros, como se indica en la salida del método summary() como resultado del cálculo de (32x (25+1)). El max-pooling no requiere parámetros, puesto que es una operación matemática que consiste en encontrar el máximo (solo necesitamos especificar los hiperparámetros que definen el tamaño de la ventana).\nConsideramos ahora un modelo algo más complejo.En este caso proponemos dos grupos de capas que tendrá 64 filtros con una ventana de 5x5 en la capa convolucional y una de 2x2 en la capa de pooling. En este caso, el número de canales de entrada tomará el valor de las 32 características que hemos obtenido de la capa anterior aunque, como ya hemos visto anteriormente, no hace falta especificarlo más allá de la primera capa porque Keras lo deduce automáticamente:\n\n# Arquitectura de red\nmod1 = keras_model_sequential() %>%  \n  layer_conv_2d(filters = 32, kernel_size = c(5, 5), activation='relu', input_shape=c(28, 28, 1)) %>% \n  layer_max_pooling_2d(pool_size = c(2, 2)) %>%\n  layer_conv_2d(filters = 64, kernel_size = c(5, 5), activation='relu') %>% \n  layer_max_pooling_2d(pool_size = c(2, 2))\nsummary(mod1)\n\nModel: \"sequential_1\"\n________________________________________________________________________________\n Layer (type)                       Output Shape                    Param #     \n================================================================================\n conv2d_2 (Conv2D)                  (None, 24, 24, 32)              832         \n max_pooling2d_2 (MaxPooling2D)     (None, 12, 12, 32)              0           \n conv2d_1 (Conv2D)                  (None, 8, 8, 64)                51264       \n max_pooling2d_1 (MaxPooling2D)     (None, 4, 4, 64)                0           \n================================================================================\nTotal params: 52096 (203.50 KB)\nTrainable params: 52096 (203.50 KB)\nNon-trainable params: 0 (0.00 Byte)\n________________________________________________________________________________\n\n\nEn este caso, podemos observar que el tamaño de la segunda capa de convolución resultante es de 8 x 8, dado que ahora partimos de una entrada de 12 x 12, una ventana deslizante de 5 x 5 y un stride de 1. El número de parámetros es 51264 porque la segunda capa tendrá 64 filtros, como hemos especificado en el argumento, con 801 parámetros cada uno: 1 corresponde al sesgo y, luego, tenemos la matriz W de 5x5 para cada una de las 32 entradas. Es decir, el valor 51264 se obtiene del cálculo de ((5 x 5 x 32) + 1) x 64.\nEn este caso la salida de las capas Conv2D y maxPooling2D es un tensor 3D de forma (height, width, número de filtros). Las dimensiones width y height tienden a reducirse a medida que nos adentramos en las capas ocultas de la red neuronal. El número de filtros es controlado a través del primer argumento pasado a la capa Conv2D.\nEl siguiente paso, ahora que tenemos 64 filtros de 4 x 4, consiste en añadir una capa densamente conectada, que servirá para alimentar una capa final de softmax para hacer la clasificación final.\nRecordemos que antes tenemos que ajustar los tensores a la entrada de la capa densa como la softmax, que es un tensor de 1D, mientras que la salida de la anterior es un tensor de 3D; por eso primero hay que «aplanar» el tensor de 3D a uno de 1D, y Keras nos lo facilita con la capa Flatten. Nuestra salida (4,4,64) se debe pasar a un vector de (1024) antes de aplicar el softmax. Veamos cómo sería el código. En este caso, el número de parámetros de la capa softmax es 1Ox1024+1O, con una salida de un vector de 10:\n\n# Arquitectura de red\nmodelo = keras_model_sequential() %>%  \n  layer_conv_2d(filters = 32, kernel_size = c(5, 5), activation='relu', input_shape=c(28, 28, 1)) %>% \n  layer_max_pooling_2d(pool_size = c(2, 2)) %>%\n  layer_conv_2d(filters = 64, kernel_size = c(5, 5), activation='relu') %>% \n  layer_max_pooling_2d(pool_size = c(2, 2)) %>%\n  layer_flatten() %>%\n  layer_dense(units = 10, activation = 'softmax')\nsummary(modelo)\n\nModel: \"sequential_2\"\n________________________________________________________________________________\n Layer (type)                       Output Shape                    Param #     \n================================================================================\n conv2d_4 (Conv2D)                  (None, 24, 24, 32)              832         \n max_pooling2d_4 (MaxPooling2D)     (None, 12, 12, 32)              0           \n conv2d_3 (Conv2D)                  (None, 8, 8, 64)                51264       \n max_pooling2d_3 (MaxPooling2D)     (None, 4, 4, 64)                0           \n flatten (Flatten)                  (None, 1024)                    0           \n dense (Dense)                      (None, 10)                      10250       \n================================================================================\nTotal params: 62346 (243.54 KB)\nTrainable params: 62346 (243.54 KB)\nNon-trainable params: 0 (0.00 Byte)\n________________________________________________________________________________\n\n\nObservando este resumen, se aprecia fácilmente que las capas convolucionales requieren memoria para guardar los filtros y memoria para guardar los parámetros aprendidos. Es importante ser consciente de los tamaños de los datos y de los parámetros porque cuando tenemos modelos basados en redes neuronales convolucionales, estos tienen muchas capas, como veremos más adelante, y estos valores pueden dispararse. Una representación más visual de la anterior explicación se muestra en la figura siguiente:\n\n\n\n\n\n\n5.3.1 Configuración, entrenamiento y evaluación del modelo\nUna vez definido el modelo de la red neuronal estamos ya en disposición de pasar a entrenar el modelo, es decir, ajustar los parámetros de todas las capas de la red neuronal convolucional. A partir de aquí, para saber cuán bien lo hace nuestro modelo, debemos hacer lo mismo que ya hicimos en apartados anteriores.\n\nmodelo %>% compile(\n  loss = 'sparse_categorical_crossentropy',\n  optimizer = optimizer_sgd(),\n  metrics = c('accuracy')\n)\n\nEntrenamos el modelo:\n\nhistory = modelo %>% \n  fit(x_train, y_train, batch_size = 100, epochs = 5)\n\nEpoch 1/5\n600/600 - 30s - loss: 0.9284 - accuracy: 0.7572 - 30s/epoch - 50ms/step\nEpoch 2/5\n600/600 - 30s - loss: 0.2572 - accuracy: 0.9242 - 30s/epoch - 49ms/step\nEpoch 3/5\n600/600 - 30s - loss: 0.1880 - accuracy: 0.9452 - 30s/epoch - 50ms/step\nEpoch 4/5\n600/600 - 28s - loss: 0.1504 - accuracy: 0.9562 - 28s/epoch - 47ms/step\nEpoch 5/5\n600/600 - 28s - loss: 0.1263 - accuracy: 0.9634 - 28s/epoch - 46ms/step\n\n\nLos resultados finales del entrenamiento los podemos ver con:\n\nhistory;plot(history)\n\n\nFinal epoch (plot to see history):\n    loss: 0.1263\naccuracy: 0.9634 \n\n\n\n\n\nEvaluamos el modelo propuesto mediante el porcentaje de clasificación correcta utilizando la muestra de validación.\n\nmodelo %>% tensorflow::evaluate(x_test, y_test)\n\n313/313 - 2s - loss: 0.1068 - accuracy: 0.9680 - 2s/epoch - 5ms/step\n\n\n     loss  accuracy \n0.1067661 0.9680000 \n\n\nTenemos un porcentaje de clasificación superior al 95%, lo que indica una clasificación muy buena.\nCompletamos la evaluación del modelo obteniendo la tabla de confusión asociada al modelo, y representamos la probabilidad de clasificación predicha de algunas de las muestras de validación. Para poder obtener la matriz de confusión es necesario obtener las predicciones del modelo para la muestra de validación.\n\n# probabilidades de clasificación de cada muestra en cada especie \nprediccion = modelo %>% predict(x_test)\n\n313/313 - 2s - 2s/epoch - 5ms/step\n\n# predicción del modelo\npr_modelo = factor((prediccion %>% k_argmax())$numpy(), levels = 0:(length(etiquetas)-1))\npr_test = factor(y_test, levels = 0:(length(etiquetas)-1))\n# matriz de confusion\ncm <- confusion_matrix(y_test, pr_modelo, metrics = list(\"Weighted Accuracy\" = TRUE))\n# Métrica global\ncm$`Weighted Accuracy`\n\n[1] 0.9936142\n\n# individuales para cada clase\ncm[[3]][[1]][,c(\"Class\", \"Balanced Accuracy\")]\n\n# A tibble: 10 × 2\n   Class `Balanced Accuracy`\n   <chr>               <dbl>\n 1 0                   0.993\n 2 1                   0.991\n 3 2                   0.979\n 4 3                   0.987\n 5 4                   0.976\n 6 5                   0.982\n 7 6                   0.983\n 8 7                   0.972\n 9 8                   0.980\n10 9                   0.978\n\n\nLa clasifiación ponderada muestra valores muy próximos a 1 indicando muy buena clasificación. Veamos la tabla de cofusión de forma gráfica.\n\nplot_confusion_matrix(cm$`Confusion Matrix`[[1]])\n\n\n\n\nMatriz de confusión\n\n\n\n\n\n\n5.3.2 Hiperparámetros de la capa convolucional\nLos principales hiperparámetros de las redes neuronales convolucionales son el tamaño de la ventana del filtro, el número de filtros, el tamaño del paso de avance (stride) y el relleno (padding). Pasemos a presentar con más detalle cada uno de ellos.\n\n5.3.2.1 Tamaño de los filtros\nEl tamaño de la ventana (window_height x window_width) que contiene información de píxeles cercanos espacialmente habitualmente es de 3 x 3 o 5 x 5. El número de filtros que nos indica el número de características que queremos manejar (output_depth) acostumbra a ser de 32 o 64. En las capas Conv2D de Keras estos hiperparámetros son los que pasamos como argumentos en este orden:\nlayer_conv_2d(filters = output_depth, kernel_size = c(window_height, window_width), ...) \n\n\n5.3.2.2 Padding\nPara explicar el concepto de relleno (padding) usaremos un ejemplo. Supongamos una imagen con 5x5 píxeles. Si elegimos una ventana de 3x3 para realizar la convolución, vemos que el tensor resultante de la operación es de tamaño 3x3. Es decir, se encoge exactamente dos píxeles por cada dimensión, en este caso. En la Figura siguiente se muestra visualmente. Supongamos que la figura de la izquierda es la imagen de 5 x 5. En ella hemos enumerado los píxeles para facilitar el seguimiento de los movimientos de la ventana de 3 x 3 para calcular los elementos del filtro. En el centro vemos cómo la ventana de 3 x 3 se ha desplazado por la imagen, dos veces hacia la derecha y dos posiciones hacia abajo. El resultado de aplicar la operación de convolución nos devuelve el filtro que hemos representado a la izquierda. Cada elemento de este filtro está etiquetado con una letra que lo asocia al contenido de la ventana deslizante con el que se calcula su valor.\n\n\n\n\n\nEste mismo efecto se puede observar en el ejemplo de red neuronal convolucional que estamos creando en este capítulo. Comenzamos con una imagen de entrada 28x28x1; los filtros resultantes son de 24x24x1 después de la primera capa de convolución. En la segunda capa de convolución, pasamos de un tensor 12x12x1 a uno 8x8x1.\nPero a veces queremos obteenr un tensor de salida de las mismas dimensiones de entrada; podemos usar para ello el hiperparámetro padding en las capas convolucionales. Con padding podemos agregar ceros (zero-padding en inglés) alrededor de las imágenes de entrada antes de hacer desizr la ventana por ella. En nuestro caso de la figura anterior, podemos añadir a la imagen de entrada una columna a la derecha, una columna a la izquierda, una fila arriba y una fila debajo de ceros. Visualmente se puede visualizar enla figura siguiente:\n\n\n\n\n\nSi ahora deslizamos la ventana de 3x3, vemos que puede desplazarse cuatro veces hacia a la derecha y cuatro hacia abajo, generando las 25 ventanas que generan el filtro de tamaño 5x5 (figura siguiente).\n\n\n\n\n\nEn Keras, este relleno con ceros en la capa Conv2D se configura con el argumento padding, que puede tener dos valores: same, que implica que se añadan tantas filas y columnas de ceros como sea necesario para que la salida tenga la misma dimensión que la entrada, y valid, que implica no hacer padding (que es el valor por defecto de este argumento en Keras).\n\n\n5.3.2.3 Stride\nOtro hiperparámetro que podemos especificar en una capa convolucional es el stride, que nos indica el número de pasos en que se mueve la ventada de los filtros. En el anterior ejemplo el stride era de 1, el valor por defecto.\nValores de stride grandes hacen decrecer el tamaño de la información que pasará a la siguiente capa. En la siguiente podemos ver el mismo ejemplo anterior pero ahora con un valor de stride de 2.\n Como vemos, la imagen de 5x5 se ha convertido en un filtro de tamaño más reducido de 2x2. Pero, en la práctica, los strides son raramente utilizados en convolucionales para reducir los tamaños; para ello se usan las operaciones de pooling que hemos presentado antes. En Keras, el stride en la capa conv2D se configura con el argumento stride que tiene por defecto el valor strides = ( 1, 1) que indica por separado el avance en las dos dimensiones.\nAntes de presenatr un nuevo conjunto de datos vamos a plantear un modelo de red mucho más complejo para el conjnto de datos digits. En concreto, vamos a intercalar varias capas dropout y nueva capa dense antes de la capa de salida.\n\n# Arquitectura de red\nmodelo = keras_model_sequential() %>%  \n  layer_conv_2d(filters = 32, kernel_size = c(5, 5), activation='relu', input_shape=c(28, 28, 1)) %>% \n  layer_max_pooling_2d(pool_size = c(2, 2)) %>%\n  layer_conv_2d(filters = 64, kernel_size = c(5, 5), activation='relu') %>% \n  layer_max_pooling_2d(pool_size = c(2, 2)) %>%\n  layer_dropout(0.25) %>%\n  layer_flatten() %>%\n  layer_dense(units = 128, activation = 'relu') %>% \n  layer_dropout(rate = 0.5) %>% \n  layer_dense(units = 10, activation = 'softmax')\nsummary(modelo)\n\nModel: \"sequential_3\"\n________________________________________________________________________________\n Layer (type)                       Output Shape                    Param #     \n================================================================================\n conv2d_6 (Conv2D)                  (None, 24, 24, 32)              832         \n max_pooling2d_6 (MaxPooling2D)     (None, 12, 12, 32)              0           \n conv2d_5 (Conv2D)                  (None, 8, 8, 64)                51264       \n max_pooling2d_5 (MaxPooling2D)     (None, 4, 4, 64)                0           \n dropout_1 (Dropout)                (None, 4, 4, 64)                0           \n flatten_1 (Flatten)                (None, 1024)                    0           \n dense_2 (Dense)                    (None, 128)                     131200      \n dropout (Dropout)                  (None, 128)                     0           \n dense_1 (Dense)                    (None, 10)                      1290        \n================================================================================\nTotal params: 184586 (721.04 KB)\nTrainable params: 184586 (721.04 KB)\nNon-trainable params: 0 (0.00 Byte)\n________________________________________________________________________________\n\n\nEl modelo tiene 184586 parámetros que debemos estimar. Configuramos el aprendizaje y entrenamos el modelo con 10 epochs y porcentaje de validación del 20%:\n\n# Proceso de aprendizaje\nmodelo %>% compile(\n  loss = 'sparse_categorical_crossentropy',\n  optimizer = optimizer_sgd(),\n  metrics = c('accuracy'))\n\n# Entrenamiento \nhistory = modelo %>% \n  fit(x_train, y_train, batch_size = 100, epochs = 10, validation_split = 0.2)  \n\nEpoch 1/10\n480/480 - 28s - loss: 1.4229 - accuracy: 0.5363 - val_loss: 0.3882 - val_accuracy: 0.9025 - 28s/epoch - 59ms/step\nEpoch 2/10\n480/480 - 27s - loss: 0.5086 - accuracy: 0.8439 - val_loss: 0.2120 - val_accuracy: 0.9404 - 27s/epoch - 57ms/step\nEpoch 3/10\n480/480 - 27s - loss: 0.3581 - accuracy: 0.8925 - val_loss: 0.1628 - val_accuracy: 0.9525 - 27s/epoch - 57ms/step\nEpoch 4/10\n480/480 - 30s - loss: 0.2871 - accuracy: 0.9153 - val_loss: 0.1368 - val_accuracy: 0.9586 - 30s/epoch - 62ms/step\nEpoch 5/10\n480/480 - 29s - loss: 0.2465 - accuracy: 0.9263 - val_loss: 0.1203 - val_accuracy: 0.9629 - 29s/epoch - 60ms/step\nEpoch 6/10\n480/480 - 29s - loss: 0.2186 - accuracy: 0.9352 - val_loss: 0.1082 - val_accuracy: 0.9671 - 29s/epoch - 60ms/step\nEpoch 7/10\n480/480 - 28s - loss: 0.2013 - accuracy: 0.9387 - val_loss: 0.1010 - val_accuracy: 0.9694 - 28s/epoch - 57ms/step\nEpoch 8/10\n480/480 - 28s - loss: 0.1798 - accuracy: 0.9456 - val_loss: 0.0935 - val_accuracy: 0.9701 - 28s/epoch - 58ms/step\nEpoch 9/10\n480/480 - 28s - loss: 0.1721 - accuracy: 0.9482 - val_loss: 0.0889 - val_accuracy: 0.9735 - 28s/epoch - 59ms/step\nEpoch 10/10\n480/480 - 27s - loss: 0.1599 - accuracy: 0.9519 - val_loss: 0.0837 - val_accuracy: 0.9744 - 27s/epoch - 57ms/step\n\n\nLos resultados finales del entrenamiento los podemos ver con:\n\nhistory;plot(history)\n\n\nFinal epoch (plot to see history):\n        loss: 0.1599\n    accuracy: 0.9519\n    val_loss: 0.08372\nval_accuracy: 0.9744 \n\n\n\n\n\nEvaluamos el modelo propuesto mediante el porcentaje de clasificación correcta utilizando la muestra de validación.\n\nmodelo %>% tensorflow::evaluate(x_test, y_test)\n\n313/313 - 2s - loss: 0.0763 - accuracy: 0.9772 - 2s/epoch - 5ms/step\n\n\n      loss   accuracy \n0.07634594 0.97719997 \n\n\nEl porcentaje de clasificación sigue siendo muy alto. En este caso no obtenemos la matriz de confusión porque los resultados son muy similares."
  },
  {
    "objectID": "50_ConvNN.html#conjunto-de-datos-fashion-minst",
    "href": "50_ConvNN.html#conjunto-de-datos-fashion-minst",
    "title": "5  Redes convolucionales",
    "section": "5.4 Conjunto de datos Fashion-minst",
    "text": "5.4 Conjunto de datos Fashion-minst\nLlegados a este punto, vamos a presentar el conjunto de datos Fashion-­MNIST sobre el que vamos hacer una análisis completo utilizando diferentes modelos de redes convolucionales. Fashion-MNIST es un conjunto de datos de las imágenes de los artículos de Zalando, una tienda de moda online alemana especializada en venta de ropa y zapatos. El conjunto de datos contiene 70000 imágenes en escala de grises en 10 categorías. Las imágenes muestran prendas individuales de ropa en baja resolución (28x28 píxeles). Se usan 60000 imágenes para entrenar la red y 10000 imágenes para evaluar la precisión con la que la red aprende a clasificar las imágenes.\nEn primer lugar cargamos los datos:\n\n# Cargamos datos\nfashion = keras::dataset_fashion_mnist()\n\n# División de muestras entrenamiento y validación\nx_train = fashion$train$x\ny_train = fashion$train$y\nx_test = fashion$test$x\ny_test = fashion$test$y\n\nIgual que en el ejemplo anterior, la carga del conjunto de datos devuelve cuatro matrices. Las matrices train son el conjunto de entrenamiento (inputs y outputs). Las matrices test son el conjunto de prueba (inputs y outputs) para evaluar la precisión del modelo. Las imágenes son matrices de 28 x 28 píxeles, con valores que van de O a 255. Las etiquetas son una matriz de enteros, que van de O a 9. Estos corresponden a la clase de ropa que representa la imagen:\n\n# Etiquetas\netiquetas = c('T-shirt/top', 'Trouser', 'Pullover', 'Dress', 'Coat', 'Sandal', 'Shirt', 'Sneaker', 'Bag', 'Ankle boot')\n\nIgual que en e ejemplo de digits vamos a escalr los valores de entrada en el rango 0-1:\n\n# Reescalamos para tener entradas en el intervalo 0-1\nx_train <- x_train / 255\nx_test <- x_test / 255\n\nPara poder representar la información contenida en cada uno de la matrices de entrenamiento definimos una función que nos permite su representación gráfica:\n\nimagen = function(i, xtr, ytr, eti)\n{\n  # Función pra representa la imagen contenida en una matriz de datos 28*28\n  #\n  # Valores de entrada\n  #   i : muestra\n  #   xtr: matriz de datos de entrada\n  #   ytr: vector de outputs\n  #   eti: vector de etiquetas de las muestras\n  #\n  # Devuelve la imagen correspondiente a xtr[i] con la etiqueta eti[ytr[i]]\n  \n  img = xtr[i, , ]\n  img = t(apply(img, 2, rev)) \n  image(1:28, 1:28, img, col = gray((0:255)/255), \n        xaxt = 'n', yaxt = 'n',\n        main = paste(eti[ytr[i] + 1]), xlab=\"\",ylab=\"\")\n}\n\nVeamos el resultado de las primeras 25 muestras de entrenamiento:\n\npar(mfrow=c(3, 3))\npar(mar=c(0.5, 0.5, 2, 0.5), xaxs='i', yaxs='i')\nfor(i in 1:9)\n{\n  imagen(i, x_train, y_train, etiquetas)\n}\n\n\n\n\n\n5.4.1 Modelo inicial\nConsideremos como punto de partida usar la misma red en la que hemos clasificado los dígitos MNIST en la sección anterior:\n\n# Arquitectura de red\nmod1 = keras_model_sequential() %>%  \n  layer_conv_2d(filters = 32, kernel_size = c(5, 5), activation='relu', input_shape=c(28, 28, 1)) %>% \n  layer_max_pooling_2d(pool_size = c(2, 2)) %>%\n  layer_conv_2d(filters = 64, kernel_size = c(5, 5), activation='relu') %>% \n  layer_max_pooling_2d(pool_size = c(2, 2)) %>%\n  layer_flatten() %>%\n  layer_dense(units = 10, activation = 'softmax')\nsummary(mod1)\n\nModel: \"sequential_4\"\n________________________________________________________________________________\n Layer (type)                       Output Shape                    Param #     \n================================================================================\n conv2d_8 (Conv2D)                  (None, 24, 24, 32)              832         \n max_pooling2d_8 (MaxPooling2D)     (None, 12, 12, 32)              0           \n conv2d_7 (Conv2D)                  (None, 8, 8, 64)                51264       \n max_pooling2d_7 (MaxPooling2D)     (None, 4, 4, 64)                0           \n flatten_2 (Flatten)                (None, 1024)                    0           \n dense_3 (Dense)                    (None, 10)                      10250       \n================================================================================\nTotal params: 62346 (243.54 KB)\nTrainable params: 62346 (243.54 KB)\nNon-trainable params: 0 (0.00 Byte)\n________________________________________________________________________________\n\n\nProcedemos con la configuración del proceso de aprendizaje y el entrenamiento del modelo. Debido al coste computacional consideramos un batch pequeño y tan solo 5 epochs.\n\n# Proceso de aprendizaje\nmod1 %>% compile(\n  loss = 'sparse_categorical_crossentropy',\n  optimizer = optimizer_sgd(),\n  metrics = c('accuracy'))\n\n# Entrenamiento \nhist1 = mod1 %>% \n  fit(x_train, y_train, batch_size = 50, epochs = 5, validation_split = 0.2)  \n\nEpoch 1/5\n960/960 - 26s - loss: 1.0396 - accuracy: 0.6353 - val_loss: 0.6411 - val_accuracy: 0.7597 - 26s/epoch - 28ms/step\nEpoch 2/5\n960/960 - 26s - loss: 0.5993 - accuracy: 0.7815 - val_loss: 0.5608 - val_accuracy: 0.7986 - 26s/epoch - 27ms/step\nEpoch 3/5\n960/960 - 27s - loss: 0.5214 - accuracy: 0.8118 - val_loss: 0.4965 - val_accuracy: 0.8231 - 27s/epoch - 28ms/step\nEpoch 4/5\n960/960 - 26s - loss: 0.4757 - accuracy: 0.8296 - val_loss: 0.4659 - val_accuracy: 0.8325 - 26s/epoch - 27ms/step\nEpoch 5/5\n960/960 - 27s - loss: 0.4462 - accuracy: 0.8418 - val_loss: 0.4446 - val_accuracy: 0.8391 - 27s/epoch - 28ms/step\n\n\nEvaluamos la capacidad de clasificación del modelo propuesto sobre la muestra de validación:\n\n# Proceso de aprendizaje\nmod1 %>% tensorflow::evaluate(x_test, y_test)\n\n313/313 - 2s - loss: 0.4584 - accuracy: 0.8367 - 2s/epoch - 5ms/step\n\n\n     loss  accuracy \n0.4584489 0.8367000 \n\n\nEl porcentaje de clasificación correcta es del 85% par el modelo propuesto. Aunque no es exageradamente bueno debemos tener en cuenta que el modleo es muy simple.\n\n\n5.4.2 Modelo 2\nEn este caso duplicamos las neuronas por capa del modelo base y añadimosuna capa densa de 64 neuronas.\n\n# Arquitectura de red\nmod2 = keras_model_sequential() %>%  \n  layer_conv_2d(filters = 64, kernel_size = c(5, 5), activation='relu', input_shape=c(28, 28, 1)) %>% \n  layer_max_pooling_2d(pool_size = c(2, 2)) %>%\n  layer_conv_2d(filters = 128, kernel_size = c(5, 5), activation='relu') %>% \n  layer_max_pooling_2d(pool_size = c(2, 2)) %>%\n  layer_flatten() %>%\n  layer_dense(units = 64, activation = 'relu') %>%\n  layer_dense(units = 10, activation = 'softmax')\nsummary(mod2)\n\nModel: \"sequential_5\"\n________________________________________________________________________________\n Layer (type)                       Output Shape                    Param #     \n================================================================================\n conv2d_10 (Conv2D)                 (None, 24, 24, 64)              1664        \n max_pooling2d_10 (MaxPooling2D)    (None, 12, 12, 64)              0           \n conv2d_9 (Conv2D)                  (None, 8, 8, 128)               204928      \n max_pooling2d_9 (MaxPooling2D)     (None, 4, 4, 128)               0           \n flatten_3 (Flatten)                (None, 2048)                    0           \n dense_5 (Dense)                    (None, 64)                      131136      \n dense_4 (Dense)                    (None, 10)                      650         \n================================================================================\nTotal params: 338378 (1.29 MB)\nTrainable params: 338378 (1.29 MB)\nNon-trainable params: 0 (0.00 Byte)\n________________________________________________________________________________\n\n\nConfiguramos y entrenamos el modelo de forma similar al modelo anterior.\n\n# Proceso de aprendizaje\nmod2 %>% compile(\n  loss = 'sparse_categorical_crossentropy',\n  optimizer = optimizer_sgd(),\n  metrics = c('accuracy'))\n\n# Entrenamiento \nhist2 = mod2 %>% \n  fit(x_train, y_train, batch_size = 50, epochs = 5, validation_split = 0.2)  \n\nEpoch 1/5\n960/960 - 67s - loss: 1.0222 - accuracy: 0.6330 - val_loss: 0.6513 - val_accuracy: 0.7619 - 67s/epoch - 70ms/step\nEpoch 2/5\n960/960 - 75s - loss: 0.5954 - accuracy: 0.7793 - val_loss: 0.5548 - val_accuracy: 0.7895 - 75s/epoch - 78ms/step\nEpoch 3/5\n960/960 - 67s - loss: 0.5156 - accuracy: 0.8109 - val_loss: 0.4796 - val_accuracy: 0.8288 - 67s/epoch - 69ms/step\nEpoch 4/5\n960/960 - 69s - loss: 0.4668 - accuracy: 0.8325 - val_loss: 0.4630 - val_accuracy: 0.8373 - 69s/epoch - 71ms/step\nEpoch 5/5\n960/960 - 66s - loss: 0.4340 - accuracy: 0.8447 - val_loss: 0.4474 - val_accuracy: 0.8384 - 66s/epoch - 69ms/step\n\n\nEvaluamos el modelo comparando con el anterior:\n\n# Proceso de aprendizaje\nmod1 %>% tensorflow::evaluate(x_test, y_test)\n\n313/313 - 2s - loss: 0.4584 - accuracy: 0.8367 - 2s/epoch - 7ms/step\n\n\n     loss  accuracy \n0.4584489 0.8367000 \n\nmod2 %>% tensorflow::evaluate(x_test, y_test)\n\n313/313 - 3s - loss: 0.4574 - accuracy: 0.8374 - 3s/epoch - 11ms/step\n\n\n     loss  accuracy \n0.4574407 0.8374000 \n\n\nA pesar del aumento de neuronas y de la nueva capa densa los resultados del modleo son comparables o incluso perores.\n\n\n5.4.3 Modelo 3\nAhora consideramos el miso modelo 1 pero cambiando el optimizar por adam:\n\n# Arquitectura de red\nmod3 = keras_model_sequential() %>%  \n  layer_conv_2d(filters = 32, kernel_size = c(5, 5), activation='relu', input_shape=c(28, 28, 1)) %>% \n  layer_max_pooling_2d(pool_size = c(2, 2)) %>%\n  layer_conv_2d(filters = 64, kernel_size = c(5, 5), activation='relu') %>% \n  layer_max_pooling_2d(pool_size = c(2, 2)) %>%\n  layer_flatten() %>%\n  layer_dense(units = 10, activation = 'softmax')\n# Proceso de aprendizaje\nmod3 %>% compile(\n  loss = 'sparse_categorical_crossentropy',\n  optimizer = optimizer_adam(),\n  metrics = c('accuracy'))\n\n# Entrenamiento \nhist3 = mod3 %>% \n  fit(x_train, y_train, batch_size = 50, epochs = 5, validation_split = 0.2)  \n\nEpoch 1/5\n960/960 - 29s - loss: 0.5301 - accuracy: 0.8106 - val_loss: 0.3913 - val_accuracy: 0.8618 - 29s/epoch - 30ms/step\nEpoch 2/5\n960/960 - 26s - loss: 0.3451 - accuracy: 0.8776 - val_loss: 0.3300 - val_accuracy: 0.8837 - 26s/epoch - 27ms/step\nEpoch 3/5\n960/960 - 28s - loss: 0.3011 - accuracy: 0.8924 - val_loss: 0.3265 - val_accuracy: 0.8843 - 28s/epoch - 29ms/step\nEpoch 4/5\n960/960 - 26s - loss: 0.2714 - accuracy: 0.9028 - val_loss: 0.3014 - val_accuracy: 0.8928 - 26s/epoch - 27ms/step\nEpoch 5/5\n960/960 - 26s - loss: 0.2497 - accuracy: 0.9104 - val_loss: 0.2810 - val_accuracy: 0.8984 - 26s/epoch - 27ms/step\n\n\nComparamos ahora ambos modelos:\n\n# Proceso de aprendizaje\nmod1 %>% tensorflow::evaluate(x_test, y_test)\n\n313/313 - 2s - loss: 0.4584 - accuracy: 0.8367 - 2s/epoch - 5ms/step\n\n\n     loss  accuracy \n0.4584489 0.8367000 \n\nmod3 %>% tensorflow::evaluate(x_test, y_test)\n\n313/313 - 2s - loss: 0.2987 - accuracy: 0.8934 - 2s/epoch - 5ms/step\n\n\n    loss accuracy \n0.298688 0.893400 \n\n\nEl cambio de optimizador mejora el modelo 1 aumentando el porcentaje de clasificación correcta.\n\n\n5.4.4 Modelo 4\nA pesar de la sencillez del modelo propuesto casi alcanzamos el 90% de clasificación correcta lo que es un gran resultado: Para tratar de mejorar dicho modleo y evitar un posible probelam de sobrentrenamiento vamos a introducir dos nuevos tipos de capas en nuestra arquitectura de red:\n\nLa capa BatchNormalization, que usa una técnica 120 introducida en el 2015 cuya idea es normalizar las entradas de la capa de tal manera que tengan una activación de salida media de cero y una desviación estándar de uno. Esto es análogo a cómo se estandarizan las entradas a las redes.\nLa capa Dropout, que se basa en ignorar ciertos conjuntos de neuronas de la red neuronal durante la fase de entrenamiento de manera aleatoria. Por «ignorar», nos referimos a que estas neuronas no se consideran durante una iteración concreta del proceso de aprendizaje.\n\nSe propone la arquitectura de red que se presenta a continuación:\n\nbuild_model = function()\n{\n  mod = keras_model_sequential() %>%  \n  layer_conv_2d(filters = 32, kernel_size = c(5, 5), activation='relu', input_shape=c(28, 28, 1)) %>% \n  layer_batch_normalization() %>%\n  layer_conv_2d(filters = 64, kernel_size = c(5, 5), activation='relu') %>% \n  layer_batch_normalization() %>%\n  layer_dropout(0.25) %>%\n  layer_conv_2d(filters = 128, kernel_size = c(5, 5), activation='relu') %>% \n  layer_batch_normalization() %>%\n  layer_dropout(0.25) %>%    \n  layer_flatten() %>%\n  layer_dense(units = 128, activation = 'relu') %>% \n  layer_batch_normalization() %>%\n  layer_dropout(0.5) %>%        \n  layer_dense(units = 10, activation = 'softmax')\nreturn(mod)  \n}\n\nCargamos y entrenamos el modelo\n\nmod4= build_model()\n# Proceso de aprendizaje\nmod4 %>% compile(\n  loss = 'sparse_categorical_crossentropy',\n  optimizer = optimizer_adam(),\n  metrics = c('accuracy'))\n\n# Entrenamiento \nhist4 = mod4 %>% \n  fit(x_train, y_train, batch_size = 50, epochs = 5, validation_split = 0.2)  \n\nEpoch 1/5\n960/960 - 382s - loss: 0.5035 - accuracy: 0.8232 - val_loss: 0.3446 - val_accuracy: 0.8753 - 382s/epoch - 398ms/step\nEpoch 2/5\n960/960 - 587s - loss: 0.3271 - accuracy: 0.8826 - val_loss: 0.2898 - val_accuracy: 0.8942 - 587s/epoch - 612ms/step\nEpoch 3/5\n960/960 - 595s - loss: 0.2765 - accuracy: 0.9014 - val_loss: 0.2731 - val_accuracy: 0.9019 - 595s/epoch - 619ms/step\nEpoch 4/5\n960/960 - 589s - loss: 0.2509 - accuracy: 0.9104 - val_loss: 0.2416 - val_accuracy: 0.9108 - 589s/epoch - 613ms/step\nEpoch 5/5\n960/960 - 585s - loss: 0.2229 - accuracy: 0.9196 - val_loss: 0.2336 - val_accuracy: 0.9141 - 585s/epoch - 610ms/step\n\n\nComparamos los resultados con el modelo anterior:\n\n# Proceso de aprendizaje\nmod3 %>% tensorflow::evaluate(x_test, y_test)\n\n313/313 - 2s - loss: 0.2987 - accuracy: 0.8934 - 2s/epoch - 8ms/step\n\n\n    loss accuracy \n0.298688 0.893400 \n\nmod4 %>% tensorflow::evaluate(x_test, y_test)\n\n313/313 - 21s - loss: 0.2479 - accuracy: 0.9092 - 21s/epoch - 68ms/step\n\n\n     loss  accuracy \n0.2479378 0.9092000 \n\n\nEl modelo propuesto mejora los resultados pero el coste computacional es mucho más alto. Esto es un probelmas habitual dentro del análisis de imágenes. Cuando trabajamos con modelos más complejos que nos proporcionan mejores resultados el coste computacional se dispara.\n\n\n5.4.5 Predicción\nUna vez establecido el modelo tan solo nos queda analizar la predicción de las muestars de validación que conseguimos con nuestro mejor modelo.\n\n# probabilidades de clasificación de cada muestra \nprediccion = mod4 %>% predict(x_test)\n\n313/313 - 22s - 22s/epoch - 69ms/step\n\n# predicción del modelo\npr_modelo = (prediccion %>% k_argmax())$numpy()\n# Matriz de confusión\ncm = confusion_matrix(y_test, pr_modelo)\n# Gráfico\nplot_confusion_matrix(cm$`Confusion Matrix`[[1]])"
  }
]