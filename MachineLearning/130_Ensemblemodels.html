<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.2.335">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">


<title>MachineLearning - 13&nbsp; Modelos de conjunto (Ensemble models)</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1.6em;
  vertical-align: middle;
}
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { color: #008000; } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { color: #008000; font-weight: bold; } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
</style>


<script src="site_libs/quarto-nav/quarto-nav.js"></script>
<script src="site_libs/quarto-nav/headroom.min.js"></script>
<script src="site_libs/clipboard/clipboard.min.js"></script>
<script src="site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="site_libs/quarto-search/fuse.min.js"></script>
<script src="site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="./">
<link href="./140_Boostingmodels.html" rel="next">
<link href="./120_DTmodels.html" rel="prev">
<script src="site_libs/quarto-html/quarto.js"></script>
<script src="site_libs/quarto-html/popper.min.js"></script>
<script src="site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="site_libs/quarto-html/anchor.min.js"></script>
<link href="site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="site_libs/quarto-html/quarto-syntax-highlighting.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="site_libs/bootstrap/bootstrap.min.js"></script>
<link href="site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="site_libs/bootstrap/bootstrap.min.css" rel="stylesheet" id="quarto-bootstrap" data-mode="light">
<script id="quarto-search-options" type="application/json">{
  "location": "sidebar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "start",
  "type": "textbox",
  "limit": 20,
  "language": {
    "search-no-results-text": "Sin resultados",
    "search-matching-documents-text": "documentos coincidentes",
    "search-copy-link-title": "Copiar enlace para buscar",
    "search-hide-matches-text": "Ocultar coincidencias adicionales",
    "search-more-match-text": "más coincidencia en este documento",
    "search-more-matches-text": "más coincidencias en este documento",
    "search-clear-button-title": "Limpiar",
    "search-detached-cancel-button-title": "Cancelar",
    "search-submit-button-title": "Entregar"
  }
}</script>

  <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js" type="text/javascript"></script>

</head>

<body class="nav-sidebar docked">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top">
  <nav class="quarto-secondary-nav" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
    <div class="container-fluid d-flex justify-content-between">
      <h1 class="quarto-secondary-nav-title"><span class="chapter-number">13</span>&nbsp; <span class="chapter-title">Modelos de conjunto (Ensemble models)</span></h1>
      <button type="button" class="quarto-btn-toggle btn" aria-label="Show secondary navigation">
        <i class="bi bi-chevron-right"></i>
      </button>
    </div>
  </nav>
</header>
<!-- content -->
<div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article">
<!-- sidebar -->
  <nav id="quarto-sidebar" class="sidebar collapse sidebar-navigation docked overflow-auto">
    <div class="pt-lg-2 mt-2 text-left sidebar-header">
    <div class="sidebar-title mb-0 py-0">
      <a href="./">MachineLearning</a> 
    </div>
      </div>
      <div class="mt-2 flex-shrink-0 align-items-center">
        <div class="sidebar-search">
        <div id="quarto-search" class="" title="Search"></div>
        </div>
      </div>
    <div class="sidebar-menu-container"> 
    <ul class="list-unstyled mt-1">
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./index.html" class="sidebar-item-text sidebar-link">Prefacio</a>
  </div>
</li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a href="./01_IntroCourse.html" class="sidebar-item-text sidebar-link">Parte 1. Introducción</a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-1" aria-expanded="true">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-1" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./10_introAD.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">1</span>&nbsp; <span class="chapter-title">Introducción al análisis de datos</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./20_introAA.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">2</span>&nbsp; <span class="chapter-title">Introducción al Aprendizaje Automático (AA)</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./30_RandRstudio.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">3</span>&nbsp; <span class="chapter-title">Introducción a R y RStudio</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./40_DataBases.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">4</span>&nbsp; <span class="chapter-title">Bases de datos</span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a href="./02_FirstStepsAA.html" class="sidebar-item-text sidebar-link">Parte 2. Primeros pasos</a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-2" aria-expanded="true">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-2" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./50_AED.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">5</span>&nbsp; <span class="chapter-title">Introducción al análisis de datos</span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a href="./03_SupervisedAA.html" class="sidebar-item-text sidebar-link">Parte 3. Aprendizaje supervisado</a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-3" aria-expanded="true">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-3" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./60_RegressionModels.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">6</span>&nbsp; <span class="chapter-title">Modelos de Regresión</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./70_LogisticModels.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">7</span>&nbsp; <span class="chapter-title">Modelos de Regresión Logística</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./80_SurvivalModels.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">8</span>&nbsp; <span class="chapter-title">Modelos de supervivencia</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./90_BayesianClassif.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">9</span>&nbsp; <span class="chapter-title">Modelos de clasificación Naïve Bayes</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./100_kNNmodels.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">10</span>&nbsp; <span class="chapter-title">Modelo de los k vecinos más cercanos (kNN)</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./110_SVMmodels.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">11</span>&nbsp; <span class="chapter-title">Máquinas de Vector Soporte (SVM)</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./120_DTmodels.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">12</span>&nbsp; <span class="chapter-title">Árboles de decisiónn (DT)</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./130_Ensemblemodels.html" class="sidebar-item-text sidebar-link active"><span class="chapter-number">13</span>&nbsp; <span class="chapter-title">Modelos de conjunto (Ensemble models)</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./140_Boostingmodels.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">14</span>&nbsp; <span class="chapter-title">Modelos Boosting</span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a href="./04_NonSupervisedAA.html" class="sidebar-item-text sidebar-link">Parte 4. Aprendizaje no supervisado</a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-4" aria-expanded="true">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-4" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./150_Discriminantmodels.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">15</span>&nbsp; <span class="chapter-title">Análisis discriminante (AD)</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./160_PrinCompmodels.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">16</span>&nbsp; <span class="chapter-title">Componentes principales (CP)</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./170_MDSmodels.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">17</span>&nbsp; <span class="chapter-title">Métodos de escalado multidimensional (MDS)</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./180_Clustermodels.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">18</span>&nbsp; <span class="chapter-title">Análisis cluster</span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./references.html" class="sidebar-item-text sidebar-link">Referencias</a>
  </div>
</li>
    </ul>
    </div>
</nav>
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
        <nav id="TOC" role="doc-toc" class="toc-active">
    <h2 id="toc-title">Tabla de contenidos</h2>
   
  <ul>
  <li><a href="#sec-130.1" id="toc-sec-130.1" class="nav-link active" data-scroll-target="#sec-130.1"><span class="toc-section-number">13.1</span>  Modelos básicos Bagging</a>
  <ul>
  <li><a href="#sec-130.1.1" id="toc-sec-130.1.1" class="nav-link" data-scroll-target="#sec-130.1.1"><span class="toc-section-number">13.1.1</span>  Voto por mayoría</a></li>
  <li><a href="#sec-130.1.2" id="toc-sec-130.1.2" class="nav-link" data-scroll-target="#sec-130.1.2"><span class="toc-section-number">13.1.2</span>  Bagging por lotes</a></li>
  </ul></li>
  <li><a href="#sec-130.2" id="toc-sec-130.2" class="nav-link" data-scroll-target="#sec-130.2"><span class="toc-section-number">13.2</span>  Modelos básicos Bagging en mlr3</a>
  <ul>
  <li><a href="#sec-130.2.1" id="toc-sec-130.2.1" class="nav-link" data-scroll-target="#sec-130.2.1"><span class="toc-section-number">13.2.1</span>  Bancos de datos</a>
  <ul class="collapse">
  <li><a href="#stroke" id="toc-stroke" class="nav-link" data-scroll-target="#stroke"><span class="toc-section-number">13.2.1.1</span>  Stroke</a></li>
  <li><a href="#water-potability" id="toc-water-potability" class="nav-link" data-scroll-target="#water-potability"><span class="toc-section-number">13.2.1.2</span>  Water Potability</a></li>
  <li><a href="#housing-in-california" id="toc-housing-in-california" class="nav-link" data-scroll-target="#housing-in-california"><span class="toc-section-number">13.2.1.3</span>  Housing in California</a></li>
  </ul></li>
  <li><a href="#sec-130.2.2" id="toc-sec-130.2.2" class="nav-link" data-scroll-target="#sec-130.2.2"><span class="toc-section-number">13.2.2</span>  Modelos</a>
  <ul class="collapse">
  <li><a href="#stroke-1" id="toc-stroke-1" class="nav-link" data-scroll-target="#stroke-1"><span class="toc-section-number">13.2.2.1</span>  Stroke</a></li>
  <li><a href="#water-potability-1" id="toc-water-potability-1" class="nav-link" data-scroll-target="#water-potability-1"><span class="toc-section-number">13.2.2.2</span>  Water Potability</a></li>
  <li><a href="#housing-in-california-1" id="toc-housing-in-california-1" class="nav-link" data-scroll-target="#housing-in-california-1"><span class="toc-section-number">13.2.2.3</span>  Housing in California</a></li>
  </ul></li>
  </ul></li>
  <li><a href="#sec-130.3" id="toc-sec-130.3" class="nav-link" data-scroll-target="#sec-130.3"><span class="toc-section-number">13.3</span>  Bosques aleatorios (Random Forests)</a>
  <ul>
  <li><a href="#sec-130.3.1" id="toc-sec-130.3.1" class="nav-link" data-scroll-target="#sec-130.3.1"><span class="toc-section-number">13.3.1</span>  Algortimo Bosques aleatorios</a></li>
  <li><a href="#sec-130.3.2" id="toc-sec-130.3.2" class="nav-link" data-scroll-target="#sec-130.3.2"><span class="toc-section-number">13.3.2</span>  Predicción mediante bosque aleatorio</a></li>
  <li><a href="#sec-130.3.3" id="toc-sec-130.3.3" class="nav-link" data-scroll-target="#sec-130.3.3"><span class="toc-section-number">13.3.3</span>  Importancia de los predictores</a>
  <ul class="collapse">
  <li><a href="#importancia-por-permutación" id="toc-importancia-por-permutación" class="nav-link" data-scroll-target="#importancia-por-permutación"><span class="toc-section-number">13.3.3.1</span>  Importancia por permutación</a></li>
  <li><a href="#incremento-de-la-pureza-de-los-nodos" id="toc-incremento-de-la-pureza-de-los-nodos" class="nav-link" data-scroll-target="#incremento-de-la-pureza-de-los-nodos"><span class="toc-section-number">13.3.3.2</span>  Incremento de la pureza de los nodos</a></li>
  </ul></li>
  <li><a href="#sec-130.3.4" id="toc-sec-130.3.4" class="nav-link" data-scroll-target="#sec-130.3.4"><span class="toc-section-number">13.3.4</span>  Hiperparámetros relevantes en el bosque aleatorio</a></li>
  <li><a href="#sec-130.3.5" id="toc-sec-130.3.5" class="nav-link" data-scroll-target="#sec-130.3.5"><span class="toc-section-number">13.3.5</span>  Codificación de predictoras cualitativas</a></li>
  </ul></li>
  <li><a href="#sec-130.4" id="toc-sec-130.4" class="nav-link" data-scroll-target="#sec-130.4"><span class="toc-section-number">13.4</span>  Bosque aleatorio en mlr3</a>
  <ul>
  <li><a href="#sec-130.4.1" id="toc-sec-130.4.1" class="nav-link" data-scroll-target="#sec-130.4.1"><span class="toc-section-number">13.4.1</span>  Modelos de bosques aleatorios</a>
  <ul class="collapse">
  <li><a href="#breast-cancer-wisconsin" id="toc-breast-cancer-wisconsin" class="nav-link" data-scroll-target="#breast-cancer-wisconsin"><span class="toc-section-number">13.4.1.1</span>  Breast Cancer Wisconsin</a></li>
  <li><a href="#water-potability-2" id="toc-water-potability-2" class="nav-link" data-scroll-target="#water-potability-2"><span class="toc-section-number">13.4.1.2</span>  Water Potability</a></li>
  <li><a href="#housing-in-california-2" id="toc-housing-in-california-2" class="nav-link" data-scroll-target="#housing-in-california-2"><span class="toc-section-number">13.4.1.3</span>  Housing in California</a></li>
  </ul></li>
  </ul></li>
  <li><a href="#sec-130.5" id="toc-sec-130.5" class="nav-link" data-scroll-target="#sec-130.5"><span class="toc-section-number">13.5</span>  Ejercicios</a></li>
  </ul>
</nav>
    </div>
<!-- main -->
<main class="content" id="quarto-document-content">

<header id="title-block-header" class="quarto-title-block default">
<div class="quarto-title">
<h1 class="title"><span id="sec-130" class="quarto-section-identifier d-none d-lg-block"><span class="chapter-number">13</span>&nbsp; <span class="chapter-title">Modelos de conjunto (Ensemble models)</span></span></h1>
</div>



<div class="quarto-title-meta">

    
  
    
  </div>
  

</header>

<p>Como ya se comentó en temas anteriores todos los modelos de aprendizaje automático sufren el problema de equilibrio entre sesgo y varianza. A medida que aumenta la complejidad de un modelo, este dispone de mayor flexibilidad para adaptarse a las observaciones, reduciendo así el sesgo y mejorando su capacidad predictiva. Sin embargo, alcanzado un determinado grado de flexibilidad, aparece el problema de sobreajuste, el modelo se ajusta tanto a los datos de entrenamiento que es incapaz de predecir correctamente nuevas observaciones.</p>
<p>Los métodos de modelos conjuntos (<em>Ensemble Models</em>) combinan múltiples modelos en uno nuevo con el objetivo de lograr un equilibro entre sesgo y varianza, tratando de obtener mejores predicciones o clasificaciones que cualquiera de los modelos individuales originales.</p>
<p>El principal reto no es obtener modelos individuales muy precisos y/o complejos, sino obtener modelos que cometan diferentes tipos de errores. Por ejemplo, si se utilizan conjuntos para la clasificación, se pueden conseguir altas precisiones si diferentes modelos base clasifican mal diferentes ejemplos de entrenamiento, incluso si la precisión del clasificador base es baja. De esta forma la combinación de todos los clasificadores nos acerca a la solución óptima.</p>
<p>En la práctica existen dos metodologías para la obtención de modelo de conjunto: <strong>Bagging</strong>, o método a partir de modelos individuales independientes, y <strong>Boosting</strong> o método a partir de modelos secuenciales.</p>
<p>En la metodología <strong><em>Bagging</em></strong> se ajustan múltiples modelos, cada uno con un subconjunto distinto de los datos de entrenamiento. En esta situación los modelos que forman el agregado participan aportando de forma individual su predicción o clasificación. Como valor final, se toma la media de todas las predicciones de los modelos individuales si estamos en un problema de regresión o la clase más frecuente del conjunto de soluciones aportadas por todos los clasificadores individuales. Los algoritmos más habituales dentro de este grupo son los de <strong>voto por mayoría</strong>, <strong>bosques aleatorios</strong>, y <strong>clasificadores <em>Bagging</em></strong>. A continuación se presenta una imagen de este proceso:</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="https://raw.githubusercontent.com/ia4legos/MachineLearning/main/images/bagging-1.png" width="550" height="400" class="figure-img"></p>
</figure>
</div>
<p>En este tema nos centramos en el estudio de los métodos de bagging, mientras que en el tema siguiente abordaremos los modelos de boosting.</p>
<section id="sec-130.1" class="level2" data-number="13.1">
<h2 data-number="13.1" class="anchored" data-anchor-id="sec-130.1"><span class="header-section-number">13.1</span> Modelos básicos Bagging</h2>
<p>El término <strong><em>bagging</em></strong> es el diminutivo de <em>bootstrap agregation</em> (<em>bootstrap</em> agregativo), y hace referencia al empleo del muestreo repetido con reposición <em>bootstrapping</em> con el fin de reducir la varianza de algunos modelos de aprendizaje estadístico haciendo uso del famoso resultado estadístico conocido como teorema central del límite.</p>
<p>Dicho teorema nos dice que si disponemos de n variables aleatorias independientes con varianza <span class="math inline">\(\sigma^2\)</span> para cada una de ellas, entonces la varianza de la media de todas ellas es <span class="math inline">\(\sigma^2/n\)</span>. En otras palabras, promediando un conjunto de observaciones se reduce la varianza.</p>
<p>Basándose en esta idea, una forma de reducir la varianza y aumentar la precisión de un método predictivo es obtener múltiples muestras de la población, ajustar un modelo distinto con cada una de ellas, y hacer la media (la moda en el caso de variables cualitativas) de las predicciones resultantes. Como en la práctica no se suele tener acceso a múltiples muestras, se puede simular el proceso recurriendo a la técnica de <em>bootstrap</em>, que genera pseudo-muestras a partir del conjunto de datos disponible mediante muestreo con reemplazamiento. Se ajusta entonces los diferentes modelos individuales propuestos a cada una de las pseudo-muestras y se agregan los resultados obtenidos en función de la variable objetivo considerada.</p>
<p>Los dos algoritmos de <em>bagging</em> más utilizados son el de <strong>voto por mayoría</strong> o <strong><em>bagging</em></strong> <strong>por lotes</strong>.</p>
<section id="sec-130.1.1" class="level3" data-number="13.1.1">
<h3 data-number="13.1.1" class="anchored" data-anchor-id="sec-130.1.1"><span class="header-section-number">13.1.1</span> Voto por mayoría</h3>
<p>El método de voto por mayoría es el más habitual dentro de los modelos de conjunto por agregación. Supongamos que ajustamos <span class="math inline">\(L\)</span> modelos de aprendizaje distintos sobre toda la muestra de entrenamiento para resolver un problema de clasificación o regresión. Obtenemos ahora la predicción para la muestra de test ( de tamaño <span class="math inline">\(m\)</span>) para cada uno de los <span class="math inline">\(L\)</span> modelos mediante:</p>
<ul>
<li>los valores predichos <span class="math inline">\(\hat{y}_1,\hat{y}_2,..., \hat{y}_m\)</span> si estamos en un problema de regresión, o</li>
<li>los valores de clasificación predichos <span class="math inline">\(\hat{c}_1,\hat{c}_2,..., \hat{c}_m\)</span> si nos enfrentamos a un problema de clasificación donde la variable respuesta puede tomar <span class="math inline">\(k\)</span> valores distintos.</li>
</ul>
<p>Para la construcción de la predicción para el modelo de conjunto se procede obteniendo:</p>
<ul>
<li>la media de los valores predichos en un problema de regresión</li>
</ul>
<p><span class="math display">\[\hat{y}_{ensemble} = \frac{\sum_{i=1}^m \hat{y}_i}{m},\]</span></p>
<ul>
<li>la moda de los valores de clasificación en un problema de clasificación</li>
</ul>
<p><span class="math display">\[\hat{c}_{ensemble} = \text{moda}\{\hat{c}_1,\hat{c}_2,..., \hat{c}_m\}.\]</span></p>
<p>En el problema de clasificación si los <span class="math inline">\(L\)</span> modelos considerados pueden estimar las probabilidades de cada clase tendremos una matriz estimada de probabilidades de dimensiones <span class="math inline">\(Lxk\)</span>,</p>
<span class="math display">\[\begin{equation}
\begin{pmatrix}
p_{1,1} &amp; p_{1,2} &amp;...&amp; p_{1,k}\\
p_{2,1} &amp; p_{2,2} &amp;...&amp; p_{2,k}\\
... &amp; ... &amp;...&amp; ...\\
p_{L-1,1} &amp; p_{L-1,2} &amp;...&amp; p_{L-1,k}\\
p_{L,1} &amp; p_{L,2} &amp;...&amp; p_{L,k}
\end{pmatrix}
\end{equation}\]</span>
<p>En esta situación tomamos como clase resultante la que proporcione un mayor valor promedio (por columnas) de las probabilidades obtenidas. Este procedimiento suele dar mejores resultados que el voto por mayoría estándar ya que nos permite tener en cuenta la variabilidad de las predicciones.</p>
</section>
<section id="sec-130.1.2" class="level3" data-number="13.1.2">
<h3 data-number="13.1.2" class="anchored" data-anchor-id="sec-130.1.2"><span class="header-section-number">13.1.2</span> Bagging por lotes</h3>
<p>En el <em>bagging</em> por lotes en lugar de entrenar diferentes algoritmos sobre el conjunto completo de datos de entrenamiento y promediar sus resultados como hace el voto por mayoría, este método entrena un único o múltiples clasificadores/regresores en diferentes subconjuntos o submuestras de los datos de entrenamiento y agrega los resultados en todos los subconjuntos de forma similar al voto por mayoría.</p>
<p>Este método de <em>bagging</em> por lotes resulta de gran utilidad para reducir el problema de sobreajuste cuando trabajamos con modelos complejos como los proporcionados por los árboles de decisión. Estos modelos basados en árboles son los que veremos más tarde bajo el nombre de <strong>bosques aleatorios</strong>.</p>
<p>Dada la naturaleza de construcción de los estimadores de <em>bagging</em> por lotes donde usamos submuestras con reemplazamiento resulta posible estimar el error de test sin necesidad de recurrir a métodos de validación cruzada. Las submuestras que son utilizadas sobre cada modelo de aprendizaje se conocen como “<em>in of bag</em>” mientras que las que no son utilizadas se conocen como “<em>out of bag</em>”. Estas últimas son utilizadas como si fuera una muestra de validación para valorar el error cometido dentro de cada uno de los modelos de aprendizaje que conforman el modelo conjunto. Definimos así el OOB error asociado con cada uno de los modelos individuales a partir de esa muestra. Dos limitaciones de este proceso son:</p>
<ul>
<li><p>El <em>Out-of-Bag Error</em> no es adecuado cuando las observaciones tienen una relación temporal (series temporales). Como la selección de las observaciones que participan en cada entrenamiento es aleatoria, no respetan el orden temporal y se estaría introduciendo información a futuro.</p></li>
<li><p>El preprocesado de los datos de entrenamiento se hace de forma conjunta, por lo que las observaciones <em>out-of-bag</em> pueden sufrir “<em>data leakage</em>”, es decir utilizan información de la muestra de entrenamiento para el ajuste del modelo. De ser así, las estimaciones del OOB-error son demasiado optimistas.</p></li>
</ul>
<p>En el método de <em>bagging</em> por lotes resulta necesario también establecer ciertos hiperparámetros asociados con la forma de selección de las submuestras, el proceso de reemplazamiento y los correspondientes al modelo de aprendizaje de cada submuestra. En la descripción de cada uno de esos algoritmos que veremos más adelante se presentarán las características propias de cada uno de ellos. Por el momento incluiremos los correspondientes a la selección de submuestras.</p>
</section>
</section>
<section id="sec-130.2" class="level2" data-number="13.2">
<h2 data-number="13.2" class="anchored" data-anchor-id="sec-130.2"><span class="header-section-number">13.2</span> Modelos básicos Bagging en mlr3</h2>
<p>Aunque la librería <code>mlr3</code> nos permite programar manualmente un algoritmo de bagging, lo habitual es utilizar los pipelines pre-construidos para bagging que están disponibles con <code>ppl("bagging")</code>. Para configurar estos pipelines debemos añadir como parámetros:</p>
<ul>
<li><p>El <code>learner</code> o <code>graphlearner</code> que utilizaremos en el proceso de bagging.</p></li>
<li><p>El número de iteraciones o repeticiones que usaremos durante el proceso de bagging, identificado con el parámetro <code>iterations</code>.</p></li>
<li><p>La proporción de muestras en el conjunto de entrenamiento, identificado con el parámetro <code>frac</code>.</p></li>
<li><p>El <code>PipeOp</code> que utilizamos para promediar los resultados, identificado con el parámetro <code>averager</code>. Las opciones por defecto son:</p>
<ul>
<li><code>po("classifavg", collect_multiplicity = TRUE))</code> para el voto por mayoría (problemas de clasificación) guardando las predicciones individuales de cada modelo.</li>
<li><code>po("regravg", collect_multiplicity = TRUE))</code> para el valor promedio de todos los modleos (problemas de regresión) guardando las predicciones individuales de cada modelo.</li>
</ul></li>
</ul>
<p>El resultado de esta función es un <code>graphlearner</code> con los métodos asociados habituales.</p>
<p>Antes de presentar los bancos de datos que utilizaremos para mostrar el uso de los modelos de bagging más básicos, cargamos todas las librerías necesarias.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb1"><pre class="sourceCode numberSource r number-lines code-with-copy"><code class="sourceCode r"><span id="cb1-1"><a href="#cb1-1"></a><span class="co"># Paquetes anteriores</span></span>
<span id="cb1-2"><a href="#cb1-2"></a><span class="fu">library</span>(tidyverse)</span>
<span id="cb1-3"><a href="#cb1-3"></a><span class="fu">library</span>(sjPlot)</span>
<span id="cb1-4"><a href="#cb1-4"></a><span class="fu">library</span>(knitr) <span class="co"># para formatos de tablas</span></span>
<span id="cb1-5"><a href="#cb1-5"></a><span class="fu">library</span>(skimr)</span>
<span id="cb1-6"><a href="#cb1-6"></a><span class="fu">library</span>(DataExplorer)</span>
<span id="cb1-7"><a href="#cb1-7"></a><span class="fu">library</span>(GGally)</span>
<span id="cb1-8"><a href="#cb1-8"></a><span class="fu">library</span>(gridExtra)</span>
<span id="cb1-9"><a href="#cb1-9"></a><span class="fu">library</span>(ggpubr)</span>
<span id="cb1-10"><a href="#cb1-10"></a><span class="fu">library</span>(cvms)</span>
<span id="cb1-11"><a href="#cb1-11"></a><span class="fu">library</span>(kknn)</span>
<span id="cb1-12"><a href="#cb1-12"></a><span class="fu">library</span>(rpart.plot)</span>
<span id="cb1-13"><a href="#cb1-13"></a><span class="fu">theme_set</span>(<span class="fu">theme_sjplot2</span>())</span>
<span id="cb1-14"><a href="#cb1-14"></a></span>
<span id="cb1-15"><a href="#cb1-15"></a><span class="co"># Paquetes AA</span></span>
<span id="cb1-16"><a href="#cb1-16"></a><span class="fu">library</span>(mlr3verse)</span>
<span id="cb1-17"><a href="#cb1-17"></a><span class="fu">library</span>(mlr3tuning)</span>
<span id="cb1-18"><a href="#cb1-18"></a><span class="fu">library</span>(mlr3tuningspaces)</span></code><button title="Copiar al portapapeles" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<section id="sec-130.2.1" class="level3" data-number="13.2.1">
<h3 data-number="13.2.1" class="anchored" data-anchor-id="sec-130.2.1"><span class="header-section-number">13.2.1</span> Bancos de datos</h3>
<p>Para ejemplificar el uso de los modelos de bagging básicos vamos a utilizar tres bancos de datos: <code>Stroke</code>, <code>Water Potability</code>, y <code>Housing in California</code> que se pueden consultar en el tema <a href="40_DataBases.html"><span>4</span></a>. De los tres con el único con el que no hemos trabajado hasta ahora es <code>Water Potability</code>. A continuación se muestra el código necesario para la carga de cada uno de esos bancos de datos, y la creación de la tarea correspondiente. Los dos primeros corresponden a problemas de clasificación mientras que el último se corresponde con un problema de regresión.</p>
<section id="stroke" class="level4" data-number="13.2.1.1">
<h4 data-number="13.2.1.1" class="anchored" data-anchor-id="stroke"><span class="header-section-number">13.2.1.1</span> Stroke</h4>
<p>El código para este banco de datos es:</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb2"><pre class="sourceCode numberSource r number-lines code-with-copy"><code class="sourceCode r"><span id="cb2-1"><a href="#cb2-1"></a><span class="co"># Leemos datos</span></span>
<span id="cb2-2"><a href="#cb2-2"></a>stroke <span class="ot">=</span> <span class="fu">read_rds</span>(<span class="st">"stroke.rds"</span>)</span>
<span id="cb2-3"><a href="#cb2-3"></a><span class="co"># Eliminamos la variable id</span></span>
<span id="cb2-4"><a href="#cb2-4"></a>stroke <span class="ot">=</span> stroke <span class="sc">%&gt;%</span> dplyr<span class="sc">::</span><span class="fu">select</span>(<span class="sc">-</span>id)</span>
<span id="cb2-5"><a href="#cb2-5"></a><span class="co"># creamos la tarea</span></span>
<span id="cb2-6"><a href="#cb2-6"></a>tsk_stroke <span class="ot">=</span> <span class="fu">as_task_classif</span>(stroke, <span class="at">target =</span> <span class="st">"stroke"</span>)</span>
<span id="cb2-7"><a href="#cb2-7"></a><span class="co"># Generamos variable de estrato</span></span>
<span id="cb2-8"><a href="#cb2-8"></a>tsk_stroke<span class="sc">$</span>col_roles<span class="sc">$</span>stratum <span class="ot">&lt;-</span> <span class="st">"stroke"</span></span></code><button title="Copiar al portapapeles" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
</section>
<section id="water-potability" class="level4" data-number="13.2.1.2">
<h4 data-number="13.2.1.2" class="anchored" data-anchor-id="water-potability"><span class="header-section-number">13.2.1.2</span> Water Potability</h4>
<p>El agua potable es el derecho humano más básico y un factor importante para la salud. El conjunto de datos Water potability, tiene por objetivo estudiar la potabilidad del agua utilizando varias propiedades químicas debido a su importancia como cuestión de salud y desarrollo a nivel nacional, regional y local. En algunas regiones, se ha demostrado que las inversiones en abastecimiento de agua y saneamiento pueden producir un beneficio económico neto, ya que la reducción de los efectos adversos para la salud y los costes de la atención sanitaria superan los costes de las intervenciones. EL target de interés <code>potability</code> indica si la muestra de agua es potable o no en función de: <code>pH</code>, <code>Hardness</code>, <code>Solids</code>, <code>Chloramines</code>, <code>Sulfate</code>, <code>Conductivity</code>, <code>Organic_carbon</code>, <code>Trihalomethanes</code>, y <code>Turbidity</code>. Este banco de datos contiene valores perdidos en diferentes variables.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb3"><pre class="sourceCode numberSource r number-lines code-with-copy"><code class="sourceCode r"><span id="cb3-1"><a href="#cb3-1"></a><span class="co"># Leemos datos</span></span>
<span id="cb3-2"><a href="#cb3-2"></a>waterpot <span class="ot">=</span> <span class="fu">read_rds</span>(<span class="st">"waterpot.rds"</span>)</span>
<span id="cb3-3"><a href="#cb3-3"></a><span class="co"># creamos la tarea</span></span>
<span id="cb3-4"><a href="#cb3-4"></a>tsk_water <span class="ot">=</span> <span class="fu">as_task_classif</span>(waterpot, <span class="at">target =</span> <span class="st">"Potability"</span>)</span>
<span id="cb3-5"><a href="#cb3-5"></a><span class="co"># Generamos variable de estrato</span></span>
<span id="cb3-6"><a href="#cb3-6"></a>tsk_water<span class="sc">$</span>col_roles<span class="sc">$</span>stratum <span class="ot">&lt;-</span> <span class="st">"Potability"</span></span></code><button title="Copiar al portapapeles" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>Valoramos la presencia de missings</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb4"><pre class="sourceCode numberSource r number-lines code-with-copy"><code class="sourceCode r"><span id="cb4-1"><a href="#cb4-1"></a>tsk_water<span class="sc">$</span><span class="fu">missings</span>()</span></code><button title="Copiar al portapapeles" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>     Potability     Chloramines    Conductivity        Hardness  Organic_carbon 
              0               0               0               0               0 
         Solids         Sulfate Trihalomethanes       Turbidity              ph 
              0             781             162               0             491 </code></pre>
</div>
</div>
<p>Aparecen valores perdidos en tres de las posibles predictoras. Representamos los datos:</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb6"><pre class="sourceCode numberSource r number-lines code-with-copy"><code class="sourceCode r"><span id="cb6-1"><a href="#cb6-1"></a><span class="fu">autoplot</span>(tsk_water, <span class="at">type =</span> <span class="st">"pairs"</span>)</span></code><button title="Copiar al portapapeles" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output-display">
<p><img src="130_Ensemblemodels_files/figure-html/bgg-005-1.png" class="img-fluid" width="1344"></p>
</div>
</div>
</section>
<section id="housing-in-california" class="level4" data-number="13.2.1.3">
<h4 data-number="13.2.1.3" class="anchored" data-anchor-id="housing-in-california"><span class="header-section-number">13.2.1.3</span> Housing in California</h4>
<p>Cargamos los datos correspondientes:</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb7"><pre class="sourceCode numberSource r number-lines code-with-copy"><code class="sourceCode r"><span id="cb7-1"><a href="#cb7-1"></a><span class="co"># Carga de datos</span></span>
<span id="cb7-2"><a href="#cb7-2"></a>housingCA <span class="ot">=</span> <span class="fu">read_rds</span>(<span class="st">"housingCA.rds"</span>)</span>
<span id="cb7-3"><a href="#cb7-3"></a><span class="co"># Creación de task</span></span>
<span id="cb7-4"><a href="#cb7-4"></a>tsk_housing <span class="ot">=</span> <span class="fu">as_task_regr</span>(housingCA, <span class="at">target =</span> <span class="st">"median_house_value"</span>)</span></code><button title="Copiar al portapapeles" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
</section>
</section>
<section id="sec-130.2.2" class="level3" data-number="13.2.2">
<h3 data-number="13.2.2" class="anchored" data-anchor-id="sec-130.2.2"><span class="header-section-number">13.2.2</span> Modelos</h3>
<p>Elaboramos nuestros primeros modelos de bagging para los diferentes bancos de datos. Utilizamos el voto por mayoría y el promedio de predicciones para resolver las tareas de clasificación y regresión.</p>
<section id="stroke-1" class="level4" data-number="13.2.2.1">
<h4 data-number="13.2.2.1" class="anchored" data-anchor-id="stroke-1"><span class="header-section-number">13.2.2.1</span> Stroke</h4>
<p>Para el proceso de bagging hemos de definir en primer caso el algoritmo de aprendizaje asociado. Utilizamos como base los modelos de árboles de decisión vistos en el tema anterior.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb8"><pre class="sourceCode numberSource r number-lines code-with-copy"><code class="sourceCode r"><span id="cb8-1"><a href="#cb8-1"></a><span class="co"># Preprocesamiento</span></span>
<span id="cb8-2"><a href="#cb8-2"></a>pp_stroke <span class="ot">=</span>  <span class="fu">po</span>(<span class="st">"imputemedian"</span>, <span class="at">affect_columns =</span> <span class="fu">selector_type</span>(<span class="st">"numeric"</span>))</span>
<span id="cb8-3"><a href="#cb8-3"></a><span class="co"># Modelo de aprendizaje combinando preprocesado y algoritmo</span></span>
<span id="cb8-4"><a href="#cb8-4"></a>dt_classif_stroke <span class="ot">=</span> <span class="fu">as_learner</span>(pp_stroke <span class="sc">%&gt;&gt;%</span> </span>
<span id="cb8-5"><a href="#cb8-5"></a>                                  <span class="fu">lrn</span>(<span class="st">"classif.rpart"</span>, <span class="at">keep_model =</span> <span class="cn">TRUE</span>, <span class="at">predict_type =</span> <span class="st">"prob"</span>, </span>
<span id="cb8-6"><a href="#cb8-6"></a>                                      <span class="at">cp =</span> <span class="fl">0.0003562633</span>,</span>
<span id="cb8-7"><a href="#cb8-7"></a>                                      <span class="at">minsplit =</span> <span class="dv">10</span>, </span>
<span id="cb8-8"><a href="#cb8-8"></a>                                      <span class="at">maxdepth =</span> <span class="dv">6</span>))</span>
<span id="cb8-9"><a href="#cb8-9"></a>dt_classif_stroke<span class="sc">$</span>id <span class="ot">=</span> <span class="st">"TreeDecision"</span></span></code><button title="Copiar al portapapeles" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>Definimos ahora el grpahlearner asociado con el proceso de bagging utilizando la función <code>ppl</code> y comparamos con el resultado de un único árbol de decisión. Realizamos un proceso de validación cruzada con cinco repeticiones para obtener resultados más estables:</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb9"><pre class="sourceCode numberSource r number-lines code-with-copy"><code class="sourceCode r"><span id="cb9-1"><a href="#cb9-1"></a><span class="fu">set.seed</span>(<span class="dv">345</span>)</span>
<span id="cb9-2"><a href="#cb9-2"></a><span class="co"># Graphleaner para bagging</span></span>
<span id="cb9-3"><a href="#cb9-3"></a>bgg_stroke <span class="ot">=</span> <span class="fu">ppl</span>(<span class="st">"bagging"</span>, dt_classif_stroke,</span>
<span id="cb9-4"><a href="#cb9-4"></a>  <span class="at">iterations =</span> <span class="dv">10</span>, <span class="at">frac =</span> <span class="fl">0.8</span>, <span class="at">averager =</span> <span class="fu">po</span>(<span class="st">"classifavg"</span>, <span class="at">collect_multiplicity =</span> <span class="cn">TRUE</span>))</span>
<span id="cb9-5"><a href="#cb9-5"></a>bgg_stroke <span class="ot">=</span> <span class="fu">as_learner</span>(bgg_stroke)</span>
<span id="cb9-6"><a href="#cb9-6"></a>bgg_stroke<span class="sc">$</span>id <span class="ot">=</span> <span class="st">"Bagging"</span></span>
<span id="cb9-7"><a href="#cb9-7"></a><span class="co"># Comparación de modelos simple y ponderado</span></span>
<span id="cb9-8"><a href="#cb9-8"></a>learners <span class="ot">=</span> <span class="fu">c</span>(dt_classif_stroke, bgg_stroke)</span>
<span id="cb9-9"><a href="#cb9-9"></a>bmr <span class="ot">=</span> <span class="fu">benchmark</span>(<span class="fu">benchmark_grid</span>(tsk_stroke, learners,</span>
<span id="cb9-10"><a href="#cb9-10"></a>  <span class="fu">rsmp</span>(<span class="st">"cv"</span>, <span class="at">folds =</span> <span class="dv">5</span>)))</span></code><button title="Copiar al portapapeles" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>INFO  [18:09:30.192] [mlr3] Running benchmark with 10 resampling iterations
INFO  [18:09:30.338] [mlr3] Applying learner 'TreeDecision' on task 'stroke' (iter 1/5)
INFO  [18:09:30.547] [mlr3] Applying learner 'TreeDecision' on task 'stroke' (iter 2/5)
INFO  [18:09:31.158] [mlr3] Applying learner 'TreeDecision' on task 'stroke' (iter 3/5)
INFO  [18:09:31.461] [mlr3] Applying learner 'TreeDecision' on task 'stroke' (iter 4/5)
INFO  [18:09:31.708] [mlr3] Applying learner 'TreeDecision' on task 'stroke' (iter 5/5)
INFO  [18:09:31.940] [mlr3] Applying learner 'Bagging' on task 'stroke' (iter 1/5)
INFO  [18:09:35.013] [mlr3] Applying learner 'Bagging' on task 'stroke' (iter 2/5)
INFO  [18:09:37.522] [mlr3] Applying learner 'Bagging' on task 'stroke' (iter 3/5)
INFO  [18:09:39.906] [mlr3] Applying learner 'Bagging' on task 'stroke' (iter 4/5)
INFO  [18:09:42.508] [mlr3] Applying learner 'Bagging' on task 'stroke' (iter 5/5)
INFO  [18:09:44.880] [mlr3] Finished benchmark</code></pre>
</div>
<div class="sourceCode cell-code" id="cb11"><pre class="sourceCode numberSource r number-lines code-with-copy"><code class="sourceCode r"><span id="cb11-1"><a href="#cb11-1"></a><span class="co"># Resultados individuales</span></span>
<span id="cb11-2"><a href="#cb11-2"></a>bmr<span class="sc">$</span><span class="fu">score</span>(<span class="fu">msr</span>(<span class="st">"classif.bacc"</span>))</span></code><button title="Copiar al portapapeles" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>    nr task_id   learner_id resampling_id iteration classif.bacc
 1:  1  stroke TreeDecision            cv         1    0.4989723
 2:  1  stroke TreeDecision            cv         2    0.5069136
 3:  1  stroke TreeDecision            cv         3    0.5158848
 4:  1  stroke TreeDecision            cv         4    0.5448560
 5:  1  stroke TreeDecision            cv         5    0.5091753
 6:  2  stroke      Bagging            cv         1    0.4994861
 7:  2  stroke      Bagging            cv         2    0.5079424
 8:  2  stroke      Bagging            cv         3    0.5000000
 9:  2  stroke      Bagging            cv         4    0.4994856
10:  2  stroke      Bagging            cv         5    0.4994856
Hidden columns: uhash, task, learner, resampling, prediction</code></pre>
</div>
<div class="sourceCode cell-code" id="cb13"><pre class="sourceCode numberSource r number-lines code-with-copy"><code class="sourceCode r"><span id="cb13-1"><a href="#cb13-1"></a><span class="co"># Resultados agregados</span></span>
<span id="cb13-2"><a href="#cb13-2"></a>bmr<span class="sc">$</span><span class="fu">aggregate</span>(<span class="fu">msr</span>(<span class="st">"classif.bacc"</span>))</span></code><button title="Copiar al portapapeles" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>   nr task_id   learner_id resampling_id iters classif.bacc
1:  1  stroke TreeDecision            cv     5    0.5151604
2:  2  stroke      Bagging            cv     5    0.5012799
Hidden columns: resample_result</code></pre>
</div>
</div>
<p>Como se puede ver en los resultados obtenidos el modelo de conjunto proporciona casi los mismo resultados que el modelo individual. En este caso la ponderación no mejora ya que el modelo individual también era bastante malo. Veamos gráficamente al comparación entre lo scores del modelo basal y del ponderado.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb15"><pre class="sourceCode numberSource r number-lines code-with-copy"><code class="sourceCode r"><span id="cb15-1"><a href="#cb15-1"></a><span class="fu">autoplot</span>(bmr, <span class="at">measure =</span> <span class="fu">msr</span>(<span class="st">"classif.bacc"</span>))</span></code><button title="Copiar al portapapeles" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output-display">
<p><img src="130_Ensemblemodels_files/figure-html/bgg-009-1.png" class="img-fluid" width="672"></p>
</div>
</div>
<p>Podemos obtener los resultados del modelo bagging de forma similar a otros modelos de aprendizaje automático:</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb16"><pre class="sourceCode numberSource r number-lines code-with-copy"><code class="sourceCode r"><span id="cb16-1"><a href="#cb16-1"></a><span class="co"># Entrenamos el modelo</span></span>
<span id="cb16-2"><a href="#cb16-2"></a>bgg_stroke<span class="sc">$</span><span class="fu">train</span>(tsk_stroke)</span>
<span id="cb16-3"><a href="#cb16-3"></a><span class="co"># Construimos la predicción</span></span>
<span id="cb16-4"><a href="#cb16-4"></a>pred <span class="ot">=</span> bgg_stroke<span class="sc">$</span><span class="fu">predict</span>(tsk_stroke)</span>
<span id="cb16-5"><a href="#cb16-5"></a>pred</span></code><button title="Copiar al portapapeles" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>&lt;PredictionClassif&gt; for 5110 observations:
    row_ids truth response   prob.No    prob.Yes
          1   Yes       No 0.7080569 0.291943082
          2   Yes       No 0.8683200 0.131680027
          3   Yes       No 0.8566943 0.143305654
---                                             
       5108    No       No 0.9924404 0.007559553
       5109    No       No 0.9187222 0.081277750
       5110    No       No 0.9924404 0.007559553</code></pre>
</div>
</div>
<p>Evaluamos la matriz de confusión:</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb18"><pre class="sourceCode numberSource r number-lines code-with-copy"><code class="sourceCode r"><span id="cb18-1"><a href="#cb18-1"></a>cm <span class="ot">=</span> <span class="fu">confusion_matrix</span>(pred<span class="sc">$</span>truth, pred<span class="sc">$</span>response)</span>
<span id="cb18-2"><a href="#cb18-2"></a><span class="fu">plot_confusion_matrix</span>(cm<span class="sc">$</span><span class="st">`</span><span class="at">Confusion Matrix</span><span class="st">`</span>[[<span class="dv">1</span>]]) </span></code><button title="Copiar al portapapeles" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output-display">
<p><img src="130_Ensemblemodels_files/figure-html/bgg-011-1.png" class="img-fluid" width="672"></p>
</div>
</div>
</section>
<section id="water-potability-1" class="level4" data-number="13.2.2.2">
<h4 data-number="13.2.2.2" class="anchored" data-anchor-id="water-potability-1"><span class="header-section-number">13.2.2.2</span> Water Potability</h4>
<p>En este caso vamos a utilizar como modelo base de aprendizaje un modelo de regresión logística donde estamos interesados en conocer la probabilidad de que una muestra se clasifique como agua potable en función de las predictoras consideradas. Dado que todas las predictoras son numéricas (y relacionadas entre si como hemos visto en la interpretación gráfica de los datos) y algunas contienen valores perdidos consideramos un modelo penalizado (en este caso elastic net con peso igual a 0.5) y el correspondiente preprocesado. En primer lugar generamos la tarea de nuevo identificando la categoría de interés:</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb19"><pre class="sourceCode numberSource r number-lines code-with-copy"><code class="sourceCode r"><span id="cb19-1"><a href="#cb19-1"></a><span class="co"># creamos la tarea</span></span>
<span id="cb19-2"><a href="#cb19-2"></a>tsk_water <span class="ot">=</span> <span class="fu">as_task_classif</span>(waterpot, <span class="at">target =</span> <span class="st">"Potability"</span>, <span class="at">positive =</span> <span class="st">"1"</span>)</span>
<span id="cb19-3"><a href="#cb19-3"></a><span class="co"># Generamos variable de estrato</span></span>
<span id="cb19-4"><a href="#cb19-4"></a>tsk_water<span class="sc">$</span>col_roles<span class="sc">$</span>stratum <span class="ot">&lt;-</span> <span class="st">"Potability"</span></span></code><button title="Copiar al portapapeles" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div class="cell">
<div class="sourceCode cell-code" id="cb20"><pre class="sourceCode numberSource r number-lines code-with-copy"><code class="sourceCode r"><span id="cb20-1"><a href="#cb20-1"></a><span class="co"># Preprocesado</span></span>
<span id="cb20-2"><a href="#cb20-2"></a>pp_water <span class="ot">=</span> <span class="fu">po</span>(<span class="st">"imputemedian"</span>, <span class="at">affect_columns =</span> <span class="fu">selector_type</span>(<span class="st">"numeric"</span>)) <span class="sc">%&gt;&gt;%</span> </span>
<span id="cb20-3"><a href="#cb20-3"></a>  <span class="fu">po</span>(<span class="st">"scale"</span>, <span class="at">param_vals =</span> <span class="fu">list</span>(<span class="at">center =</span> <span class="cn">TRUE</span>, <span class="at">scale =</span> <span class="cn">TRUE</span>)) </span>
<span id="cb20-4"><a href="#cb20-4"></a><span class="co"># Definimos learner basal</span></span>
<span id="cb20-5"><a href="#cb20-5"></a>learner <span class="ot">=</span> <span class="fu">lrn</span>(<span class="st">"classif.cv_glmnet"</span>, <span class="at">type.logistic =</span> <span class="st">"Newton"</span>, <span class="at">standardize =</span> <span class="cn">FALSE</span>,</span>
<span id="cb20-6"><a href="#cb20-6"></a>              <span class="at">alpha =</span> <span class="fl">0.5</span>, <span class="at">predict_type =</span> <span class="st">"prob"</span>)</span>
<span id="cb20-7"><a href="#cb20-7"></a><span class="co"># Graphlearner: Preprocesado y learner</span></span>
<span id="cb20-8"><a href="#cb20-8"></a>logm_classif_water <span class="ot">=</span> <span class="fu">as_learner</span>(pp_water <span class="sc">%&gt;&gt;%</span> learner)</span>
<span id="cb20-9"><a href="#cb20-9"></a>logm_classif_water<span class="sc">$</span>id <span class="ot">=</span> <span class="st">"LogisticReg"</span></span></code><button title="Copiar al portapapeles" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>Construíos el modelo de bagging y vemos los resultados obtenidos:</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb21"><pre class="sourceCode numberSource r number-lines code-with-copy"><code class="sourceCode r"><span id="cb21-1"><a href="#cb21-1"></a><span class="fu">set.seed</span>(<span class="dv">345</span>)</span>
<span id="cb21-2"><a href="#cb21-2"></a><span class="co"># Graphleaner para bagging</span></span>
<span id="cb21-3"><a href="#cb21-3"></a>bgg_water <span class="ot">=</span> <span class="fu">ppl</span>(<span class="st">"bagging"</span>, logm_classif_water,</span>
<span id="cb21-4"><a href="#cb21-4"></a>  <span class="at">iterations =</span> <span class="dv">10</span>, <span class="at">frac =</span> <span class="fl">0.8</span>, <span class="at">averager =</span> <span class="fu">po</span>(<span class="st">"classifavg"</span>, <span class="at">collect_multiplicity =</span> <span class="cn">TRUE</span>))</span>
<span id="cb21-5"><a href="#cb21-5"></a>bgg_water <span class="ot">=</span> <span class="fu">as_learner</span>(bgg_water)</span>
<span id="cb21-6"><a href="#cb21-6"></a>bgg_water<span class="sc">$</span>id <span class="ot">=</span> <span class="st">"Bagging"</span></span>
<span id="cb21-7"><a href="#cb21-7"></a><span class="co"># Comparación de modelos simple y ponderado</span></span>
<span id="cb21-8"><a href="#cb21-8"></a>learners <span class="ot">=</span> <span class="fu">c</span>(logm_classif_water, bgg_water)</span>
<span id="cb21-9"><a href="#cb21-9"></a>bmr <span class="ot">=</span> <span class="fu">benchmark</span>(<span class="fu">benchmark_grid</span>(tsk_water, learners,</span>
<span id="cb21-10"><a href="#cb21-10"></a>  <span class="fu">rsmp</span>(<span class="st">"cv"</span>, <span class="at">folds =</span> <span class="dv">5</span>)))</span></code><button title="Copiar al portapapeles" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>INFO  [18:09:49.843] [mlr3] Running benchmark with 10 resampling iterations
INFO  [18:09:49.851] [mlr3] Applying learner 'LogisticReg' on task 'waterpot' (iter 1/5)
INFO  [18:09:50.402] [mlr3] Applying learner 'LogisticReg' on task 'waterpot' (iter 2/5)
INFO  [18:09:50.853] [mlr3] Applying learner 'LogisticReg' on task 'waterpot' (iter 3/5)
INFO  [18:09:51.304] [mlr3] Applying learner 'LogisticReg' on task 'waterpot' (iter 4/5)
INFO  [18:09:51.976] [mlr3] Applying learner 'LogisticReg' on task 'waterpot' (iter 5/5)
INFO  [18:09:52.555] [mlr3] Applying learner 'Bagging' on task 'waterpot' (iter 1/5)
INFO  [18:09:56.946] [mlr3] Applying learner 'Bagging' on task 'waterpot' (iter 2/5)
INFO  [18:10:02.478] [mlr3] Applying learner 'Bagging' on task 'waterpot' (iter 3/5)
INFO  [18:10:08.481] [mlr3] Applying learner 'Bagging' on task 'waterpot' (iter 4/5)
INFO  [18:10:13.913] [mlr3] Applying learner 'Bagging' on task 'waterpot' (iter 5/5)
INFO  [18:10:18.298] [mlr3] Finished benchmark</code></pre>
</div>
<div class="sourceCode cell-code" id="cb23"><pre class="sourceCode numberSource r number-lines code-with-copy"><code class="sourceCode r"><span id="cb23-1"><a href="#cb23-1"></a><span class="co"># Resultados individuales</span></span>
<span id="cb23-2"><a href="#cb23-2"></a>bmr<span class="sc">$</span><span class="fu">score</span>(<span class="fu">msr</span>(<span class="st">"classif.bacc"</span>))</span></code><button title="Copiar al portapapeles" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>    nr  task_id  learner_id resampling_id iteration classif.bacc
 1:  1 waterpot LogisticReg            cv         1          0.5
 2:  1 waterpot LogisticReg            cv         2          0.5
 3:  1 waterpot LogisticReg            cv         3          0.5
 4:  1 waterpot LogisticReg            cv         4          0.5
 5:  1 waterpot LogisticReg            cv         5          0.5
 6:  2 waterpot     Bagging            cv         1          0.5
 7:  2 waterpot     Bagging            cv         2          0.5
 8:  2 waterpot     Bagging            cv         3          0.5
 9:  2 waterpot     Bagging            cv         4          0.5
10:  2 waterpot     Bagging            cv         5          0.5
Hidden columns: uhash, task, learner, resampling, prediction</code></pre>
</div>
<div class="sourceCode cell-code" id="cb25"><pre class="sourceCode numberSource r number-lines code-with-copy"><code class="sourceCode r"><span id="cb25-1"><a href="#cb25-1"></a><span class="co"># Resultados agregados</span></span>
<span id="cb25-2"><a href="#cb25-2"></a>bmr<span class="sc">$</span><span class="fu">aggregate</span>(<span class="fu">msr</span>(<span class="st">"classif.bacc"</span>))</span></code><button title="Copiar al portapapeles" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>   nr  task_id  learner_id resampling_id iters classif.bacc
1:  1 waterpot LogisticReg            cv     5          0.5
2:  2 waterpot     Bagging            cv     5          0.5
Hidden columns: resample_result</code></pre>
</div>
</div>
<p>Podemos ver que el comportamiento con ambas modelizaciones nos proporciona el mismo resultado. La solución es bastante estable aunque bastante deficiente. Analizamos con detalle el modelo bagging que hemos construido:</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb27"><pre class="sourceCode numberSource r number-lines code-with-copy"><code class="sourceCode r"><span id="cb27-1"><a href="#cb27-1"></a><span class="co"># Entrenamos el modelo</span></span>
<span id="cb27-2"><a href="#cb27-2"></a>bgg_water<span class="sc">$</span><span class="fu">train</span>(tsk_water)</span>
<span id="cb27-3"><a href="#cb27-3"></a><span class="co"># Construimos la predicción</span></span>
<span id="cb27-4"><a href="#cb27-4"></a>pred <span class="ot">=</span> bgg_water<span class="sc">$</span><span class="fu">predict</span>(tsk_water)</span>
<span id="cb27-5"><a href="#cb27-5"></a><span class="co"># matriz de confusión</span></span>
<span id="cb27-6"><a href="#cb27-6"></a>cm <span class="ot">=</span> <span class="fu">confusion_matrix</span>(pred<span class="sc">$</span>truth, pred<span class="sc">$</span>response)</span>
<span id="cb27-7"><a href="#cb27-7"></a><span class="fu">plot_confusion_matrix</span>(cm<span class="sc">$</span><span class="st">`</span><span class="at">Confusion Matrix</span><span class="st">`</span>[[<span class="dv">1</span>]]) </span></code><button title="Copiar al portapapeles" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output-display">
<p><img src="130_Ensemblemodels_files/figure-html/bgg-015-1.png" class="img-fluid" width="672"></p>
</div>
</div>
<p>Se ve claramente el mal funcionamiento del modelo ya que clasifica todas las muestras como no potable, a pesar de que el número de muestras que originalmente eran potables es bastante elevado.</p>
</section>
<section id="housing-in-california-1" class="level4" data-number="13.2.2.3">
<h4 data-number="13.2.2.3" class="anchored" data-anchor-id="housing-in-california-1"><span class="header-section-number">13.2.2.3</span> Housing in California</h4>
<p>En este caso nos enfrentamos a un problema de regresión, pero en lugar de utilizar un modelo lineal como modelo basal vamos a utilizar un árbol de decisión con las configuraciones por defecto. En primer lugar configuramos el modelo basal.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb28"><pre class="sourceCode numberSource r number-lines code-with-copy"><code class="sourceCode r"><span id="cb28-1"><a href="#cb28-1"></a><span class="co"># Preprocesamiento</span></span>
<span id="cb28-2"><a href="#cb28-2"></a>pp_housing <span class="ot">=</span> </span>
<span id="cb28-3"><a href="#cb28-3"></a>   <span class="fu">po</span>(<span class="st">"scale"</span>, <span class="at">param_vals =</span> <span class="fu">list</span>(<span class="at">center =</span> <span class="cn">TRUE</span>, <span class="at">scale =</span> <span class="cn">TRUE</span>)) <span class="sc">%&gt;&gt;%</span></span>
<span id="cb28-4"><a href="#cb28-4"></a>   <span class="fu">po</span>(<span class="st">"imputemedian"</span>, <span class="at">affect_columns =</span> <span class="fu">selector_type</span>(<span class="st">"numeric"</span>)) </span>
<span id="cb28-5"><a href="#cb28-5"></a><span class="co"># Modelo de aprendizaje combinando preprocesado y algoritmo</span></span>
<span id="cb28-6"><a href="#cb28-6"></a>dt_regr_housing <span class="ot">=</span> <span class="fu">as_learner</span>(pp_housing <span class="sc">%&gt;&gt;%</span> </span>
<span id="cb28-7"><a href="#cb28-7"></a>                                  <span class="fu">lrn</span>(<span class="st">"regr.rpart"</span>, <span class="at">keep_model =</span> <span class="cn">TRUE</span>))</span>
<span id="cb28-8"><a href="#cb28-8"></a>dt_regr_housing<span class="sc">$</span>id <span class="ot">=</span> <span class="st">"TreeDecision"</span></span></code><button title="Copiar al portapapeles" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>Establecemos ahora el modelo bagging</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb29"><pre class="sourceCode numberSource r number-lines code-with-copy"><code class="sourceCode r"><span id="cb29-1"><a href="#cb29-1"></a><span class="fu">set.seed</span>(<span class="dv">345</span>)</span>
<span id="cb29-2"><a href="#cb29-2"></a><span class="co"># Graphleaner para bagging</span></span>
<span id="cb29-3"><a href="#cb29-3"></a>bgg_housing <span class="ot">=</span> <span class="fu">ppl</span>(<span class="st">"bagging"</span>, dt_regr_housing,</span>
<span id="cb29-4"><a href="#cb29-4"></a>  <span class="at">iterations =</span> <span class="dv">10</span>, <span class="at">frac =</span> <span class="fl">0.8</span>, <span class="at">averager =</span> <span class="fu">po</span>(<span class="st">"regravg"</span>, <span class="at">collect_multiplicity =</span> <span class="cn">TRUE</span>))</span>
<span id="cb29-5"><a href="#cb29-5"></a>bgg_housing <span class="ot">=</span> <span class="fu">as_learner</span>(bgg_housing)</span>
<span id="cb29-6"><a href="#cb29-6"></a>bgg_housing<span class="sc">$</span>id <span class="ot">=</span> <span class="st">"Bagging"</span></span>
<span id="cb29-7"><a href="#cb29-7"></a><span class="co"># Comparación de modelos simple y ponderado</span></span>
<span id="cb29-8"><a href="#cb29-8"></a>learners <span class="ot">=</span> <span class="fu">c</span>(dt_regr_housing, bgg_housing)</span>
<span id="cb29-9"><a href="#cb29-9"></a>bmr <span class="ot">=</span> <span class="fu">benchmark</span>(<span class="fu">benchmark_grid</span>(tsk_housing, learners,</span>
<span id="cb29-10"><a href="#cb29-10"></a>  <span class="fu">rsmp</span>(<span class="st">"cv"</span>, <span class="at">folds =</span> <span class="dv">5</span>)))</span></code><button title="Copiar al portapapeles" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>INFO  [18:10:24.037] [mlr3] Running benchmark with 10 resampling iterations
INFO  [18:10:24.044] [mlr3] Applying learner 'TreeDecision' on task 'housingCA' (iter 1/5)
INFO  [18:10:24.402] [mlr3] Applying learner 'TreeDecision' on task 'housingCA' (iter 2/5)
INFO  [18:10:24.775] [mlr3] Applying learner 'TreeDecision' on task 'housingCA' (iter 3/5)
INFO  [18:10:25.157] [mlr3] Applying learner 'TreeDecision' on task 'housingCA' (iter 4/5)
INFO  [18:10:25.603] [mlr3] Applying learner 'TreeDecision' on task 'housingCA' (iter 5/5)
INFO  [18:10:26.009] [mlr3] Applying learner 'Bagging' on task 'housingCA' (iter 1/5)
INFO  [18:10:31.175] [mlr3] Applying learner 'Bagging' on task 'housingCA' (iter 2/5)
INFO  [18:10:37.142] [mlr3] Applying learner 'Bagging' on task 'housingCA' (iter 3/5)
INFO  [18:10:43.292] [mlr3] Applying learner 'Bagging' on task 'housingCA' (iter 4/5)
INFO  [18:10:48.688] [mlr3] Applying learner 'Bagging' on task 'housingCA' (iter 5/5)
INFO  [18:10:54.347] [mlr3] Finished benchmark</code></pre>
</div>
<div class="sourceCode cell-code" id="cb31"><pre class="sourceCode numberSource r number-lines code-with-copy"><code class="sourceCode r"><span id="cb31-1"><a href="#cb31-1"></a><span class="co"># Resultados individuales</span></span>
<span id="cb31-2"><a href="#cb31-2"></a>bmr<span class="sc">$</span><span class="fu">score</span>(<span class="fu">msr</span>(<span class="st">"regr.smape"</span>))</span></code><button title="Copiar al portapapeles" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>    nr   task_id   learner_id resampling_id iteration regr.smape
 1:  1 housingCA TreeDecision            cv         1  0.2744759
 2:  1 housingCA TreeDecision            cv         2  0.2768960
 3:  1 housingCA TreeDecision            cv         3  0.2748795
 4:  1 housingCA TreeDecision            cv         4  0.2739820
 5:  1 housingCA TreeDecision            cv         5  0.2774013
 6:  2 housingCA      Bagging            cv         1  0.2690379
 7:  2 housingCA      Bagging            cv         2  0.2753205
 8:  2 housingCA      Bagging            cv         3  0.2705382
 9:  2 housingCA      Bagging            cv         4  0.2717273
10:  2 housingCA      Bagging            cv         5  0.2735402
Hidden columns: uhash, task, learner, resampling, prediction</code></pre>
</div>
<div class="sourceCode cell-code" id="cb33"><pre class="sourceCode numberSource r number-lines code-with-copy"><code class="sourceCode r"><span id="cb33-1"><a href="#cb33-1"></a><span class="co"># Resultados agregados</span></span>
<span id="cb33-2"><a href="#cb33-2"></a>bmr<span class="sc">$</span><span class="fu">aggregate</span>(<span class="fu">msr</span>(<span class="st">"regr.smape"</span>))</span></code><button title="Copiar al portapapeles" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>   nr   task_id   learner_id resampling_id iters regr.smape
1:  1 housingCA TreeDecision            cv     5  0.2755269
2:  2 housingCA      Bagging            cv     5  0.2720328
Hidden columns: resample_result</code></pre>
</div>
</div>
<p>Aunque los resultados son muy similares para ambas modelizaciones, podemos ver que el <code>sMAPE</code> es algo inferior para el modelo bagging que para el modelo basal. Mejoramos, aunque muy levemente, la capacidad explicativa de nuestro modelo. En este caso también podríamos evaluar la capacidad del modelo mediante la representación gráfica de los valores observados frente a los predichos por el modelo.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb35"><pre class="sourceCode numberSource r number-lines code-with-copy"><code class="sourceCode r"><span id="cb35-1"><a href="#cb35-1"></a><span class="co"># Entrenamiento</span></span>
<span id="cb35-2"><a href="#cb35-2"></a>bgg_housing<span class="sc">$</span><span class="fu">train</span>(tsk_housing)</span>
<span id="cb35-3"><a href="#cb35-3"></a><span class="co"># Predicción</span></span>
<span id="cb35-4"><a href="#cb35-4"></a>pred <span class="ot">=</span> bgg_housing<span class="sc">$</span><span class="fu">predict</span>(tsk_housing)</span>
<span id="cb35-5"><a href="#cb35-5"></a><span class="co"># Gráfico</span></span>
<span id="cb35-6"><a href="#cb35-6"></a><span class="fu">autoplot</span>(pred, <span class="at">type =</span> <span class="st">"xy"</span>) <span class="sc">+</span> <span class="fu">labs</span>(<span class="at">title =</span> <span class="st">"Observados vs predichos"</span>)</span></code><button title="Copiar al portapapeles" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output-display">
<p><img src="130_Ensemblemodels_files/figure-html/bgg-018-1.png" class="img-fluid" width="672"></p>
</div>
</div>
<p>Claramente la nube de puntos es muy dispersa y el modelo no es capaz de ajustar correctamente.</p>
<p>Los modelos de bagging tienden a producir soluciones muy similares a los de los modelos de base utilizados, dado que siempre se utilizan todas las observaciones y todas las predictoras en cada iteración de la ponderación. Sin embargo, se pueden construir otro tipo de modelos de bagging en los que en cada iteración se puede usar un conjunto de entrenamiento diferente y un conjunto de predictoras, en lugar de todas ellas. Estos son los modelos de bosques aleatorios que pasamos a describir a continuación.</p>
</section>
</section>
</section>
<section id="sec-130.3" class="level2" data-number="13.3">
<h2 data-number="13.3" class="anchored" data-anchor-id="sec-130.3"><span class="header-section-number">13.3</span> Bosques aleatorios (Random Forests)</h2>
<p>Un modelo de <strong>bosque aleatorio</strong> está formado por un conjunto de árboles de decisión individuales, cada uno entrenado con una muestra ligeramente distinta de los datos de entrenamiento generada mediante <em>bootstrapping</em>. La predicción de una nueva observación se obtiene agregando las predicciones de todos los árboles individuales que forman el modelo.</p>
<p>Muchos métodos predictivos generan modelos globales en los que disponemos de una única ecuación o modelo de predicción. Sin embargo, en situaciones complejas con múltiples predictores, que interaccionan entre ellos de forma compleja y no lineal, es muy difícil encontrar un modelo predictivo lo suficientemente preciso. Como ya hemos visto anteriormente los árboles de decisión nos permiten obtener un modelo con el que podemos manejar de forma sencilla relaciones complejas entre las posibles predictoras</p>
<p>Ahora, como ya hemos visto, la utilización de los árboles de decisión no está exenta de dificultades y por ese motivo se introduce aquí el algoritmo de bosque aleatorio que es un método de conjunto <em>bagging</em> que nos permite mejorar la capacidad predictiva de los árboles de decisión individuales.</p>
<p>Entre las ventajas del uso de este tipo de algoritmo podemos destacar:</p>
<ul>
<li>Son capaces de seleccionar predictores de forma automática.</li>
<li>Pueden aplicarse a problemas de regresión y clasificación.</li>
<li>Al tratarse de métodos no paramétricos no es necesario que se cumpla ningún tipo de distribución específica.</li>
<li>Por lo general, requieren mucha menos limpieza y preprocesado de los datos en comparación a otros métodos de aprendizaje estadístico (por ejemplo, no requieren estandarización).</li>
<li>No se ven muy influenciados por <em>outliers</em>.</li>
<li>Son muy útiles en la exploración de datos, permiten identificar de forma rápida y eficiente las variables (predictores) más importantes.</li>
<li>Gracias al <em>Out-of-Bag Error</em> puede estimarse su error de validación sin necesidad de recurrir a estrategias computacionalmente costosas como la validación cruzada.</li>
</ul>
<p>Entre las desventajas podemos destacar:</p>
<ul>
<li>Al combinar múltiples árboles, se pierde la interpretabilidad que tienen los modelos basados en un único árbol.</li>
<li>Cuando tratan con predictores continuos pierden parte de su información al categorizarlas en el momento de la división de los nodos.</li>
<li>Por la forma de construcción de los árboles de decisión los predictores continuos o predictores cualitativos con muchos niveles tienen mayor probabilidad de contener, solo por azar, algún punto de corte óptimo, por lo que suelen verse favorecidos en la creación de los árboles.</li>
<li>No son capaces de extrapolar fuera del rango de los predictores observados en los datos de entrenamiento.</li>
</ul>
<section id="sec-130.3.1" class="level3" data-number="13.3.1">
<h3 data-number="13.3.1" class="anchored" data-anchor-id="sec-130.3.1"><span class="header-section-number">13.3.1</span> Algortimo Bosques aleatorios</h3>
<p>Antes de presentar el algoritmo específico del bosque aleatorio es necesario conocer como funciona el proceso de <em>bagging</em> para un único árbol de decisión. Dicho algoritmo se organiza en tres pasos:</p>
<ol type="1">
<li>Generar 𝐵 <em>pseudo-training sets</em> mediante <em>bootstrapping</em> a partir de la muestra de entrenamiento original.</li>
<li>Entrenar un árbol con cada una de las 𝐵 muestras del paso 1. Cada árbol se crea sin apenas restricciones y no se somete a <em>pruning</em>, por lo que tiene varianza alta pero poco sesgo. En la mayoría de casos, la única regla de parada es el número mínimo de observaciones que deben tener los nodos terminales. El valor óptimo de este hiperparámetro puede obtenerse comparando el <em>out of bag error</em> o mediante validación cruzada.</li>
<li>Para cada una de la muestras de validación, se obtiene la predicción en cada uno de los 𝐵 árboles. El valor final de la predicción se obtiene como la media de las 𝐵 predicciones en el caso de variables cuantitativas y como la clase predicha más frecuente (moda) para variables cualitativas.</li>
</ol>
<p>En el algoritmo descrito, el número de árboles creados no es un hiperparámetro crítico en cuanto a que, por mucho que se incremente el número, no se aumenta el riesgo de <em>overfitting</em>. Alcanzado un determinado número de árboles, la reducción del <em>test error</em> se estabiliza. A pesar de ello, cada árbol ocupa memoria, por lo que no conviene almacenar más de los necesarios.</p>
<p>El algoritmo de <em>Random Forest</em> es una modificación del proceso de <em>bagging</em> anterior que consigue mejorar los resultados gracias a que considera árboles lo más independientes posibles.</p>
<p>Supóngase un conjunto de datos en el que hay un predictor muy influyente, junto con otros moderadamente influyentes. En este escenario, todos o casi todos los árboles creados en el proceso de <em>bagging</em> estarán dominados por el mismo predictor y serán muy parecidos entre ellos. Como consecuencia de la alta correlación entre los árboles, el proceso de <em>bagging</em> apenas conseguirá disminuir la varianza y, por lo tanto, tampoco mejorar el modelo. <em>Random forest</em> evita este problema haciendo una selección aleatoria de <span class="math inline">\(𝑚\)</span> predictores antes de evaluar cada división. De esta forma, un promedio de <span class="math inline">\((𝑝−𝑚)/𝑝\)</span> divisiones no contemplará el predictor influyente, permitiendo que otros predictores puedan ser seleccionados. Añadiendo este paso extra se consigue descorrelacionar los árboles todavía más, con lo que su agregación consigue una mayor reducción de la varianza. Algunas recomendaciones para la selección de <span class="math inline">\(m\)</span> son:</p>
<ul>
<li>La raíz cuadrada del número total de predictores para problemas de clasificación:</li>
</ul>
<p><span class="math display">\[m \approx \sqrt{p}\]</span></p>
<ul>
<li>Un tercio del número de predictores para problemas de regresión:</li>
</ul>
<p><span class="math display">\[m \approx p/3\]</span></p>
<ul>
<li>Si los predictores están muy correlacionados, valores pequeños de <span class="math inline">\(𝑚\)</span> consiguen mejores resultados.</li>
</ul>
</section>
<section id="sec-130.3.2" class="level3" data-number="13.3.2">
<h3 data-number="13.3.2" class="anchored" data-anchor-id="sec-130.3.2"><span class="header-section-number">13.3.2</span> Predicción mediante bosque aleatorio</h3>
<p>Para realizar la predicción de un bosque aleatorio utilizamos el principio de <em>bagging</em>, de forma que, una vez determinamos el nodo terminal al que es asignada la observación a predecir en cada uno de los árboles, utilizamos las observaciones contenidas en dicho nodo terminal para la predicción individual de cada uno de ellos. Si estamos en un modelo de regresión obtenemos la media de todas las observaciones del nodo terminal en cada árbol, mientras que si estamos en un problema de clasificación actuamos mediante el voto por mayoría.</p>
<p>Una vez obtenemos las predicciones individuales la predicción conjunta se obtiene a partir de la media o de la categoría más frecuente de todas ellas en función de que estemos en un problema de predicción o clasificación.</p>
<p>Sin embargo, en los problemas de regresión la predicción de un árbol de regresión puede verse como una variante de vecinos cercanos en la que, solo las observaciones que forman parte del mismo nodo terminal que la observación predicha tienen influencia. Siguiendo esta aproximación, la predicción del árbol se define como la media ponderada de todas las observaciones de entrenamiento, donde el peso de cada observación depende únicamente de si forma parte o no del mismo nodo terminal, es decir, definimos los pesos del árbol j como un vector de <span class="math inline">\(n\)</span> componentes donde cada una de las componentes toma el valor <span class="math inline">\(w_j = 1/n_j\)</span> si la observación pertenece al nodo terminal <span class="math inline">\(j\)</span> con <span class="math inline">\(n_j\)</span> observaciones, y 0 en otro caso. Para el bosque aleatorio esto equivale a la media ponderada de todas las observaciones, empleando como pesos la media de los vectores de pesos de los <span class="math inline">\(M\)</span> árboles considerados, es decir,</p>
<p><span class="math display">\[\hat{w}=\frac{\sum_{i=1}^{M}  w_i}{M}\]</span></p>
<p><span class="math display">\[y_{pred} = \sum_{i=1}^n \hat{w}_i y_i\]</span></p>
</section>
<section id="sec-130.3.3" class="level3" data-number="13.3.3">
<h3 data-number="13.3.3" class="anchored" data-anchor-id="sec-130.3.3"><span class="header-section-number">13.3.3</span> Importancia de los predictores</h3>
<p>Si bien es cierto que el bosque aleatorio consigue mejorar la capacidad predictiva en comparación a los modelos basados en un único árbol, esto tiene un coste asociado, la interpretabilidad del modelo se reduce. Al tratarse de una combinación de múltiples árboles, no es posible obtener una representación gráfica sencilla del modelo y no es inmediato identificar de forma visual que predictores son más importantes. Sin embargo, se han desarrollado nuevas estrategias para cuantificar la importancia de los predictores que hacen de los modelos de bosque aleatorio una herramienta muy potente, no solo para predecir, sino también para el análisis exploratorio. Dos de estas medidas son: importancia por permutación e impureza de nodos.</p>
<section id="importancia-por-permutación" class="level4" data-number="13.3.3.1">
<h4 data-number="13.3.3.1" class="anchored" data-anchor-id="importancia-por-permutación"><span class="header-section-number">13.3.3.1</span> Importancia por permutación</h4>
<p>Identifica la influencia que tiene cada predictor sobre una determinada métrica de evaluación del modelo (estimada por <em>out-of-bag error</em> o validación cruzada). El valor asociado con cada predictor se obtiene de la siguiente forma:</p>
<ol type="1">
<li><p>Crear el conjunto de árboles que forman el modelo.</p></li>
<li><p>Calcular una determinada métrica de error (mse, <em>classification error</em>, …). Este es el valor de referencia (<span class="math inline">\(𝑒𝑟𝑟_0\)</span>).</p></li>
<li><p>Para cada predictor <span class="math inline">\(𝑗\)</span>:</p></li>
</ol>
<ul>
<li><p>Permutar en todos los árboles del modelo los valores del predictor <span class="math inline">\(𝑗\)</span> manteniendo el resto constante.</p></li>
<li><p>Recalcular la métrica tras la permutación, llámese (<span class="math inline">\(𝑒𝑟𝑟_𝑗\)</span>).</p></li>
<li><p>Calcular el incremento en la métrica debido a la permutación del predictor <span class="math inline">\(𝑗\)</span></p></li>
</ul>
<p><span class="math display">\[\%I_𝑗=100*\frac{err_j-err_0}{err_0}\]</span></p>
<p>Si el predictor permutado estaba contribuyendo al modelo, es de esperar que el modelo aumente su error, ya que se pierde la información que proporcionaba esa variable. El porcentaje en que se incrementa el error debido a la permutación del predictor <span class="math inline">\(𝑗\)</span> puede interpretarse como la influencia que tiene <span class="math inline">\(𝑗\)</span> sobre el modelo. Algo que suele llevar a confusiones es el hecho de que este incremento puede resultar negativo. Si la variable no contribuye al modelo, es posible que, al reorganizarla aleatoriamente, solo por azar, se consiga mejorar ligeramente el modelo, por lo que <span class="math inline">\((𝑒𝑟𝑟_𝑗−𝑒𝑟𝑟_0)\)</span> es negativo. A modo general, se puede considerar que estas variables tienen una importancia próxima a cero.</p>
<p>Aunque esta estrategia suele ser la más recomendada, cabe tomar algunas precauciones en su interpretación. Lo que cuantifican es la influencia que tienen los predictores sobre el modelo, no su relación con la variable respuesta. ¿Por qué es esto tan importante? Supóngase un escenario en el que se emplea esta estrategia con la finalidad de identificar qué predictores están relacionados con el peso de una persona, y que dos de los predictores son: el índice de masa corporal (IMC) y la altura. Como IMC y altura están muy correlacionados entre sí (la información que aportan es redundante), cuando se permute uno de ellos, el impacto en el modelo será mínimo, ya que el otro aporta la misma información. Como resultado, estos predictores aparecerán como poco influyentes aun cuando realmente están muy relacionados con la variable respuesta. Una forma de evitar problemas de este tipo es, siempre que se excluyan predictores de un modelo, comprobar el impacto que tiene en su capacidad predictiva.</p>
</section>
<section id="incremento-de-la-pureza-de-los-nodos" class="level4" data-number="13.3.3.2">
<h4 data-number="13.3.3.2" class="anchored" data-anchor-id="incremento-de-la-pureza-de-los-nodos"><span class="header-section-number">13.3.3.2</span> Incremento de la pureza de los nodos</h4>
<p>Cuantifica el incremento total en la pureza de los nodos debido a divisiones en las que participa el predictor (promedio de todos los árboles). La forma de calcularlo es la siguiente: en cada división de los árboles, se registra el descenso conseguido en la medida empleada como criterio de división (índice Gini, MSE, entropía, …). Para cada uno de los predictores, se calcula el descenso medio conseguido en el conjunto de árboles que forman el conjunto. Cuanto mayor sea este valor medio, mayor la contribución del predictor en el modelo.</p>
</section>
</section>
<section id="sec-130.3.4" class="level3" data-number="13.3.4">
<h3 data-number="13.3.4" class="anchored" data-anchor-id="sec-130.3.4"><span class="header-section-number">13.3.4</span> Hiperparámetros relevantes en el bosque aleatorio</h3>
<p>Del conjunto de hiperparámetros que se pueden modificar en el bosque aleatorio los dos más interesantes son el número de árboles considerados y el número máximo de predictoras usadas en la construcción de cada árbol.</p>
<p>Lo habitual es proceder de forma individual estudiando la influencia de cada uno de los hiperparámetros respecto de la capacidad predictiva del modelo utilizando el <em>out of bag score</em> (aunque se puede configurar el algoritmo para utilizar otra). Esas curvas de influencia nos permiten determinar la evolución del error del modelo con respecto a ese hiperparámetro y obtener así el conjunto óptimo de valores.</p>
<p>Sin embargo, aunque el análisis individual de los hiperparámetros es útil para entender su impacto en el modelo e identificar rangos de interés, la búsqueda final no debe hacerse de forma secuencial, ya que cada hiperparámetro interacciona con los demás. Es preferible recurrir a <em>grid search</em> o <em>random search</em> para analizar varias combinaciones de hiperparámetros. Los dos métodos más habituales son el <em>grid search</em> basado en el <em>out of bag</em> o el <em>grid search</em> basado en validación cruzada.</p>
</section>
<section id="sec-130.3.5" class="level3" data-number="13.3.5">
<h3 data-number="13.3.5" class="anchored" data-anchor-id="sec-130.3.5"><span class="header-section-number">13.3.5</span> Codificación de predictoras cualitativas</h3>
<p>Los modelos basados en árboles de decisión, entre ellos <em>Random Forest</em>, son capaces de utilizar predictores categóricos en su forma natural sin necesidad de convertirlos en variables <em>dummy</em> mediante <em>one hot encoding</em>. Sin embargo, en la práctica, depende de la implementación que tenga la librería o software utilizado. Esto tiene impacto directo en la estructura de los árboles generados y, en consecuencia, en los resultados predictivos del modelo y en la importancia calculada para los predictores.</p>
<p>Entre las dificultades más relevantes al utilizar <em>one hot encoding</em> se pueden destacar:</p>
<ul>
<li>El entrenamiento de los modelos es más costoso cuando se aplica <em>one hot encoding</em> debido al aumento de dimensionalidad al crear las nuevas variables <em>dummy</em>, obligando a que el algoritmo tenga que analizar muchos más puntos de división.</li>
<li>Al convertir una variable categórica en múltiples variables <em>dummy</em> su importancia queda diluida, dificultando que el modelo pueda aprender de ella y perdiendo así capacidad predictiva. Este efecto es mayor cuantos más niveles tiene la variable original.</li>
<li>Al diluir la importancia de los predictores categóricos, estos tienen menos probabilidad de ser seleccionados por el modelo, lo que desvirtúa las métricas que miden la importancia de los predictores.</li>
</ul>
<p>Por el momento, en Scikit-Learn es necesario hacer <em>one hot encoding</em> para convertir las variables categóricas en variables <em>dummy</em> si deseamos usar <em>random forest</em>. La implementación de <code>H2O</code> sí permite utilizar directamente variables categóricas.</p>
</section>
</section>
<section id="sec-130.4" class="level2" data-number="13.4">
<h2 data-number="13.4" class="anchored" data-anchor-id="sec-130.4"><span class="header-section-number">13.4</span> Bosque aleatorio en mlr3</h2>
<p>Los algoritmos básicos de bosques aleatorios que podemos encontrar en <code>mlr3</code>:</p>
<ul>
<li><code>regr.ranger</code> para abordar tareas de regresión.</li>
<li><code>classif.ranger</code> para abordar tareas de clasificación.</li>
</ul>
<p>Estos algoritmos son una implementación rápida de bosques aleatorios o partición recursiva, particularmente adecuada para datos de alta dimensión.</p>
<p>Otros algoritmos disponibles en la librería <code>mlr3extralearners</code> son:</p>
<ul>
<li><code>classif.randomForest</code> y <code>regr.randomForest</code>, para tareas de clasificación y regresión.</li>
<li><code>classif.rfsrc</code> y <code>regr.rfsrc</code>, utilizando programación en paralelo, y que se pueden utilizar tanto en problemas de clasificación, regresión, supervivencia, y otros más.</li>
<li><code>classif.cforest</code> y <code>regr.cforest</code>, que son algoritmos para la partición recursiva basada en modelos que produce un árbol con modelos ajustados asociados con cada nodo terminal.</li>
</ul>
<p>En este tema nosotros nos centramos en los modelos básicos de bosques aleatorios cuyos hiperparámetros más relevantes son:</p>
<ul>
<li><code>importance</code>: Modo de importancia utilizado en la construcción del bosque aleatorio “none”, “impurity”, “impurity_corrected”, “permutation”. La medida de ‘impureza’ es el índice de Gini para la clasificación, la varianza de las respuestas para la regresión.</li>
<li><code>max_depth</code>: profundidad máxima del árbol. Un valor de 0 corresponde a un árbol sin limitaciones.</li>
<li><code>min.node.size</code>: Número de observaciones mínimo en los nodos terminales.</li>
<li><code>mtry</code>: Número de variables a considerar en la división de cada nodo. El valor predeterminado es la raíz cuadrada (redondeada hacia abajo) de las variables numéricas. Alternativamente, una función de un solo argumento devuelve un número entero, dado el número de variables independientes.</li>
<li><code>mtry.ratio</code>: Proporción de variables a considerar en la división de cada nodo que toma valores en el intervalo <span class="math inline">\([0,1]\)</span>.</li>
<li><code>splitrule</code>: regla de división utilizada. Para tareas de clasificación se considera <code>gini</code> (valor por defecto), <code>extratrees</code>, y <code>hellinger</code>. Para tareas de regresión se considera <code>variance</code> (valor por defecto), <code>extratrees</code>, <code>max-stat</code>, y <code>beta</code>.</li>
<li><code>sample.fraction</code>: Fracción de observaciones para la muestra. El valor predeterminado es 1 para muestreo con reemplazo.</li>
<li><code>num.trees</code>: número de árboles considerados en la construcción del bosque aleatorio. El valor por defecto es 500.</li>
<li><code>oob.error</code>: condición lógica que indica se se debe calcular el error de predicción oob.</li>
</ul>
<p>En los puntos siguientes analizamos los modelos básicos de bosques aleatorios para cada uno de nuestros problemas, y finalizaremos con la optimización de parámetros para alcanzar el mejor modelo posible. Se deja para el lector la modelización con otros algoritmos de bosques aleatorios.</p>
<section id="sec-130.4.1" class="level3" data-number="13.4.1">
<h3 data-number="13.4.1" class="anchored" data-anchor-id="sec-130.4.1"><span class="header-section-number">13.4.1</span> Modelos de bosques aleatorios</h3>
<p>Como en el caso de árboles aleatorios no resulta necesario estandarizar las variables numéricas pero si es necesario imputar los valores perdidos en la tarea de preprocesamiento. Sin embargo, para que los resultados sean comparables con los obtenidos en el punto anterior vamos a realizar todo el preprocesamiento.</p>
<section id="breast-cancer-wisconsin" class="level4" data-number="13.4.1.1">
<h4 data-number="13.4.1.1" class="anchored" data-anchor-id="breast-cancer-wisconsin"><span class="header-section-number">13.4.1.1</span> Breast Cancer Wisconsin</h4>
<p>Definimos el algoritmo de aprendizaje asociado así como las tareas de preprocesamiento.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb36"><pre class="sourceCode numberSource r number-lines code-with-copy"><code class="sourceCode r"><span id="cb36-1"><a href="#cb36-1"></a><span class="co"># Preprocesamiento</span></span>
<span id="cb36-2"><a href="#cb36-2"></a>pp_stroke <span class="ot">=</span>  <span class="fu">po</span>(<span class="st">"imputemedian"</span>, <span class="at">affect_columns =</span> <span class="fu">selector_type</span>(<span class="st">"numeric"</span>))</span>
<span id="cb36-3"><a href="#cb36-3"></a><span class="co"># Modelo de aprendizaje combinando preprocesado y algoritmo</span></span>
<span id="cb36-4"><a href="#cb36-4"></a>rf_classif_stroke <span class="ot">=</span> <span class="fu">as_learner</span>(pp_stroke <span class="sc">%&gt;&gt;%</span> </span>
<span id="cb36-5"><a href="#cb36-5"></a>                                  <span class="fu">lrn</span>(<span class="st">"classif.ranger"</span>, <span class="at">importance =</span> <span class="st">"impurity"</span>))</span>
<span id="cb36-6"><a href="#cb36-6"></a>rf_classif_stroke<span class="sc">$</span>id <span class="ot">=</span> <span class="st">"RandomForest"</span></span></code><button title="Copiar al portapapeles" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>Comenzamos con le entrenamiento del modelo definiendo en primer lugar las muestras de entrenamiento y validación:</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb37"><pre class="sourceCode numberSource r number-lines code-with-copy"><code class="sourceCode r"><span id="cb37-1"><a href="#cb37-1"></a><span class="co"># División de muestras</span></span>
<span id="cb37-2"><a href="#cb37-2"></a><span class="fu">set.seed</span>(<span class="dv">432</span>)</span>
<span id="cb37-3"><a href="#cb37-3"></a><span class="co"># Creamos la partición</span></span>
<span id="cb37-4"><a href="#cb37-4"></a>splits <span class="ot">=</span> mlr3<span class="sc">::</span><span class="fu">partition</span>(tsk_stroke, <span class="at">ratio =</span> <span class="fl">0.8</span>)</span>
<span id="cb37-5"><a href="#cb37-5"></a><span class="co"># Muestras de entrenamiento y validación</span></span>
<span id="cb37-6"><a href="#cb37-6"></a>tsk_train_stroke <span class="ot">=</span> tsk_stroke<span class="sc">$</span><span class="fu">clone</span>()<span class="sc">$</span><span class="fu">filter</span>(splits<span class="sc">$</span>train)</span>
<span id="cb37-7"><a href="#cb37-7"></a>tsk_test_stroke  <span class="ot">=</span> tsk_stroke<span class="sc">$</span><span class="fu">clone</span>()<span class="sc">$</span><span class="fu">filter</span>(splits<span class="sc">$</span>test)</span>
<span id="cb37-8"><a href="#cb37-8"></a><span class="co"># Entrenamiento del modelo</span></span>
<span id="cb37-9"><a href="#cb37-9"></a>rf_classif_stroke<span class="sc">$</span><span class="fu">train</span>(tsk_train_stroke)</span>
<span id="cb37-10"><a href="#cb37-10"></a><span class="co"># modelo construido</span></span>
<span id="cb37-11"><a href="#cb37-11"></a>modelo <span class="ot">=</span> rf_classif_stroke<span class="sc">$</span>model<span class="sc">$</span>classif.ranger<span class="sc">$</span>model</span></code><button title="Copiar al portapapeles" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>Analizamos ahora los resultados del modelo obtenido. Comenzamos con los resultados generales del modelo:</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb38"><pre class="sourceCode numberSource r number-lines code-with-copy"><code class="sourceCode r"><span id="cb38-1"><a href="#cb38-1"></a><span class="co"># Características del modelo</span></span>
<span id="cb38-2"><a href="#cb38-2"></a>modelo</span></code><button title="Copiar al portapapeles" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Ranger result

Call:
 ranger::ranger(dependent.variable.name = task$target_names, data = task$data(),      probability = self$predict_type == "prob", case.weights = task$weights$weight,      num.threads = 1L, importance = "impurity") 

Type:                             Classification 
Number of trees:                  500 
Sample size:                      4088 
Number of independent variables:  10 
Mtry:                             3 
Target node size:                 1 
Variable importance mode:         impurity 
Splitrule:                        gini 
OOB prediction error:             4.94 % </code></pre>
</div>
</div>
<p>Podemos ver que el modelo obtenido tiene un 4.94% de error de predicción. Estudiamos ahora la contribución de cada predictora en el modelo obtenido partir de la importancia de cada una de ellas.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb40"><pre class="sourceCode numberSource r number-lines code-with-copy"><code class="sourceCode r"><span id="cb40-1"><a href="#cb40-1"></a><span class="co"># Importancia de las predictoras (ordenada)</span></span>
<span id="cb40-2"><a href="#cb40-2"></a><span class="fu">sort</span>(modelo<span class="sc">$</span>variable.importance, <span class="at">decreasing =</span> <span class="cn">TRUE</span>)</span></code><button title="Copiar al portapapeles" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>avg_glucose_level               age               bmi    smoking_status 
        96.466818         81.110334         79.201270         24.443464 
        work_type    Residence_type            gender      hypertension 
        16.776643         12.009533         11.287812          9.087196 
    heart_disease      ever_married 
         8.994403          7.157174 </code></pre>
</div>
</div>
<p>Las tres predictoras con una mayor contribución en la construcción del bosque aleatorio son <code>avg_glucose_level</code>, <code>age</code>, y <code>bmi</code>, muy por encima del resto de predictoras. En muchas situaciones prácticas se puede utilizar el resultado de la importancia para construir un nuevo modelo de aprendizaje basado únicamente en dichas predictoras. En este caso nos podríamos plantear un modelo de regresión logística o un árbol de decisión que solo contemplara dichas variables.</p>
<p>Por el momento nos centramos en ampliar el aprendizaje sobre nuestro modelo analizando las predicciones para la muestra de entrenamiento y validación.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb42"><pre class="sourceCode numberSource r number-lines code-with-copy"><code class="sourceCode r"><span id="cb42-1"><a href="#cb42-1"></a><span class="co"># Predicción de la muestra de entrenamiento y validación</span></span>
<span id="cb42-2"><a href="#cb42-2"></a>pred_train <span class="ot">=</span> rf_classif_stroke<span class="sc">$</span><span class="fu">predict</span>(tsk_train_stroke)</span>
<span id="cb42-3"><a href="#cb42-3"></a>pred_test <span class="ot">=</span> rf_classif_stroke<span class="sc">$</span><span class="fu">predict</span>(tsk_test_stroke)</span>
<span id="cb42-4"><a href="#cb42-4"></a><span class="co"># scores de validación</span></span>
<span id="cb42-5"><a href="#cb42-5"></a>measures <span class="ot">=</span> <span class="fu">msrs</span>(<span class="fu">c</span>(<span class="st">"classif.acc"</span>, <span class="st">"classif.bacc"</span>))</span>
<span id="cb42-6"><a href="#cb42-6"></a><span class="co"># Muestra de entrenamiento</span></span>
<span id="cb42-7"><a href="#cb42-7"></a>pred_train<span class="sc">$</span><span class="fu">score</span>(measures)</span></code><button title="Copiar al portapapeles" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code> classif.acc classif.bacc 
   0.9985323    0.9849246 </code></pre>
</div>
<div class="sourceCode cell-code" id="cb44"><pre class="sourceCode numberSource r number-lines code-with-copy"><code class="sourceCode r"><span id="cb44-1"><a href="#cb44-1"></a><span class="co"># Muestra de validación</span></span>
<span id="cb44-2"><a href="#cb44-2"></a>pred_test<span class="sc">$</span><span class="fu">score</span>(measures)</span></code><button title="Copiar al portapapeles" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code> classif.acc classif.bacc 
   0.9500978    0.4994856 </code></pre>
</div>
</div>
<p>De nuevo el porcentaje de clasificación correcta ponderado muestra valores muy bajos en comparación con el no ponderado. Este comportamiento es similar al visto en modelos anteriores. Analizamos la tabla de confusión de la muestra de validación:</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb46"><pre class="sourceCode numberSource r number-lines code-with-copy"><code class="sourceCode r"><span id="cb46-1"><a href="#cb46-1"></a>cm <span class="ot">=</span> <span class="fu">confusion_matrix</span>(pred_test<span class="sc">$</span>truth, pred_test<span class="sc">$</span>response)</span>
<span id="cb46-2"><a href="#cb46-2"></a><span class="fu">plot_confusion_matrix</span>(cm<span class="sc">$</span><span class="st">`</span><span class="at">Confusion Matrix</span><span class="st">`</span>[[<span class="dv">1</span>]]) </span></code><button title="Copiar al portapapeles" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output-display">
<p><img src="130_Ensemblemodels_files/figure-html/bgg-024-1.png" class="img-fluid" width="672"></p>
</div>
</div>
<p>Se puede ver claramente que le modelo no proporciona una solución adecuada ya que no es capaz de clasificar correctamente ninguna de las muestras originales correspondientes a sujetos que han sufrido un ictus. En el proceso de optimización trataremos de mejorar los resultados de este algoritmo.</p>
<p>Para comenzar el proceso de optimización nos centramos en los hiperparámetros: <code>mtry.ratio</code>, <code>num.trees</code>, y <code>sample.fraction</code>. Establecemos el proceso de optimización como en otras ocasiones aumentando el número de iteraciones a 50 debido al alto número de predictoras involucradas. Necesitamos recorrer el espacio de búsqueda (sin mucho coste computacional) para tratar de acercarnos al óptimo.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb47"><pre class="sourceCode numberSource r number-lines code-with-copy"><code class="sourceCode r"><span id="cb47-1"><a href="#cb47-1"></a>rf_classif_stroke <span class="ot">=</span> <span class="fu">lrn</span>(<span class="st">"classif.ranger"</span>, <span class="at">importance =</span> <span class="st">"impurity"</span>,</span>
<span id="cb47-2"><a href="#cb47-2"></a>                         <span class="at">mtry.ratio =</span> <span class="fu">to_tune</span>(<span class="fl">1e-02</span>, <span class="dv">1</span>, <span class="at">logscale =</span> <span class="cn">TRUE</span>),</span>
<span id="cb47-3"><a href="#cb47-3"></a>                         <span class="at">num.trees =</span> <span class="fu">to_tune</span>(<span class="dv">100</span>, <span class="dv">1000</span>),</span>
<span id="cb47-4"><a href="#cb47-4"></a>                         <span class="at">sample.fraction =</span> <span class="fu">to_tune</span>(<span class="fl">1e-01</span>, <span class="dv">1</span>, <span class="at">logscale =</span> <span class="cn">TRUE</span>)</span>
<span id="cb47-5"><a href="#cb47-5"></a>                         )</span>
<span id="cb47-6"><a href="#cb47-6"></a>gr_stroke <span class="ot">=</span>  pp_stroke <span class="sc">%&gt;&gt;%</span> rf_classif_stroke</span>
<span id="cb47-7"><a href="#cb47-7"></a>gr_stroke <span class="ot">=</span> GraphLearner<span class="sc">$</span><span class="fu">new</span>(gr_stroke)</span>
<span id="cb47-8"><a href="#cb47-8"></a></span>
<span id="cb47-9"><a href="#cb47-9"></a><span class="co"># Fijamos semilla para reproducibilidad del proceso</span></span>
<span id="cb47-10"><a href="#cb47-10"></a><span class="fu">set.seed</span>(<span class="dv">123</span>)</span>
<span id="cb47-11"><a href="#cb47-11"></a><span class="co"># Definimos instancia de optimización fijando el número de evaluaciones</span></span>
<span id="cb47-12"><a href="#cb47-12"></a>instance <span class="ot">=</span> <span class="fu">tune</span>(</span>
<span id="cb47-13"><a href="#cb47-13"></a>  <span class="at">tuner =</span> <span class="fu">tnr</span>(<span class="st">"random_search"</span>),</span>
<span id="cb47-14"><a href="#cb47-14"></a>  <span class="at">task =</span> tsk_stroke,</span>
<span id="cb47-15"><a href="#cb47-15"></a>  <span class="at">learner =</span> gr_stroke,</span>
<span id="cb47-16"><a href="#cb47-16"></a>  <span class="at">resampling =</span> <span class="fu">rsmp</span>(<span class="st">"cv"</span>, <span class="at">folds =</span> <span class="dv">3</span>),</span>
<span id="cb47-17"><a href="#cb47-17"></a>  <span class="at">measures =</span> <span class="fu">msr</span>(<span class="st">"classif.bacc"</span>),</span>
<span id="cb47-18"><a href="#cb47-18"></a>  <span class="at">term_evals =</span> <span class="dv">50</span></span>
<span id="cb47-19"><a href="#cb47-19"></a>)</span></code><button title="Copiar al portapapeles" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>Podemos ver los resultados obtenidos con</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb48"><pre class="sourceCode numberSource r number-lines code-with-copy"><code class="sourceCode r"><span id="cb48-1"><a href="#cb48-1"></a>instance<span class="sc">$</span>result_y</span></code><button title="Copiar al portapapeles" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>classif.bacc 
   0.5033988 </code></pre>
</div>
<div class="sourceCode cell-code" id="cb50"><pre class="sourceCode numberSource r number-lines code-with-copy"><code class="sourceCode r"><span id="cb50-1"><a href="#cb50-1"></a>instance<span class="sc">$</span>result_x_domain</span></code><button title="Copiar al portapapeles" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>$classif.ranger.mtry.ratio
[1] 0.8179929

$classif.ranger.num.trees
[1] 222

$classif.ranger.sample.fraction
[1] 0.2600791</code></pre>
</div>
</div>
<p>donde observamos los valores óptimos de los hiperparámetros y el porcentaje de clasificación alcanzado del 50.3%. La solución óptima es muy similar a la opción por defecto. No hemos mejorado prácticamente nada respecto de la solución inicial.</p>
</section>
<section id="water-potability-2" class="level4" data-number="13.4.1.2">
<h4 data-number="13.4.1.2" class="anchored" data-anchor-id="water-potability-2"><span class="header-section-number">13.4.1.2</span> Water Potability</h4>
<p>Como en otras situaciones empezamos por el modelo de aprendizaje por defecto.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb52"><pre class="sourceCode numberSource r number-lines code-with-copy"><code class="sourceCode r"><span id="cb52-1"><a href="#cb52-1"></a><span class="co"># Preprocesado</span></span>
<span id="cb52-2"><a href="#cb52-2"></a>pp_water <span class="ot">=</span> <span class="fu">po</span>(<span class="st">"imputemedian"</span>, <span class="at">affect_columns =</span> <span class="fu">selector_type</span>(<span class="st">"numeric"</span>)) <span class="sc">%&gt;&gt;%</span> </span>
<span id="cb52-3"><a href="#cb52-3"></a>  <span class="fu">po</span>(<span class="st">"scale"</span>, <span class="at">param_vals =</span> <span class="fu">list</span>(<span class="at">center =</span> <span class="cn">TRUE</span>, <span class="at">scale =</span> <span class="cn">TRUE</span>)) </span>
<span id="cb52-4"><a href="#cb52-4"></a><span class="co"># Modelo de aprendizaje combinando preprocesado y algoritmo</span></span>
<span id="cb52-5"><a href="#cb52-5"></a>rf_classif_water <span class="ot">=</span> <span class="fu">as_learner</span>(pp_water <span class="sc">%&gt;&gt;%</span> </span>
<span id="cb52-6"><a href="#cb52-6"></a>                                  <span class="fu">lrn</span>(<span class="st">"classif.ranger"</span>, <span class="at">importance =</span> <span class="st">"impurity"</span>))</span>
<span id="cb52-7"><a href="#cb52-7"></a>rf_classif_water<span class="sc">$</span>id <span class="ot">=</span> <span class="st">"RandomForest"</span></span></code><button title="Copiar al portapapeles" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>Comenzamos con le entrenamiento del modelo definiendo en primer lugar las muestras de entrenamiento y validación:</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb53"><pre class="sourceCode numberSource r number-lines code-with-copy"><code class="sourceCode r"><span id="cb53-1"><a href="#cb53-1"></a><span class="co"># División de muestras</span></span>
<span id="cb53-2"><a href="#cb53-2"></a><span class="fu">set.seed</span>(<span class="dv">432</span>)</span>
<span id="cb53-3"><a href="#cb53-3"></a><span class="co"># Creamos la partición</span></span>
<span id="cb53-4"><a href="#cb53-4"></a>splits <span class="ot">=</span> mlr3<span class="sc">::</span><span class="fu">partition</span>(tsk_water, <span class="at">ratio =</span> <span class="fl">0.8</span>)</span>
<span id="cb53-5"><a href="#cb53-5"></a><span class="co"># Muestras de entrenamiento y validación</span></span>
<span id="cb53-6"><a href="#cb53-6"></a>tsk_train_water <span class="ot">=</span> tsk_water<span class="sc">$</span><span class="fu">clone</span>()<span class="sc">$</span><span class="fu">filter</span>(splits<span class="sc">$</span>train)</span>
<span id="cb53-7"><a href="#cb53-7"></a>tsk_test_water  <span class="ot">=</span> tsk_water<span class="sc">$</span><span class="fu">clone</span>()<span class="sc">$</span><span class="fu">filter</span>(splits<span class="sc">$</span>test)</span>
<span id="cb53-8"><a href="#cb53-8"></a><span class="co"># Entrenamiento del modelo</span></span>
<span id="cb53-9"><a href="#cb53-9"></a>rf_classif_water<span class="sc">$</span><span class="fu">train</span>(tsk_train_water)</span>
<span id="cb53-10"><a href="#cb53-10"></a><span class="co"># modelo construido</span></span>
<span id="cb53-11"><a href="#cb53-11"></a>modelo <span class="ot">=</span> rf_classif_water<span class="sc">$</span>model<span class="sc">$</span>classif.ranger<span class="sc">$</span>model</span></code><button title="Copiar al portapapeles" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>Analizamos ahora los resultados del modelo obtenido. Comenzamos con los resultados generales del modelo:</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb54"><pre class="sourceCode numberSource r number-lines code-with-copy"><code class="sourceCode r"><span id="cb54-1"><a href="#cb54-1"></a><span class="co"># Características del modelo</span></span>
<span id="cb54-2"><a href="#cb54-2"></a>modelo</span></code><button title="Copiar al portapapeles" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Ranger result

Call:
 ranger::ranger(dependent.variable.name = task$target_names, data = task$data(),      probability = self$predict_type == "prob", case.weights = task$weights$weight,      num.threads = 1L, importance = "impurity") 

Type:                             Classification 
Number of trees:                  500 
Sample size:                      2620 
Number of independent variables:  9 
Mtry:                             3 
Target node size:                 1 
Variable importance mode:         impurity 
Splitrule:                        gini 
OOB prediction error:             33.44 % </code></pre>
</div>
</div>
<p>Podemos ver que el modelo obtenido tiene un 33.44% de error de predicción. Estudiamos ahora la contribución de cada predictora en el modelo obtenido partir de la importancia de cada una de ellas.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb56"><pre class="sourceCode numberSource r number-lines code-with-copy"><code class="sourceCode r"><span id="cb56-1"><a href="#cb56-1"></a><span class="co"># Importancia de las predictoras (ordenada)</span></span>
<span id="cb56-2"><a href="#cb56-2"></a><span class="fu">sort</span>(modelo<span class="sc">$</span>variable.importance, <span class="at">decreasing =</span> <span class="cn">TRUE</span>)</span></code><button title="Copiar al portapapeles" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>             ph         Sulfate        Hardness     Chloramines          Solids 
       158.1590        150.7318        149.1244        145.9815        144.7664 
   Conductivity  Organic_carbon Trihalomethanes       Turbidity 
       129.0813        126.2509        122.9520        119.2023 </code></pre>
</div>
</div>
<p>En este caso no hay muchas diferencias entre las contribuciones de las predictoras, lo que no nos permite destacar una predictora o un grupo de ellas sobre el resto. Finalizamos con el análisis de predicción:</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb58"><pre class="sourceCode numberSource r number-lines code-with-copy"><code class="sourceCode r"><span id="cb58-1"><a href="#cb58-1"></a><span class="co"># Predicción de la muestra de entrenamiento y validación</span></span>
<span id="cb58-2"><a href="#cb58-2"></a>pred_train <span class="ot">=</span> rf_classif_water<span class="sc">$</span><span class="fu">predict</span>(tsk_train_water)</span>
<span id="cb58-3"><a href="#cb58-3"></a>pred_test <span class="ot">=</span> rf_classif_water<span class="sc">$</span><span class="fu">predict</span>(tsk_test_water)</span>
<span id="cb58-4"><a href="#cb58-4"></a><span class="co"># scores de validación</span></span>
<span id="cb58-5"><a href="#cb58-5"></a>measures <span class="ot">=</span> <span class="fu">msrs</span>(<span class="fu">c</span>(<span class="st">"classif.acc"</span>, <span class="st">"classif.bacc"</span>))</span>
<span id="cb58-6"><a href="#cb58-6"></a><span class="co"># Muestra de entrenamiento</span></span>
<span id="cb58-7"><a href="#cb58-7"></a>pred_train<span class="sc">$</span><span class="fu">score</span>(measures)</span></code><button title="Copiar al portapapeles" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code> classif.acc classif.bacc 
           1            1 </code></pre>
</div>
<div class="sourceCode cell-code" id="cb60"><pre class="sourceCode numberSource r number-lines code-with-copy"><code class="sourceCode r"><span id="cb60-1"><a href="#cb60-1"></a><span class="co"># Muestra de validación</span></span>
<span id="cb60-2"><a href="#cb60-2"></a>pred_test<span class="sc">$</span><span class="fu">score</span>(measures)</span></code><button title="Copiar al portapapeles" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code> classif.acc classif.bacc 
   0.6768293    0.6175781 </code></pre>
</div>
<div class="sourceCode cell-code" id="cb62"><pre class="sourceCode numberSource r number-lines code-with-copy"><code class="sourceCode r"><span id="cb62-1"><a href="#cb62-1"></a><span class="co"># matriz de confusión</span></span>
<span id="cb62-2"><a href="#cb62-2"></a>cm <span class="ot">=</span> <span class="fu">confusion_matrix</span>(pred_test<span class="sc">$</span>truth, pred_test<span class="sc">$</span>response)</span>
<span id="cb62-3"><a href="#cb62-3"></a><span class="fu">plot_confusion_matrix</span>(cm<span class="sc">$</span><span class="st">`</span><span class="at">Confusion Matrix</span><span class="st">`</span>[[<span class="dv">1</span>]]) </span></code><button title="Copiar al portapapeles" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output-display">
<p><img src="130_Ensemblemodels_files/figure-html/bgg-031-1.png" class="img-fluid" width="672"></p>
</div>
</div>
<p>En este caso el porcentaje de clasificación correcta ponderada se sitúa en el 61.75%. El mayor error de clasificación se produce al predecir las muestras clasificadas originalmente como potables, ya que el 25.5% de ellas son clasificadas por el modelo como no potables. Sin embargo, si hemos mejorado los resultados del modelo bagging planteado anteriormente.</p>
<p>Veamos que ocurre al intentar optimizar los hiperparámetros del modelo. En este caso reducimos la búsqueda de <code>mtry</code> dado que tenemos menos predictoras, y reducimos le intervalo de búsqueda de <code>num.trees</code>. Además aumentamos el número de evaluaciones del algoritmo de búsqueda ya que utilizamos <code>grid_search</code> y deseamos una búsqueda fina.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb63"><pre class="sourceCode numberSource r number-lines code-with-copy"><code class="sourceCode r"><span id="cb63-1"><a href="#cb63-1"></a>rf_classif_water <span class="ot">=</span> <span class="fu">lrn</span>(<span class="st">"classif.ranger"</span>, <span class="at">importance =</span> <span class="st">"impurity"</span>,</span>
<span id="cb63-2"><a href="#cb63-2"></a>                         <span class="at">mtry.ratio =</span> <span class="fu">to_tune</span>(<span class="fl">1e-02</span>, <span class="dv">1</span>, <span class="at">logscale =</span> <span class="cn">TRUE</span>),</span>
<span id="cb63-3"><a href="#cb63-3"></a>                         <span class="at">num.trees =</span> <span class="fu">to_tune</span>(<span class="dv">100</span>, <span class="dv">2000</span>),</span>
<span id="cb63-4"><a href="#cb63-4"></a>                         <span class="at">sample.fraction =</span> <span class="fu">to_tune</span>(<span class="fl">1e-01</span>, <span class="dv">1</span>, <span class="at">logscale =</span> <span class="cn">TRUE</span>)</span>
<span id="cb63-5"><a href="#cb63-5"></a>                         )</span>
<span id="cb63-6"><a href="#cb63-6"></a>gr_water <span class="ot">=</span>  <span class="fu">as_learner</span>(pp_water <span class="sc">%&gt;&gt;%</span> rf_classif_water)</span>
<span id="cb63-7"><a href="#cb63-7"></a></span>
<span id="cb63-8"><a href="#cb63-8"></a><span class="co"># Fijamos semilla para reproducibilidad del proceso</span></span>
<span id="cb63-9"><a href="#cb63-9"></a><span class="fu">set.seed</span>(<span class="dv">123</span>)</span>
<span id="cb63-10"><a href="#cb63-10"></a><span class="co"># Definimos instancia de optimización fijando el número de evaluaciones</span></span>
<span id="cb63-11"><a href="#cb63-11"></a>instance <span class="ot">=</span> <span class="fu">tune</span>(</span>
<span id="cb63-12"><a href="#cb63-12"></a>  <span class="at">tuner =</span> <span class="fu">tnr</span>(<span class="st">"grid_search"</span>),</span>
<span id="cb63-13"><a href="#cb63-13"></a>  <span class="at">task =</span> tsk_water,</span>
<span id="cb63-14"><a href="#cb63-14"></a>  <span class="at">learner =</span> gr_water,</span>
<span id="cb63-15"><a href="#cb63-15"></a>  <span class="at">resampling =</span> <span class="fu">rsmp</span>(<span class="st">"cv"</span>, <span class="at">folds =</span> <span class="dv">3</span>),</span>
<span id="cb63-16"><a href="#cb63-16"></a>  <span class="at">measures =</span> <span class="fu">msr</span>(<span class="st">"classif.bacc"</span>),</span>
<span id="cb63-17"><a href="#cb63-17"></a>  <span class="at">term_evals =</span> <span class="dv">50</span></span>
<span id="cb63-18"><a href="#cb63-18"></a>)</span></code><button title="Copiar al portapapeles" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>Podemos ver los resultados obtenidos con:</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb64"><pre class="sourceCode numberSource r number-lines code-with-copy"><code class="sourceCode r"><span id="cb64-1"><a href="#cb64-1"></a>instance<span class="sc">$</span>result_y</span></code><button title="Copiar al portapapeles" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>classif.bacc 
   0.6182979 </code></pre>
</div>
<div class="sourceCode cell-code" id="cb66"><pre class="sourceCode numberSource r number-lines code-with-copy"><code class="sourceCode r"><span id="cb66-1"><a href="#cb66-1"></a>instance<span class="sc">$</span>result_x_domain</span></code><button title="Copiar al portapapeles" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>$classif.ranger.mtry.ratio
[1] 0.5994843

$classif.ranger.num.trees
[1] 2000

$classif.ranger.sample.fraction
[1] 1</code></pre>
</div>
</div>
<p>La solución óptima alcanza un porcentaje de clasificación correcta ponderada del 61.82%, prácticamente igual al del modelo sin optimización. Sin modificar más hiperparámetros la solución obtenida en ambas situaciones es muy similar.</p>
</section>
<section id="housing-in-california-2" class="level4" data-number="13.4.1.3">
<h4 data-number="13.4.1.3" class="anchored" data-anchor-id="housing-in-california-2"><span class="header-section-number">13.4.1.3</span> Housing in California</h4>
<p>En este caso nos enfrentamos a un problema de regresión. En primer lugar configuramos el modelo por defecto</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb68"><pre class="sourceCode numberSource r number-lines code-with-copy"><code class="sourceCode r"><span id="cb68-1"><a href="#cb68-1"></a><span class="co"># Preprocesamiento</span></span>
<span id="cb68-2"><a href="#cb68-2"></a>pp_housing <span class="ot">=</span> </span>
<span id="cb68-3"><a href="#cb68-3"></a>   <span class="fu">po</span>(<span class="st">"scale"</span>, <span class="at">param_vals =</span> <span class="fu">list</span>(<span class="at">center =</span> <span class="cn">TRUE</span>, <span class="at">scale =</span> <span class="cn">TRUE</span>)) <span class="sc">%&gt;&gt;%</span></span>
<span id="cb68-4"><a href="#cb68-4"></a>   <span class="fu">po</span>(<span class="st">"imputemedian"</span>, <span class="at">affect_columns =</span> <span class="fu">selector_type</span>(<span class="st">"numeric"</span>)) </span>
<span id="cb68-5"><a href="#cb68-5"></a><span class="co"># Modelo de aprendizaje combinando preprocesado y algoritmo</span></span>
<span id="cb68-6"><a href="#cb68-6"></a>rf_regr_housing <span class="ot">=</span> <span class="fu">as_learner</span>(pp_housing <span class="sc">%&gt;&gt;%</span> </span>
<span id="cb68-7"><a href="#cb68-7"></a>                                  <span class="fu">lrn</span>(<span class="st">"regr.ranger"</span>, <span class="at">importance =</span> <span class="st">"impurity"</span>))</span>
<span id="cb68-8"><a href="#cb68-8"></a>rf_regr_housing<span class="sc">$</span>id <span class="ot">=</span> <span class="st">"RandomForest"</span></span></code><button title="Copiar al portapapeles" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>Comenzamos con le entrenamiento del modelo definiendo en primer lugar las muestras de entrenamiento y validación:</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb69"><pre class="sourceCode numberSource r number-lines code-with-copy"><code class="sourceCode r"><span id="cb69-1"><a href="#cb69-1"></a><span class="co"># División de muestras</span></span>
<span id="cb69-2"><a href="#cb69-2"></a><span class="fu">set.seed</span>(<span class="dv">432</span>)</span>
<span id="cb69-3"><a href="#cb69-3"></a><span class="co"># Creamos la partición</span></span>
<span id="cb69-4"><a href="#cb69-4"></a>splits <span class="ot">=</span> mlr3<span class="sc">::</span><span class="fu">partition</span>(tsk_housing, <span class="at">ratio =</span> <span class="fl">0.8</span>)</span>
<span id="cb69-5"><a href="#cb69-5"></a><span class="co"># Muestras de entrenamiento y validación</span></span>
<span id="cb69-6"><a href="#cb69-6"></a>tsk_train_housing <span class="ot">=</span> tsk_housing<span class="sc">$</span><span class="fu">clone</span>()<span class="sc">$</span><span class="fu">filter</span>(splits<span class="sc">$</span>train)</span>
<span id="cb69-7"><a href="#cb69-7"></a>tsk_test_housing  <span class="ot">=</span> tsk_housing<span class="sc">$</span><span class="fu">clone</span>()<span class="sc">$</span><span class="fu">filter</span>(splits<span class="sc">$</span>test)</span>
<span id="cb69-8"><a href="#cb69-8"></a><span class="co"># Entrenamiento del modelo</span></span>
<span id="cb69-9"><a href="#cb69-9"></a>rf_regr_housing<span class="sc">$</span><span class="fu">train</span>(tsk_train_housing)</span>
<span id="cb69-10"><a href="#cb69-10"></a><span class="co"># modelo construido</span></span>
<span id="cb69-11"><a href="#cb69-11"></a>modelo <span class="ot">=</span> rf_regr_housing<span class="sc">$</span>model<span class="sc">$</span>regr.ranger<span class="sc">$</span>model</span></code><button title="Copiar al portapapeles" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>Analizamos ahora los resultados del modelo obtenido. Comenzamos con los resultados generales del modelo:</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb70"><pre class="sourceCode numberSource r number-lines code-with-copy"><code class="sourceCode r"><span id="cb70-1"><a href="#cb70-1"></a><span class="co"># Características del modelo</span></span>
<span id="cb70-2"><a href="#cb70-2"></a>modelo</span></code><button title="Copiar al portapapeles" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Ranger result

Call:
 ranger::ranger(dependent.variable.name = task$target_names, data = task$data(),      case.weights = task$weights$weight, num.threads = 1L, importance = "impurity") 

Type:                             Regression 
Number of trees:                  500 
Sample size:                      16511 
Number of independent variables:  9 
Mtry:                             3 
Target node size:                 5 
Variable importance mode:         impurity 
Splitrule:                        variance 
OOB prediction error (MSE):       2399285409 
R squared (OOB):                  0.8211186 </code></pre>
</div>
</div>
<p>En este caso podemos ver que le <span class="math inline">\(R^2\)</span> obtenido con este modelo se sitúa en el 82.11%, lo que no es un valor fantástico pero si bastante alto dado el gran número de predictoras y muestras consideradas. Podemos evaluar la importancia de las predictoras</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb72"><pre class="sourceCode numberSource r number-lines code-with-copy"><code class="sourceCode r"><span id="cb72-1"><a href="#cb72-1"></a><span class="co"># Importancia de las predictoras (ordenada)</span></span>
<span id="cb72-2"><a href="#cb72-2"></a><span class="fu">sort</span>(modelo<span class="sc">$</span>variable.importance, <span class="at">decreasing =</span> <span class="cn">TRUE</span>)</span></code><button title="Copiar al portapapeles" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>     median_income          longitude           latitude    ocean_proximity 
      8.751658e+13       2.907831e+13       2.750543e+13       2.563794e+13 
housing_median_age         population        total_rooms     total_bedrooms 
      1.125149e+13       1.113980e+13       1.009497e+13       7.433084e+12 
        households 
      7.271314e+12 </code></pre>
</div>
</div>
<p>Todas contribuyen aunque en mayor medida el precio de la vivienda viene determinando por <code>median_income</code>, <code>longitude</code>. <code>latitude</code>, y <code>ocean_proximity</code>. Veamos el <code>sMAPE</code> que obtenemos con este modelo:</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb74"><pre class="sourceCode numberSource r number-lines code-with-copy"><code class="sourceCode r"><span id="cb74-1"><a href="#cb74-1"></a><span class="co"># Predicción de la muestra de entrenamiento y validación</span></span>
<span id="cb74-2"><a href="#cb74-2"></a>pred_train <span class="ot">=</span> rf_regr_housing<span class="sc">$</span><span class="fu">predict</span>(tsk_train_housing)</span>
<span id="cb74-3"><a href="#cb74-3"></a>pred_test <span class="ot">=</span> rf_regr_housing<span class="sc">$</span><span class="fu">predict</span>(tsk_test_housing)</span>
<span id="cb74-4"><a href="#cb74-4"></a><span class="co"># scores de validación</span></span>
<span id="cb74-5"><a href="#cb74-5"></a>measures <span class="ot">=</span> <span class="fu">msr</span>(<span class="st">"regr.smape"</span>)</span>
<span id="cb74-6"><a href="#cb74-6"></a><span class="co"># Muestra de entrenamiento</span></span>
<span id="cb74-7"><a href="#cb74-7"></a>pred_train<span class="sc">$</span><span class="fu">score</span>(measures)</span></code><button title="Copiar al portapapeles" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>regr.smape 
0.07453686 </code></pre>
</div>
<div class="sourceCode cell-code" id="cb76"><pre class="sourceCode numberSource r number-lines code-with-copy"><code class="sourceCode r"><span id="cb76-1"><a href="#cb76-1"></a><span class="co"># Muestra de validación</span></span>
<span id="cb76-2"><a href="#cb76-2"></a>pred_test<span class="sc">$</span><span class="fu">score</span>(measures)</span></code><button title="Copiar al portapapeles" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>regr.smape 
 0.1619824 </code></pre>
</div>
</div>
<p>Podemos ver como los valores son mejores que los obtenidos con el modelo de bagging inicial, demostrando que el modelo random forest consigue mejorar la predicción del target. Para finalizar exploramos la optimización de hiperparámetros con un esquema similar al del ejemplo anterior.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb78"><pre class="sourceCode numberSource r number-lines code-with-copy"><code class="sourceCode r"><span id="cb78-1"><a href="#cb78-1"></a>rf_regr_housing <span class="ot">=</span> <span class="fu">lrn</span>(<span class="st">"regr.ranger"</span>, <span class="at">importance =</span> <span class="st">"impurity"</span>,</span>
<span id="cb78-2"><a href="#cb78-2"></a>                         <span class="at">mtry.ratio =</span> <span class="fu">to_tune</span>(<span class="fl">1e-02</span>, <span class="dv">1</span>, <span class="at">logscale =</span> <span class="cn">TRUE</span>),</span>
<span id="cb78-3"><a href="#cb78-3"></a>                         <span class="at">num.trees =</span> <span class="fu">to_tune</span>(<span class="dv">100</span>, <span class="dv">2000</span>),</span>
<span id="cb78-4"><a href="#cb78-4"></a>                         <span class="at">sample.fraction =</span> <span class="fu">to_tune</span>(<span class="fl">1e-01</span>, <span class="dv">1</span>, <span class="at">logscale =</span> <span class="cn">TRUE</span>)</span>
<span id="cb78-5"><a href="#cb78-5"></a>                         )</span>
<span id="cb78-6"><a href="#cb78-6"></a>gr_housing <span class="ot">=</span>  <span class="fu">as_learner</span>(pp_housing <span class="sc">%&gt;&gt;%</span> rf_regr_housing)</span>
<span id="cb78-7"><a href="#cb78-7"></a></span>
<span id="cb78-8"><a href="#cb78-8"></a><span class="co"># Fijamos semilla para reproducibilidad del proceso</span></span>
<span id="cb78-9"><a href="#cb78-9"></a><span class="fu">set.seed</span>(<span class="dv">123</span>)</span>
<span id="cb78-10"><a href="#cb78-10"></a><span class="co"># Definimos instancia de optimización fijando el número de evaluaciones</span></span>
<span id="cb78-11"><a href="#cb78-11"></a>instance <span class="ot">=</span> <span class="fu">tune</span>(</span>
<span id="cb78-12"><a href="#cb78-12"></a>  <span class="at">tuner =</span> <span class="fu">tnr</span>(<span class="st">"grid_search"</span>),</span>
<span id="cb78-13"><a href="#cb78-13"></a>  <span class="at">task =</span> tsk_housing,</span>
<span id="cb78-14"><a href="#cb78-14"></a>  <span class="at">learner =</span> gr_housing,</span>
<span id="cb78-15"><a href="#cb78-15"></a>  <span class="at">resampling =</span> <span class="fu">rsmp</span>(<span class="st">"cv"</span>, <span class="at">folds =</span> <span class="dv">3</span>),</span>
<span id="cb78-16"><a href="#cb78-16"></a>  <span class="at">measures =</span> <span class="fu">msr</span>(<span class="st">"regr.smape"</span>),</span>
<span id="cb78-17"><a href="#cb78-17"></a>  <span class="at">term_evals =</span> <span class="dv">50</span></span>
<span id="cb78-18"><a href="#cb78-18"></a>)</span></code><button title="Copiar al portapapeles" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>Podemos ver los resultados obtenidos con:</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb79"><pre class="sourceCode numberSource r number-lines code-with-copy"><code class="sourceCode r"><span id="cb79-1"><a href="#cb79-1"></a>instance<span class="sc">$</span>result_y</span></code><button title="Copiar al portapapeles" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>regr.smape 
 0.1622815 </code></pre>
</div>
<div class="sourceCode cell-code" id="cb81"><pre class="sourceCode numberSource r number-lines code-with-copy"><code class="sourceCode r"><span id="cb81-1"><a href="#cb81-1"></a>instance<span class="sc">$</span>result_x_domain</span></code><button title="Copiar al portapapeles" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>$regr.ranger.mtry.ratio
[1] 0.5994843

$regr.ranger.num.trees
[1] 2000

$regr.ranger.sample.fraction
[1] 1</code></pre>
</div>
</div>
<p>A pesar de la búsqueda que hemos hecho (sobre todo computacionalmente hablando) el <code>smape</code> es prácticamente idéntico al obtenido con el modelo sin optimización. Es posible que alguna combinación pueda alcanzar un valor más bajo, pero el tiempo computacional puede ser excesivo sino se usa más de un procesador.</p>
</section>
</section>
</section>
<section id="sec-130.5" class="level2" data-number="13.5">
<h2 data-number="13.5" class="anchored" data-anchor-id="sec-130.5"><span class="header-section-number">13.5</span> Ejercicios</h2>
<ol type="1">
<li>Ajustar un modelo de aprendizaje automático basado en bosques aleatorios para el banco de datos <code>Mushroom</code><a href="40_DataBases.html#sec-mushroom"><span>4.3.4</span></a>.</li>
<li>Ajustar un modelo de aprendizaje automático basado en bosques aleatorios para el banco de datos <code>Hepatitis</code><a href="40_DataBases.html#sec-hepatitis"><span>4.3.9</span></a>.</li>
<li>Ajustar un modelo de aprendizaje automático basado en bosques aleatorios para el banco de datos <code>Abalone</code><a href="40_DataBases.html#sec-abalone"><span>4.3.1</span></a>.</li>
<li>Ajustar un modelo de aprendizaje automático basado en bosques aleatorios para el banco de datos <code>Us economic time series</code><a href="40_DataBases.html#sec-usaets"><span>4.2.7</span></a>.</li>
<li>Ajustar un modelo de aprendizaje automático basado en bosques aleatorios para el banco de datos <code>QSAR</code><a href="40_DataBases.html#sec-qsar"><span>4.2.8</span></a>.</li>
</ol>


</section>

</main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const clipboard = new window.ClipboardJS('.code-copy-button', {
    target: function(trigger) {
      return trigger.previousElementSibling;
    }
  });
  clipboard.on('success', function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "¡Copiado!");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "¡Copiado!");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  });
  function tippyHover(el, contentFn) {
    const config = {
      allowHTML: true,
      content: contentFn,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start'
    };
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      return note.innerHTML;
    });
  }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
});
</script>
<nav class="page-navigation">
  <div class="nav-page nav-page-previous">
      <a href="./120_DTmodels.html" class="pagination-link">
        <i class="bi bi-arrow-left-short"></i> <span class="nav-page-text"><span class="chapter-number">12</span>&nbsp; <span class="chapter-title">Árboles de decisiónn (DT)</span></span>
      </a>          
  </div>
  <div class="nav-page nav-page-next">
      <a href="./140_Boostingmodels.html" class="pagination-link">
        <span class="nav-page-text"><span class="chapter-number">14</span>&nbsp; <span class="chapter-title">Modelos Boosting</span></span> <i class="bi bi-arrow-right-short"></i>
      </a>
  </div>
</nav>
</div> <!-- /content -->
<footer class="footer">
  <div class="nav-footer">
    <div class="nav-footer-left">Copyright 2023, IA4LEGOS. Universidad Miguel Hernández de Elche</div>   
  </div>
</footer>



</body></html>