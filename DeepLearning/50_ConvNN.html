<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.2.335">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">


<title>MachineLearning - 5&nbsp; Redes convolucionales</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1.6em;
  vertical-align: middle;
}
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { color: #008000; } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { color: #008000; font-weight: bold; } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
</style>


<script src="site_libs/quarto-nav/quarto-nav.js"></script>
<script src="site_libs/quarto-nav/headroom.min.js"></script>
<script src="site_libs/clipboard/clipboard.min.js"></script>
<script src="site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="site_libs/quarto-search/fuse.min.js"></script>
<script src="site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="./">
<link href="./references.html" rel="next">
<link href="./40_AplMD.html" rel="prev">
<script src="site_libs/quarto-html/quarto.js"></script>
<script src="site_libs/quarto-html/popper.min.js"></script>
<script src="site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="site_libs/quarto-html/anchor.min.js"></script>
<link href="site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="site_libs/quarto-html/quarto-syntax-highlighting.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="site_libs/bootstrap/bootstrap.min.js"></script>
<link href="site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="site_libs/bootstrap/bootstrap.min.css" rel="stylesheet" id="quarto-bootstrap" data-mode="light">
<script id="quarto-search-options" type="application/json">{
  "location": "sidebar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "start",
  "type": "textbox",
  "limit": 20,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit"
  }
}</script>

  <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js" type="text/javascript"></script>

</head>

<body class="nav-sidebar docked">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top">
  <nav class="quarto-secondary-nav" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
    <div class="container-fluid d-flex justify-content-between">
      <h1 class="quarto-secondary-nav-title"><span class="chapter-number">5</span>&nbsp; <span class="chapter-title">Redes convolucionales</span></h1>
      <button type="button" class="quarto-btn-toggle btn" aria-label="Show secondary navigation">
        <i class="bi bi-chevron-right"></i>
      </button>
    </div>
  </nav>
</header>
<!-- content -->
<div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article">
<!-- sidebar -->
  <nav id="quarto-sidebar" class="sidebar collapse sidebar-navigation docked overflow-auto">
    <div class="pt-lg-2 mt-2 text-left sidebar-header">
    <div class="sidebar-title mb-0 py-0">
      <a href="./">MachineLearning</a> 
    </div>
      </div>
      <div class="mt-2 flex-shrink-0 align-items-center">
        <div class="sidebar-search">
        <div id="quarto-search" class="" title="Search"></div>
        </div>
      </div>
    <div class="sidebar-menu-container"> 
    <ul class="list-unstyled mt-1">
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./index.html" class="sidebar-item-text sidebar-link">Deep Learning</a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./10_IntroDL.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">1</span>&nbsp; <span class="chapter-title">Introducción</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./20_TrainDL.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">2</span>&nbsp; <span class="chapter-title">Entrenamiento de la red neuronal</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./30_RMDDL.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">3</span>&nbsp; <span class="chapter-title">Redes multicapa densas con Keras</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./40_AplMD.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">4</span>&nbsp; <span class="chapter-title">Aplicaciones Redes multicapa densas</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./50_ConvNN.html" class="sidebar-item-text sidebar-link active"><span class="chapter-number">5</span>&nbsp; <span class="chapter-title">Redes convolucionales</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./references.html" class="sidebar-item-text sidebar-link">References</a>
  </div>
</li>
    </ul>
    </div>
</nav>
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
        <nav id="TOC" role="doc-toc" class="toc-active">
    <h2 id="toc-title">Table of contents</h2>
   
  <ul>
  <li><a href="#cómo-aprende-una-res-convolucional" id="toc-cómo-aprende-una-res-convolucional" class="nav-link active" data-scroll-target="#cómo-aprende-una-res-convolucional"><span class="toc-section-number">5.1</span>  ¿Cómo aprende una res convolucional?</a></li>
  <li><a href="#aspecto-matemáticos-de-las-convoluciones" id="toc-aspecto-matemáticos-de-las-convoluciones" class="nav-link" data-scroll-target="#aspecto-matemáticos-de-las-convoluciones"><span class="toc-section-number">5.2</span>  Aspecto matemáticos de las convoluciones</a>
  <ul>
  <li><a href="#operación-de-convolución" id="toc-operación-de-convolución" class="nav-link" data-scroll-target="#operación-de-convolución"><span class="toc-section-number">5.2.1</span>  Operación de convolución</a></li>
  <li><a href="#operación-de-pooling" id="toc-operación-de-pooling" class="nav-link" data-scroll-target="#operación-de-pooling"><span class="toc-section-number">5.2.2</span>  Operación de pooling</a></li>
  </ul></li>
  <li><a href="#implementación-de-modelos-básicos-en-keras" id="toc-implementación-de-modelos-básicos-en-keras" class="nav-link" data-scroll-target="#implementación-de-modelos-básicos-en-keras"><span class="toc-section-number">5.3</span>  Implementación de modelos básicos en Keras</a>
  <ul>
  <li><a href="#configuración-entrenamiento-y-evaluación-del-modelo" id="toc-configuración-entrenamiento-y-evaluación-del-modelo" class="nav-link" data-scroll-target="#configuración-entrenamiento-y-evaluación-del-modelo"><span class="toc-section-number">5.3.1</span>  Configuración, entrenamiento y evaluación del modelo</a></li>
  <li><a href="#hiperparámetros-de-la-capa-convolucional" id="toc-hiperparámetros-de-la-capa-convolucional" class="nav-link" data-scroll-target="#hiperparámetros-de-la-capa-convolucional"><span class="toc-section-number">5.3.2</span>  Hiperparámetros de la capa convolucional</a>
  <ul class="collapse">
  <li><a href="#tamaño-de-los-filtros" id="toc-tamaño-de-los-filtros" class="nav-link" data-scroll-target="#tamaño-de-los-filtros"><span class="toc-section-number">5.3.2.1</span>  Tamaño de los filtros</a></li>
  <li><a href="#padding" id="toc-padding" class="nav-link" data-scroll-target="#padding"><span class="toc-section-number">5.3.2.2</span>  Padding</a></li>
  <li><a href="#stride" id="toc-stride" class="nav-link" data-scroll-target="#stride"><span class="toc-section-number">5.3.2.3</span>  Stride</a></li>
  </ul></li>
  </ul></li>
  <li><a href="#conjunto-de-datos-fashion-minst" id="toc-conjunto-de-datos-fashion-minst" class="nav-link" data-scroll-target="#conjunto-de-datos-fashion-minst"><span class="toc-section-number">5.4</span>  Conjunto de datos Fashion-minst</a>
  <ul>
  <li><a href="#modelo-inicial" id="toc-modelo-inicial" class="nav-link" data-scroll-target="#modelo-inicial"><span class="toc-section-number">5.4.1</span>  Modelo inicial</a></li>
  <li><a href="#modelo-2" id="toc-modelo-2" class="nav-link" data-scroll-target="#modelo-2"><span class="toc-section-number">5.4.2</span>  Modelo 2</a></li>
  <li><a href="#modelo-3" id="toc-modelo-3" class="nav-link" data-scroll-target="#modelo-3"><span class="toc-section-number">5.4.3</span>  Modelo 3</a></li>
  <li><a href="#modelo-4" id="toc-modelo-4" class="nav-link" data-scroll-target="#modelo-4"><span class="toc-section-number">5.4.4</span>  Modelo 4</a></li>
  <li><a href="#predicción" id="toc-predicción" class="nav-link" data-scroll-target="#predicción"><span class="toc-section-number">5.4.5</span>  Predicción</a></li>
  </ul></li>
  </ul>
</nav>
    </div>
<!-- main -->
<main class="content" id="quarto-document-content">

<header id="title-block-header" class="quarto-title-block default">
<div class="quarto-title">
<h1 class="title d-none d-lg-block"><span class="chapter-number">5</span>&nbsp; <span class="chapter-title">Redes convolucionales</span></h1>
</div>



<div class="quarto-title-meta">

    
  
    
  </div>
  

</header>

<p>Una red neuronal convolucional (Convolutional Neural Networks en inglés, con los acrónimos CNN o ConvNets) es un caso concreto de redes neuronales que fueron ya usadas a finales de los 90 pero que en estos últimos años se han popularizado enormemente al conseguir resultados muy impresionantes en el reconocimiento de imagen, impactando profundamente en el área de visión por computador.</p>
<p>Las redes neuronales convolucionales son muy similares a las redes neuronales presentadas hasta ahora: están formadas por neuronas que tienen parámetros en forma de pesos y sesgos que se pueden aprender. Pero un rasgo diferencial de las redes neuronales convolucionales es que hacen la suposición explícita de que las entradas son imágenes, cosa que nos permite codificar ciertas propiedades en la arquitectura para reconocer elementos concretos en las imágenes.</p>
<p>Para hacernos una idea intuitiva sobre cómo funcionan estas redes neuronales, pensemos en cómo nosotros reconocemos las cosas. Por ejemplo, si vemos una cara, a reconocemos porque tiene orejas, ojos, una nariz, cabello, etc. Entonces, para decidir si algo es una cara, lo hacemos como si tuviéramos unas casillas mentales de verificación de las características que vamos marcando. Algunas veces una cara puede no tener una oreja por estar tapada por el pelo, pero igualmente la clasificamos como cara porque vemos los ojos, la nariz y la boca. En este caso, podemos ver a una red neuronal convolucional como un clasificador equivalente a los presentados anteriormente, que predice una probabilidad de que la imagen de entrada sea cara o no cara.</p>
<p>Pero, en realidad, antes de poder clasificar debemos saber cómo es una oreja o una nariz para saber si están en una imagen; es decir, previamente debemos identificar líneas, bordes, texturas o formas que sean similares a las que contienen las orejas o narices que hemos visto antes. Esto es lo que las capas de una red neuronal convolucional tienen encomendado hacer.</p>
<p>Pero identificar estos elementos no es suficiente para poder decir que algo es una cara. Además, debemos poder identificar cómo las partes de una cara se encuentran colocadas entre sí, tamaños relativos, etc. De lo contrario, la cara no se parecería a lo que estamos acostumbrados. Es decir, una cara está formada por una boca, una nariz y dos ojos, pero la disposición entre ellos es importante, ya que si la disposición no es la adecuada -por ejemplo, si la nariz se encuentra por debajo de la boca- no podemos considerar la imagen como una cara, a pesar de contener todos los elementos que conforman una cara.</p>
<p>En una red convulacional para la detección de imágenes una primera capa convolucional aprende elementos básicos como aristas, y una segunda capa convolucional aprende patrones compuestos de elementos básicos aprendidos en la capa anterior. Y así sucesivamente en cada capa hasta ir aprendiendo patrones muy complejos.</p>
<p>Cargamos las librerías necesarias para el trabajo en este tema:</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb1"><pre class="sourceCode numberSource r number-lines code-with-copy"><code class="sourceCode r"><span id="cb1-1"><a href="#cb1-1"></a><span class="co"># Paquetes anteriores</span></span>
<span id="cb1-2"><a href="#cb1-2"></a><span class="fu">library</span>(tidyverse)</span>
<span id="cb1-3"><a href="#cb1-3"></a><span class="fu">library</span>(sjPlot)</span>
<span id="cb1-4"><a href="#cb1-4"></a><span class="fu">library</span>(knitr) <span class="co"># para formatos de tablas</span></span>
<span id="cb1-5"><a href="#cb1-5"></a><span class="fu">library</span>(gridExtra)</span>
<span id="cb1-6"><a href="#cb1-6"></a><span class="fu">library</span>(ggpubr)</span>
<span id="cb1-7"><a href="#cb1-7"></a><span class="fu">library</span>(cvms)</span>
<span id="cb1-8"><a href="#cb1-8"></a><span class="fu">theme_set</span>(<span class="fu">theme_sjplot2</span>())</span>
<span id="cb1-9"><a href="#cb1-9"></a><span class="fu">library</span>(mlr3verse)</span>
<span id="cb1-10"><a href="#cb1-10"></a><span class="fu">library</span>(tensorflow)</span>
<span id="cb1-11"><a href="#cb1-11"></a><span class="fu">library</span>(keras)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<section id="cómo-aprende-una-res-convolucional" class="level2" data-number="5.1">
<h2 data-number="5.1" class="anchored" data-anchor-id="cómo-aprende-una-res-convolucional"><span class="header-section-number">5.1</span> ¿Cómo aprende una res convolucional?</h2>
<p>Las Redes neuronales Convolucionales aprenden a reconocer una diversidad de objetos dentro de imágenes, pero para ello necesitan “entrenarse” de previo con una cantidad importante de “muestras” de cada objeto, y a su vez, poder generalizarlo. Nuestra red va a poder reconocer por ejemplo un cierto tipo de célula porque ya la ha “visto” anteriormente muchas veces, pero no solo buscará células semejantes sino que podrá inferir imagenes que no conozca pero que relaciona y en donde podrían existir similitudes, y esta es la parte inteligente del conocimiento.</p>
<p>El reconocimiento de imagénes comienza por la pixelización de una imagen:</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="https://raw.githubusercontent.com/ia4legos/Deeplearning/main/images/imagenpixel001.png" width="650" height="350" class="figure-img"></p>
</figure>
</div>
<p>Podemos hacer los mismo utilizando la descomposición RGB del color:</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="https://raw.githubusercontent.com/ia4legos/Deeplearning/main/images/imagenpixel002.png" width="650" height="450" class="figure-img"></p>
</figure>
</div>
</section>
<section id="aspecto-matemáticos-de-las-convoluciones" class="level2" data-number="5.2">
<h2 data-number="5.2" class="anchored" data-anchor-id="aspecto-matemáticos-de-las-convoluciones"><span class="header-section-number">5.2</span> Aspecto matemáticos de las convoluciones</h2>
<p>Antes de meternos de lleno con las redes, necesitamos comprender bien el concepto de convolución. La convolución es un operador matemático que se define como la integral del producto de dos funciones (<span class="math inline">\(f\)</span> y <span class="math inline">\(g\)</span>) donde una de ellas está desplazada una distancia <span class="math inline">\(t\)</span>:</p>
<p><span class="math display">\[(f*g)(t) =\int_{-\infty}^{\infty} f(x)g(t-x)dx\]</span></p>
<p>Nosotros vamos a adaptar este operador a una versión bidimensional y discreta:</p>
<p><span class="math display">\[(f*g)(i,j) = \sum_{-\infty}^{\infty} \sum_{-\infty}^{\infty} f(x,y)g(i-x,j-y)\]</span></p>
<p>¿Y para qué nos va a servir? Antes habíamos dicho que nuestro cerebro integraba simples estímulos visuales procedentes de cada fotorreceptor de la retina para producir elementos de información cada vez más compleja y elaborada para permitir luego su reconocimiento. Es como decir que para reconocer una cara nuestro sistema visual registra primero fragmentos de la imagen como pupilas, comisuras de labios, lóbulos de orejas… para luego formar ojos, bocas, orejas… para, finalmente, formar caras. Bueno, pues con la operación de convolución vamos a hacer algo así.</p>
<p>Partamos de una imagen cualquiera, tomémosla en escala de grises para que sea algo más sencilla. Por ahora solo tenemos píxeles. ¿Cuáles serían las características más sencillas que podríamos encontrar? Quizá serían las características que encontraríamos en regiones de tamaño 3×3 de la imagen. ¿Qué cabe en una región tan pequeña? Podríamos encontrar un borde vertical, un borde horizontal, una esquina, un punto… cosas así.</p>
<p>En esta situación consideramos como <span class="math inline">\(g\)</span> nuestra imagen. Para ejempificar consideramos una imagen en blanco y negro en una cuadrícula 6x6 como la siguiente:</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="https://raw.githubusercontent.com/ia4legos/Deeplearning/main/images/Convnet001.png" width="350" height="350" class="figure-img"></p>
</figure>
</div>
<p>donde identificamos cada cuadrícula con 0 si hay imagen y con 255 las cuadrículas en blanco (intensidad de píxel), lo que nos porporciona la forma que vemos en la imagen anterior.</p>
<p>En primer lugar vamos a tratar de establecer un detector de bordes verticales, es decir queremos identificar las casilla que se encentran en las filas 1 a 5 de la columna 2. Para ello consideramos la función <span class="math inline">\(f\)</span> que denominmos como kernel con la forma:</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="https://raw.githubusercontent.com/ia4legos/Deeplearning/main/images/Convnet002.png" width="150" height="150" class="figure-img"></p>
</figure>
</div>
<p>y supongamos que queremos calcular la convolución en las coordenadas (2,1) de la imagen (<span class="math inline">\(g\)</span>) mediante el kernel <span class="math inline">\(f\)</span>. Gráficamente se vería como la superposición del kernel sobre la imagen en esas coordendas y multiplicar celda a celda sus correspondientes valores para, finalmente, sumarlo todo. El resultado obtenido es:</p>
<p><img src="https://raw.githubusercontent.com/ia4legos/Deeplearning/main/images/Convnet003.png" data-fig-align="center" width="350" height="350"> El resultado que nos devuelve es 765. Es decir, un valor alto, lo que nos permite identificar el borde vertical de la imagen. Si aplicamos el kernel en las posiciones (1,1), (2,1), (3,1), (4,1), y (5,1) podemos identificar todo el borde vertical de la imagen. De froma algo simialr podemos identificar los bordes horizontales con un kernel:</p>
<pre><code>array([[1., 1., 1.],
       [0., 0., 0.],
       [-1., -1., -1.]])</code></pre>
<p>y los bordes diagonales con un kernel:</p>
<pre><code>array([[2., 1., 0.],
       [1., 0., -1.],
       [0., -1., -2.]])</code></pre>
<p>Estos kernels se puden generalizar a diferentes tipos de imágenes y bordes. La convolución en su versión bidimensional y discretaen estas situaciones se podría definir como:</p>
<p><span class="math display">\[conv2D(i,j) = \sum_{y=0}^{2} \sum_{x=0}^{2} kernel(x,y)imagen(i+x,j+y)\]</span> ## Componentes básicos de una red neuronal</p>
<p>Ahora que tenemos una visión intuitiva sobre cómo clasifican una imagen las redes neuronales convolucionales, vamos a trabajar con el banco de datos DIGITS para mostrar su funcionamiento. A partir de él, introduciremos las dos capas que definen a las redes neuronales convolucionales, que pueden expresarse como grupos de neuronas especializadas en dos operaciones: convolución y pooling.</p>
<section id="operación-de-convolución" class="level3" data-number="5.2.1">
<h3 data-number="5.2.1" class="anchored" data-anchor-id="operación-de-convolución"><span class="header-section-number">5.2.1</span> Operación de convolución</h3>
<p>La diferencia fundamental entre una capa densamente conectada y una capa especializada en la operación de convolución, que llamaremos capa convolucional, es que la capa densa aprende patrones globales en su espacio global de entrada, mientras que la capa convolucional aprende patrones locales dentro de la imagen en pequeñas ventanas de dos dimensiones.</p>
<p>De manera intuitiva, podríamos decir que el propósito principal de una capa convolucional es detectar características o rasgos visuales en las imágenes, como aristas, líneas, gotas de color, etc. Esta es una propiedad muy interesante porque una vez aprendida una característica en un punto concreto de la imagen, la puede reconocer después en cualquier parte de la misma. En cambio, una red neuronal densamente conectada tiene que aprender el patrón nuevamente si este aparece en una nueva localización de la imagen.</p>
<p>Otra característica importante es que las capas convolucionales pueden aprender jerarquías espaciales de patrones. Por ejemplo, una primera capa convolucional puede aprender elementos básicos como aristas, y una segunda capa convolucional puede aprender patrones compuestos de elementos básicos aprendidos en la capa anterior. Y así sucesivamente hasta ir aprendiendo patrones muy complejos. Esto permite que las redes neuronales convolucionales aprendan eficientemente conceptos visuales cada vez más complejos y abstractos.</p>
<p>En general, las capas convoluciones operan sobre tensores 3D, llamados mapas de características (feature maps en inglés), con dos ejes espaciales de altura y anchura (height y width), además de un eje de canal (channels) también llamado profundidad (depth). Para una imagen de color RGB, la dimensión del eje depth es 3, pues la imagen tiene tres canales: rojo, verde y azul (red, green y blue). Para una imagen en blanco y negro, como es el caso de los dígitos MNIST, la dimensión del eje depth es 1 (nivel de gris).</p>
<p>En el caso de MNIST, como entrada en nuestra red neuronal podemos pensar en un espacio de neuronas de dos dimensiones 28 x 28, que transformaremos en un tensor 3D (heíght = 28, width = 28, depth = 1 ), aunque la tercera dimensión en este caso sea de tamaño 1. Una primera capa de neuronas ocultas conectadas a las neuronas de la capa de entrada que hemos comentado realizarán las operaciones convolucionales que acabamos de describir. Pero, como hemos avanzado, no se conectan todas las neuronas de entrada con todas las neuronas de este primer nivel de neuronas ocultas (como en el caso de las redes neuronales densamente conectadas); solo se hace por pequeñas zonas localizadas del espacio de las neuronas de entrada que almacenan los píxeles de la imagen. Visualmente, se podría representar tal como se muestra en la figura siguiente:</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="https://raw.githubusercontent.com/ia4legos/Deeplearning/main/images/Convnet004.png" width="550" height="350" class="figure-img"></p>
</figure>
</div>
<p>En el caso de nuestro ejemplo, cada neurona de la capa oculta será conectada a una pequeña región de 5 x 5 neuronas (es decir, 25 neuronas) de la capa de entrada (de 28 x 28). Intuitivamente, se puede pensar en una ventana del tamaño de 5 x 5 que va recorriendo toda la capa de 28 x 28 que contiene la imagen.</p>
<p>Esta ventana va deslizándose a lo largo de toda la capa de neuronas. Por cada posición de la ventana hay una neurona en la capa oculta que procesa esta información. La ventana empieza en la esquina superior izquierda de la imagen, y esto le da la información necesaria a la primera neurona de la capa oculta.</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="https://raw.githubusercontent.com/ia4legos/Deeplearning/main/images/Convnet005.png" width="550" height="350" class="figure-img"></p>
</figure>
</div>
<p>A continuación, la ventana se desliza una posición hacia la derecha para «conectar» las 5 x 5 neuronas de la capa de entrada incluidas en esta ventana con la segunda neurona de la capa oculta. Y así, sucesivamente, va recorriendo todo el espacio de la capa de entrada, de izquierda a derecha y de arriba abajo.</p>
<p>Analizando un poco el ejemplo concreto que hemos propuesto, observemos que si tenemos una entrada de 28 x 28 píxeles y una ventana de 5 x 5, nos define un espacio de 24 x 24 neuronas en la primera capa oculta, debido a que la ventana solo se puede desplazar 23 neuronas hacia la derecha y 23 hacia abajo antes de chocar con el lado derecho (o inferior) de la imagen de entrada.</p>
<p>Quisiéramos hacer notar al lector o lectora que el supuesto que hemos hecho es que la ventana hace movimientos de avance de 1 píxel en cada paso, tanto en horizontal como en vertical, cuando empieza una nueva fila. Por ello, en cada paso la nueva ventana se solapa con la anterior, excepto en esta línea de píxeles que hemos avanzado. Pero, como veremos en la siguiente sección, en redes neuronales convolucionales se pueden usar diferentes longitudes de pasos de avance (el parámetro llamado stride). En las redes neuronales onvolucionales también se puede aplicar una técnica de relleno de ceros alrededor del margen de la imagen para mejorar el resultado del barrido que se realiza con la ventana que se va deslizando. El parámetro para definir este relleno recibe el nombre de padding, el cual también se presentará con más detalle en la siguiente sección.</p>
<p>En nuestro caso de estudio, y siguiendo el formalismo ya presentado previamente, para «conectar» cada neurona de la capa oculta con las 25 neuronas que le corresponden de la capa de entrada usaremos un valor de sesgo b y una matriz de pesos W de tamaño 5 x 5, que llamaremos filtro (o kernel y filteren inglés). El valor de cada punto de la capa oculta corresponde al producto escalar entre el filtro y el conjunto de 25 neuronas (5 x 5) de la capa de entrada.</p>
<p>Ahora bien, lo particular y muy importante de las redes convolucionales es que se usa el mismo filtro (la misma matriz W de pesos y el mismo sesgo b) para todas las neuronas de la capa oculta: en nuestro caso para las 24 x 24 neuronas (576 neuronas en total) de la primera capa oculta. En este caso concreto, esta compartición reduce de manera drástica el número de parámetros que tendría una red neuronal si no la hiciéramos: pasa de 14400 parámetros que tendrían que ser ajustados (5 x 5 x 24 x 24) a 25 (5 x 5) parámetros más los sesgos b.</p>
<p>Esta matriz de pesos W, compartida con el sesgo b, es similar a los filtros que usamos para retocar imágenes, que en nuestro caso sirven para buscar características locales en pequeños grupos de entradas.</p>
<p>En resumen, una convolución es el tratamiento de una matriz de entrada por otra que llamamos filtro. Pero un filtro definido por una matriz W y un sesgo b solo permiten detectar una característica concreta en una imagen. Por tanto, para poder realizar el reconocimiento de imágenes se propone usar varios filtros a la vez, uno para cada característica que queramos detectar. Por eso una capa convolucional completa en una red neuronal convolucional incluye varios filtros.</p>
<p>Una manera habitual de representar visualmente esta capa convolucional es la que se muestra en la figura siguiente, donde se visualiza que la capa convolucional está compuesta por varios filtros. En nuestro ejemplo proponemos 32 filtros, donde cada filtro se define con una matriz W de pesos compartida de 5 x 5 y un sesgo b. En este ejemplo, la primera capa convolucional recibe un tensor de entrada de tamaño (28, 28, 1) y genera una salida de tamaño (24, 24, 32), un tensor 3D que contiene las 32 salidas de 24 x 24 píxeles resultado de computar los 32 filtros sobre la entrada.</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="https://raw.githubusercontent.com/ia4legos/Deeplearning/main/images/Convnet006.png" width="550" height="350" class="figure-img"></p>
</figure>
</div>
</section>
<section id="operación-de-pooling" class="level3" data-number="5.2.2">
<h3 data-number="5.2.2" class="anchored" data-anchor-id="operación-de-pooling"><span class="header-section-number">5.2.2</span> Operación de pooling</h3>
<p>Además de las capas convolucionales que acabamos de describir, las redes neuronales convolucionales acompañan a la capa de convolución con unas capas de pooling -que podríamos traducir por agrupación-, que suelen ser aplicadas inmediatamente después de las capas convolucionales. Una primera aproximación para entender para qué sirven estas capas es considerar que las capas de pooling hacen una simplificación de la información recogida por la capa convolucional y crean una versión condensada de la información contenida en esta capa.</p>
<p>En nuestro ejemplo de dígitos MNIST, vamos a escoger una ventana de 2 x 2 sobre la capa convolucional y vamos a sintetizar la información en un punto en la capa de pooling. Visualmente, se puede expresar como en la figura siguiente.</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="https://raw.githubusercontent.com/ia4legos/Deeplearning/main/images/Convnet007.png" width="550" height="350" class="figure-img"></p>
</figure>
</div>
<p>Hay varias maneras de condensar la información, pero una habitual y que usaremos es la conocida como max-pooling. Como valor, se queda con el valor máximo de los que había en la ventana de entrada de 2 x 2 que, en nuestro caso, ha «troceado» en 12 x 12 ventanas la capa de pooling. En este caso, se divide por 4 el tamaño de la salida de la capa de pooling en relación a la capa convolucional donde se aplica el pooling, y queda con tamaño de 12 x 12.</p>
<p>También se puede utilizar average-pooling en lugar de max-pooling, donde cada grupo de puntos de entrada se transforma en el valor promedio del grupo de puntos, en vez de su valor máximo. Pero, en general, el max-pooling tiende a funcionar muy bien.</p>
<p>Es interesante remarcar que con la transformación de poo/ing mantenemos la relación espacial. Para verlo visualmente, cojamos el siguiente ejemplo de una matriz de 12 x 12 donde tenemos representado un 7 (imaginemos que los píxeles por los que pasamos por encima contienen un 1 y el resto O; no lo hemos añadido al dibujo para simplificar su visualización). Esto se representa visualmente en la figura siguiente. Si aplicamos una operación de max-pooling con una ventana de 2 x 2 (lo representamos en la matriz central que divide el espacio en un mosaico con regiones del tamaño de la ventana), obtenemos una matriz de 6 x 6 donde se mantiene una representación que nos recuerda sin ninguna duda al número 7 (lo podemos ver en la figura de la derecha, donde hemos marcado en blanco los ceros y en negro los puntos con valor 1 ).</p>
<p><img src="https://raw.githubusercontent.com/ia4legos/Deeplearning/main/images/Convnet008.png" data-fig-align="center" width="550" height="350"> Como hemos mencionado anteriormente, la capa convolucional alberga más de un filtro y, por tanto, como aplicamos el max-pooling a cada uno de estos filtros separadamente, la capa de pooling contendrá tantos filtros de pooling como filtros convolucionales había, tal como se representa en la figura siguiente</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="https://raw.githubusercontent.com/ia4legos/Deeplearning/main/images/Convnet009.png" width="550" height="350" class="figure-img"></p>
</figure>
</div>
<p>La capa convolucíonal alberga 32 filtros y al aplicar el max-pooling a cada uno de ellos separadamente, la capa de pooling contendrá tantos filtros de pooling como filtros convolucionales.</p>
<p>Dado que teníamos un espacio de 24 x 24 neuronas en cada filtro convolucional, después de hacer el pooling tenemos 12 x 12 neuronas, que corresponden a las 12 x 12 regiones de tamaño 2 x 2 que aparecen al dividir el espacio de neuronas del espacio del filtro de la capa convolucional y este por los 32 filtros convolucionales.</p>
</section>
</section>
<section id="implementación-de-modelos-básicos-en-keras" class="level2" data-number="5.3">
<h2 data-number="5.3" class="anchored" data-anchor-id="implementación-de-modelos-básicos-en-keras"><span class="header-section-number">5.3</span> Implementación de modelos básicos en Keras</h2>
<p>Veamos cómo se puede programar este ejemplo de red neuronal convolucional que hemos presentado en Keras. Como hemos comentado, hay varios valores a concretar para parametrizar las capas de convolución y pooling. En nuestro caso, usaremos un modelo simplificado con un stride de 1 en cada dimensión (tamaño del paso con el que desliza la ventana) y un padding de O (en este caso no hay relleno de ceros alrededor de la imagen). Ambos hiperparámetros los presentaremos en la siguiente sección. El pooling que aplicaremos será un max-pooling como el descrito anteriormente con una ventana de 2x2.</p>
<p>En primer lugar cargamos los datos Digits:</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb4"><pre class="sourceCode numberSource r number-lines code-with-copy"><code class="sourceCode r"><span id="cb4-1"><a href="#cb4-1"></a><span class="co"># Cargamos datos</span></span>
<span id="cb4-2"><a href="#cb4-2"></a>mnist <span class="ot">&lt;-</span> keras<span class="sc">::</span><span class="fu">dataset_mnist</span>()</span>
<span id="cb4-3"><a href="#cb4-3"></a><span class="co"># División de muestras entrenamiento y validación</span></span>
<span id="cb4-4"><a href="#cb4-4"></a>x_train <span class="ot">&lt;-</span> mnist<span class="sc">$</span>train<span class="sc">$</span>x</span>
<span id="cb4-5"><a href="#cb4-5"></a>y_train <span class="ot">&lt;-</span> mnist<span class="sc">$</span>train<span class="sc">$</span>y</span>
<span id="cb4-6"><a href="#cb4-6"></a>x_test <span class="ot">&lt;-</span> mnist<span class="sc">$</span>test<span class="sc">$</span>x</span>
<span id="cb4-7"><a href="#cb4-7"></a>y_test <span class="ot">&lt;-</span> mnist<span class="sc">$</span>test<span class="sc">$</span>y</span>
<span id="cb4-8"><a href="#cb4-8"></a><span class="co"># Reescalamos para tener entradas en el intervalo 0-1</span></span>
<span id="cb4-9"><a href="#cb4-9"></a>x_train <span class="ot">&lt;-</span> x_train <span class="sc">/</span> <span class="dv">255</span></span>
<span id="cb4-10"><a href="#cb4-10"></a>x_test <span class="ot">&lt;-</span> x_test <span class="sc">/</span> <span class="dv">255</span></span>
<span id="cb4-11"><a href="#cb4-11"></a><span class="co"># Etiquetas</span></span>
<span id="cb4-12"><a href="#cb4-12"></a>etiquetas <span class="ot">=</span> <span class="dv">0</span><span class="sc">:</span><span class="dv">9</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>Pasamos a implementar nuestra primera red neuronal convolucional, que consistirá en una convolución seguida de un max-pooling. En nuestro caso, tendremos 32 filtros, usaremos una ventana de 5 x 5 para la capa convolucional y una ventana de 2 x 2 para la capa de pooling. Usaremos, por ejemplo, la función de activación ReLU. En este caso, estamos configurando una red neuronal convolucional para procesar un tensor de entrada de tamaño (28, 28, 1 ), que es el tamaño de las imágenes MNIST (el tercer parámetro es el canal de color que, en nuestro caso, es 1), y lo especificamos mediante el valor del argumento input_ shape= (28, 28, 1) en nuestra primera capa. Veamos cómo es el código de Keras:</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb5"><pre class="sourceCode numberSource r number-lines code-with-copy"><code class="sourceCode r"><span id="cb5-1"><a href="#cb5-1"></a><span class="co"># Arquitectura de red</span></span>
<span id="cb5-2"><a href="#cb5-2"></a>mod <span class="ot">=</span> <span class="fu">keras_model_sequential</span>() <span class="sc">%&gt;%</span>  </span>
<span id="cb5-3"><a href="#cb5-3"></a>  <span class="fu">layer_conv_2d</span>(<span class="at">filters =</span> <span class="dv">32</span>, <span class="at">kernel_size =</span> <span class="fu">c</span>(<span class="dv">5</span>, <span class="dv">5</span>), <span class="at">activation=</span><span class="st">'relu'</span>, <span class="at">input_shape=</span><span class="fu">c</span>(<span class="dv">28</span>, <span class="dv">28</span>, <span class="dv">1</span>)) <span class="sc">%&gt;%</span> </span>
<span id="cb5-4"><a href="#cb5-4"></a>  <span class="fu">layer_max_pooling_2d</span>(<span class="at">pool_size =</span> <span class="fu">c</span>(<span class="dv">2</span>, <span class="dv">2</span>)) </span>
<span id="cb5-5"><a href="#cb5-5"></a><span class="fu">summary</span>(mod)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Model: "sequential"
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 conv2d (Conv2D)                    (None, 24, 24, 32)              832         
 max_pooling2d (MaxPooling2D)       (None, 12, 12, 32)              0           
================================================================================
Total params: 832 (3.25 KB)
Trainable params: 832 (3.25 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________</code></pre>
</div>
</div>
<p>El número de parámetros de la capa conv2D corresponde a la matriz de pesos W de 5 x 5; y un sesgo b para cada uno de los filtros es 832 parámetros, como se indica en la salida del método <code>summary()</code> como resultado del cálculo de (32x (25+1)). El max-pooling no requiere parámetros, puesto que es una operación matemática que consiste en encontrar el máximo (solo necesitamos especificar los hiperparámetros que definen el tamaño de la ventana).</p>
<p>Consideramos ahora un modelo algo más complejo.En este caso proponemos dos grupos de capas que tendrá 64 filtros con una ventana de 5x5 en la capa convolucional y una de 2x2 en la capa de pooling. En este caso, el número de canales de entrada tomará el valor de las 32 características que hemos obtenido de la capa anterior aunque, como ya hemos visto anteriormente, no hace falta especificarlo más allá de la primera capa porque Keras lo deduce automáticamente:</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb7"><pre class="sourceCode numberSource r number-lines code-with-copy"><code class="sourceCode r"><span id="cb7-1"><a href="#cb7-1"></a><span class="co"># Arquitectura de red</span></span>
<span id="cb7-2"><a href="#cb7-2"></a>mod1 <span class="ot">=</span> <span class="fu">keras_model_sequential</span>() <span class="sc">%&gt;%</span>  </span>
<span id="cb7-3"><a href="#cb7-3"></a>  <span class="fu">layer_conv_2d</span>(<span class="at">filters =</span> <span class="dv">32</span>, <span class="at">kernel_size =</span> <span class="fu">c</span>(<span class="dv">5</span>, <span class="dv">5</span>), <span class="at">activation=</span><span class="st">'relu'</span>, <span class="at">input_shape=</span><span class="fu">c</span>(<span class="dv">28</span>, <span class="dv">28</span>, <span class="dv">1</span>)) <span class="sc">%&gt;%</span> </span>
<span id="cb7-4"><a href="#cb7-4"></a>  <span class="fu">layer_max_pooling_2d</span>(<span class="at">pool_size =</span> <span class="fu">c</span>(<span class="dv">2</span>, <span class="dv">2</span>)) <span class="sc">%&gt;%</span></span>
<span id="cb7-5"><a href="#cb7-5"></a>  <span class="fu">layer_conv_2d</span>(<span class="at">filters =</span> <span class="dv">64</span>, <span class="at">kernel_size =</span> <span class="fu">c</span>(<span class="dv">5</span>, <span class="dv">5</span>), <span class="at">activation=</span><span class="st">'relu'</span>) <span class="sc">%&gt;%</span> </span>
<span id="cb7-6"><a href="#cb7-6"></a>  <span class="fu">layer_max_pooling_2d</span>(<span class="at">pool_size =</span> <span class="fu">c</span>(<span class="dv">2</span>, <span class="dv">2</span>))</span>
<span id="cb7-7"><a href="#cb7-7"></a><span class="fu">summary</span>(mod1)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Model: "sequential_1"
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 conv2d_2 (Conv2D)                  (None, 24, 24, 32)              832         
 max_pooling2d_2 (MaxPooling2D)     (None, 12, 12, 32)              0           
 conv2d_1 (Conv2D)                  (None, 8, 8, 64)                51264       
 max_pooling2d_1 (MaxPooling2D)     (None, 4, 4, 64)                0           
================================================================================
Total params: 52096 (203.50 KB)
Trainable params: 52096 (203.50 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________</code></pre>
</div>
</div>
<p>En este caso, podemos observar que el tamaño de la segunda capa de convolución resultante es de 8 x 8, dado que ahora partimos de una entrada de 12 x 12, una ventana deslizante de 5 x 5 y un stride de 1. El número de parámetros es 51264 porque la segunda capa tendrá 64 filtros, como hemos especificado en el argumento, con 801 parámetros cada uno: 1 corresponde al sesgo y, luego, tenemos la matriz W de 5x5 para cada una de las 32 entradas. Es decir, el valor 51264 se obtiene del cálculo de ((5 x 5 x 32) + 1) x 64.</p>
<p>En este caso la salida de las capas Conv2D y maxPooling2D es un tensor 3D de forma (height, width, número de filtros). Las dimensiones width y height tienden a reducirse a medida que nos adentramos en las capas ocultas de la red neuronal. El número de filtros es controlado a través del primer argumento pasado a la capa Conv2D.</p>
<p>El siguiente paso, ahora que tenemos 64 filtros de 4 x 4, consiste en añadir una capa densamente conectada, que servirá para alimentar una capa final de softmax para hacer la clasificación final.</p>
<p>Recordemos que antes tenemos que ajustar los tensores a la entrada de la capa densa como la softmax, que es un tensor de 1D, mientras que la salida de la anterior es un tensor de 3D; por eso primero hay que «aplanar» el tensor de 3D a uno de 1D, y Keras nos lo facilita con la capa <code>Flatten</code>. Nuestra salida (4,4,64) se debe pasar a un vector de (1024) antes de aplicar el softmax. Veamos cómo sería el código. En este caso, el número de parámetros de la capa softmax es 1Ox1024+1O, con una salida de un vector de 10:</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb9"><pre class="sourceCode numberSource r number-lines code-with-copy"><code class="sourceCode r"><span id="cb9-1"><a href="#cb9-1"></a><span class="co"># Arquitectura de red</span></span>
<span id="cb9-2"><a href="#cb9-2"></a>modelo <span class="ot">=</span> <span class="fu">keras_model_sequential</span>() <span class="sc">%&gt;%</span>  </span>
<span id="cb9-3"><a href="#cb9-3"></a>  <span class="fu">layer_conv_2d</span>(<span class="at">filters =</span> <span class="dv">32</span>, <span class="at">kernel_size =</span> <span class="fu">c</span>(<span class="dv">5</span>, <span class="dv">5</span>), <span class="at">activation=</span><span class="st">'relu'</span>, <span class="at">input_shape=</span><span class="fu">c</span>(<span class="dv">28</span>, <span class="dv">28</span>, <span class="dv">1</span>)) <span class="sc">%&gt;%</span> </span>
<span id="cb9-4"><a href="#cb9-4"></a>  <span class="fu">layer_max_pooling_2d</span>(<span class="at">pool_size =</span> <span class="fu">c</span>(<span class="dv">2</span>, <span class="dv">2</span>)) <span class="sc">%&gt;%</span></span>
<span id="cb9-5"><a href="#cb9-5"></a>  <span class="fu">layer_conv_2d</span>(<span class="at">filters =</span> <span class="dv">64</span>, <span class="at">kernel_size =</span> <span class="fu">c</span>(<span class="dv">5</span>, <span class="dv">5</span>), <span class="at">activation=</span><span class="st">'relu'</span>) <span class="sc">%&gt;%</span> </span>
<span id="cb9-6"><a href="#cb9-6"></a>  <span class="fu">layer_max_pooling_2d</span>(<span class="at">pool_size =</span> <span class="fu">c</span>(<span class="dv">2</span>, <span class="dv">2</span>)) <span class="sc">%&gt;%</span></span>
<span id="cb9-7"><a href="#cb9-7"></a>  <span class="fu">layer_flatten</span>() <span class="sc">%&gt;%</span></span>
<span id="cb9-8"><a href="#cb9-8"></a>  <span class="fu">layer_dense</span>(<span class="at">units =</span> <span class="dv">10</span>, <span class="at">activation =</span> <span class="st">'softmax'</span>)</span>
<span id="cb9-9"><a href="#cb9-9"></a><span class="fu">summary</span>(modelo)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Model: "sequential_2"
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 conv2d_4 (Conv2D)                  (None, 24, 24, 32)              832         
 max_pooling2d_4 (MaxPooling2D)     (None, 12, 12, 32)              0           
 conv2d_3 (Conv2D)                  (None, 8, 8, 64)                51264       
 max_pooling2d_3 (MaxPooling2D)     (None, 4, 4, 64)                0           
 flatten (Flatten)                  (None, 1024)                    0           
 dense (Dense)                      (None, 10)                      10250       
================================================================================
Total params: 62346 (243.54 KB)
Trainable params: 62346 (243.54 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________</code></pre>
</div>
</div>
<p>Observando este resumen, se aprecia fácilmente que las capas convolucionales requieren memoria para guardar los filtros y memoria para guardar los parámetros aprendidos. Es importante ser consciente de los tamaños de los datos y de los parámetros porque cuando tenemos modelos basados en redes neuronales convolucionales, estos tienen muchas capas, como veremos más adelante, y estos valores pueden dispararse. Una representación más visual de la anterior explicación se muestra en la figura siguiente:</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="https://raw.githubusercontent.com/ia4legos/Deeplearning/main/images/Convnet010.png" width="550" height="350" class="figure-img"></p>
</figure>
</div>
<section id="configuración-entrenamiento-y-evaluación-del-modelo" class="level3" data-number="5.3.1">
<h3 data-number="5.3.1" class="anchored" data-anchor-id="configuración-entrenamiento-y-evaluación-del-modelo"><span class="header-section-number">5.3.1</span> Configuración, entrenamiento y evaluación del modelo</h3>
<p>Una vez definido el modelo de la red neuronal estamos ya en disposición de pasar a entrenar el modelo, es decir, ajustar los parámetros de todas las capas de la red neuronal convolucional. A partir de aquí, para saber cuán bien lo hace nuestro modelo, debemos hacer lo mismo que ya hicimos en apartados anteriores.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb11"><pre class="sourceCode numberSource r number-lines code-with-copy"><code class="sourceCode r"><span id="cb11-1"><a href="#cb11-1"></a>modelo <span class="sc">%&gt;%</span> <span class="fu">compile</span>(</span>
<span id="cb11-2"><a href="#cb11-2"></a>  <span class="at">loss =</span> <span class="st">'sparse_categorical_crossentropy'</span>,</span>
<span id="cb11-3"><a href="#cb11-3"></a>  <span class="at">optimizer =</span> <span class="fu">optimizer_sgd</span>(),</span>
<span id="cb11-4"><a href="#cb11-4"></a>  <span class="at">metrics =</span> <span class="fu">c</span>(<span class="st">'accuracy'</span>)</span>
<span id="cb11-5"><a href="#cb11-5"></a>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>Entrenamos el modelo:</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb12"><pre class="sourceCode numberSource r number-lines code-with-copy"><code class="sourceCode r"><span id="cb12-1"><a href="#cb12-1"></a>history <span class="ot">=</span> modelo <span class="sc">%&gt;%</span> </span>
<span id="cb12-2"><a href="#cb12-2"></a>  <span class="fu">fit</span>(x_train, y_train, <span class="at">batch_size =</span> <span class="dv">100</span>, <span class="at">epochs =</span> <span class="dv">5</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Epoch 1/5
600/600 - 30s - loss: 0.9284 - accuracy: 0.7572 - 30s/epoch - 50ms/step
Epoch 2/5
600/600 - 30s - loss: 0.2572 - accuracy: 0.9242 - 30s/epoch - 49ms/step
Epoch 3/5
600/600 - 30s - loss: 0.1880 - accuracy: 0.9452 - 30s/epoch - 50ms/step
Epoch 4/5
600/600 - 28s - loss: 0.1504 - accuracy: 0.9562 - 28s/epoch - 47ms/step
Epoch 5/5
600/600 - 28s - loss: 0.1263 - accuracy: 0.9634 - 28s/epoch - 46ms/step</code></pre>
</div>
</div>
<p>Los resultados finales del entrenamiento los podemos ver con:</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb14"><pre class="sourceCode numberSource r number-lines code-with-copy"><code class="sourceCode r"><span id="cb14-1"><a href="#cb14-1"></a>history;<span class="fu">plot</span>(history)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>
Final epoch (plot to see history):
    loss: 0.1263
accuracy: 0.9634 </code></pre>
</div>
<div class="cell-output-display">
<p><img src="50_ConvNN_files/figure-html/covnet-008-1.png" class="img-fluid" width="672"></p>
</div>
</div>
<p>Evaluamos el modelo propuesto mediante el porcentaje de clasificación correcta utilizando la muestra de validación.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb16"><pre class="sourceCode numberSource r number-lines code-with-copy"><code class="sourceCode r"><span id="cb16-1"><a href="#cb16-1"></a>modelo <span class="sc">%&gt;%</span> tensorflow<span class="sc">::</span><span class="fu">evaluate</span>(x_test, y_test)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>313/313 - 2s - loss: 0.1068 - accuracy: 0.9680 - 2s/epoch - 5ms/step</code></pre>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>     loss  accuracy 
0.1067661 0.9680000 </code></pre>
</div>
</div>
<p>Tenemos un porcentaje de clasificación superior al 95%, lo que indica una clasificación muy buena.</p>
<p>Completamos la evaluación del modelo obteniendo la tabla de confusión asociada al modelo, y representamos la probabilidad de clasificación predicha de algunas de las muestras de validación. Para poder obtener la matriz de confusión es necesario obtener las predicciones del modelo para la muestra de validación.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb19"><pre class="sourceCode numberSource r number-lines code-with-copy"><code class="sourceCode r"><span id="cb19-1"><a href="#cb19-1"></a><span class="co"># probabilidades de clasificación de cada muestra en cada especie </span></span>
<span id="cb19-2"><a href="#cb19-2"></a>prediccion <span class="ot">=</span> modelo <span class="sc">%&gt;%</span> <span class="fu">predict</span>(x_test)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>313/313 - 2s - 2s/epoch - 5ms/step</code></pre>
</div>
<div class="sourceCode cell-code" id="cb21"><pre class="sourceCode numberSource r number-lines code-with-copy"><code class="sourceCode r"><span id="cb21-1"><a href="#cb21-1"></a><span class="co"># predicción del modelo</span></span>
<span id="cb21-2"><a href="#cb21-2"></a>pr_modelo <span class="ot">=</span> <span class="fu">factor</span>((prediccion <span class="sc">%&gt;%</span> <span class="fu">k_argmax</span>())<span class="sc">$</span><span class="fu">numpy</span>(), <span class="at">levels =</span> <span class="dv">0</span><span class="sc">:</span>(<span class="fu">length</span>(etiquetas)<span class="sc">-</span><span class="dv">1</span>))</span>
<span id="cb21-3"><a href="#cb21-3"></a>pr_test <span class="ot">=</span> <span class="fu">factor</span>(y_test, <span class="at">levels =</span> <span class="dv">0</span><span class="sc">:</span>(<span class="fu">length</span>(etiquetas)<span class="sc">-</span><span class="dv">1</span>))</span>
<span id="cb21-4"><a href="#cb21-4"></a><span class="co"># matriz de confusion</span></span>
<span id="cb21-5"><a href="#cb21-5"></a>cm <span class="ot">&lt;-</span> <span class="fu">confusion_matrix</span>(y_test, pr_modelo, <span class="at">metrics =</span> <span class="fu">list</span>(<span class="st">"Weighted Accuracy"</span> <span class="ot">=</span> <span class="cn">TRUE</span>))</span>
<span id="cb21-6"><a href="#cb21-6"></a><span class="co"># Métrica global</span></span>
<span id="cb21-7"><a href="#cb21-7"></a>cm<span class="sc">$</span><span class="st">`</span><span class="at">Weighted Accuracy</span><span class="st">`</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>[1] 0.9936142</code></pre>
</div>
<div class="sourceCode cell-code" id="cb23"><pre class="sourceCode numberSource r number-lines code-with-copy"><code class="sourceCode r"><span id="cb23-1"><a href="#cb23-1"></a><span class="co"># individuales para cada clase</span></span>
<span id="cb23-2"><a href="#cb23-2"></a>cm[[<span class="dv">3</span>]][[<span class="dv">1</span>]][,<span class="fu">c</span>(<span class="st">"Class"</span>, <span class="st">"Balanced Accuracy"</span>)]</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code># A tibble: 10 × 2
   Class `Balanced Accuracy`
   &lt;chr&gt;               &lt;dbl&gt;
 1 0                   0.993
 2 1                   0.991
 3 2                   0.979
 4 3                   0.987
 5 4                   0.976
 6 5                   0.982
 7 6                   0.983
 8 7                   0.972
 9 8                   0.980
10 9                   0.978</code></pre>
</div>
</div>
<p>La clasifiación ponderada muestra valores muy próximos a 1 indicando muy buena clasificación. Veamos la tabla de cofusión de forma gráfica.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb25"><pre class="sourceCode numberSource r number-lines code-with-copy"><code class="sourceCode r"><span id="cb25-1"><a href="#cb25-1"></a><span class="fu">plot_confusion_matrix</span>(cm<span class="sc">$</span><span class="st">`</span><span class="at">Confusion Matrix</span><span class="st">`</span>[[<span class="dv">1</span>]])</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output-display">
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="50_ConvNN_files/figure-html/covnet-011-1.png" class="img-fluid figure-img" width="960"></p>
<p></p><figcaption class="figure-caption">Matriz de confusión</figcaption><p></p>
</figure>
</div>
</div>
</div>
</section>
<section id="hiperparámetros-de-la-capa-convolucional" class="level3" data-number="5.3.2">
<h3 data-number="5.3.2" class="anchored" data-anchor-id="hiperparámetros-de-la-capa-convolucional"><span class="header-section-number">5.3.2</span> Hiperparámetros de la capa convolucional</h3>
<p>Los principales hiperparámetros de las redes neuronales convolucionales son el tamaño de la ventana del filtro, el número de filtros, el tamaño del paso de avance (stride) y el relleno (padding). Pasemos a presentar con más detalle cada uno de ellos.</p>
<section id="tamaño-de-los-filtros" class="level4" data-number="5.3.2.1">
<h4 data-number="5.3.2.1" class="anchored" data-anchor-id="tamaño-de-los-filtros"><span class="header-section-number">5.3.2.1</span> Tamaño de los filtros</h4>
<p>El tamaño de la ventana (window_height x window_width) que contiene información de píxeles cercanos espacialmente habitualmente es de 3 x 3 o 5 x 5. El número de filtros que nos indica el número de características que queremos manejar (output_depth) acostumbra a ser de 32 o 64. En las capas Conv2D de Keras estos hiperparámetros son los que pasamos como argumentos en este orden:</p>
<pre><code>layer_conv_2d(filters = output_depth, kernel_size = c(window_height, window_width), ...) </code></pre>
</section>
<section id="padding" class="level4" data-number="5.3.2.2">
<h4 data-number="5.3.2.2" class="anchored" data-anchor-id="padding"><span class="header-section-number">5.3.2.2</span> Padding</h4>
<p>Para explicar el concepto de relleno (padding) usaremos un ejemplo. Supongamos una imagen con 5x5 píxeles. Si elegimos una ventana de 3x3 para realizar la convolución, vemos que el tensor resultante de la operación es de tamaño 3x3. Es decir, se encoge exactamente dos píxeles por cada dimensión, en este caso. En la Figura siguiente se muestra visualmente. Supongamos que la figura de la izquierda es la imagen de 5 x 5. En ella hemos enumerado los píxeles para facilitar el seguimiento de los movimientos de la ventana de 3 x 3 para calcular los elementos del filtro. En el centro vemos cómo la ventana de 3 x 3 se ha desplazado por la imagen, dos veces hacia la derecha y dos posiciones hacia abajo. El resultado de aplicar la operación de convolución nos devuelve el filtro que hemos representado a la izquierda. Cada elemento de este filtro está etiquetado con una letra que lo asocia al contenido de la ventana deslizante con el que se calcula su valor.</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="https://raw.githubusercontent.com/ia4legos/Deeplearning/main/images/Convnet011.png" width="550" height="350" class="figure-img"></p>
</figure>
</div>
<p>Este mismo efecto se puede observar en el ejemplo de red neuronal convolucional que estamos creando en este capítulo. Comenzamos con una imagen de entrada 28x28x1; los filtros resultantes son de 24x24x1 después de la primera capa de convolución. En la segunda capa de convolución, pasamos de un tensor 12x12x1 a uno 8x8x1.</p>
<p>Pero a veces queremos obteenr un tensor de salida de las mismas dimensiones de entrada; podemos usar para ello el hiperparámetro <code>padding</code> en las capas convolucionales. Con padding podemos agregar ceros (zero-padding en inglés) alrededor de las imágenes de entrada antes de hacer desizr la ventana por ella. En nuestro caso de la figura anterior, podemos añadir a la imagen de entrada una columna a la derecha, una columna a la izquierda, una fila arriba y una fila debajo de ceros. Visualmente se puede visualizar enla figura siguiente:</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="https://raw.githubusercontent.com/ia4legos/Deeplearning/main/images/Convnet012.png" width="200" height="200" class="figure-img"></p>
</figure>
</div>
<p>Si ahora deslizamos la ventana de 3x3, vemos que puede desplazarse cuatro veces hacia a la derecha y cuatro hacia abajo, generando las 25 ventanas que generan el filtro de tamaño 5x5 (figura siguiente).</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="https://raw.githubusercontent.com/ia4legos/Deeplearning/main/images/Convnet013.png" width="450" height="450" class="figure-img"></p>
</figure>
</div>
<p>En Keras, este relleno con ceros en la capa Conv2D se configura con el argumento <code>padding</code>, que puede tener dos valores: <code>same</code>, que implica que se añadan tantas filas y columnas de ceros como sea necesario para que la salida tenga la misma dimensión que la entrada, y <code>valid</code>, que implica no hacer padding (que es el valor por defecto de este argumento en Keras).</p>
</section>
<section id="stride" class="level4" data-number="5.3.2.3">
<h4 data-number="5.3.2.3" class="anchored" data-anchor-id="stride"><span class="header-section-number">5.3.2.3</span> Stride</h4>
<p>Otro hiperparámetro que podemos especificar en una capa convolucional es el <code>stride</code>, que nos indica el número de pasos en que se mueve la ventada de los filtros. En el anterior ejemplo el stride era de 1, el valor por defecto.</p>
<p>Valores de stride grandes hacen decrecer el tamaño de la información que pasará a la siguiente capa. En la siguiente podemos ver el mismo ejemplo anterior pero ahora con un valor de stride de 2.</p>
<p><img src="https://raw.githubusercontent.com/ia4legos/Deeplearning/main/images/Convnet014.png" data-fig-align="center" width="550" height="250"> Como vemos, la imagen de 5x5 se ha convertido en un filtro de tamaño más reducido de 2x2. Pero, en la práctica, los strides son raramente utilizados en convolucionales para reducir los tamaños; para ello se usan las operaciones de pooling que hemos presentado antes. En Keras, el stride en la capa conv2D se configura con el argumento stride que tiene por defecto el valor <code>strides = ( 1, 1)</code> que indica por separado el avance en las dos dimensiones.</p>
<p>Antes de presenatr un nuevo conjunto de datos vamos a plantear un modelo de red mucho más complejo para el conjnto de datos digits. En concreto, vamos a intercalar varias capas dropout y nueva capa dense antes de la capa de salida.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb27"><pre class="sourceCode numberSource r number-lines code-with-copy"><code class="sourceCode r"><span id="cb27-1"><a href="#cb27-1"></a><span class="co"># Arquitectura de red</span></span>
<span id="cb27-2"><a href="#cb27-2"></a>modelo <span class="ot">=</span> <span class="fu">keras_model_sequential</span>() <span class="sc">%&gt;%</span>  </span>
<span id="cb27-3"><a href="#cb27-3"></a>  <span class="fu">layer_conv_2d</span>(<span class="at">filters =</span> <span class="dv">32</span>, <span class="at">kernel_size =</span> <span class="fu">c</span>(<span class="dv">5</span>, <span class="dv">5</span>), <span class="at">activation=</span><span class="st">'relu'</span>, <span class="at">input_shape=</span><span class="fu">c</span>(<span class="dv">28</span>, <span class="dv">28</span>, <span class="dv">1</span>)) <span class="sc">%&gt;%</span> </span>
<span id="cb27-4"><a href="#cb27-4"></a>  <span class="fu">layer_max_pooling_2d</span>(<span class="at">pool_size =</span> <span class="fu">c</span>(<span class="dv">2</span>, <span class="dv">2</span>)) <span class="sc">%&gt;%</span></span>
<span id="cb27-5"><a href="#cb27-5"></a>  <span class="fu">layer_conv_2d</span>(<span class="at">filters =</span> <span class="dv">64</span>, <span class="at">kernel_size =</span> <span class="fu">c</span>(<span class="dv">5</span>, <span class="dv">5</span>), <span class="at">activation=</span><span class="st">'relu'</span>) <span class="sc">%&gt;%</span> </span>
<span id="cb27-6"><a href="#cb27-6"></a>  <span class="fu">layer_max_pooling_2d</span>(<span class="at">pool_size =</span> <span class="fu">c</span>(<span class="dv">2</span>, <span class="dv">2</span>)) <span class="sc">%&gt;%</span></span>
<span id="cb27-7"><a href="#cb27-7"></a>  <span class="fu">layer_dropout</span>(<span class="fl">0.25</span>) <span class="sc">%&gt;%</span></span>
<span id="cb27-8"><a href="#cb27-8"></a>  <span class="fu">layer_flatten</span>() <span class="sc">%&gt;%</span></span>
<span id="cb27-9"><a href="#cb27-9"></a>  <span class="fu">layer_dense</span>(<span class="at">units =</span> <span class="dv">128</span>, <span class="at">activation =</span> <span class="st">'relu'</span>) <span class="sc">%&gt;%</span> </span>
<span id="cb27-10"><a href="#cb27-10"></a>  <span class="fu">layer_dropout</span>(<span class="at">rate =</span> <span class="fl">0.5</span>) <span class="sc">%&gt;%</span> </span>
<span id="cb27-11"><a href="#cb27-11"></a>  <span class="fu">layer_dense</span>(<span class="at">units =</span> <span class="dv">10</span>, <span class="at">activation =</span> <span class="st">'softmax'</span>)</span>
<span id="cb27-12"><a href="#cb27-12"></a><span class="fu">summary</span>(modelo)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Model: "sequential_3"
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 conv2d_6 (Conv2D)                  (None, 24, 24, 32)              832         
 max_pooling2d_6 (MaxPooling2D)     (None, 12, 12, 32)              0           
 conv2d_5 (Conv2D)                  (None, 8, 8, 64)                51264       
 max_pooling2d_5 (MaxPooling2D)     (None, 4, 4, 64)                0           
 dropout_1 (Dropout)                (None, 4, 4, 64)                0           
 flatten_1 (Flatten)                (None, 1024)                    0           
 dense_2 (Dense)                    (None, 128)                     131200      
 dropout (Dropout)                  (None, 128)                     0           
 dense_1 (Dense)                    (None, 10)                      1290        
================================================================================
Total params: 184586 (721.04 KB)
Trainable params: 184586 (721.04 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________</code></pre>
</div>
</div>
<p>El modelo tiene 184586 parámetros que debemos estimar. Configuramos el aprendizaje y entrenamos el modelo con 10 epochs y porcentaje de validación del 20%:</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb29"><pre class="sourceCode numberSource r number-lines code-with-copy"><code class="sourceCode r"><span id="cb29-1"><a href="#cb29-1"></a><span class="co"># Proceso de aprendizaje</span></span>
<span id="cb29-2"><a href="#cb29-2"></a>modelo <span class="sc">%&gt;%</span> <span class="fu">compile</span>(</span>
<span id="cb29-3"><a href="#cb29-3"></a>  <span class="at">loss =</span> <span class="st">'sparse_categorical_crossentropy'</span>,</span>
<span id="cb29-4"><a href="#cb29-4"></a>  <span class="at">optimizer =</span> <span class="fu">optimizer_sgd</span>(),</span>
<span id="cb29-5"><a href="#cb29-5"></a>  <span class="at">metrics =</span> <span class="fu">c</span>(<span class="st">'accuracy'</span>))</span>
<span id="cb29-6"><a href="#cb29-6"></a></span>
<span id="cb29-7"><a href="#cb29-7"></a><span class="co"># Entrenamiento </span></span>
<span id="cb29-8"><a href="#cb29-8"></a>history <span class="ot">=</span> modelo <span class="sc">%&gt;%</span> </span>
<span id="cb29-9"><a href="#cb29-9"></a>  <span class="fu">fit</span>(x_train, y_train, <span class="at">batch_size =</span> <span class="dv">100</span>, <span class="at">epochs =</span> <span class="dv">10</span>, <span class="at">validation_split =</span> <span class="fl">0.2</span>)  </span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Epoch 1/10
480/480 - 28s - loss: 1.4229 - accuracy: 0.5363 - val_loss: 0.3882 - val_accuracy: 0.9025 - 28s/epoch - 59ms/step
Epoch 2/10
480/480 - 27s - loss: 0.5086 - accuracy: 0.8439 - val_loss: 0.2120 - val_accuracy: 0.9404 - 27s/epoch - 57ms/step
Epoch 3/10
480/480 - 27s - loss: 0.3581 - accuracy: 0.8925 - val_loss: 0.1628 - val_accuracy: 0.9525 - 27s/epoch - 57ms/step
Epoch 4/10
480/480 - 30s - loss: 0.2871 - accuracy: 0.9153 - val_loss: 0.1368 - val_accuracy: 0.9586 - 30s/epoch - 62ms/step
Epoch 5/10
480/480 - 29s - loss: 0.2465 - accuracy: 0.9263 - val_loss: 0.1203 - val_accuracy: 0.9629 - 29s/epoch - 60ms/step
Epoch 6/10
480/480 - 29s - loss: 0.2186 - accuracy: 0.9352 - val_loss: 0.1082 - val_accuracy: 0.9671 - 29s/epoch - 60ms/step
Epoch 7/10
480/480 - 28s - loss: 0.2013 - accuracy: 0.9387 - val_loss: 0.1010 - val_accuracy: 0.9694 - 28s/epoch - 57ms/step
Epoch 8/10
480/480 - 28s - loss: 0.1798 - accuracy: 0.9456 - val_loss: 0.0935 - val_accuracy: 0.9701 - 28s/epoch - 58ms/step
Epoch 9/10
480/480 - 28s - loss: 0.1721 - accuracy: 0.9482 - val_loss: 0.0889 - val_accuracy: 0.9735 - 28s/epoch - 59ms/step
Epoch 10/10
480/480 - 27s - loss: 0.1599 - accuracy: 0.9519 - val_loss: 0.0837 - val_accuracy: 0.9744 - 27s/epoch - 57ms/step</code></pre>
</div>
</div>
<p>Los resultados finales del entrenamiento los podemos ver con:</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb31"><pre class="sourceCode numberSource r number-lines code-with-copy"><code class="sourceCode r"><span id="cb31-1"><a href="#cb31-1"></a>history;<span class="fu">plot</span>(history)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>
Final epoch (plot to see history):
        loss: 0.1599
    accuracy: 0.9519
    val_loss: 0.08372
val_accuracy: 0.9744 </code></pre>
</div>
<div class="cell-output-display">
<p><img src="50_ConvNN_files/figure-html/covnet-014-1.png" class="img-fluid" width="672"></p>
</div>
</div>
<p>Evaluamos el modelo propuesto mediante el porcentaje de clasificación correcta utilizando la muestra de validación.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb33"><pre class="sourceCode numberSource r number-lines code-with-copy"><code class="sourceCode r"><span id="cb33-1"><a href="#cb33-1"></a>modelo <span class="sc">%&gt;%</span> tensorflow<span class="sc">::</span><span class="fu">evaluate</span>(x_test, y_test)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>313/313 - 2s - loss: 0.0763 - accuracy: 0.9772 - 2s/epoch - 5ms/step</code></pre>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>      loss   accuracy 
0.07634594 0.97719997 </code></pre>
</div>
</div>
<p>El porcentaje de clasificación sigue siendo muy alto. En este caso no obtenemos la matriz de confusión porque los resultados son muy similares.</p>
</section>
</section>
</section>
<section id="conjunto-de-datos-fashion-minst" class="level2" data-number="5.4">
<h2 data-number="5.4" class="anchored" data-anchor-id="conjunto-de-datos-fashion-minst"><span class="header-section-number">5.4</span> Conjunto de datos Fashion-minst</h2>
<p>Llegados a este punto, vamos a presentar el conjunto de datos Fashion-­MNIST sobre el que vamos hacer una análisis completo utilizando diferentes modelos de redes convolucionales. Fashion-MNIST es un conjunto de datos de las imágenes de los artículos de Zalando, una tienda de moda online alemana especializada en venta de ropa y zapatos. El conjunto de datos contiene 70000 imágenes en escala de grises en 10 categorías. Las imágenes muestran prendas individuales de ropa en baja resolución (28x28 píxeles). Se usan 60000 imágenes para entrenar la red y 10000 imágenes para evaluar la precisión con la que la red aprende a clasificar las imágenes.</p>
<p>En primer lugar cargamos los datos:</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb36"><pre class="sourceCode numberSource r number-lines code-with-copy"><code class="sourceCode r"><span id="cb36-1"><a href="#cb36-1"></a><span class="co"># Cargamos datos</span></span>
<span id="cb36-2"><a href="#cb36-2"></a>fashion <span class="ot">=</span> keras<span class="sc">::</span><span class="fu">dataset_fashion_mnist</span>()</span>
<span id="cb36-3"><a href="#cb36-3"></a></span>
<span id="cb36-4"><a href="#cb36-4"></a><span class="co"># División de muestras entrenamiento y validación</span></span>
<span id="cb36-5"><a href="#cb36-5"></a>x_train <span class="ot">=</span> fashion<span class="sc">$</span>train<span class="sc">$</span>x</span>
<span id="cb36-6"><a href="#cb36-6"></a>y_train <span class="ot">=</span> fashion<span class="sc">$</span>train<span class="sc">$</span>y</span>
<span id="cb36-7"><a href="#cb36-7"></a>x_test <span class="ot">=</span> fashion<span class="sc">$</span>test<span class="sc">$</span>x</span>
<span id="cb36-8"><a href="#cb36-8"></a>y_test <span class="ot">=</span> fashion<span class="sc">$</span>test<span class="sc">$</span>y</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>Igual que en el ejemplo anterior, la carga del conjunto de datos devuelve cuatro matrices. Las matrices train son el conjunto de entrenamiento (inputs y outputs). Las matrices test son el conjunto de prueba (inputs y outputs) para evaluar la precisión del modelo. Las imágenes son matrices de 28 x 28 píxeles, con valores que van de O a 255. Las etiquetas son una matriz de enteros, que van de O a 9. Estos corresponden a la clase de ropa que representa la imagen:</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb37"><pre class="sourceCode numberSource r number-lines code-with-copy"><code class="sourceCode r"><span id="cb37-1"><a href="#cb37-1"></a><span class="co"># Etiquetas</span></span>
<span id="cb37-2"><a href="#cb37-2"></a>etiquetas <span class="ot">=</span> <span class="fu">c</span>(<span class="st">'T-shirt/top'</span>, <span class="st">'Trouser'</span>, <span class="st">'Pullover'</span>, <span class="st">'Dress'</span>, <span class="st">'Coat'</span>, <span class="st">'Sandal'</span>, <span class="st">'Shirt'</span>, <span class="st">'Sneaker'</span>, <span class="st">'Bag'</span>, <span class="st">'Ankle boot'</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>Igual que en e ejemplo de digits vamos a escalr los valores de entrada en el rango 0-1:</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb38"><pre class="sourceCode numberSource r number-lines code-with-copy"><code class="sourceCode r"><span id="cb38-1"><a href="#cb38-1"></a><span class="co"># Reescalamos para tener entradas en el intervalo 0-1</span></span>
<span id="cb38-2"><a href="#cb38-2"></a>x_train <span class="ot">&lt;-</span> x_train <span class="sc">/</span> <span class="dv">255</span></span>
<span id="cb38-3"><a href="#cb38-3"></a>x_test <span class="ot">&lt;-</span> x_test <span class="sc">/</span> <span class="dv">255</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>Para poder representar la información contenida en cada uno de la matrices de entrenamiento definimos una función que nos permite su representación gráfica:</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb39"><pre class="sourceCode numberSource r number-lines code-with-copy"><code class="sourceCode r"><span id="cb39-1"><a href="#cb39-1"></a>imagen <span class="ot">=</span> <span class="cf">function</span>(i, xtr, ytr, eti)</span>
<span id="cb39-2"><a href="#cb39-2"></a>{</span>
<span id="cb39-3"><a href="#cb39-3"></a>  <span class="co"># Función pra representa la imagen contenida en una matriz de datos 28*28</span></span>
<span id="cb39-4"><a href="#cb39-4"></a>  <span class="co">#</span></span>
<span id="cb39-5"><a href="#cb39-5"></a>  <span class="co"># Valores de entrada</span></span>
<span id="cb39-6"><a href="#cb39-6"></a>  <span class="co">#   i : muestra</span></span>
<span id="cb39-7"><a href="#cb39-7"></a>  <span class="co">#   xtr: matriz de datos de entrada</span></span>
<span id="cb39-8"><a href="#cb39-8"></a>  <span class="co">#   ytr: vector de outputs</span></span>
<span id="cb39-9"><a href="#cb39-9"></a>  <span class="co">#   eti: vector de etiquetas de las muestras</span></span>
<span id="cb39-10"><a href="#cb39-10"></a>  <span class="co">#</span></span>
<span id="cb39-11"><a href="#cb39-11"></a>  <span class="co"># Devuelve la imagen correspondiente a xtr[i] con la etiqueta eti[ytr[i]]</span></span>
<span id="cb39-12"><a href="#cb39-12"></a>  </span>
<span id="cb39-13"><a href="#cb39-13"></a>  img <span class="ot">=</span> xtr[i, , ]</span>
<span id="cb39-14"><a href="#cb39-14"></a>  img <span class="ot">=</span> <span class="fu">t</span>(<span class="fu">apply</span>(img, <span class="dv">2</span>, rev)) </span>
<span id="cb39-15"><a href="#cb39-15"></a>  <span class="fu">image</span>(<span class="dv">1</span><span class="sc">:</span><span class="dv">28</span>, <span class="dv">1</span><span class="sc">:</span><span class="dv">28</span>, img, <span class="at">col =</span> <span class="fu">gray</span>((<span class="dv">0</span><span class="sc">:</span><span class="dv">255</span>)<span class="sc">/</span><span class="dv">255</span>), </span>
<span id="cb39-16"><a href="#cb39-16"></a>        <span class="at">xaxt =</span> <span class="st">'n'</span>, <span class="at">yaxt =</span> <span class="st">'n'</span>,</span>
<span id="cb39-17"><a href="#cb39-17"></a>        <span class="at">main =</span> <span class="fu">paste</span>(eti[ytr[i] <span class="sc">+</span> <span class="dv">1</span>]), <span class="at">xlab=</span><span class="st">""</span>,<span class="at">ylab=</span><span class="st">""</span>)</span>
<span id="cb39-18"><a href="#cb39-18"></a>}</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>Veamos el resultado de las primeras 25 muestras de entrenamiento:</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb40"><pre class="sourceCode numberSource r number-lines code-with-copy"><code class="sourceCode r"><span id="cb40-1"><a href="#cb40-1"></a><span class="fu">par</span>(<span class="at">mfrow=</span><span class="fu">c</span>(<span class="dv">3</span>, <span class="dv">3</span>))</span>
<span id="cb40-2"><a href="#cb40-2"></a><span class="fu">par</span>(<span class="at">mar=</span><span class="fu">c</span>(<span class="fl">0.5</span>, <span class="fl">0.5</span>, <span class="dv">2</span>, <span class="fl">0.5</span>), <span class="at">xaxs=</span><span class="st">'i'</span>, <span class="at">yaxs=</span><span class="st">'i'</span>)</span>
<span id="cb40-3"><a href="#cb40-3"></a><span class="cf">for</span>(i <span class="cf">in</span> <span class="dv">1</span><span class="sc">:</span><span class="dv">9</span>)</span>
<span id="cb40-4"><a href="#cb40-4"></a>{</span>
<span id="cb40-5"><a href="#cb40-5"></a>  <span class="fu">imagen</span>(i, x_train, y_train, etiquetas)</span>
<span id="cb40-6"><a href="#cb40-6"></a>}</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output-display">
<p><img src="50_ConvNN_files/figure-html/covnet-020-1.png" class="img-fluid" width="672"></p>
</div>
</div>
<section id="modelo-inicial" class="level3" data-number="5.4.1">
<h3 data-number="5.4.1" class="anchored" data-anchor-id="modelo-inicial"><span class="header-section-number">5.4.1</span> Modelo inicial</h3>
<p>Consideremos como punto de partida usar la misma red en la que hemos clasificado los dígitos MNIST en la sección anterior:</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb41"><pre class="sourceCode numberSource r number-lines code-with-copy"><code class="sourceCode r"><span id="cb41-1"><a href="#cb41-1"></a><span class="co"># Arquitectura de red</span></span>
<span id="cb41-2"><a href="#cb41-2"></a>mod1 <span class="ot">=</span> <span class="fu">keras_model_sequential</span>() <span class="sc">%&gt;%</span>  </span>
<span id="cb41-3"><a href="#cb41-3"></a>  <span class="fu">layer_conv_2d</span>(<span class="at">filters =</span> <span class="dv">32</span>, <span class="at">kernel_size =</span> <span class="fu">c</span>(<span class="dv">5</span>, <span class="dv">5</span>), <span class="at">activation=</span><span class="st">'relu'</span>, <span class="at">input_shape=</span><span class="fu">c</span>(<span class="dv">28</span>, <span class="dv">28</span>, <span class="dv">1</span>)) <span class="sc">%&gt;%</span> </span>
<span id="cb41-4"><a href="#cb41-4"></a>  <span class="fu">layer_max_pooling_2d</span>(<span class="at">pool_size =</span> <span class="fu">c</span>(<span class="dv">2</span>, <span class="dv">2</span>)) <span class="sc">%&gt;%</span></span>
<span id="cb41-5"><a href="#cb41-5"></a>  <span class="fu">layer_conv_2d</span>(<span class="at">filters =</span> <span class="dv">64</span>, <span class="at">kernel_size =</span> <span class="fu">c</span>(<span class="dv">5</span>, <span class="dv">5</span>), <span class="at">activation=</span><span class="st">'relu'</span>) <span class="sc">%&gt;%</span> </span>
<span id="cb41-6"><a href="#cb41-6"></a>  <span class="fu">layer_max_pooling_2d</span>(<span class="at">pool_size =</span> <span class="fu">c</span>(<span class="dv">2</span>, <span class="dv">2</span>)) <span class="sc">%&gt;%</span></span>
<span id="cb41-7"><a href="#cb41-7"></a>  <span class="fu">layer_flatten</span>() <span class="sc">%&gt;%</span></span>
<span id="cb41-8"><a href="#cb41-8"></a>  <span class="fu">layer_dense</span>(<span class="at">units =</span> <span class="dv">10</span>, <span class="at">activation =</span> <span class="st">'softmax'</span>)</span>
<span id="cb41-9"><a href="#cb41-9"></a><span class="fu">summary</span>(mod1)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Model: "sequential_4"
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 conv2d_8 (Conv2D)                  (None, 24, 24, 32)              832         
 max_pooling2d_8 (MaxPooling2D)     (None, 12, 12, 32)              0           
 conv2d_7 (Conv2D)                  (None, 8, 8, 64)                51264       
 max_pooling2d_7 (MaxPooling2D)     (None, 4, 4, 64)                0           
 flatten_2 (Flatten)                (None, 1024)                    0           
 dense_3 (Dense)                    (None, 10)                      10250       
================================================================================
Total params: 62346 (243.54 KB)
Trainable params: 62346 (243.54 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________</code></pre>
</div>
</div>
<p>Procedemos con la configuración del proceso de aprendizaje y el entrenamiento del modelo. Debido al coste computacional consideramos un batch pequeño y tan solo 5 epochs.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb43"><pre class="sourceCode numberSource r number-lines code-with-copy"><code class="sourceCode r"><span id="cb43-1"><a href="#cb43-1"></a><span class="co"># Proceso de aprendizaje</span></span>
<span id="cb43-2"><a href="#cb43-2"></a>mod1 <span class="sc">%&gt;%</span> <span class="fu">compile</span>(</span>
<span id="cb43-3"><a href="#cb43-3"></a>  <span class="at">loss =</span> <span class="st">'sparse_categorical_crossentropy'</span>,</span>
<span id="cb43-4"><a href="#cb43-4"></a>  <span class="at">optimizer =</span> <span class="fu">optimizer_sgd</span>(),</span>
<span id="cb43-5"><a href="#cb43-5"></a>  <span class="at">metrics =</span> <span class="fu">c</span>(<span class="st">'accuracy'</span>))</span>
<span id="cb43-6"><a href="#cb43-6"></a></span>
<span id="cb43-7"><a href="#cb43-7"></a><span class="co"># Entrenamiento </span></span>
<span id="cb43-8"><a href="#cb43-8"></a>hist1 <span class="ot">=</span> mod1 <span class="sc">%&gt;%</span> </span>
<span id="cb43-9"><a href="#cb43-9"></a>  <span class="fu">fit</span>(x_train, y_train, <span class="at">batch_size =</span> <span class="dv">50</span>, <span class="at">epochs =</span> <span class="dv">5</span>, <span class="at">validation_split =</span> <span class="fl">0.2</span>)  </span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Epoch 1/5
960/960 - 26s - loss: 1.0396 - accuracy: 0.6353 - val_loss: 0.6411 - val_accuracy: 0.7597 - 26s/epoch - 28ms/step
Epoch 2/5
960/960 - 26s - loss: 0.5993 - accuracy: 0.7815 - val_loss: 0.5608 - val_accuracy: 0.7986 - 26s/epoch - 27ms/step
Epoch 3/5
960/960 - 27s - loss: 0.5214 - accuracy: 0.8118 - val_loss: 0.4965 - val_accuracy: 0.8231 - 27s/epoch - 28ms/step
Epoch 4/5
960/960 - 26s - loss: 0.4757 - accuracy: 0.8296 - val_loss: 0.4659 - val_accuracy: 0.8325 - 26s/epoch - 27ms/step
Epoch 5/5
960/960 - 27s - loss: 0.4462 - accuracy: 0.8418 - val_loss: 0.4446 - val_accuracy: 0.8391 - 27s/epoch - 28ms/step</code></pre>
</div>
</div>
<p>Evaluamos la capacidad de clasificación del modelo propuesto sobre la muestra de validación:</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb45"><pre class="sourceCode numberSource r number-lines code-with-copy"><code class="sourceCode r"><span id="cb45-1"><a href="#cb45-1"></a><span class="co"># Proceso de aprendizaje</span></span>
<span id="cb45-2"><a href="#cb45-2"></a>mod1 <span class="sc">%&gt;%</span> tensorflow<span class="sc">::</span><span class="fu">evaluate</span>(x_test, y_test)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>313/313 - 2s - loss: 0.4584 - accuracy: 0.8367 - 2s/epoch - 5ms/step</code></pre>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>     loss  accuracy 
0.4584489 0.8367000 </code></pre>
</div>
</div>
<p>El porcentaje de clasificación correcta es del 85% par el modelo propuesto. Aunque no es exageradamente bueno debemos tener en cuenta que el modleo es muy simple.</p>
</section>
<section id="modelo-2" class="level3" data-number="5.4.2">
<h3 data-number="5.4.2" class="anchored" data-anchor-id="modelo-2"><span class="header-section-number">5.4.2</span> Modelo 2</h3>
<p>En este caso duplicamos las neuronas por capa del modelo base y añadimosuna capa densa de 64 neuronas.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb48"><pre class="sourceCode numberSource r number-lines code-with-copy"><code class="sourceCode r"><span id="cb48-1"><a href="#cb48-1"></a><span class="co"># Arquitectura de red</span></span>
<span id="cb48-2"><a href="#cb48-2"></a>mod2 <span class="ot">=</span> <span class="fu">keras_model_sequential</span>() <span class="sc">%&gt;%</span>  </span>
<span id="cb48-3"><a href="#cb48-3"></a>  <span class="fu">layer_conv_2d</span>(<span class="at">filters =</span> <span class="dv">64</span>, <span class="at">kernel_size =</span> <span class="fu">c</span>(<span class="dv">5</span>, <span class="dv">5</span>), <span class="at">activation=</span><span class="st">'relu'</span>, <span class="at">input_shape=</span><span class="fu">c</span>(<span class="dv">28</span>, <span class="dv">28</span>, <span class="dv">1</span>)) <span class="sc">%&gt;%</span> </span>
<span id="cb48-4"><a href="#cb48-4"></a>  <span class="fu">layer_max_pooling_2d</span>(<span class="at">pool_size =</span> <span class="fu">c</span>(<span class="dv">2</span>, <span class="dv">2</span>)) <span class="sc">%&gt;%</span></span>
<span id="cb48-5"><a href="#cb48-5"></a>  <span class="fu">layer_conv_2d</span>(<span class="at">filters =</span> <span class="dv">128</span>, <span class="at">kernel_size =</span> <span class="fu">c</span>(<span class="dv">5</span>, <span class="dv">5</span>), <span class="at">activation=</span><span class="st">'relu'</span>) <span class="sc">%&gt;%</span> </span>
<span id="cb48-6"><a href="#cb48-6"></a>  <span class="fu">layer_max_pooling_2d</span>(<span class="at">pool_size =</span> <span class="fu">c</span>(<span class="dv">2</span>, <span class="dv">2</span>)) <span class="sc">%&gt;%</span></span>
<span id="cb48-7"><a href="#cb48-7"></a>  <span class="fu">layer_flatten</span>() <span class="sc">%&gt;%</span></span>
<span id="cb48-8"><a href="#cb48-8"></a>  <span class="fu">layer_dense</span>(<span class="at">units =</span> <span class="dv">64</span>, <span class="at">activation =</span> <span class="st">'relu'</span>) <span class="sc">%&gt;%</span></span>
<span id="cb48-9"><a href="#cb48-9"></a>  <span class="fu">layer_dense</span>(<span class="at">units =</span> <span class="dv">10</span>, <span class="at">activation =</span> <span class="st">'softmax'</span>)</span>
<span id="cb48-10"><a href="#cb48-10"></a><span class="fu">summary</span>(mod2)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Model: "sequential_5"
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 conv2d_10 (Conv2D)                 (None, 24, 24, 64)              1664        
 max_pooling2d_10 (MaxPooling2D)    (None, 12, 12, 64)              0           
 conv2d_9 (Conv2D)                  (None, 8, 8, 128)               204928      
 max_pooling2d_9 (MaxPooling2D)     (None, 4, 4, 128)               0           
 flatten_3 (Flatten)                (None, 2048)                    0           
 dense_5 (Dense)                    (None, 64)                      131136      
 dense_4 (Dense)                    (None, 10)                      650         
================================================================================
Total params: 338378 (1.29 MB)
Trainable params: 338378 (1.29 MB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________</code></pre>
</div>
</div>
<p>Configuramos y entrenamos el modelo de forma similar al modelo anterior.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb50"><pre class="sourceCode numberSource r number-lines code-with-copy"><code class="sourceCode r"><span id="cb50-1"><a href="#cb50-1"></a><span class="co"># Proceso de aprendizaje</span></span>
<span id="cb50-2"><a href="#cb50-2"></a>mod2 <span class="sc">%&gt;%</span> <span class="fu">compile</span>(</span>
<span id="cb50-3"><a href="#cb50-3"></a>  <span class="at">loss =</span> <span class="st">'sparse_categorical_crossentropy'</span>,</span>
<span id="cb50-4"><a href="#cb50-4"></a>  <span class="at">optimizer =</span> <span class="fu">optimizer_sgd</span>(),</span>
<span id="cb50-5"><a href="#cb50-5"></a>  <span class="at">metrics =</span> <span class="fu">c</span>(<span class="st">'accuracy'</span>))</span>
<span id="cb50-6"><a href="#cb50-6"></a></span>
<span id="cb50-7"><a href="#cb50-7"></a><span class="co"># Entrenamiento </span></span>
<span id="cb50-8"><a href="#cb50-8"></a>hist2 <span class="ot">=</span> mod2 <span class="sc">%&gt;%</span> </span>
<span id="cb50-9"><a href="#cb50-9"></a>  <span class="fu">fit</span>(x_train, y_train, <span class="at">batch_size =</span> <span class="dv">50</span>, <span class="at">epochs =</span> <span class="dv">5</span>, <span class="at">validation_split =</span> <span class="fl">0.2</span>)  </span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Epoch 1/5
960/960 - 67s - loss: 1.0222 - accuracy: 0.6330 - val_loss: 0.6513 - val_accuracy: 0.7619 - 67s/epoch - 70ms/step
Epoch 2/5
960/960 - 75s - loss: 0.5954 - accuracy: 0.7793 - val_loss: 0.5548 - val_accuracy: 0.7895 - 75s/epoch - 78ms/step
Epoch 3/5
960/960 - 67s - loss: 0.5156 - accuracy: 0.8109 - val_loss: 0.4796 - val_accuracy: 0.8288 - 67s/epoch - 69ms/step
Epoch 4/5
960/960 - 69s - loss: 0.4668 - accuracy: 0.8325 - val_loss: 0.4630 - val_accuracy: 0.8373 - 69s/epoch - 71ms/step
Epoch 5/5
960/960 - 66s - loss: 0.4340 - accuracy: 0.8447 - val_loss: 0.4474 - val_accuracy: 0.8384 - 66s/epoch - 69ms/step</code></pre>
</div>
</div>
<p>Evaluamos el modelo comparando con el anterior:</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb52"><pre class="sourceCode numberSource r number-lines code-with-copy"><code class="sourceCode r"><span id="cb52-1"><a href="#cb52-1"></a><span class="co"># Proceso de aprendizaje</span></span>
<span id="cb52-2"><a href="#cb52-2"></a>mod1 <span class="sc">%&gt;%</span> tensorflow<span class="sc">::</span><span class="fu">evaluate</span>(x_test, y_test)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>313/313 - 2s - loss: 0.4584 - accuracy: 0.8367 - 2s/epoch - 7ms/step</code></pre>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>     loss  accuracy 
0.4584489 0.8367000 </code></pre>
</div>
<div class="sourceCode cell-code" id="cb55"><pre class="sourceCode numberSource r number-lines code-with-copy"><code class="sourceCode r"><span id="cb55-1"><a href="#cb55-1"></a>mod2 <span class="sc">%&gt;%</span> tensorflow<span class="sc">::</span><span class="fu">evaluate</span>(x_test, y_test)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>313/313 - 3s - loss: 0.4574 - accuracy: 0.8374 - 3s/epoch - 11ms/step</code></pre>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>     loss  accuracy 
0.4574407 0.8374000 </code></pre>
</div>
</div>
<p>A pesar del aumento de neuronas y de la nueva capa densa los resultados del modleo son comparables o incluso perores.</p>
</section>
<section id="modelo-3" class="level3" data-number="5.4.3">
<h3 data-number="5.4.3" class="anchored" data-anchor-id="modelo-3"><span class="header-section-number">5.4.3</span> Modelo 3</h3>
<p>Ahora consideramos el miso modelo 1 pero cambiando el optimizar por <code>adam</code>:</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb58"><pre class="sourceCode numberSource r number-lines code-with-copy"><code class="sourceCode r"><span id="cb58-1"><a href="#cb58-1"></a><span class="co"># Arquitectura de red</span></span>
<span id="cb58-2"><a href="#cb58-2"></a>mod3 <span class="ot">=</span> <span class="fu">keras_model_sequential</span>() <span class="sc">%&gt;%</span>  </span>
<span id="cb58-3"><a href="#cb58-3"></a>  <span class="fu">layer_conv_2d</span>(<span class="at">filters =</span> <span class="dv">32</span>, <span class="at">kernel_size =</span> <span class="fu">c</span>(<span class="dv">5</span>, <span class="dv">5</span>), <span class="at">activation=</span><span class="st">'relu'</span>, <span class="at">input_shape=</span><span class="fu">c</span>(<span class="dv">28</span>, <span class="dv">28</span>, <span class="dv">1</span>)) <span class="sc">%&gt;%</span> </span>
<span id="cb58-4"><a href="#cb58-4"></a>  <span class="fu">layer_max_pooling_2d</span>(<span class="at">pool_size =</span> <span class="fu">c</span>(<span class="dv">2</span>, <span class="dv">2</span>)) <span class="sc">%&gt;%</span></span>
<span id="cb58-5"><a href="#cb58-5"></a>  <span class="fu">layer_conv_2d</span>(<span class="at">filters =</span> <span class="dv">64</span>, <span class="at">kernel_size =</span> <span class="fu">c</span>(<span class="dv">5</span>, <span class="dv">5</span>), <span class="at">activation=</span><span class="st">'relu'</span>) <span class="sc">%&gt;%</span> </span>
<span id="cb58-6"><a href="#cb58-6"></a>  <span class="fu">layer_max_pooling_2d</span>(<span class="at">pool_size =</span> <span class="fu">c</span>(<span class="dv">2</span>, <span class="dv">2</span>)) <span class="sc">%&gt;%</span></span>
<span id="cb58-7"><a href="#cb58-7"></a>  <span class="fu">layer_flatten</span>() <span class="sc">%&gt;%</span></span>
<span id="cb58-8"><a href="#cb58-8"></a>  <span class="fu">layer_dense</span>(<span class="at">units =</span> <span class="dv">10</span>, <span class="at">activation =</span> <span class="st">'softmax'</span>)</span>
<span id="cb58-9"><a href="#cb58-9"></a><span class="co"># Proceso de aprendizaje</span></span>
<span id="cb58-10"><a href="#cb58-10"></a>mod3 <span class="sc">%&gt;%</span> <span class="fu">compile</span>(</span>
<span id="cb58-11"><a href="#cb58-11"></a>  <span class="at">loss =</span> <span class="st">'sparse_categorical_crossentropy'</span>,</span>
<span id="cb58-12"><a href="#cb58-12"></a>  <span class="at">optimizer =</span> <span class="fu">optimizer_adam</span>(),</span>
<span id="cb58-13"><a href="#cb58-13"></a>  <span class="at">metrics =</span> <span class="fu">c</span>(<span class="st">'accuracy'</span>))</span>
<span id="cb58-14"><a href="#cb58-14"></a></span>
<span id="cb58-15"><a href="#cb58-15"></a><span class="co"># Entrenamiento </span></span>
<span id="cb58-16"><a href="#cb58-16"></a>hist3 <span class="ot">=</span> mod3 <span class="sc">%&gt;%</span> </span>
<span id="cb58-17"><a href="#cb58-17"></a>  <span class="fu">fit</span>(x_train, y_train, <span class="at">batch_size =</span> <span class="dv">50</span>, <span class="at">epochs =</span> <span class="dv">5</span>, <span class="at">validation_split =</span> <span class="fl">0.2</span>)  </span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Epoch 1/5
960/960 - 29s - loss: 0.5301 - accuracy: 0.8106 - val_loss: 0.3913 - val_accuracy: 0.8618 - 29s/epoch - 30ms/step
Epoch 2/5
960/960 - 26s - loss: 0.3451 - accuracy: 0.8776 - val_loss: 0.3300 - val_accuracy: 0.8837 - 26s/epoch - 27ms/step
Epoch 3/5
960/960 - 28s - loss: 0.3011 - accuracy: 0.8924 - val_loss: 0.3265 - val_accuracy: 0.8843 - 28s/epoch - 29ms/step
Epoch 4/5
960/960 - 26s - loss: 0.2714 - accuracy: 0.9028 - val_loss: 0.3014 - val_accuracy: 0.8928 - 26s/epoch - 27ms/step
Epoch 5/5
960/960 - 26s - loss: 0.2497 - accuracy: 0.9104 - val_loss: 0.2810 - val_accuracy: 0.8984 - 26s/epoch - 27ms/step</code></pre>
</div>
</div>
<p>Comparamos ahora ambos modelos:</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb60"><pre class="sourceCode numberSource r number-lines code-with-copy"><code class="sourceCode r"><span id="cb60-1"><a href="#cb60-1"></a><span class="co"># Proceso de aprendizaje</span></span>
<span id="cb60-2"><a href="#cb60-2"></a>mod1 <span class="sc">%&gt;%</span> tensorflow<span class="sc">::</span><span class="fu">evaluate</span>(x_test, y_test)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>313/313 - 2s - loss: 0.4584 - accuracy: 0.8367 - 2s/epoch - 5ms/step</code></pre>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>     loss  accuracy 
0.4584489 0.8367000 </code></pre>
</div>
<div class="sourceCode cell-code" id="cb63"><pre class="sourceCode numberSource r number-lines code-with-copy"><code class="sourceCode r"><span id="cb63-1"><a href="#cb63-1"></a>mod3 <span class="sc">%&gt;%</span> tensorflow<span class="sc">::</span><span class="fu">evaluate</span>(x_test, y_test)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>313/313 - 2s - loss: 0.2987 - accuracy: 0.8934 - 2s/epoch - 5ms/step</code></pre>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>    loss accuracy 
0.298688 0.893400 </code></pre>
</div>
</div>
<p>El cambio de optimizador mejora el modelo 1 aumentando el porcentaje de clasificación correcta.</p>
</section>
<section id="modelo-4" class="level3" data-number="5.4.4">
<h3 data-number="5.4.4" class="anchored" data-anchor-id="modelo-4"><span class="header-section-number">5.4.4</span> Modelo 4</h3>
<p>A pesar de la sencillez del modelo propuesto casi alcanzamos el 90% de clasificación correcta lo que es un gran resultado: Para tratar de mejorar dicho modleo y evitar un posible probelam de sobrentrenamiento vamos a introducir dos nuevos tipos de capas en nuestra arquitectura de red:</p>
<ul>
<li><p>La capa <code>BatchNormalization</code>, que usa una técnica 120 introducida en el 2015 cuya idea es normalizar las entradas de la capa de tal manera que tengan una activación de salida media de cero y una desviación estándar de uno. Esto es análogo a cómo se estandarizan las entradas a las redes.</p></li>
<li><p>La capa <code>Dropout</code>, que se basa en ignorar ciertos conjuntos de neuronas de la red neuronal durante la fase de entrenamiento de manera aleatoria. Por «ignorar», nos referimos a que estas neuronas no se consideran durante una iteración concreta del proceso de aprendizaje.</p></li>
</ul>
<p>Se propone la arquitectura de red que se presenta a continuación:</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb66"><pre class="sourceCode numberSource r number-lines code-with-copy"><code class="sourceCode r"><span id="cb66-1"><a href="#cb66-1"></a>build_model <span class="ot">=</span> <span class="cf">function</span>()</span>
<span id="cb66-2"><a href="#cb66-2"></a>{</span>
<span id="cb66-3"><a href="#cb66-3"></a>  mod <span class="ot">=</span> <span class="fu">keras_model_sequential</span>() <span class="sc">%&gt;%</span>  </span>
<span id="cb66-4"><a href="#cb66-4"></a>  <span class="fu">layer_conv_2d</span>(<span class="at">filters =</span> <span class="dv">32</span>, <span class="at">kernel_size =</span> <span class="fu">c</span>(<span class="dv">5</span>, <span class="dv">5</span>), <span class="at">activation=</span><span class="st">'relu'</span>, <span class="at">input_shape=</span><span class="fu">c</span>(<span class="dv">28</span>, <span class="dv">28</span>, <span class="dv">1</span>)) <span class="sc">%&gt;%</span> </span>
<span id="cb66-5"><a href="#cb66-5"></a>  <span class="fu">layer_batch_normalization</span>() <span class="sc">%&gt;%</span></span>
<span id="cb66-6"><a href="#cb66-6"></a>  <span class="fu">layer_conv_2d</span>(<span class="at">filters =</span> <span class="dv">64</span>, <span class="at">kernel_size =</span> <span class="fu">c</span>(<span class="dv">5</span>, <span class="dv">5</span>), <span class="at">activation=</span><span class="st">'relu'</span>) <span class="sc">%&gt;%</span> </span>
<span id="cb66-7"><a href="#cb66-7"></a>  <span class="fu">layer_batch_normalization</span>() <span class="sc">%&gt;%</span></span>
<span id="cb66-8"><a href="#cb66-8"></a>  <span class="fu">layer_dropout</span>(<span class="fl">0.25</span>) <span class="sc">%&gt;%</span></span>
<span id="cb66-9"><a href="#cb66-9"></a>  <span class="fu">layer_conv_2d</span>(<span class="at">filters =</span> <span class="dv">128</span>, <span class="at">kernel_size =</span> <span class="fu">c</span>(<span class="dv">5</span>, <span class="dv">5</span>), <span class="at">activation=</span><span class="st">'relu'</span>) <span class="sc">%&gt;%</span> </span>
<span id="cb66-10"><a href="#cb66-10"></a>  <span class="fu">layer_batch_normalization</span>() <span class="sc">%&gt;%</span></span>
<span id="cb66-11"><a href="#cb66-11"></a>  <span class="fu">layer_dropout</span>(<span class="fl">0.25</span>) <span class="sc">%&gt;%</span>    </span>
<span id="cb66-12"><a href="#cb66-12"></a>  <span class="fu">layer_flatten</span>() <span class="sc">%&gt;%</span></span>
<span id="cb66-13"><a href="#cb66-13"></a>  <span class="fu">layer_dense</span>(<span class="at">units =</span> <span class="dv">128</span>, <span class="at">activation =</span> <span class="st">'relu'</span>) <span class="sc">%&gt;%</span> </span>
<span id="cb66-14"><a href="#cb66-14"></a>  <span class="fu">layer_batch_normalization</span>() <span class="sc">%&gt;%</span></span>
<span id="cb66-15"><a href="#cb66-15"></a>  <span class="fu">layer_dropout</span>(<span class="fl">0.5</span>) <span class="sc">%&gt;%</span>        </span>
<span id="cb66-16"><a href="#cb66-16"></a>  <span class="fu">layer_dense</span>(<span class="at">units =</span> <span class="dv">10</span>, <span class="at">activation =</span> <span class="st">'softmax'</span>)</span>
<span id="cb66-17"><a href="#cb66-17"></a><span class="fu">return</span>(mod)  </span>
<span id="cb66-18"><a href="#cb66-18"></a>}</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>Cargamos y entrenamos el modelo</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb67"><pre class="sourceCode numberSource r number-lines code-with-copy"><code class="sourceCode r"><span id="cb67-1"><a href="#cb67-1"></a>mod4<span class="ot">=</span> <span class="fu">build_model</span>()</span>
<span id="cb67-2"><a href="#cb67-2"></a><span class="co"># Proceso de aprendizaje</span></span>
<span id="cb67-3"><a href="#cb67-3"></a>mod4 <span class="sc">%&gt;%</span> <span class="fu">compile</span>(</span>
<span id="cb67-4"><a href="#cb67-4"></a>  <span class="at">loss =</span> <span class="st">'sparse_categorical_crossentropy'</span>,</span>
<span id="cb67-5"><a href="#cb67-5"></a>  <span class="at">optimizer =</span> <span class="fu">optimizer_adam</span>(),</span>
<span id="cb67-6"><a href="#cb67-6"></a>  <span class="at">metrics =</span> <span class="fu">c</span>(<span class="st">'accuracy'</span>))</span>
<span id="cb67-7"><a href="#cb67-7"></a></span>
<span id="cb67-8"><a href="#cb67-8"></a><span class="co"># Entrenamiento </span></span>
<span id="cb67-9"><a href="#cb67-9"></a>hist4 <span class="ot">=</span> mod4 <span class="sc">%&gt;%</span> </span>
<span id="cb67-10"><a href="#cb67-10"></a>  <span class="fu">fit</span>(x_train, y_train, <span class="at">batch_size =</span> <span class="dv">50</span>, <span class="at">epochs =</span> <span class="dv">5</span>, <span class="at">validation_split =</span> <span class="fl">0.2</span>)  </span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Epoch 1/5
960/960 - 382s - loss: 0.5035 - accuracy: 0.8232 - val_loss: 0.3446 - val_accuracy: 0.8753 - 382s/epoch - 398ms/step
Epoch 2/5
960/960 - 587s - loss: 0.3271 - accuracy: 0.8826 - val_loss: 0.2898 - val_accuracy: 0.8942 - 587s/epoch - 612ms/step
Epoch 3/5
960/960 - 595s - loss: 0.2765 - accuracy: 0.9014 - val_loss: 0.2731 - val_accuracy: 0.9019 - 595s/epoch - 619ms/step
Epoch 4/5
960/960 - 589s - loss: 0.2509 - accuracy: 0.9104 - val_loss: 0.2416 - val_accuracy: 0.9108 - 589s/epoch - 613ms/step
Epoch 5/5
960/960 - 585s - loss: 0.2229 - accuracy: 0.9196 - val_loss: 0.2336 - val_accuracy: 0.9141 - 585s/epoch - 610ms/step</code></pre>
</div>
</div>
<p>Comparamos los resultados con el modelo anterior:</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb69"><pre class="sourceCode numberSource r number-lines code-with-copy"><code class="sourceCode r"><span id="cb69-1"><a href="#cb69-1"></a><span class="co"># Proceso de aprendizaje</span></span>
<span id="cb69-2"><a href="#cb69-2"></a>mod3 <span class="sc">%&gt;%</span> tensorflow<span class="sc">::</span><span class="fu">evaluate</span>(x_test, y_test)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>313/313 - 2s - loss: 0.2987 - accuracy: 0.8934 - 2s/epoch - 8ms/step</code></pre>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>    loss accuracy 
0.298688 0.893400 </code></pre>
</div>
<div class="sourceCode cell-code" id="cb72"><pre class="sourceCode numberSource r number-lines code-with-copy"><code class="sourceCode r"><span id="cb72-1"><a href="#cb72-1"></a>mod4 <span class="sc">%&gt;%</span> tensorflow<span class="sc">::</span><span class="fu">evaluate</span>(x_test, y_test)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>313/313 - 21s - loss: 0.2479 - accuracy: 0.9092 - 21s/epoch - 68ms/step</code></pre>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>     loss  accuracy 
0.2479378 0.9092000 </code></pre>
</div>
</div>
<p>El modelo propuesto mejora los resultados pero el coste computacional es mucho más alto. Esto es un probelmas habitual dentro del análisis de imágenes. Cuando trabajamos con modelos más complejos que nos proporcionan mejores resultados el coste computacional se dispara.</p>
</section>
<section id="predicción" class="level3" data-number="5.4.5">
<h3 data-number="5.4.5" class="anchored" data-anchor-id="predicción"><span class="header-section-number">5.4.5</span> Predicción</h3>
<p>Una vez establecido el modelo tan solo nos queda analizar la predicción de las muestars de validación que conseguimos con nuestro mejor modelo.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb75"><pre class="sourceCode numberSource r number-lines code-with-copy"><code class="sourceCode r"><span id="cb75-1"><a href="#cb75-1"></a><span class="co"># probabilidades de clasificación de cada muestra </span></span>
<span id="cb75-2"><a href="#cb75-2"></a>prediccion <span class="ot">=</span> mod4 <span class="sc">%&gt;%</span> <span class="fu">predict</span>(x_test)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>313/313 - 22s - 22s/epoch - 69ms/step</code></pre>
</div>
<div class="sourceCode cell-code" id="cb77"><pre class="sourceCode numberSource r number-lines code-with-copy"><code class="sourceCode r"><span id="cb77-1"><a href="#cb77-1"></a><span class="co"># predicción del modelo</span></span>
<span id="cb77-2"><a href="#cb77-2"></a>pr_modelo <span class="ot">=</span> (prediccion <span class="sc">%&gt;%</span> <span class="fu">k_argmax</span>())<span class="sc">$</span><span class="fu">numpy</span>()</span>
<span id="cb77-3"><a href="#cb77-3"></a><span class="co"># Matriz de confusión</span></span>
<span id="cb77-4"><a href="#cb77-4"></a>cm <span class="ot">=</span> <span class="fu">confusion_matrix</span>(y_test, pr_modelo)</span>
<span id="cb77-5"><a href="#cb77-5"></a><span class="co"># Gráfico</span></span>
<span id="cb77-6"><a href="#cb77-6"></a><span class="fu">plot_confusion_matrix</span>(cm<span class="sc">$</span><span class="st">`</span><span class="at">Confusion Matrix</span><span class="st">`</span>[[<span class="dv">1</span>]])</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output-display">
<p><img src="50_ConvNN_files/figure-html/covnet-031-1.png" class="img-fluid" width="576"></p>
</div>
</div>


</section>
</section>

</main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const clipboard = new window.ClipboardJS('.code-copy-button', {
    target: function(trigger) {
      return trigger.previousElementSibling;
    }
  });
  clipboard.on('success', function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Copied!");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  });
  function tippyHover(el, contentFn) {
    const config = {
      allowHTML: true,
      content: contentFn,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start'
    };
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      return note.innerHTML;
    });
  }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
});
</script>
<nav class="page-navigation">
  <div class="nav-page nav-page-previous">
      <a href="./40_AplMD.html" class="pagination-link">
        <i class="bi bi-arrow-left-short"></i> <span class="nav-page-text"><span class="chapter-number">4</span>&nbsp; <span class="chapter-title">Aplicaciones Redes multicapa densas</span></span>
      </a>          
  </div>
  <div class="nav-page nav-page-next">
      <a href="./references.html" class="pagination-link">
        <span class="nav-page-text">References</span> <i class="bi bi-arrow-right-short"></i>
      </a>
  </div>
</nav>
</div> <!-- /content -->
<footer class="footer">
  <div class="nav-footer">
    <div class="nav-footer-left">Copyright 2023, IA4LEGOS. Universidad Miguel Hernández de Elche</div>   
  </div>
</footer>



</body></html>