<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.2.335">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">


<title>MachineLearning - 3&nbsp; Redes multicapa densas con Keras</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1.6em;
  vertical-align: middle;
}
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { color: #008000; } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { color: #008000; font-weight: bold; } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
</style>


<script src="site_libs/quarto-nav/quarto-nav.js"></script>
<script src="site_libs/quarto-nav/headroom.min.js"></script>
<script src="site_libs/clipboard/clipboard.min.js"></script>
<script src="site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="site_libs/quarto-search/fuse.min.js"></script>
<script src="site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="./">
<link href="./40_AplMD.html" rel="next">
<link href="./20_TrainDL.html" rel="prev">
<script src="site_libs/quarto-html/quarto.js"></script>
<script src="site_libs/quarto-html/popper.min.js"></script>
<script src="site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="site_libs/quarto-html/anchor.min.js"></script>
<link href="site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="site_libs/quarto-html/quarto-syntax-highlighting.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="site_libs/bootstrap/bootstrap.min.js"></script>
<link href="site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="site_libs/bootstrap/bootstrap.min.css" rel="stylesheet" id="quarto-bootstrap" data-mode="light">
<script id="quarto-search-options" type="application/json">{
  "location": "sidebar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "start",
  "type": "textbox",
  "limit": 20,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit"
  }
}</script>

  <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js" type="text/javascript"></script>

</head>

<body class="nav-sidebar docked">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top">
  <nav class="quarto-secondary-nav" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
    <div class="container-fluid d-flex justify-content-between">
      <h1 class="quarto-secondary-nav-title"><span class="chapter-number">3</span>&nbsp; <span class="chapter-title">Redes multicapa densas con Keras</span></h1>
      <button type="button" class="quarto-btn-toggle btn" aria-label="Show secondary navigation">
        <i class="bi bi-chevron-right"></i>
      </button>
    </div>
  </nav>
</header>
<!-- content -->
<div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article">
<!-- sidebar -->
  <nav id="quarto-sidebar" class="sidebar collapse sidebar-navigation docked overflow-auto">
    <div class="pt-lg-2 mt-2 text-left sidebar-header">
    <div class="sidebar-title mb-0 py-0">
      <a href="./">MachineLearning</a> 
    </div>
      </div>
      <div class="mt-2 flex-shrink-0 align-items-center">
        <div class="sidebar-search">
        <div id="quarto-search" class="" title="Search"></div>
        </div>
      </div>
    <div class="sidebar-menu-container"> 
    <ul class="list-unstyled mt-1">
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./index.html" class="sidebar-item-text sidebar-link">Deep Learning</a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./10_IntroDL.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">1</span>&nbsp; <span class="chapter-title">Introducción</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./20_TrainDL.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">2</span>&nbsp; <span class="chapter-title">Entrenamiento de la red neuronal</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./30_RMDDL.html" class="sidebar-item-text sidebar-link active"><span class="chapter-number">3</span>&nbsp; <span class="chapter-title">Redes multicapa densas con Keras</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./40_AplMD.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">4</span>&nbsp; <span class="chapter-title">Aplicaciones Redes multicapa densas</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./50_ConvNN.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">5</span>&nbsp; <span class="chapter-title">Redes convolucionales</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./references.html" class="sidebar-item-text sidebar-link">References</a>
  </div>
</li>
    </ul>
    </div>
</nav>
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
        <nav id="TOC" role="doc-toc" class="toc-active">
    <h2 id="toc-title">Table of contents</h2>
   
  <ul>
  <li><a href="#qué-es-keras" id="toc-qué-es-keras" class="nav-link active" data-scroll-target="#qué-es-keras"><span class="toc-section-number">3.1</span>  ¿Qué es Keras?</a>
  <ul>
  <li><a href="#características" id="toc-características" class="nav-link" data-scroll-target="#características"><span class="toc-section-number">3.1.1</span>  Características</a></li>
  <li><a href="#fundamentos" id="toc-fundamentos" class="nav-link" data-scroll-target="#fundamentos"><span class="toc-section-number">3.1.2</span>  Fundamentos</a></li>
  <li><a href="#por-qué-necesitamos-keras" id="toc-por-qué-necesitamos-keras" class="nav-link" data-scroll-target="#por-qué-necesitamos-keras"><span class="toc-section-number">3.1.3</span>  ¿Por qué necesitamos Keras?</a></li>
  <li><a href="#cómo-construir-un-modelo-en-keras" id="toc-cómo-construir-un-modelo-en-keras" class="nav-link" data-scroll-target="#cómo-construir-un-modelo-en-keras"><span class="toc-section-number">3.1.4</span>  ¿Cómo construir un modelo en keras?</a></li>
  <li><a href="#ventajas-de-utilizar-keras" id="toc-ventajas-de-utilizar-keras" class="nav-link" data-scroll-target="#ventajas-de-utilizar-keras"><span class="toc-section-number">3.1.5</span>  Ventajas de utilizar Keras</a></li>
  <li><a href="#quién-utiliza-keras" id="toc-quién-utiliza-keras" class="nav-link" data-scroll-target="#quién-utiliza-keras"><span class="toc-section-number">3.1.6</span>  ¿Quién utiliza keras?</a></li>
  <li><a href="#puesta-en-marcha-de-keras" id="toc-puesta-en-marcha-de-keras" class="nav-link" data-scroll-target="#puesta-en-marcha-de-keras"><span class="toc-section-number">3.1.7</span>  Puesta en marcha de Keras</a></li>
  </ul></li>
  <li><a href="#nuestras-primeras-redes-con-keras" id="toc-nuestras-primeras-redes-con-keras" class="nav-link" data-scroll-target="#nuestras-primeras-redes-con-keras"><span class="toc-section-number">3.2</span>  Nuestras primeras redes con Keras</a>
  <ul>
  <li><a href="#datos-iris" id="toc-datos-iris" class="nav-link" data-scroll-target="#datos-iris"><span class="toc-section-number">3.2.1</span>  Datos Iris</a>
  <ul class="collapse">
  <li><a href="#arquitectura-de-la-red" id="toc-arquitectura-de-la-red" class="nav-link" data-scroll-target="#arquitectura-de-la-red"><span class="toc-section-number">3.2.1.1</span>  Arquitectura de la red</a></li>
  <li><a href="#proceso-de-aprendizaje" id="toc-proceso-de-aprendizaje" class="nav-link" data-scroll-target="#proceso-de-aprendizaje"><span class="toc-section-number">3.2.1.2</span>  Proceso de aprendizaje</a></li>
  <li><a href="#entrenamiento-del-modelo" id="toc-entrenamiento-del-modelo" class="nav-link" data-scroll-target="#entrenamiento-del-modelo"><span class="toc-section-number">3.2.1.3</span>  Entrenamiento del modelo</a></li>
  <li><a href="#evaluación-del-modelo" id="toc-evaluación-del-modelo" class="nav-link" data-scroll-target="#evaluación-del-modelo"><span class="toc-section-number">3.2.1.4</span>  Evaluación del modelo</a></li>
  <li><a href="#validación-del-modelo" id="toc-validación-del-modelo" class="nav-link" data-scroll-target="#validación-del-modelo"><span class="toc-section-number">3.2.1.5</span>  Validación del modelo</a></li>
  </ul></li>
  <li><a href="#datos-digits" id="toc-datos-digits" class="nav-link" data-scroll-target="#datos-digits"><span class="toc-section-number">3.2.2</span>  Datos Digits</a>
  <ul class="collapse">
  <li><a href="#arquitectura-de-la-red-1" id="toc-arquitectura-de-la-red-1" class="nav-link" data-scroll-target="#arquitectura-de-la-red-1"><span class="toc-section-number">3.2.2.1</span>  Arquitectura de la red</a></li>
  <li><a href="#proceso-de-aprendizaje-1" id="toc-proceso-de-aprendizaje-1" class="nav-link" data-scroll-target="#proceso-de-aprendizaje-1"><span class="toc-section-number">3.2.2.2</span>  Proceso de aprendizaje</a></li>
  <li><a href="#entrenamiento-del-modelo-1" id="toc-entrenamiento-del-modelo-1" class="nav-link" data-scroll-target="#entrenamiento-del-modelo-1"><span class="toc-section-number">3.2.2.3</span>  Entrenamiento del modelo</a></li>
  <li><a href="#evaluación-del-modelo-1" id="toc-evaluación-del-modelo-1" class="nav-link" data-scroll-target="#evaluación-del-modelo-1"><span class="toc-section-number">3.2.2.4</span>  Evaluación del modelo</a></li>
  <li><a href="#validación-del-modelo-1" id="toc-validación-del-modelo-1" class="nav-link" data-scroll-target="#validación-del-modelo-1"><span class="toc-section-number">3.2.2.5</span>  Validación del modelo</a></li>
  </ul></li>
  </ul></li>
  <li><a href="#parámetros-e-hiperparámetros-de-la-red" id="toc-parámetros-e-hiperparámetros-de-la-red" class="nav-link" data-scroll-target="#parámetros-e-hiperparámetros-de-la-red"><span class="toc-section-number">3.3</span>  Parámetros e hiperparámetros de la red</a>
  <ul>
  <li><a href="#grupos-de-hiperparámetros" id="toc-grupos-de-hiperparámetros" class="nav-link" data-scroll-target="#grupos-de-hiperparámetros"><span class="toc-section-number">3.3.1</span>  Grupos de hiperparámetros</a>
  <ul class="collapse">
  <li><a href="#a-nivel-de-estructura-y-topologia" id="toc-a-nivel-de-estructura-y-topologia" class="nav-link" data-scroll-target="#a-nivel-de-estructura-y-topologia"><span class="toc-section-number">3.3.1.1</span>  A nivel de estructura y topologia</a></li>
  <li><a href="#a-nivel-de-algoritmo-de-aprendizaje" id="toc-a-nivel-de-algoritmo-de-aprendizaje" class="nav-link" data-scroll-target="#a-nivel-de-algoritmo-de-aprendizaje"><span class="toc-section-number">3.3.1.2</span>  A nivel de algoritmo de aprendizaje</a></li>
  </ul></li>
  </ul></li>
  <li><a href="#sobreajuste-e-infraajuste" id="toc-sobreajuste-e-infraajuste" class="nav-link" data-scroll-target="#sobreajuste-e-infraajuste"><span class="toc-section-number">3.4</span>  Sobreajuste e infraajuste</a>
  <ul>
  <li><a href="#reduciendo-el-tamaño-de-la-red" id="toc-reduciendo-el-tamaño-de-la-red" class="nav-link" data-scroll-target="#reduciendo-el-tamaño-de-la-red"><span class="toc-section-number">3.4.1</span>  Reduciendo el tamaño de la red</a></li>
  <li><a href="#regularización-de-parámetros" id="toc-regularización-de-parámetros" class="nav-link" data-scroll-target="#regularización-de-parámetros"><span class="toc-section-number">3.4.2</span>  Regularización de parámetros</a></li>
  <li><a href="#añadiendo-abandono-dropout" id="toc-añadiendo-abandono-dropout" class="nav-link" data-scroll-target="#añadiendo-abandono-dropout"><span class="toc-section-number">3.4.3</span>  Añadiendo abandono (dropout)</a></li>
  <li><a href="#parada-temprana-early-stopping" id="toc-parada-temprana-early-stopping" class="nav-link" data-scroll-target="#parada-temprana-early-stopping"><span class="toc-section-number">3.4.4</span>  Parada temprana (early stopping)</a></li>
  </ul></li>
  </ul>
</nav>
    </div>
<!-- main -->
<main class="content" id="quarto-document-content">

<header id="title-block-header" class="quarto-title-block default">
<div class="quarto-title">
<h1 class="title d-none d-lg-block"><span class="chapter-number">3</span>&nbsp; <span class="chapter-title">Redes multicapa densas con Keras</span></h1>
</div>



<div class="quarto-title-meta">

    
  
    
  </div>
  

</header>

<p>En este tema introducimos las redes multicapa densas e introducimos la librería Keras para su implementación. Mostraremos nuestras primeras redes en dos porblemas de clasificación habituales en la literatura: <code>iris</code> y <code>digits</code>.</p>
<section id="qué-es-keras" class="level2" data-number="3.1">
<h2 data-number="3.1" class="anchored" data-anchor-id="qué-es-keras"><span class="header-section-number">3.1</span> ¿Qué es Keras?</h2>
<p>Aunque las redes neuronales profundas están de moda, la complejidad de los principales marcos de trabajo ha sido una barrera para su uso por parte de los desarrolladores que se inician en el aprendizaje automático. Ha habido varias propuestas de APIs de alto nivel mejoradas y simplificadas para construir modelos de redes neuronales, todas las cuales tienden a parecer similares desde la distancia, pero muestran diferencias al examinarlas más de cerca.</p>
<p>Keras es una de las principales API de redes neuronales de alto nivel. Está escrita en Python y admite múltiples motores de cálculo de redes neuronales <em>backend</em>, como TensorFlow, Theano o Microsoft Cognitive Toolkit. Proporciona una forma muy limpia y fácil de crear modelos de aprendizaje profundo. Keras no es un marco independiente, sino una interfaz para principiantes (API) para acceder y programar una variedad de marcos de Machine Learning. Theano, Microsoft Cognitive Toolkit y TensorFlow son algunos de los marcos soportados por Keras.</p>
<p>Keras es relativamente fácil de aprender y trabajar con él, porque proporciona un <em>frontend</em> de Python con un alto nivel de abstracción mientras que tiene la opción de múltiples <em>backend</em> para fines de computación. Esto hace que Keras sea más lento que otros marcos de aprendizaje profundo, pero extremadamente amigable para los principiantes. Está integrado en TensorFlow y se puede utilizar para realizar desarrollos mucho más rápido, ya que proporciona módulos incorporados para todos los cálculos de redes neuronales. Al mismo tiempo, los cálculos que implican tensores, gráficos de cálculo, sesiones y otros, pueden hacerse a medida utilizando la API del núcleo de TensorFlow, lo que te proporciona una flexibilidad y un control total sobre tu aplicación y te permite implementar tus ideas en un tiempo relativamente corto.</p>
<section id="características" class="level3" data-number="3.1.1">
<h3 data-number="3.1.1" class="anchored" data-anchor-id="características"><span class="header-section-number">3.1.1</span> Características</h3>
<p>Keras tiene las siguientes características más destacadas:</p>
<ul>
<li>Ofrece a los usuarios un marco de trabajo fácil de usar, junto con métodos y herramientas de creación de prototipos más rápidos.</li>
<li>Funciona eficientemente tanto en la CPU como en la GPU, sin ningún tipo de contratiempo.</li>
<li>Ofrece una API consistente que proporciona la información necesaria cuando se produce un error.</li>
<li>Puedes personalizar las funcionalidades de tu código hasta un gran punto. Incluso una pequeña personalización supone un gran cambio porque estas funcionalidades están profundamente integradas con el <em>backend</em> de bajo nivel.</li>
<li>Permite trabajar tanto con redes neuronales convolucionales (CNN) como con redes neuronales recurrentes (RNN) para una variedad de aplicaciones como Visión Computacional y el análisis de series temporales, respectivamente.</li>
<li>Su funcionalidad sin fisuras permite utilizar tanto CNN como RNN si es necesario.</li>
<li>Soporta completamente arquitecturas de red arbitrarias, poniendo a disposición de los usuarios la posibilidad de compartir modelos y capas.</li>
</ul>
</section>
<section id="fundamentos" class="level3" data-number="3.1.2">
<h3 data-number="3.1.2" class="anchored" data-anchor-id="fundamentos"><span class="header-section-number">3.1.2</span> Fundamentos</h3>
<p>Keras fue creado para ser amigable, modular, fácil de extender y para trabajar con Python. La API fue diseñada para seres humanos, no para máquinas, y sigue las mejores prácticas para reducir la carga cognitiva.</p>
<p>Las capas neuronales, las funciones de coste, los optimizadores, los esquemas de inicialización, las funciones de activación y los esquemas de regularización son módulos independientes que se pueden combinar para crear nuevos modelos. Es sencillo añadir nuevos módulos, como nuevas clases y funciones. Los modelos se definen en código Python, no en archivos de configuración de modelos separados.</p>
</section>
<section id="por-qué-necesitamos-keras" class="level3" data-number="3.1.3">
<h3 data-number="3.1.3" class="anchored" data-anchor-id="por-qué-necesitamos-keras"><span class="header-section-number">3.1.3</span> ¿Por qué necesitamos Keras?</h3>
<p>Entre las características que podemos destacar de keras tenemos:</p>
<ul>
<li>Es una API que fue hecha para ser fácil de aprender para la gente. Keras fue hecho para ser simple. Ofrece APIs consistentes y simples, reduce las acciones requeridas para implementar código común y explica claramente los errores del usuario.</li>
<li>El tiempo de creación de prototipos en Keras es menor. Esto significa que tus ideas pueden ser implementadas y desplegadas en un tiempo más corto. Keras también proporciona una variedad de opciones de despliegue en función de las necesidades del usuario.</li>
<li>Los lenguajes con un alto nivel de abstracción y características incorporadas son lentos y construir características personalizadas en ellos pueden ser difícil, pero Keras se ejecuta sobre TensorFlow y es relativamente rápido. Keras también está profundamente integrado con TensorFlow, por lo que puedes crear flujos de trabajo personalizados con facilidad.</li>
<li>La comunidad de investigadores de Keras es amplia y muy desarrollada. La documentación y la ayuda disponibles son mucho más extensas que las de otros marcos de Deep Learning.</li>
<li>Keras es utilizado comercialmente por muchas empresas como Netflix, Uber, Square, Yelp, que han desplegado productos en el dominio público que se construyen utilizando Keras.</li>
</ul>
</section>
<section id="cómo-construir-un-modelo-en-keras" class="level3" data-number="3.1.4">
<h3 data-number="3.1.4" class="anchored" data-anchor-id="cómo-construir-un-modelo-en-keras"><span class="header-section-number">3.1.4</span> ¿Cómo construir un modelo en keras?</h3>
<p>Keras es una biblioteca que trabaja con modelos. Proporciona los bloques de construcción para desarrollar modelos complejos de Deep Learning.</p>
<p>A diferencia de los <em>frameworks</em> independientes, este <em>software</em> de código abierto no se ocupa de las operaciones simples de bajo nivel por sí mismo. En su lugar, utiliza las bibliotecas de los marcos de Machine Learning asociados para este fin. Estas actúan como una especie de motor <em>backend</em> para Keras.</p>
<p>Dado que la idea es ser modular, las capas deseadas para la red neuronal que se está desarrollando se conectan entre sí sin que el usuario de Keras tenga que entender o controlar el <em>backend</em> real del marco seleccionado.</p>
<p>Como se ha mencionado anteriormente, Keras utiliza las tres herramientas TensorFlow, Theano y Microsoft Cognitive Toolkit. Estas tienen interfaces listas para usar que permiten un acceso rápido e intuitivo al respectivo <em>backend</em>.</p>
<p>No es necesario decidirse por un único framework porque se puede cambiar fácilmente entre los diferentes <em>backends</em>. También es posible elegir un <em>backend</em> diferente de las tres soluciones nombradas aquí. Solo tienes que especificarlo en el archivo de configuración, y tiene las siguientes tres funciones disponibles: <em>placeholder</em>, variable y función.</p>
</section>
<section id="ventajas-de-utilizar-keras" class="level3" data-number="3.1.5">
<h3 data-number="3.1.5" class="anchored" data-anchor-id="ventajas-de-utilizar-keras"><span class="header-section-number">3.1.5</span> Ventajas de utilizar Keras</h3>
<p>Keras ha sido una excelente adición a las herramientas existentes para el desarrollo de redes neuronales, ya que esta biblioteca de código abierto simplifica enormemente el proceso. La usabilidad es la clave aquí. Keras funciona como una interfaz diseñada explícitamente para los humanos y solo en segundo lugar para las máquinas.</p>
<p>Las acciones del usuario se reducen al mínimo, y si aún así se producen errores, se proporciona una retroalimentación relevante para ayudar a corregirlos. Esto hace que sea comparativamente fácil de aprender a usar y permite un mayor nivel de productividad.</p>
<p>A continuación, un resumen de algunas ventajas adicionales proporcionadas por Keras:</p>
<ul>
<li>Amplio soporte de plataforma para los modelos desarrollados. Los modelos desarrollados con Keras pueden ser fácilmente desplegados en diferentes plataformas.</li>
<li>Soporte para múltiples motores de <em>backend</em>. Keras te da la libertad de elegir el <em>backend</em> que quieras y combinar múltiples <em>backends</em>. También puede transferir un modelo desarrollado a otro <em>backend</em> en cualquier momento.</li>
<li>Extraordinario soporte multi-GPU. Cuando se utiliza Keras, el trabajo de computación para los procesos de Deep Learning desarrollados puede distribuirse fácilmente entre múltiples chips o tarjetas gráficas.</li>
</ul>
</section>
<section id="quién-utiliza-keras" class="level3" data-number="3.1.6">
<h3 data-number="3.1.6" class="anchored" data-anchor-id="quién-utiliza-keras"><span class="header-section-number">3.1.6</span> ¿Quién utiliza keras?</h3>
<p>Como interfaz universal para las plataformas de Machine Learning, Keras se utiliza actualmente en una gran variedad de proyectos en el campo de la Inteligencia Artificial. A mediados de 2018, esta biblioteca ya contaba con más de 250.000 usuarios individuales, y este número ha aumentado mucho después desde su inclusión en el software TensorFlow.</p>
<p>Gracias a la libertad de elección del <em>framework</em> subyacente, la gratuidad de las licencias y su independencia de plataforma, Keras es la solución perfecta para todo tipo de aplicaciones profesionales de redes neuronales tanto en la industria como en la investigación. Por ejemplo, empresas conocidas como Netflix, Uber y Yelp, así como organizaciones como la NASA, y el Centro Europeo para la Investigación Nuclear (CERN), utilizan Keras o el paquete TensorFlow Keras en sus proyectos.</p>
</section>
<section id="puesta-en-marcha-de-keras" class="level3" data-number="3.1.7">
<h3 data-number="3.1.7" class="anchored" data-anchor-id="puesta-en-marcha-de-keras"><span class="header-section-number">3.1.7</span> Puesta en marcha de Keras</h3>
<p>Para la puesta en marcha del API Keras necesitamos ir instalando diferentes librerías. En este punto detallamos ese proceso que en muchas ocasiones es bastante lento. Una vez instaladas las libreías se cargaran como el resto de librerías de R.</p>
<p>En primer lugar debemos instalar la librería tensorflow:</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb1"><pre class="sourceCode numberSource r number-lines code-with-copy"><code class="sourceCode r"><span id="cb1-1"><a href="#cb1-1"></a>utils<span class="sc">::</span><span class="fu">install.packages</span>(<span class="st">"remotes"</span>)</span>
<span id="cb1-2"><a href="#cb1-2"></a>remotes<span class="sc">::</span><span class="fu">install_github</span>(<span class="st">"rstudio/tensorflow"</span>, <span class="at">force=</span><span class="cn">TRUE</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>Ahora instalamos la última vesión del interprete de python:</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb2"><pre class="sourceCode numberSource r number-lines code-with-copy"><code class="sourceCode r"><span id="cb2-1"><a href="#cb2-1"></a>reticulate<span class="sc">::</span><span class="fu">install_python</span>()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>Ponemos en marcha tensorflow</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb3"><pre class="sourceCode numberSource r number-lines code-with-copy"><code class="sourceCode r"><span id="cb3-1"><a href="#cb3-1"></a><span class="fu">library</span>(tensorflow)</span>
<span id="cb3-2"><a href="#cb3-2"></a><span class="fu">install_tensorflow</span>(<span class="at">envname =</span> <span class="st">"r-tensorflow"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Virtual environment 'r-tensorflow' removed.
Using Python: /Users/javiermorales/.pyenv/versions/3.9.18/bin/python3.9
Creating virtual environment 'r-tensorflow' ... 
Done!
Installing packages: pip, wheel, setuptools
Virtual environment 'r-tensorflow' successfully created.
Using virtual environment 'r-tensorflow' ...

Installation complete.</code></pre>
</div>
</div>
<p>Ahora comenzamos con la instalación y puesta en marcha de Keras</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb5"><pre class="sourceCode numberSource r number-lines code-with-copy"><code class="sourceCode r"><span id="cb5-1"><a href="#cb5-1"></a><span class="co">#install.packages("keras")</span></span>
<span id="cb5-2"><a href="#cb5-2"></a><span class="fu">library</span>(keras)</span>
<span id="cb5-3"><a href="#cb5-3"></a><span class="fu">install_keras</span>()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Virtual environment 'r-tensorflow' removed.
Using Python: /Users/javiermorales/.pyenv/versions/3.9.18/bin/python3.9
Creating virtual environment 'r-tensorflow' ... 
Done!
Installing packages: pip, wheel, setuptools
Virtual environment 'r-tensorflow' successfully created.
Using virtual environment 'r-tensorflow' ...

Installation complete.</code></pre>
</div>
</div>
<p>Una vez finalizado el proceso nos basta con cargar la librería keras para acceder a todos sus recursos. Cargamos todas las librería necesarias.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb7"><pre class="sourceCode numberSource r number-lines code-with-copy"><code class="sourceCode r"><span id="cb7-1"><a href="#cb7-1"></a><span class="co"># Paquetes anteriores</span></span>
<span id="cb7-2"><a href="#cb7-2"></a><span class="fu">library</span>(tidyverse)</span>
<span id="cb7-3"><a href="#cb7-3"></a><span class="fu">library</span>(sjPlot)</span>
<span id="cb7-4"><a href="#cb7-4"></a><span class="fu">library</span>(knitr) <span class="co"># para formatos de tablas</span></span>
<span id="cb7-5"><a href="#cb7-5"></a><span class="fu">library</span>(gridExtra)</span>
<span id="cb7-6"><a href="#cb7-6"></a><span class="fu">library</span>(ggpubr)</span>
<span id="cb7-7"><a href="#cb7-7"></a><span class="fu">theme_set</span>(<span class="fu">theme_sjplot2</span>())</span>
<span id="cb7-8"><a href="#cb7-8"></a><span class="fu">library</span>(mlr3verse)</span>
<span id="cb7-9"><a href="#cb7-9"></a><span class="fu">library</span>(tensorflow)</span>
<span id="cb7-10"><a href="#cb7-10"></a><span class="fu">library</span>(keras)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
</section>
</section>
<section id="nuestras-primeras-redes-con-keras" class="level2" data-number="3.2">
<h2 data-number="3.2" class="anchored" data-anchor-id="nuestras-primeras-redes-con-keras"><span class="header-section-number">3.2</span> Nuestras primeras redes con Keras</h2>
<p>De la misma manera que cuando uno empieza a programar en un lenguaje nuevo existe la tradición de hacerlo con un <code>print Hello World</code>, en aprendizaje profundo se empieza por crear modelos para problemas de clasificación. Los ejemplos que presentamos nos permitirán adentrarnos paulatinamente en los conceptos básicos de las redes neuronales, reduciendo todo lo posible conceptos teóricos, con el objetivo de ofrecer al lector o lectora una visión global de un caso concreto para facilitar la lectura de los cuadernos posteriores, donde se profundiza en diferentes aspectos del área.</p>
<section id="datos-iris" class="level3" data-number="3.2.1">
<h3 data-number="3.2.1" class="anchored" data-anchor-id="datos-iris"><span class="header-section-number">3.2.1</span> Datos Iris</h3>
<p>La base de datos iris consta de 50 muestras de cada una de las tres especies de Iris: Iris Setosa, Iris virginica e Iris versicolor. Se escogieron cuatro características de cada muestra: la longitud y el ancho de los sépalos y pétalos, en centímetros. El objetivo que se persigue es predecir la clase de especie (species) que es en función de sus características. Las variables contenidas en el banco de datos son:</p>
<ul>
<li><code>sepal_length</code>: longitud del sépalo (en cm)</li>
<li><code>sepal_width</code>: anchura del sépalo (en cm)</li>
<li><code>petal_length</code>: longitud del pétalo (en cm)</li>
<li><code>petal_width</code>: anchura del pétalo (en cm)</li>
<li><code>species</code>: especie de la flor (Iris Setosa, Iris virginica e Iris versicolor)</li>
</ul>
<p>El objetivo que se persigue es predecir la clase de especie (<code>species</code>) que es en función de sus características. Cargamos los datos y los preparamos para el análisis. COmo los datos están ordenos por especiedebeos barajarlos para evitar que al obtener la muestra de entrenamiento y validación tengamos sesgos de selección. Además debemos estandarizar las variables numéricas.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb8"><pre class="sourceCode numberSource r number-lines code-with-copy"><code class="sourceCode r"><span id="cb8-1"><a href="#cb8-1"></a><span class="co"># Cargamos datos</span></span>
<span id="cb8-2"><a href="#cb8-2"></a>iris <span class="ot">=</span> <span class="fu">read_rds</span>(<span class="st">"iris.rds"</span>)</span>
<span id="cb8-3"><a href="#cb8-3"></a><span class="co"># Barajamos los datos</span></span>
<span id="cb8-4"><a href="#cb8-4"></a>iris <span class="ot">=</span> <span class="fu">slice_sample</span>(iris, <span class="at">n =</span> <span class="fu">nrow</span>(iris))</span>
<span id="cb8-5"><a href="#cb8-5"></a>nombres <span class="ot">=</span> <span class="fu">levels</span>(iris<span class="sc">$</span>species)</span>
<span id="cb8-6"><a href="#cb8-6"></a></span>
<span id="cb8-7"><a href="#cb8-7"></a><span class="co"># Predictoras y respuesta</span></span>
<span id="cb8-8"><a href="#cb8-8"></a>X <span class="ot">=</span> dplyr<span class="sc">::</span><span class="fu">select</span>(iris, <span class="sc">-</span><span class="st">"species"</span>)</span>
<span id="cb8-9"><a href="#cb8-9"></a><span class="co"># Codificamos la respuesta numéricamente y restamos 1 ya que los array  se inicializan en cero en python</span></span>
<span id="cb8-10"><a href="#cb8-10"></a>y <span class="ot">=</span> <span class="fu">as.numeric</span>(iris<span class="sc">$</span>species)<span class="sc">-</span><span class="dv">1</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>Creamos la muestra de entrenamiento (80%) y validación (20%).</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb9"><pre class="sourceCode numberSource r number-lines code-with-copy"><code class="sourceCode r"><span id="cb9-1"><a href="#cb9-1"></a><span class="co"># semilla para reproducibilidad</span></span>
<span id="cb9-2"><a href="#cb9-2"></a><span class="fu">set.seed</span>(<span class="dv">123</span>)</span>
<span id="cb9-3"><a href="#cb9-3"></a><span class="co"># Proporción muestra de entrenamiento</span></span>
<span id="cb9-4"><a href="#cb9-4"></a>np <span class="ot">=</span> <span class="fl">0.8</span></span>
<span id="cb9-5"><a href="#cb9-5"></a><span class="co"># Índices de la muestra de entrenamiento</span></span>
<span id="cb9-6"><a href="#cb9-6"></a>ids_train <span class="ot">=</span> <span class="fu">sample</span>(<span class="fu">nrow</span>(iris), np<span class="sc">*</span><span class="fu">nrow</span>(iris))</span>
<span id="cb9-7"><a href="#cb9-7"></a><span class="co"># Muestras de entrenamiento y validación</span></span>
<span id="cb9-8"><a href="#cb9-8"></a>X_train_iris <span class="ot">=</span> X[ids_train,]</span>
<span id="cb9-9"><a href="#cb9-9"></a>X_test_iris <span class="ot">=</span> X[<span class="sc">-</span>ids_train,]</span>
<span id="cb9-10"><a href="#cb9-10"></a>y_train_iris <span class="ot">=</span> y[ids_train]</span>
<span id="cb9-11"><a href="#cb9-11"></a>y_test_iris <span class="ot">=</span> y[<span class="sc">-</span>ids_train]</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>Ahora estandarizamos a partir de la media y desviación típica de las predictoras en la muestra de entrenamiento.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb10"><pre class="sourceCode numberSource r number-lines code-with-copy"><code class="sourceCode r"><span id="cb10-1"><a href="#cb10-1"></a><span class="co"># Variables en el modelo</span></span>
<span id="cb10-2"><a href="#cb10-2"></a>nvari <span class="ot">=</span> <span class="fu">ncol</span>(X)</span>
<span id="cb10-3"><a href="#cb10-3"></a><span class="do">############# Estandarización ###############</span></span>
<span id="cb10-4"><a href="#cb10-4"></a><span class="co"># Medias</span></span>
<span id="cb10-5"><a href="#cb10-5"></a>mean_train <span class="ot">=</span> <span class="fu">apply</span>(X_train_iris, <span class="dv">2</span>, mean)</span>
<span id="cb10-6"><a href="#cb10-6"></a><span class="co"># Desviaciones típicas</span></span>
<span id="cb10-7"><a href="#cb10-7"></a>sd_train <span class="ot">=</span> <span class="fu">apply</span>(X_train_iris, <span class="dv">2</span>, sd)</span>
<span id="cb10-8"><a href="#cb10-8"></a><span class="co"># Estandarizamos muestra de entrenamiento</span></span>
<span id="cb10-9"><a href="#cb10-9"></a>Xest_train_iris <span class="ot">=</span> <span class="fu">scale</span>(X_train_iris, mean_train, sd_train)</span>
<span id="cb10-10"><a href="#cb10-10"></a><span class="co"># Estandarizamos muestra de validación</span></span>
<span id="cb10-11"><a href="#cb10-11"></a>Xest_test_iris <span class="ot">=</span> <span class="fu">scale</span>(X_test_iris, mean_train, sd_train)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<section id="arquitectura-de-la-red" class="level4" data-number="3.2.1.1">
<h4 data-number="3.2.1.1" class="anchored" data-anchor-id="arquitectura-de-la-red"><span class="header-section-number">3.2.1.1</span> Arquitectura de la red</h4>
<p>Una vez preparados los datos tenemos que definir la arquitectura de la red que vamos a utilizar. La estructura de datos principal en Keras es la clase <code>Sequential</code> que permite la creación de una red neuronal básica. En este caso, el modelo en Keras se considera como una secuencia de capas; cada una de ellas va «destilando» gradualmente los datos de entrada para obtener la salida deseada.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb11"><pre class="sourceCode numberSource r number-lines code-with-copy"><code class="sourceCode r"><span id="cb11-1"><a href="#cb11-1"></a>modelo_iris <span class="ot">=</span> <span class="fu">keras_model_sequential</span>()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>El modelo creado en este momento es un contenedor, pues no contiene ningún tipo de información. Para ir introduciendo capas en la arquitectura de la red utilizamos el comando <code>model.add</code> donde identificamos las características de cada una de las capas ocultas que podemos ir considerando. Para empezar, la clase <code>Dense</code> nos permite definir una capa densa, es decir, una capa donde todas las entradas están conectadas con todas las salidas. Requiere los siguientes parámetros de entrada:</p>
<ul>
<li><strong>units</strong>: número entero que indica la dimensión de la capa de salida, es decir, el número de neuronas que se utilizan.</li>
<li><strong>activation</strong>: función de activación que se aplica a la salida de la capa, es decir, si el modelo tiene un comportamiento lineal o si lo usamos para realizar, por ejemplo, una Regresión Logística o una Red Neuronal.</li>
<li><strong>input_dim</strong>: tupla que indica el tamaño de los datos de entrada.</li>
</ul>
<p>También a menudo se indica la inicialización de los pesos como argumento de las capas Dense. Los valores iniciales deben ser adecuados para que el problema de optimización converja tan rápido como sea posible en el proceso de entrenamiento de la red. En el manual de Keras se pueden encontrar las diversas opciones de inicialización.</p>
<p>El número de capas necesarias no se sabe a priori, por lo que se suele establecer mediante un procedimiento de ensayo y error. Normalmente, la red necesaria será aquella que sea lo suficientemente grande para capturar la estructura y las dimensiones del problema. Siempre hay que tener en cuenta que la última capa de la red debe disponer de tantas neuronas como respuestas posibles de la respuesta. En este caso como la respuesta tiene tres clases, la última capa de la red debe tener tres neuronas. Además, dado que estamos en un problema de clasificación la función de activación a utilizar es <code>softmax</code>.</p>
<p>En este problema consideramos dos capas. En la primera definimos los datos de entrada con 20 neuronas artificiales y función de activación <code>relu</code>, y en la segunda tenemos la capa de salida. A continuación vemos el código necesario. Vamos a fijar la semilla inicial de los pesos de la red para poder reproducir los resultados. Para ello utilizamos la función <code>initializer_glorot_normal</code> que tiene por único parámetro el número aleatorio de inicio.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb12"><pre class="sourceCode numberSource r number-lines code-with-copy"><code class="sourceCode r"><span id="cb12-1"><a href="#cb12-1"></a><span class="co"># Fijamos semilla de los pesos iniciales para poder </span></span>
<span id="cb12-2"><a href="#cb12-2"></a>inicializador <span class="ot">=</span> <span class="fu">initializer_glorot_normal</span>(<span class="at">seed =</span> <span class="dv">15</span>)</span>
<span id="cb12-3"><a href="#cb12-3"></a></span>
<span id="cb12-4"><a href="#cb12-4"></a>modelo_iris <span class="sc">%&gt;%</span> </span>
<span id="cb12-5"><a href="#cb12-5"></a>  <span class="fu">layer_dense</span>(<span class="at">units =</span> <span class="dv">20</span>, <span class="at">activation =</span> <span class="st">'relu'</span>, <span class="at">input_shape =</span> <span class="fu">c</span>(<span class="fu">ncol</span>(Xest_test_iris)), <span class="at">kernel_initializer =</span> inicializador) <span class="sc">%&gt;%</span> </span>
<span id="cb12-6"><a href="#cb12-6"></a>  <span class="fu">layer_dense</span>(<span class="at">units =</span> <span class="dv">3</span>, <span class="at">activation =</span> <span class="st">'softmax'</span>, <span class="at">kernel_initializer =</span> inicializador)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>Podemos ver ahora la arquitectura que hemos diseñado con:</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb13"><pre class="sourceCode numberSource r number-lines code-with-copy"><code class="sourceCode r"><span id="cb13-1"><a href="#cb13-1"></a><span class="fu">summary</span>(modelo_iris)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Model: "sequential"
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_1 (Dense)                    (None, 20)                      100         
 dense (Dense)                      (None, 3)                       63          
================================================================================
Total params: 163 (652.00 Byte)
Trainable params: 163 (652.00 Byte)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________</code></pre>
</div>
</div>
<p>El método muestra todas las capas del modelo, lo que incluye el nombre de cada capa (que se genera automáticamente, a menos que lo configuremos en un argumento al crear la capa), su forma de salida y su número de parámetros. La salida finaliza con el número total de parámetros, incluidos los parámetros entrenables y no entrenables.</p>
</section>
<section id="proceso-de-aprendizaje" class="level4" data-number="3.2.1.2">
<h4 data-number="3.2.1.2" class="anchored" data-anchor-id="proceso-de-aprendizaje"><span class="header-section-number">3.2.1.2</span> Proceso de aprendizaje</h4>
<p>A partir del modelo <code>Sequential</code>, podemos definir las capas del modelo de manera sencilla, tal como hemos avanzado en el apartado anterior. Una vez que tengamos nuestro modelo definido, debemos configurar cómo será su proceso de aprendizaje con el método <code>compile()</code>, con el que podemos especificar algunas propiedades a través de argumentos del método.</p>
<p>El primero de estos argumentos es la función de coste (<code>loss function</code>), que usaremos para evaluar el grado de error entre las salidas calculadas y las salidas deseadas de los datos de entrenamiento. Por otro lado, se especifica un optimizador que, como veremos, es la manera que tenemos de indicar los detalles del algoritmo de optimización que permite a la red neuronal calcular los pesos de los parámetros durante el entrenamiento a partir de los datos de entrada y la función de coste definida.</p>
<p>Finalmente, debemos indicar la métrica que usaremos para monitorizar el proceso de aprendizaje (y prueba) de nuestra red neuronal. En este primer ejemplo solo tendremos en cuenta el porcentaje de casos correctamente clasificados (<code>accuracy</code>). Por ejemplo, en nuestro ejemplo podemos especificar los siguientes argumentos en el método <code>compile()</code> para probarlo:</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb15"><pre class="sourceCode numberSource r number-lines code-with-copy"><code class="sourceCode r"><span id="cb15-1"><a href="#cb15-1"></a>modelo_iris <span class="sc">%&gt;%</span> <span class="fu">compile</span>(</span>
<span id="cb15-2"><a href="#cb15-2"></a>  <span class="at">loss =</span> <span class="st">'sparse_categorical_crossentropy'</span>,</span>
<span id="cb15-3"><a href="#cb15-3"></a>  <span class="at">optimizer =</span> <span class="fu">optimizer_sgd</span>(),</span>
<span id="cb15-4"><a href="#cb15-4"></a>  <span class="at">metrics =</span> <span class="fu">c</span>(<span class="st">'accuracy'</span>)</span>
<span id="cb15-5"><a href="#cb15-5"></a>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>La elección de la función de pérdida viene determinada en gran medida por el tipo de tarea o problema que se desea abordar. En la tabla siguiente tenemos un pequeño resumen de su uso:</p>
<table class="table">
<colgroup>
<col style="width: 37%">
<col style="width: 33%">
<col style="width: 28%">
</colgroup>
<thead>
<tr class="header">
<th>Tipo de problema</th>
<th>Función de activación de la última capa</th>
<th>Función de pérdida</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>Clasificación múltiple con one-hot</td>
<td>softmax</td>
<td><code>categorical_crossentropy</code></td>
</tr>
<tr class="even">
<td>Clasificación múltiple con índice categoría</td>
<td>softmax</td>
<td><code>sparse_categorical_crossentropy</code></td>
</tr>
<tr class="odd">
<td>Regresión de un valor arbitrario</td>
<td></td>
<td><code>mse</code></td>
</tr>
<tr class="even">
<td>Regresión a valores en [0,1]</td>
<td>sigmoid</td>
<td><code>mse</code> o <code>binary_crossentropy</code></td>
</tr>
<tr class="odd">
<td>Clasificación binaria</td>
<td>sigmoid</td>
<td><code>binary_crossentropy</code></td>
</tr>
</tbody>
</table>
<p>En cuanto a los optimizadores disponibles en TensorFlow con la API Keras tenemos: SGD (descenso del gradiente estocástico), RMSprop, AdaGrad, Adadelta, Adam, Adamax, y Nadam. Estos optimizadores son variantes u optimizaciones del algoritmo de descenso del gradiente presentado, que usan hiperparámetros que explicaremos en próximos cuadernos. En la actualidad el algoritmo preferido es Adam ya que es el que proporciona mejores resultados de forma general.</p>
<p>Para saber las métricas disponibles se puede consultar este <a href="https://keras.io/api/metrics/">enlace</a>, mientars que para consultar los optimizadores disponibles se puede visitar esta <a href="https://keras.io/api/optimizers/">página</a>.</p>
</section>
<section id="entrenamiento-del-modelo" class="level4" data-number="3.2.1.3">
<h4 data-number="3.2.1.3" class="anchored" data-anchor-id="entrenamiento-del-modelo"><span class="header-section-number">3.2.1.3</span> Entrenamiento del modelo</h4>
<p>Una vez definido nuestro modelo y configurado su método de aprendizaje, este ya está listo para ser entrenado. Para ello, podemos entrenar o ajustar el modelo a los datos de entrenamiento de que disponemos invocando al método <code>fit()</code> del modelo. Los parámetros de entrada de esta función son los siguientes: * <strong>x</strong>: datos de entrada. * <strong>y</strong>: etiquetas de los datos de entrada. * <strong>batch_size</strong>: número de muestras que se utilizan en cada iteración del entrenamiento. Cuando la cantidad de datos es muy elevada (miles o millones) es conveniente usar un <em>batch_size</em> pequeño (de unos cuántos miles de datos) para evitar problemas de almacenamiento en la memoria del ordenador.</p>
<ul>
<li><p><strong>epochs</strong>: número de veces que se itera sobre el conjunto de datos de entrenamiento completo durante el proceso de entrenamiento.</p></li>
<li><p><strong>verbose</strong>: indica el nivel de detalle de la información que se muestra en pantalla durante el entrenamiento. Si es 0 no se muestra nada, 1 se muestra una barra de progreso y 2 se muestra una línea por época.</p></li>
</ul>
<p>El código siguiente configura el entrenamiento del modelo. Dado que el número de muestras es muy reducido no configuramos el <code>batch_size</code>.</p>
<p>El concepto de sobreajuste de un modelo (overfitting en inglés) se produce cuando el modelo obtenido se ajusta tanto a los ejemplos etiquetados de entrenamiento que no puede realizar las predicciones correctas en ejemplos de datos nuevos que nunca ha visto antes. En resumen, con overfitting o sobreajuste nos referimos a lo que le sucede a un modelo cuando este modela los datos de entrenamiento demasiado bien, aprendiendo detalles de estos que no son generales. Esto es debido a que sobre entrenamos nuestro modelo y este estará considerando como válidos solo los datos idénticos a los de nuestro conjunto de entrenamiento, incluidos sus defectos (también llamado ruido en nuestro contexto). Es decir, nos encontramos en la situación de que el modelo puede tener una baja tasa de error de clasificación para los datos de entrenamiento, pero no se generaliza bien a la población general de datos en los que estamos interesados.</p>
<p>Es evidente que, en general, esta situación presenta un impacto negativo en la eficiencia del modelo cuando este se usa para inferencia con datos nuevos. Por ello, es muy importante evitar estar en esta situación; de aquí la utilidad de reservar una parte de datos de entrenamiento como datos de validación. Podemos añadir el porcentaje de datos de validación dentro de la muestra de entrenamiento dentro del ajuste del modelo con el parámetro <code>validation_split</code>. Como este banco de datos es muy pequeño vamos a prescindir por el momento de dicho parámetro, que si incorporaremos en modelos con un mayor número de muestras.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb16"><pre class="sourceCode numberSource r number-lines code-with-copy"><code class="sourceCode r"><span id="cb16-1"><a href="#cb16-1"></a>history_iris <span class="ot">=</span> modelo_iris <span class="sc">%&gt;%</span> </span>
<span id="cb16-2"><a href="#cb16-2"></a>  <span class="fu">fit</span>(Xest_train_iris, y_train_iris,  <span class="at">epochs =</span> <span class="dv">20</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Epoch 1/20
4/4 - 1s - loss: 1.1106 - accuracy: 0.4417 - 555ms/epoch - 139ms/step
Epoch 2/20
4/4 - 0s - loss: 1.0732 - accuracy: 0.4417 - 35ms/epoch - 9ms/step
Epoch 3/20
4/4 - 0s - loss: 1.0386 - accuracy: 0.4500 - 10ms/epoch - 3ms/step
Epoch 4/20
4/4 - 0s - loss: 1.0058 - accuracy: 0.4583 - 9ms/epoch - 2ms/step
Epoch 5/20
4/4 - 0s - loss: 0.9752 - accuracy: 0.4667 - 9ms/epoch - 2ms/step
Epoch 6/20
4/4 - 0s - loss: 0.9466 - accuracy: 0.4667 - 9ms/epoch - 2ms/step
Epoch 7/20
4/4 - 0s - loss: 0.9198 - accuracy: 0.4833 - 13ms/epoch - 3ms/step
Epoch 8/20
4/4 - 0s - loss: 0.8947 - accuracy: 0.4833 - 9ms/epoch - 2ms/step
Epoch 9/20
4/4 - 0s - loss: 0.8717 - accuracy: 0.5083 - 10ms/epoch - 2ms/step
Epoch 10/20
4/4 - 0s - loss: 0.8498 - accuracy: 0.5500 - 11ms/epoch - 3ms/step
Epoch 11/20
4/4 - 0s - loss: 0.8293 - accuracy: 0.5500 - 10ms/epoch - 3ms/step
Epoch 12/20
4/4 - 0s - loss: 0.8098 - accuracy: 0.5917 - 9ms/epoch - 2ms/step
Epoch 13/20
4/4 - 0s - loss: 0.7913 - accuracy: 0.6083 - 9ms/epoch - 2ms/step
Epoch 14/20
4/4 - 0s - loss: 0.7741 - accuracy: 0.6250 - 9ms/epoch - 2ms/step
Epoch 15/20
4/4 - 0s - loss: 0.7574 - accuracy: 0.6333 - 10ms/epoch - 2ms/step
Epoch 16/20
4/4 - 0s - loss: 0.7421 - accuracy: 0.6417 - 10ms/epoch - 3ms/step
Epoch 17/20
4/4 - 0s - loss: 0.7275 - accuracy: 0.6500 - 9ms/epoch - 2ms/step
Epoch 18/20
4/4 - 0s - loss: 0.7140 - accuracy: 0.6750 - 9ms/epoch - 2ms/step
Epoch 19/20
4/4 - 0s - loss: 0.7011 - accuracy: 0.6917 - 9ms/epoch - 2ms/step
Epoch 20/20
4/4 - 0s - loss: 0.6887 - accuracy: 0.7000 - 9ms/epoch - 2ms/step</code></pre>
</div>
</div>
<p>Este método encuentra el valor de los parámetros de la red mediante el algoritmo iterativo de entrenamiento que hemos especificado en el argumento optimizer del método <code>compile()</code>. A grandes rasgos, en cada iteración de este algoritmo, este coge datos de entrenamiento de <code>x_train</code>, los pasa a través de la red neuronal (con los valores que en aquel momento tengan sus parámetros), compara el resultado obtenido con el esperado (indicado en <code>y_train</code>) y calcula la función de coste para guiar el proceso de ajuste de los parámetros del modelo. Intuitivamente consiste en aplicar el optimizador especificado anteriormente en el método <code>compile()</code> para calcular un nuevo valor de cada uno de los parámetros (pesos y sesgos) del modelo en cada iteración, de tal forma de que se reduzca el valor de la pérdida en siguientes iteraciones. Podemos ver la evolución de la función de pérdida y del porcentaje de clasificación correcta con el código siguiente.</p>
<p>Los resultados finales del entrenamiento los podemos ver con:</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb18"><pre class="sourceCode numberSource r number-lines code-with-copy"><code class="sourceCode r"><span id="cb18-1"><a href="#cb18-1"></a>history_iris</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>
Final epoch (plot to see history):
    loss: 0.6887
accuracy: 0.7 </code></pre>
</div>
</div>
<p>El porcentaje de clasificación correcto conseguido no es excesivamente bueno para la muestra de entrenamiento. Aunque los resultados no son espectaculares comparados con otros métodos de clasificación para este conjunto de datos, debemos tener en cuenta que hemos probado una red neuronal muy sencilla con solo una capa oculta. Podemos analizar la evolución del proceso de aprendizaje representando gráficamente los resultados obtenidos:</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb20"><pre class="sourceCode numberSource r number-lines code-with-copy"><code class="sourceCode r"><span id="cb20-1"><a href="#cb20-1"></a><span class="fu">plot</span>(history_iris) <span class="sc">+</span> <span class="fu">ylim</span>(<span class="dv">0</span>,<span class="dv">1</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output-display">
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="30_RMDDL_files/figure-html/rmdDL-014-1.png" class="img-fluid figure-img" width="576"></p>
<p></p><figcaption class="figure-caption">Proceso de aprendizaje. Datos Iris</figcaption><p></p>
</figure>
</div>
</div>
</div>
<p>Se puede ver como el modelo converge rápidamente (valores de loss y accuracy estables desde la epoch 10 más o menos).</p>
</section>
<section id="evaluación-del-modelo" class="level4" data-number="3.2.1.4">
<h4 data-number="3.2.1.4" class="anchored" data-anchor-id="evaluación-del-modelo"><span class="header-section-number">3.2.1.4</span> Evaluación del modelo</h4>
<p>Una vez entrenada la red neuronal llega el momento de evaluar como se comporta con los datos de validación. Para esta tarea utilizamos el método <code>evaluate()</code>. Este nos devuelve el valor de la función de pérdida y el porcentaje de clasificación correcta. Veamos los resultados para nuestro banco de datos.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb21"><pre class="sourceCode numberSource r number-lines code-with-copy"><code class="sourceCode r"><span id="cb21-1"><a href="#cb21-1"></a>modelo_iris <span class="sc">%&gt;%</span> tensorflow<span class="sc">::</span><span class="fu">evaluate</span>(Xest_test_iris, y_test_iris)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>1/1 - 0s - loss: 0.7027 - accuracy: 0.6667 - 175ms/epoch - 175ms/step</code></pre>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>     loss  accuracy 
0.7026886 0.6666667 </code></pre>
</div>
</div>
<p>¿ Qué porcentaje de clasificación correcta alcanzamos para la muestra de validación?¿Cómo lo interpretamos?.</p>
<p>Una herramienta muy utilizada en el aprendizaje automático para evaluar el rendimiento de modelos de clasificación es la matriz de confusión que contabiliza las predicciones en comparación con los valores reales. Usamos esta tabla para entender mejor cómo de bien o de mal el modelo se comporta, y es muy útil para mostrar de forma explícita cuándo una clase es confundida con otra. Para poder obtener la matriz de confusión es necesario obtener las predicciones del modelo para la muestra de validación y compararla con los datos originales. En el código siguiente se muestra como obtener dichos valores. Las funciones utilizadas devuelven valores numéricos que convertimos en factor con las etiquetas de los nombres de la especies consideradas.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb24"><pre class="sourceCode numberSource r number-lines code-with-copy"><code class="sourceCode r"><span id="cb24-1"><a href="#cb24-1"></a><span class="co"># probabilidades de clasificación de cada muestra en cada especie </span></span>
<span id="cb24-2"><a href="#cb24-2"></a>prediccion <span class="ot">=</span> modelo_iris <span class="sc">%&gt;%</span> <span class="fu">predict</span>(Xest_test_iris)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>1/1 - 0s - 105ms/epoch - 105ms/step</code></pre>
</div>
<div class="sourceCode cell-code" id="cb26"><pre class="sourceCode numberSource r number-lines code-with-copy"><code class="sourceCode r"><span id="cb26-1"><a href="#cb26-1"></a><span class="co"># predicción del modelo</span></span>
<span id="cb26-2"><a href="#cb26-2"></a>pr_modelo <span class="ot">=</span> <span class="fu">factor</span>((prediccion <span class="sc">%&gt;%</span> <span class="fu">k_argmax</span>())<span class="sc">$</span><span class="fu">numpy</span>(), <span class="at">levels =</span> <span class="dv">0</span><span class="sc">:</span>(<span class="fu">length</span>(nombres)<span class="sc">-</span><span class="dv">1</span>), <span class="at">labels =</span> nombres)</span>
<span id="cb26-3"><a href="#cb26-3"></a><span class="co"># valores originales</span></span>
<span id="cb26-4"><a href="#cb26-4"></a>pr_test <span class="ot">=</span> <span class="fu">factor</span>(y_test_iris, <span class="at">levels =</span> <span class="dv">0</span><span class="sc">:</span><span class="dv">0</span><span class="sc">:</span>(<span class="fu">length</span>(nombres)<span class="sc">-</span><span class="dv">1</span>), <span class="at">labels =</span> nombres)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>En los problemas de clasificación el objetivo es predecir correctamente la categoría de clasificación de cada observación. Así pues, las métricas naturales para evaluar estos modelos estarán basadas en contabilizar las coincidencias entre la clasificación correcta y la conseguida o predicha con el modelo.</p>
<p>Se pueden obtener muchas métricas relacionadas con la matriz de confusión entre las que destaca el porcentaje de clasificación correcta ponderado que es el utilizado cuando las categorias de la respuesta están desequilibradas, es decir, sus tamaños son muy diferentes. Para obtener la matriz de confusión utilizamos la librería <code>cvms</code> que dispone de la función <code>confusion_matrix</code> que nos permite seleccionar entre las métricas siguientes:</p>
<table class="table">
<thead>
<tr class="header">
<th>Metric</th>
<th>Name</th>
<th>Default</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>Balanced Accuracy</td>
<td>“Balanced Accuracy”</td>
<td>Enabled</td>
</tr>
<tr class="even">
<td>Accuracy</td>
<td>“Accuracy”</td>
<td>Disabled</td>
</tr>
<tr class="odd">
<td>Weighted Accuracy</td>
<td>“Weighted Accuracy”</td>
<td>Disabled</td>
</tr>
<tr class="even">
<td>F1</td>
<td>“F1”</td>
<td>Enabled</td>
</tr>
<tr class="odd">
<td>Sensitivity</td>
<td>“Sensitivity”</td>
<td>Enabled</td>
</tr>
<tr class="even">
<td>Specificity</td>
<td>“Specificity”</td>
<td>Enabled</td>
</tr>
<tr class="odd">
<td>Positive Predictive Value</td>
<td>“Pos Pred Value”</td>
<td>Enabled</td>
</tr>
<tr class="even">
<td>Negative Predictive Value</td>
<td>“Neg Pred Value”</td>
<td>Enabled</td>
</tr>
<tr class="odd">
<td>Kappa</td>
<td>“Kappa”</td>
<td>Enabled</td>
</tr>
<tr class="even">
<td>Matthews Correlation Coefficient</td>
<td>“MCC”</td>
<td>Enabled</td>
</tr>
<tr class="odd">
<td>Detection Rate</td>
<td>“Detection Rate”</td>
<td>Enabled</td>
</tr>
<tr class="even">
<td>Detection Prevalence</td>
<td>“Detection Prevalence”</td>
<td>Enabled</td>
</tr>
<tr class="odd">
<td>Prevalence</td>
<td>“Prevalence”</td>
<td>Enabled</td>
</tr>
<tr class="even">
<td>False Negative Rate</td>
<td>“False Neg Rate”</td>
<td>Disabled</td>
</tr>
<tr class="odd">
<td>False Positive Rate</td>
<td>“False Pos Rate”</td>
<td>Disabled</td>
</tr>
<tr class="even">
<td>False Discovery Rate</td>
<td>“False Discovery Rate”</td>
<td>Disabled</td>
</tr>
<tr class="odd">
<td>False Omission Rate</td>
<td>“False Omission Rate”</td>
<td>Disabled</td>
</tr>
<tr class="even">
<td>Threat Score</td>
<td>“Threat Score”</td>
<td>Disabled</td>
</tr>
</tbody>
</table>
<p>En este caso utilizamos como métrica el porcentaje de clasificación correcta ponderada. En primer lugar mostramos los resultados globales, el resultado para la métrica de interés, y la representación gráfica de la matriz de confusión.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb27"><pre class="sourceCode numberSource r number-lines code-with-copy"><code class="sourceCode r"><span id="cb27-1"><a href="#cb27-1"></a><span class="fu">library</span>(cvms)</span>
<span id="cb27-2"><a href="#cb27-2"></a>cm <span class="ot">&lt;-</span> <span class="fu">confusion_matrix</span>(pr_test, pr_modelo,</span>
<span id="cb27-3"><a href="#cb27-3"></a>  <span class="at">metrics =</span> <span class="fu">list</span>(<span class="st">"Weighted Accuracy"</span> <span class="ot">=</span> <span class="cn">TRUE</span>)</span>
<span id="cb27-4"><a href="#cb27-4"></a>)</span>
<span id="cb27-5"><a href="#cb27-5"></a><span class="co"># Matriz de confusión</span></span>
<span id="cb27-6"><a href="#cb27-6"></a>cm<span class="sc">$</span>Table</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>[[1]]
                 Target
Prediction        Iris-setosa Iris-versicolor Iris-virginica
  Iris-setosa              10               1              0
  Iris-versicolor           0               2              1
  Iris-virginica            0               8              8</code></pre>
</div>
</div>
<p>Podemos acceder a la métrica de interés con:</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb29"><pre class="sourceCode numberSource r number-lines code-with-copy"><code class="sourceCode r"><span id="cb29-1"><a href="#cb29-1"></a><span class="co"># Global</span></span>
<span id="cb29-2"><a href="#cb29-2"></a>cm<span class="sc">$</span><span class="st">`</span><span class="at">Weighted Accuracy</span><span class="st">`</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>[1] 0.7766667</code></pre>
</div>
<div class="sourceCode cell-code" id="cb31"><pre class="sourceCode numberSource r number-lines code-with-copy"><code class="sourceCode r"><span id="cb31-1"><a href="#cb31-1"></a><span class="co"># individuales para cada clase</span></span>
<span id="cb31-2"><a href="#cb31-2"></a>cm[[<span class="dv">3</span>]][[<span class="dv">1</span>]][,<span class="fu">c</span>(<span class="st">"Class"</span>, <span class="st">"Balanced Accuracy"</span>,<span class="st">"Accuracy"</span>)]</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code># A tibble: 3 × 3
  Class           `Balanced Accuracy` Accuracy
  &lt;chr&gt;                         &lt;dbl&gt;    &lt;dbl&gt;
1 Iris-setosa                   0.975    0.967
2 Iris-versicolor               0.565    0.667
3 Iris-virginica                0.754    0.7  </code></pre>
</div>
</div>
<p>¿Cómo interpretamos los resultados obtenidos de forma global y particular?. Veamos la matriz de confusión para detectar donde se producen las discrepancias en la clasificación:</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb33"><pre class="sourceCode numberSource r number-lines code-with-copy"><code class="sourceCode r"><span id="cb33-1"><a href="#cb33-1"></a><span class="fu">plot_confusion_matrix</span>(cm<span class="sc">$</span><span class="st">`</span><span class="at">Confusion Matrix</span><span class="st">`</span>[[<span class="dv">1</span>]])</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output-display">
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="30_RMDDL_files/figure-html/rmdDL-019-1.png" class="img-fluid figure-img" width="576"></p>
<p></p><figcaption class="figure-caption">Matriz de confusión. Datos Iris</figcaption><p></p>
</figure>
</div>
</div>
</div>
<p>¿que podemos comentar sobre la matriz de confusión?</p>
<p>Para finalizar vamos a representar la clasificación individual de cada una de las muestras de validación. Para esta faena creamos una función que nos proporciona un dataframe con los datos necesarios para el análisis individual de cada sujeto a partir de la matriz de las predicciones obtenida anteriormente.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb34"><pre class="sourceCode numberSource r number-lines code-with-copy"><code class="sourceCode r"><span id="cb34-1"><a href="#cb34-1"></a>genera_dat_indiv <span class="ot">=</span> <span class="cf">function</span>(dfpred, clases, eti_test){</span>
<span id="cb34-2"><a href="#cb34-2"></a>  <span class="co"># Función para generar banco de datos para el análisis individual de la predicción</span></span>
<span id="cb34-3"><a href="#cb34-3"></a>  </span>
<span id="cb34-4"><a href="#cb34-4"></a>  <span class="co"># Valores de entrada</span></span>
<span id="cb34-5"><a href="#cb34-5"></a>  <span class="co">#   dfpred: matriz numérica con las predicciones de cada clase</span></span>
<span id="cb34-6"><a href="#cb34-6"></a>  <span class="co">#   clases: etiquetas con los nombres de las clases</span></span>
<span id="cb34-7"><a href="#cb34-7"></a>  <span class="co">#   eti_test: etiquetas de la respuesta en la muestra de test</span></span>
<span id="cb34-8"><a href="#cb34-8"></a>  </span>
<span id="cb34-9"><a href="#cb34-9"></a>  <span class="co"># Valores de salida</span></span>
<span id="cb34-10"><a href="#cb34-10"></a>  <span class="co">#   dataframe con columnas: </span></span>
<span id="cb34-11"><a href="#cb34-11"></a>  <span class="co">#      sample: sujeto (repetido tantas veces como clases)</span></span>
<span id="cb34-12"><a href="#cb34-12"></a>  <span class="co">#      class: clase </span></span>
<span id="cb34-13"><a href="#cb34-13"></a>  <span class="co">#      probability: probabilidad predicha de la clase</span></span>
<span id="cb34-14"><a href="#cb34-14"></a>  <span class="co">#      target: clase observada  (repetido tantas veces como clases)</span></span>
<span id="cb34-15"><a href="#cb34-15"></a>  <span class="co">#      coincidencia: vector para saber cuando coinciden clase original y predicha</span></span>
<span id="cb34-16"><a href="#cb34-16"></a>  <span class="co">#      max: probabilidad máxima observada asignada a la clase predicha </span></span>
<span id="cb34-17"><a href="#cb34-17"></a>  </span>
<span id="cb34-18"><a href="#cb34-18"></a>  <span class="co"># Número de muestras</span></span>
<span id="cb34-19"><a href="#cb34-19"></a>  nval <span class="ot">=</span> <span class="fu">nrow</span>(dfpred)</span>
<span id="cb34-20"><a href="#cb34-20"></a>  <span class="co"># Número de clases </span></span>
<span id="cb34-21"><a href="#cb34-21"></a>  nclases <span class="ot">=</span> <span class="fu">length</span>(clases)</span>
<span id="cb34-22"><a href="#cb34-22"></a>  <span class="co"># Convertimos data.frame y asignamos nombres a las columnas</span></span>
<span id="cb34-23"><a href="#cb34-23"></a>  df <span class="ot">=</span> <span class="fu">as.data.frame</span>(dfpred)</span>
<span id="cb34-24"><a href="#cb34-24"></a>  <span class="fu">colnames</span>(df) <span class="ot">=</span> clases</span>
<span id="cb34-25"><a href="#cb34-25"></a>  <span class="co"># Añadimos el sujeto</span></span>
<span id="cb34-26"><a href="#cb34-26"></a>  df[<span class="st">"sample"</span>] <span class="ot">=</span> <span class="dv">1</span><span class="sc">:</span>nval</span>
<span id="cb34-27"><a href="#cb34-27"></a>  <span class="co"># preparamos los datos para el gráfico desdoblando el data frame</span></span>
<span id="cb34-28"><a href="#cb34-28"></a>  pred_gr <span class="ot">=</span> df <span class="sc">%&gt;%</span></span>
<span id="cb34-29"><a href="#cb34-29"></a>  <span class="fu">pivot_longer</span>(</span>
<span id="cb34-30"><a href="#cb34-30"></a>    <span class="at">cols =</span> <span class="sc">!</span>sample, </span>
<span id="cb34-31"><a href="#cb34-31"></a>    <span class="at">names_to =</span> <span class="st">"class"</span>, </span>
<span id="cb34-32"><a href="#cb34-32"></a>    <span class="at">values_to =</span> <span class="st">"probability"</span></span>
<span id="cb34-33"><a href="#cb34-33"></a>  )</span>
<span id="cb34-34"><a href="#cb34-34"></a>  <span class="co"># Añadimos target</span></span>
<span id="cb34-35"><a href="#cb34-35"></a>  pred_gr[<span class="st">"target"</span>] <span class="ot">=</span> <span class="fu">rep</span>(eti_test, <span class="at">each =</span> nclases)</span>
<span id="cb34-36"><a href="#cb34-36"></a>  <span class="co"># máximo de probabilidad</span></span>
<span id="cb34-37"><a href="#cb34-37"></a>  pred_gr[<span class="st">"max"</span>] <span class="ot">=</span> <span class="fu">rep</span>(<span class="fu">apply</span>(df[,<span class="dv">1</span><span class="sc">:</span>nclases],<span class="dv">1</span>,max), <span class="at">each =</span> nclases)</span>
<span id="cb34-38"><a href="#cb34-38"></a>  <span class="co"># condiciones lógicas para selección de casos</span></span>
<span id="cb34-39"><a href="#cb34-39"></a>  sel1 <span class="ot">=</span> (pred_gr[<span class="st">"class"</span>] <span class="sc">==</span> pred_gr[<span class="st">"target"</span>])      <span class="co"># igualdad entre clase observada y predicha</span></span>
<span id="cb34-40"><a href="#cb34-40"></a>  sel2 <span class="ot">=</span> (pred_gr[<span class="st">"probability"</span>] <span class="sc">==</span> pred_gr[<span class="st">"max"</span>])   <span class="co"># posición donde registrar probabilidad máxima</span></span>
<span id="cb34-41"><a href="#cb34-41"></a>  <span class="co"># Identifica muestras en als que la clasificación coincide con el target</span></span>
<span id="cb34-42"><a href="#cb34-42"></a>  pred_gr[<span class="st">"coincidencia"</span>] <span class="ot">=</span> ((sel1 <span class="sc">==</span> <span class="cn">TRUE</span>) <span class="sc">&amp;</span> (sel2 <span class="sc">==</span> <span class="cn">TRUE</span>))</span>
<span id="cb34-43"><a href="#cb34-43"></a>  <span class="co"># Calculo de probabilidad máxima asiganda a la categoria predicha</span></span>
<span id="cb34-44"><a href="#cb34-44"></a>  pred_gr[<span class="st">"max"</span>] <span class="ot">=</span> pred_gr[<span class="st">"max"</span>]<span class="sc">*</span>sel2</span>
<span id="cb34-45"><a href="#cb34-45"></a>  <span class="fu">return</span>(pred_gr)</span>
<span id="cb34-46"><a href="#cb34-46"></a>}</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>Obtenemos los datos con la función anterior e identificamos las muestras en las que la predicción no coincide con el valor observado:</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb35"><pre class="sourceCode numberSource r number-lines code-with-copy"><code class="sourceCode r"><span id="cb35-1"><a href="#cb35-1"></a><span class="co"># Datos</span></span>
<span id="cb35-2"><a href="#cb35-2"></a>datos_pred <span class="ot">=</span> <span class="fu">genera_dat_indiv</span>(prediccion, nombres, pr_test)</span>
<span id="cb35-3"><a href="#cb35-3"></a><span class="co"># datos de observaciones que no coinciden</span></span>
<span id="cb35-4"><a href="#cb35-4"></a>datos_pred[(datos_pred<span class="sc">$</span>max<span class="sc">&gt;</span><span class="dv">0</span>) <span class="sc">&amp;</span> (datos_pred<span class="sc">$</span>coincidencia <span class="sc">==</span> <span class="cn">FALSE</span>), <span class="fu">c</span>(<span class="st">"sample"</span>, <span class="st">"class"</span>, <span class="st">"probability"</span>, <span class="st">"target"</span>)]</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code># A tibble: 10 × 4
   sample class           probability target         
    &lt;int&gt; &lt;chr&gt;                 &lt;dbl&gt; &lt;fct&gt;          
 1      4 Iris-virginica        0.392 Iris-versicolor
 2      5 Iris-virginica        0.644 Iris-versicolor
 3      7 Iris-virginica        0.498 Iris-versicolor
 4     15 Iris-virginica        0.503 Iris-versicolor
 5     17 Iris-setosa           0.363 Iris-versicolor
 6     19 Iris-virginica        0.429 Iris-versicolor
 7     20 Iris-virginica        0.443 Iris-versicolor
 8     22 Iris-versicolor       0.461 Iris-virginica 
 9     26 Iris-virginica        0.414 Iris-versicolor
10     28 Iris-virginica        0.445 Iris-versicolor</code></pre>
</div>
</div>
<p>Ahora podemos representar el comportamiento de cada muestra mediante un gráfico de barras con las probabilidades de clasificación de cada clase. Para hacer esto definimos una función donde debemos incorporar los datos de predicción que hemos preparado antes y el índice de la muestra que queremos representar. La función representa mediante barras azules las probabilidades de asignación, barra de color verde a la probabilidad más alta cuando la predicción de clase coincide con el original, y en color rojo a la probabilidad más alta cuando la predicción de clase no coincide con el original.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb37"><pre class="sourceCode numberSource r number-lines code-with-copy"><code class="sourceCode r"><span id="cb37-1"><a href="#cb37-1"></a>grafica_clf <span class="ot">=</span> <span class="cf">function</span>(datos,idx)</span>
<span id="cb37-2"><a href="#cb37-2"></a>{</span>
<span id="cb37-3"><a href="#cb37-3"></a>  <span class="co"># Datos de un sujeto</span></span>
<span id="cb37-4"><a href="#cb37-4"></a>  dfsel <span class="ot">=</span> datos[datos<span class="sc">$</span>sample<span class="sc">==</span>idx,]</span>
<span id="cb37-5"><a href="#cb37-5"></a>  <span class="co"># Gráfico</span></span>
<span id="cb37-6"><a href="#cb37-6"></a>  <span class="cf">if</span>(<span class="fu">sum</span>(dfsel<span class="sc">$</span>coincidencia)<span class="sc">==</span><span class="dv">1</span>)</span>
<span id="cb37-7"><a href="#cb37-7"></a>  {</span>
<span id="cb37-8"><a href="#cb37-8"></a>  <span class="fu">ggplot</span>(dfsel, <span class="fu">aes</span>(class, probability)) <span class="sc">+</span> </span>
<span id="cb37-9"><a href="#cb37-9"></a>      <span class="fu">geom_bar</span>(<span class="at">stat=</span><span class="st">"identity"</span>, <span class="at">fill =</span> <span class="st">"blue"</span>) <span class="sc">+</span></span>
<span id="cb37-10"><a href="#cb37-10"></a>      <span class="fu">scale_y_continuous</span>(<span class="at">breaks =</span> <span class="fu">seq</span>(<span class="dv">0</span>,<span class="dv">1</span>,<span class="fl">0.1</span>), <span class="at">limits=</span><span class="fu">c</span>(<span class="dv">0</span>,<span class="dv">1</span>)) <span class="sc">+</span></span>
<span id="cb37-11"><a href="#cb37-11"></a>      <span class="fu">geom_bar</span>(<span class="fu">aes</span>(target, max), <span class="at">fill=</span><span class="st">"red"</span>, <span class="at">stat=</span><span class="st">"identity"</span>) <span class="sc">+</span></span>
<span id="cb37-12"><a href="#cb37-12"></a>      <span class="fu">geom_bar</span>(<span class="fu">aes</span>(target[coincidencia], max[coincidencia]), <span class="at">fill=</span><span class="st">"green"</span>, <span class="at">stat=</span><span class="st">"identity"</span>, <span class="at">na.rm =</span> <span class="cn">TRUE</span>) <span class="sc">+</span></span>
<span id="cb37-13"><a href="#cb37-13"></a>      <span class="fu">theme</span>(<span class="at">legend.position =</span> <span class="st">"none"</span>)</span>
<span id="cb37-14"><a href="#cb37-14"></a>  }</span>
<span id="cb37-15"><a href="#cb37-15"></a>  <span class="cf">else</span>{</span>
<span id="cb37-16"><a href="#cb37-16"></a>  <span class="fu">ggplot</span>(dfsel, <span class="fu">aes</span>(class, probability)) <span class="sc">+</span> </span>
<span id="cb37-17"><a href="#cb37-17"></a>      <span class="fu">geom_bar</span>(<span class="at">stat=</span><span class="st">"identity"</span>, <span class="at">fill =</span> <span class="st">"blue"</span>) <span class="sc">+</span></span>
<span id="cb37-18"><a href="#cb37-18"></a>      <span class="fu">scale_y_continuous</span>(<span class="at">breaks =</span> <span class="fu">seq</span>(<span class="dv">0</span>,<span class="dv">1</span>,<span class="fl">0.1</span>), <span class="at">limits=</span><span class="fu">c</span>(<span class="dv">0</span>,<span class="dv">1</span>)) <span class="sc">+</span></span>
<span id="cb37-19"><a href="#cb37-19"></a>      <span class="fu">geom_bar</span>(<span class="fu">aes</span>(target, max), <span class="at">fill=</span><span class="st">"red"</span>, <span class="at">stat=</span><span class="st">"identity"</span>) <span class="sc">+</span></span>
<span id="cb37-20"><a href="#cb37-20"></a>      <span class="fu">theme</span>(<span class="at">legend.position =</span> <span class="st">"none"</span>)    </span>
<span id="cb37-21"><a href="#cb37-21"></a>  }</span>
<span id="cb37-22"><a href="#cb37-22"></a>}</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>Representamos todas las muestras:</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb38"><pre class="sourceCode numberSource r number-lines code-with-copy"><code class="sourceCode r"><span id="cb38-1"><a href="#cb38-1"></a>graf <span class="ot">=</span> <span class="fu">list</span>()</span>
<span id="cb38-2"><a href="#cb38-2"></a><span class="cf">for</span> (i <span class="cf">in</span> <span class="dv">1</span><span class="sc">:</span><span class="fu">length</span>(y_test_iris))</span>
<span id="cb38-3"><a href="#cb38-3"></a>{</span>
<span id="cb38-4"><a href="#cb38-4"></a>  graf[[i]] <span class="ot">=</span> <span class="fu">grafica_clf</span>(datos_pred, i)</span>
<span id="cb38-5"><a href="#cb38-5"></a>}</span>
<span id="cb38-6"><a href="#cb38-6"></a><span class="fu">ggarrange</span>(<span class="at">plotlist=</span>graf,<span class="at">ncol=</span><span class="dv">5</span>,<span class="at">nrow=</span><span class="dv">6</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output-display">
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="30_RMDDL_files/figure-html/rmdDL-023-1.png" class="img-fluid figure-img" width="1440"></p>
<p></p><figcaption class="figure-caption">Clasificación. Datos Iris</figcaption><p></p>
</figure>
</div>
</div>
</div>
<p>¿Qué muestras son clasificadas de forma incorrecta?</p>
</section>
<section id="validación-del-modelo" class="level4" data-number="3.2.1.5">
<h4 data-number="3.2.1.5" class="anchored" data-anchor-id="validación-del-modelo"><span class="header-section-number">3.2.1.5</span> Validación del modelo</h4>
<p>Como ya hemos visto, la solución obtenida depende de la muestra de entrenamiento y de las semillas prefijadas en el periodo de entrenamiento. Sin embargo, en las tareas de aprendizaje automático resulta necesario conocer la validez del modelo obtenido, y más concretamente la estabilidad de la solución propuesta utilizando métodos de validación cruzada.</p>
<p>Los dos modelos de validación cruzada más habituales son <code>Hold-out validation</code> y <code>K-fold cross-validation</code>. Dado que el número de muestras de entrenamiento suele ser bastante elevado en los modelos de redes neuronales consideramos que el segundo de los métodos de validación puede resultar más adecuado porque además conseguimos acelerar el proceso de convergencia.</p>
<p>Este método de validación consiste en dividir los datos en K particiones de igual tamaño. Para cada partición i, se entrena un modelo en las K - 1 particiones restantes y se evalúa en la partición i. La puntuación final es la media de las K puntuaciones obtenidas. Podemos estudiar así la variabilidad de la evaluación en las k particiones. Este método es útil cuando el rendimiento del modelo muestra una variación significativa en función de la división entrenamiento-prueba. Para realizar este proceso debemos establecer un procedimiento secuencial para la creación de los diferentes fold de datos, y considerar un función que nos permita explicitar el modelo de red (arquitectura y proceso de aprendizaje) que será el miso para todos los folds. En primer lugar vemos la función para estabecer el modelo que define la arquitectura de red y proceso de aprendizaje que vamos a utilizar. Por el momento la función no tiene ningún parámetro.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb39"><pre class="sourceCode numberSource r number-lines code-with-copy"><code class="sourceCode r"><span id="cb39-1"><a href="#cb39-1"></a><span class="co"># Función para la definición del modelo</span></span>
<span id="cb39-2"><a href="#cb39-2"></a>build_model <span class="ot">=</span> <span class="cf">function</span>()</span>
<span id="cb39-3"><a href="#cb39-3"></a>{</span>
<span id="cb39-4"><a href="#cb39-4"></a>  <span class="co"># Arquitectura del modelo</span></span>
<span id="cb39-5"><a href="#cb39-5"></a>  inicializador <span class="ot">=</span> <span class="fu">initializer_glorot_normal</span>(<span class="at">seed =</span> <span class="dv">15</span>)</span>
<span id="cb39-6"><a href="#cb39-6"></a>  modelo <span class="ot">=</span> <span class="fu">keras_model_sequential</span>() <span class="sc">%&gt;%</span> </span>
<span id="cb39-7"><a href="#cb39-7"></a>    <span class="fu">layer_dense</span>(<span class="at">units =</span> <span class="dv">20</span>, <span class="at">activation =</span> <span class="st">'relu'</span>, <span class="at">input_shape =</span> <span class="dv">4</span>, <span class="at">kernel_initializer =</span> inicializador) <span class="sc">%&gt;%</span> </span>
<span id="cb39-8"><a href="#cb39-8"></a>    <span class="fu">layer_dense</span>(<span class="at">units =</span> <span class="dv">3</span>, <span class="at">activation =</span> <span class="st">'softmax'</span>, <span class="at">kernel_initializer =</span> inicializador)</span>
<span id="cb39-9"><a href="#cb39-9"></a>  <span class="co"># Proceso de aprendizaje</span></span>
<span id="cb39-10"><a href="#cb39-10"></a>  modelo <span class="sc">%&gt;%</span> <span class="fu">compile</span>(</span>
<span id="cb39-11"><a href="#cb39-11"></a>    <span class="at">loss =</span> <span class="st">'sparse_categorical_crossentropy'</span>,</span>
<span id="cb39-12"><a href="#cb39-12"></a>    <span class="at">optimizer =</span> <span class="fu">optimizer_sgd</span>(),</span>
<span id="cb39-13"><a href="#cb39-13"></a>    <span class="at">metrics =</span> <span class="fu">c</span>(<span class="st">'accuracy'</span>)</span>
<span id="cb39-14"><a href="#cb39-14"></a>  )</span>
<span id="cb39-15"><a href="#cb39-15"></a>  <span class="co"># Devolvemos el modelo configurado</span></span>
<span id="cb39-16"><a href="#cb39-16"></a>  <span class="fu">return</span>(modelo)</span>
<span id="cb39-17"><a href="#cb39-17"></a>}</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>Podemos ver como funciona la función con el código siguiente:</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb40"><pre class="sourceCode numberSource r number-lines code-with-copy"><code class="sourceCode r"><span id="cb40-1"><a href="#cb40-1"></a>modelo <span class="ot">=</span> <span class="fu">build_model</span>()</span>
<span id="cb40-2"><a href="#cb40-2"></a><span class="fu">summary</span>(modelo)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Model: "sequential_1"
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_3 (Dense)                    (None, 20)                      100         
 dense_2 (Dense)                    (None, 3)                       63          
================================================================================
Total params: 163 (652.00 Byte)
Trainable params: 163 (652.00 Byte)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________</code></pre>
</div>
</div>
<p>El modelo es el mismo que hemos utilizado en el análisis del ejemplo. En este primer ejmeplo vamos a considerar <span class="math inline">\(k=5\)</span> folds lo que supone que dividimos nuestra muestra original en 5 subconjuntos de 30 muestras, de forma que en cada iteración tenemos 30 observaciones para la muestra de validación y 120 para el entrenamiento. Definimos a continuación el proceso de entrenamiento y la evaluación del modelo para cada uno de los folds. Consideramos <code>accuray</code> y <code>weight accuray</code> como las métricas de valoración del modelo.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb42"><pre class="sourceCode numberSource r number-lines code-with-copy"><code class="sourceCode r"><span id="cb42-1"><a href="#cb42-1"></a><span class="co"># Establecemos número de folds</span></span>
<span id="cb42-2"><a href="#cb42-2"></a>folds <span class="ot">=</span> <span class="dv">5</span></span>
<span id="cb42-3"><a href="#cb42-3"></a><span class="co"># Tamaño de cada fold</span></span>
<span id="cb42-4"><a href="#cb42-4"></a>nfolds <span class="ot">=</span> <span class="fu">nrow</span>(iris)<span class="sc">/</span>folds</span>
<span id="cb42-5"><a href="#cb42-5"></a><span class="co"># Variable que codifica cada fold</span></span>
<span id="cb42-6"><a href="#cb42-6"></a>codfold <span class="ot">=</span> <span class="fu">rep</span>(<span class="dv">1</span><span class="sc">:</span>folds,<span class="fu">rep</span>(nfolds, folds))</span>
<span id="cb42-7"><a href="#cb42-7"></a><span class="co"># Generamos data frame con valores originales y el código del fold</span></span>
<span id="cb42-8"><a href="#cb42-8"></a>df <span class="ot">=</span> <span class="fu">cbind</span>(iris, codfold)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>En primer lugar vamos a verificar si todos los folds contienen valores de todas las clases que deseamos predecir, ya que sino el proceso de evaluación podría dar errores. Si esto ocurre se puede aumentar el tamaño del fold para evitar este problema.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb43"><pre class="sourceCode numberSource r number-lines code-with-copy"><code class="sourceCode r"><span id="cb43-1"><a href="#cb43-1"></a>df <span class="sc">%&gt;%</span> <span class="fu">group_by</span>(codfold) <span class="sc">%&gt;%</span> <span class="fu">summarise</span>(<span class="at">conteo =</span> <span class="fu">n_distinct</span>(species))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code># A tibble: 5 × 2
  codfold conteo
    &lt;int&gt;  &lt;int&gt;
1       1      3
2       2      3
3       3      3
4       4      3
5       5      3</code></pre>
</div>
</div>
<p>Todos los folds contienen observaciones de la tres especies. Definimos ahora un bucle que nos permite realizar el proceso de validación.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb45"><pre class="sourceCode numberSource r number-lines code-with-copy"><code class="sourceCode r"><span id="cb45-1"><a href="#cb45-1"></a><span class="co"># Predictoras y respuesta</span></span>
<span id="cb45-2"><a href="#cb45-2"></a>X_iris <span class="ot">=</span> dplyr<span class="sc">::</span><span class="fu">select</span>(df, <span class="sc">-</span><span class="fu">c</span>(<span class="st">"species"</span>,<span class="st">"codfold"</span>))</span>
<span id="cb45-3"><a href="#cb45-3"></a><span class="co"># Codificamos la respuesta numéricamente y restamos 1 ya los array  se incializan en ceor en python</span></span>
<span id="cb45-4"><a href="#cb45-4"></a>y_iris <span class="ot">=</span> <span class="fu">as.numeric</span>(df<span class="sc">$</span>species)<span class="sc">-</span><span class="dv">1</span></span>
<span id="cb45-5"><a href="#cb45-5"></a></span>
<span id="cb45-6"><a href="#cb45-6"></a><span class="co"># Inicializamos los vectores donde almacenamos las métricas de validación de los sucesivos modelos</span></span>
<span id="cb45-7"><a href="#cb45-7"></a>acc_mod <span class="ot">=</span> <span class="fu">c</span>()</span>
<span id="cb45-8"><a href="#cb45-8"></a>wacc_mod <span class="ot">=</span> <span class="fu">c</span>()</span>
<span id="cb45-9"><a href="#cb45-9"></a>metricas <span class="ot">=</span> <span class="fu">c</span>()</span>
<span id="cb45-10"><a href="#cb45-10"></a></span>
<span id="cb45-11"><a href="#cb45-11"></a><span class="co"># Bucle para cada fold</span></span>
<span id="cb45-12"><a href="#cb45-12"></a><span class="cf">for</span>(i <span class="cf">in</span> <span class="dv">1</span><span class="sc">:</span>folds)</span>
<span id="cb45-13"><a href="#cb45-13"></a>{</span>
<span id="cb45-14"><a href="#cb45-14"></a>  <span class="co"># Índice para la muestra de test</span></span>
<span id="cb45-15"><a href="#cb45-15"></a>  test <span class="ot">=</span> (nfolds<span class="sc">*</span>(i<span class="dv">-1</span>) <span class="sc">+</span><span class="dv">1</span>)<span class="sc">:</span>(nfolds<span class="sc">*</span>i)</span>
<span id="cb45-16"><a href="#cb45-16"></a>  <span class="co"># Muestras de entrenamiento y test</span></span>
<span id="cb45-17"><a href="#cb45-17"></a>  xtrain <span class="ot">=</span> X_iris[<span class="sc">-</span>test,]</span>
<span id="cb45-18"><a href="#cb45-18"></a>  xtest <span class="ot">=</span> X_iris[test,]</span>
<span id="cb45-19"><a href="#cb45-19"></a>  ytrain <span class="ot">=</span> y_iris[<span class="sc">-</span>test]</span>
<span id="cb45-20"><a href="#cb45-20"></a>  ytest <span class="ot">=</span> y_iris[test]</span>
<span id="cb45-21"><a href="#cb45-21"></a>  <span class="co"># Estandarización</span></span>
<span id="cb45-22"><a href="#cb45-22"></a>  <span class="co"># Medias</span></span>
<span id="cb45-23"><a href="#cb45-23"></a>  mean_train <span class="ot">=</span> <span class="fu">apply</span>(xtrain, <span class="dv">2</span>, mean)</span>
<span id="cb45-24"><a href="#cb45-24"></a>  <span class="co"># Desviaciones típicas</span></span>
<span id="cb45-25"><a href="#cb45-25"></a>  sd_train <span class="ot">=</span> <span class="fu">apply</span>(xtrain, <span class="dv">2</span>, sd)</span>
<span id="cb45-26"><a href="#cb45-26"></a>  <span class="co"># Estandarizamos muestra de entrenamiento</span></span>
<span id="cb45-27"><a href="#cb45-27"></a>  xtrain <span class="ot">=</span> <span class="fu">scale</span>(xtrain, mean_train, sd_train)</span>
<span id="cb45-28"><a href="#cb45-28"></a>  <span class="co"># Estandarizamos muestra de validación</span></span>
<span id="cb45-29"><a href="#cb45-29"></a>  xtest <span class="ot">=</span> <span class="fu">scale</span>(xtest, mean_train, sd_train)</span>
<span id="cb45-30"><a href="#cb45-30"></a>  </span>
<span id="cb45-31"><a href="#cb45-31"></a>  <span class="co"># Modelo de red</span></span>
<span id="cb45-32"><a href="#cb45-32"></a>  modelo <span class="ot">=</span> <span class="fu">build_model</span>()</span>
<span id="cb45-33"><a href="#cb45-33"></a>  <span class="fu">cat</span>(<span class="st">"Comienza el entrenamiento para el fold "</span>, i, <span class="st">"</span><span class="sc">\n</span><span class="st">"</span>)</span>
<span id="cb45-34"><a href="#cb45-34"></a>  <span class="co"># Entrenamiento del modelo</span></span>
<span id="cb45-35"><a href="#cb45-35"></a>  history <span class="ot">=</span> modelo <span class="sc">%&gt;%</span>  <span class="fu">fit</span>(xtrain, ytrain,  <span class="at">batch_size =</span> <span class="dv">50</span>, <span class="at">epochs =</span> <span class="dv">10</span>, <span class="at">verbose =</span> <span class="cn">FALSE</span>)</span>
<span id="cb45-36"><a href="#cb45-36"></a>  <span class="co"># Evaluación del modelo</span></span>
<span id="cb45-37"><a href="#cb45-37"></a>  acc_mod[i] <span class="ot">=</span> (modelo <span class="sc">%&gt;%</span> tensorflow<span class="sc">::</span><span class="fu">evaluate</span>(xtest, ytest))[<span class="dv">2</span>]</span>
<span id="cb45-38"><a href="#cb45-38"></a>  <span class="co"># Predicción con el modelo</span></span>
<span id="cb45-39"><a href="#cb45-39"></a>  prediccion <span class="ot">=</span> modelo <span class="sc">%&gt;%</span> <span class="fu">predict</span>(xtest)</span>
<span id="cb45-40"><a href="#cb45-40"></a>  <span class="co"># predicción del modelo</span></span>
<span id="cb45-41"><a href="#cb45-41"></a>  pr_modelo <span class="ot">=</span> <span class="fu">factor</span>((prediccion <span class="sc">%&gt;%</span> <span class="fu">k_argmax</span>())<span class="sc">$</span><span class="fu">numpy</span>(), <span class="at">levels =</span> <span class="dv">0</span><span class="sc">:</span>(<span class="fu">length</span>(nombres)<span class="sc">-</span><span class="dv">1</span>))</span>
<span id="cb45-42"><a href="#cb45-42"></a>  pr_test <span class="ot">=</span> <span class="fu">factor</span>(ytest, <span class="at">levels =</span> <span class="dv">0</span><span class="sc">:</span>(<span class="fu">length</span>(nombres)<span class="sc">-</span><span class="dv">1</span>))</span>
<span id="cb45-43"><a href="#cb45-43"></a>  wacc_mod[i] <span class="ot">=</span> <span class="fu">confusion_matrix</span>(pr_test, pr_modelo, <span class="at">metrics =</span> <span class="fu">list</span>(<span class="st">"Weighted Accuracy"</span> <span class="ot">=</span> <span class="cn">TRUE</span>))<span class="sc">$</span><span class="st">`</span><span class="at">Weighted Accuracy</span><span class="st">`</span></span>
<span id="cb45-44"><a href="#cb45-44"></a>  metricas <span class="ot">=</span> <span class="fu">rbind</span>(metricas,<span class="fu">c</span>(i, acc_mod[i],wacc_mod[i]))</span>
<span id="cb45-45"><a href="#cb45-45"></a>  }</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Comienza el entrenamiento para el fold  1 
1/1 - 0s - loss: 1.0110 - accuracy: 0.3333 - 128ms/epoch - 128ms/step
1/1 - 0s - 57ms/epoch - 57ms/step
Comienza el entrenamiento para el fold  2 
1/1 - 0s - loss: 0.7185 - accuracy: 0.6333 - 127ms/epoch - 127ms/step
1/1 - 0s - 44ms/epoch - 44ms/step
Comienza el entrenamiento para el fold  3 
1/1 - 0s - loss: 0.9221 - accuracy: 0.5000 - 114ms/epoch - 114ms/step
1/1 - 0s - 45ms/epoch - 45ms/step
Comienza el entrenamiento para el fold  4 
1/1 - 0s - loss: 0.8709 - accuracy: 0.5333 - 130ms/epoch - 130ms/step
1/1 - 0s - 68ms/epoch - 68ms/step
Comienza el entrenamiento para el fold  5 
1/1 - 0s - loss: 0.9695 - accuracy: 0.4333 - 124ms/epoch - 124ms/step
1/1 - 0s - 200ms/epoch - 200ms/step</code></pre>
</div>
<div class="sourceCode cell-code" id="cb47"><pre class="sourceCode numberSource r number-lines code-with-copy"><code class="sourceCode r"><span id="cb47-1"><a href="#cb47-1"></a><span class="fu">colnames</span>(metricas) <span class="ot">=</span> <span class="fu">c</span>(<span class="st">"Fold"</span>,<span class="st">"Acc"</span>,<span class="st">"WAcc"</span>)</span>
<span id="cb47-2"><a href="#cb47-2"></a>metricas</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>     Fold       Acc      WAcc
[1,]    1 0.3333333 0.4966667
[2,]    2 0.6333333 0.8266667
[3,]    3 0.5000000 0.6700000
[4,]    4 0.5333334 0.6877778
[5,]    5 0.4333333 0.5733333</code></pre>
</div>
</div>
<p>Definimos ahora una función para el análisis descriptivo de cada una de las métricas. la función proporciona la media, desviación típica, y los percentiles asociados.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb49"><pre class="sourceCode numberSource r number-lines code-with-copy"><code class="sourceCode r"><span id="cb49-1"><a href="#cb49-1"></a>describe <span class="ot">=</span> <span class="cf">function</span>(dat)</span>
<span id="cb49-2"><a href="#cb49-2"></a>{</span>
<span id="cb49-3"><a href="#cb49-3"></a>  ds <span class="ot">=</span> <span class="fu">data.frame</span>(<span class="at">media =</span> <span class="fu">mean</span>(dat), <span class="at">dt =</span> <span class="fu">sd</span>(dat), </span>
<span id="cb49-4"><a href="#cb49-4"></a>                  <span class="at">p05 =</span> <span class="fu">quantile</span>(dat, <span class="fl">0.05</span>),</span>
<span id="cb49-5"><a href="#cb49-5"></a>                  <span class="at">p25 =</span> <span class="fu">quantile</span>(dat, <span class="fl">0.25</span>),</span>
<span id="cb49-6"><a href="#cb49-6"></a>                  <span class="at">p50 =</span> <span class="fu">quantile</span>(dat, <span class="fl">0.50</span>),</span>
<span id="cb49-7"><a href="#cb49-7"></a>                  <span class="at">p75 =</span> <span class="fu">quantile</span>(dat, <span class="fl">0.75</span>),</span>
<span id="cb49-8"><a href="#cb49-8"></a>                  <span class="at">p95 =</span> <span class="fu">quantile</span>(dat, <span class="fl">0.95</span>))</span>
<span id="cb49-9"><a href="#cb49-9"></a>  <span class="fu">row.names</span>(ds) <span class="ot">=</span> <span class="st">""</span></span>
<span id="cb49-10"><a href="#cb49-10"></a>  <span class="fu">return</span>(ds)</span>
<span id="cb49-11"><a href="#cb49-11"></a>}</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>Veamos los resultados:</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb50"><pre class="sourceCode numberSource r number-lines code-with-copy"><code class="sourceCode r"><span id="cb50-1"><a href="#cb50-1"></a><span class="co"># Accuracy</span></span>
<span id="cb50-2"><a href="#cb50-2"></a><span class="fu">describe</span>(metricas[,<span class="dv">2</span>])</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>     media        dt       p05       p25 p50       p75       p95
 0.4866667 0.1120516 0.3533333 0.4333333 0.5 0.5333334 0.6133333</code></pre>
</div>
<div class="sourceCode cell-code" id="cb52"><pre class="sourceCode numberSource r number-lines code-with-copy"><code class="sourceCode r"><span id="cb52-1"><a href="#cb52-1"></a><span class="co"># WAccuracy</span></span>
<span id="cb52-2"><a href="#cb52-2"></a><span class="fu">describe</span>(metricas[,<span class="dv">3</span>])</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>     media        dt   p05       p25  p50       p75       p95
 0.6508889 0.1249232 0.512 0.5733333 0.67 0.6877778 0.7988889</code></pre>
</div>
</div>
<p>¿Cómo interpretamos los resultados obtenidos para ambas métricas?</p>
</section>
</section>
<section id="datos-digits" class="level3" data-number="3.2.2">
<h3 data-number="3.2.2" class="anchored" data-anchor-id="datos-digits"><span class="header-section-number">3.2.2</span> Datos Digits</h3>
<p>Este conjunto de datos trata el problema de reconocimiento de números escritos a mano. El conjunto de datos MNIST está formado por imágenes de dígitos escritos a mano. Este conjunto de datos contiene 60000 muestras para entrenar el modelo y 1000 adicionales para testearlo, y es ideal para adentrarse por primera vez en técnicas de reconocimiento de patrones sin tener que dedicar mucho tiempo al preproceso y formateado de datos. Ambos son muy importantes y costosos en el análisis de datos, y de especial complejidad cuando se está trabajando con imágenes. Este conjunto de datos solo requiere pequeñas transformaciones que comentaremos a continuación. El conjunto de imágenes, originales en blanco y negro, han sido normalizadas a 20 x 20 píxeles, y conservan su relación de aspecto. En este caso, es importante notar que las imágenes contienen niveles de grises como resultado de la técnica de anti-aliasing, usada en el algoritmo de normalización (reducir la resolución de todas las imágenes). Posteriormente, las imágenes se han centrado en 28 x 28 píxeles -se calcula el centro de masa de estos y se traslada la imagen con el fin de posicionar este punto en el centro del campo de 28 x 28-. Estas imágenes, de entrada, se representan en una matriz con las intensidades de cada uno de los 28 x 28 píxeles con valores entre [0, 255]. Además, el conjunto de datos dispone de una etiqueta para cada una de las imágenes, que indica qué dígito representa (entre el 0 y el 9), es decir, a qué clase corresponde. En este ejemplo, vamos a representar esta etiqueta con un vector de 1 0 posiciones, donde la posición correspondiente al dígito que representa la imagen contiene un 1, y el resto son 0.</p>
<p>En primer lugar cargamos los datos que se encuentra disponibles dentro de la librería <code>Keras</code>. Este objeto contiene dos listas <code>mnist$train</code> y <code>mnist$test</code>. Estas a su vez contienen dos elementos, 2 arrays, <code>mnist$train$x</code> con las imágenes y <code>mnist$train$y</code> con las etiquetas de cada una, o dicho de otra forma, el número que aparece en la imagen.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb54"><pre class="sourceCode numberSource r number-lines code-with-copy"><code class="sourceCode r"><span id="cb54-1"><a href="#cb54-1"></a><span class="co"># Cargamos datos</span></span>
<span id="cb54-2"><a href="#cb54-2"></a>mnist <span class="ot">&lt;-</span> keras<span class="sc">::</span><span class="fu">dataset_mnist</span>()</span>
<span id="cb54-3"><a href="#cb54-3"></a><span class="co"># División de muestras entrenamiento y validación</span></span>
<span id="cb54-4"><a href="#cb54-4"></a>x_train <span class="ot">&lt;-</span> mnist<span class="sc">$</span>train<span class="sc">$</span>x</span>
<span id="cb54-5"><a href="#cb54-5"></a>y_train <span class="ot">&lt;-</span> mnist<span class="sc">$</span>train<span class="sc">$</span>y</span>
<span id="cb54-6"><a href="#cb54-6"></a>x_test <span class="ot">&lt;-</span> mnist<span class="sc">$</span>test<span class="sc">$</span>x</span>
<span id="cb54-7"><a href="#cb54-7"></a>y_test <span class="ot">&lt;-</span> mnist<span class="sc">$</span>test<span class="sc">$</span>y</span>
<span id="cb54-8"><a href="#cb54-8"></a><span class="co"># Etiquetas</span></span>
<span id="cb54-9"><a href="#cb54-9"></a>etiquetas <span class="ot">=</span> <span class="dv">0</span><span class="sc">:</span><span class="dv">9</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>Podemos acceder a la matriz de inputs correspondiente al primer elemento de la muestra de entrenamiento y al target correspondiente con:</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb55"><pre class="sourceCode numberSource r number-lines code-with-copy"><code class="sourceCode r"><span id="cb55-1"><a href="#cb55-1"></a><span class="co"># Input</span></span>
<span id="cb55-2"><a href="#cb55-2"></a>x_train[<span class="dv">1</span>,,]</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>      [,1] [,2] [,3] [,4] [,5] [,6] [,7] [,8] [,9] [,10] [,11] [,12] [,13]
 [1,]    0    0    0    0    0    0    0    0    0     0     0     0     0
 [2,]    0    0    0    0    0    0    0    0    0     0     0     0     0
 [3,]    0    0    0    0    0    0    0    0    0     0     0     0     0
 [4,]    0    0    0    0    0    0    0    0    0     0     0     0     0
 [5,]    0    0    0    0    0    0    0    0    0     0     0     0     0
 [6,]    0    0    0    0    0    0    0    0    0     0     0     0     3
 [7,]    0    0    0    0    0    0    0    0   30    36    94   154   170
 [8,]    0    0    0    0    0    0    0   49  238   253   253   253   253
 [9,]    0    0    0    0    0    0    0   18  219   253   253   253   253
[10,]    0    0    0    0    0    0    0    0   80   156   107   253   253
[11,]    0    0    0    0    0    0    0    0    0    14     1   154   253
[12,]    0    0    0    0    0    0    0    0    0     0     0   139   253
[13,]    0    0    0    0    0    0    0    0    0     0     0    11   190
[14,]    0    0    0    0    0    0    0    0    0     0     0     0    35
[15,]    0    0    0    0    0    0    0    0    0     0     0     0     0
[16,]    0    0    0    0    0    0    0    0    0     0     0     0     0
[17,]    0    0    0    0    0    0    0    0    0     0     0     0     0
[18,]    0    0    0    0    0    0    0    0    0     0     0     0     0
[19,]    0    0    0    0    0    0    0    0    0     0     0     0     0
[20,]    0    0    0    0    0    0    0    0    0     0     0     0    39
[21,]    0    0    0    0    0    0    0    0    0     0    24   114   221
[22,]    0    0    0    0    0    0    0    0   23    66   213   253   253
[23,]    0    0    0    0    0    0   18  171  219   253   253   253   253
[24,]    0    0    0    0   55  172  226  253  253   253   253   244   133
[25,]    0    0    0    0  136  253  253  253  212   135   132    16     0
[26,]    0    0    0    0    0    0    0    0    0     0     0     0     0
[27,]    0    0    0    0    0    0    0    0    0     0     0     0     0
[28,]    0    0    0    0    0    0    0    0    0     0     0     0     0
      [,14] [,15] [,16] [,17] [,18] [,19] [,20] [,21] [,22] [,23] [,24] [,25]
 [1,]     0     0     0     0     0     0     0     0     0     0     0     0
 [2,]     0     0     0     0     0     0     0     0     0     0     0     0
 [3,]     0     0     0     0     0     0     0     0     0     0     0     0
 [4,]     0     0     0     0     0     0     0     0     0     0     0     0
 [5,]     0     0     0     0     0     0     0     0     0     0     0     0
 [6,]    18    18    18   126   136   175    26   166   255   247   127     0
 [7,]   253   253   253   253   253   225   172   253   242   195    64     0
 [8,]   253   253   253   253   251    93    82    82    56    39     0     0
 [9,]   253   198   182   247   241     0     0     0     0     0     0     0
[10,]   205    11     0    43   154     0     0     0     0     0     0     0
[11,]    90     0     0     0     0     0     0     0     0     0     0     0
[12,]   190     2     0     0     0     0     0     0     0     0     0     0
[13,]   253    70     0     0     0     0     0     0     0     0     0     0
[14,]   241   225   160   108     1     0     0     0     0     0     0     0
[15,]    81   240   253   253   119    25     0     0     0     0     0     0
[16,]     0    45   186   253   253   150    27     0     0     0     0     0
[17,]     0     0    16    93   252   253   187     0     0     0     0     0
[18,]     0     0     0     0   249   253   249    64     0     0     0     0
[19,]     0    46   130   183   253   253   207     2     0     0     0     0
[20,]   148   229   253   253   253   250   182     0     0     0     0     0
[21,]   253   253   253   253   201    78     0     0     0     0     0     0
[22,]   253   253   198    81     2     0     0     0     0     0     0     0
[23,]   195    80     9     0     0     0     0     0     0     0     0     0
[24,]    11     0     0     0     0     0     0     0     0     0     0     0
[25,]     0     0     0     0     0     0     0     0     0     0     0     0
[26,]     0     0     0     0     0     0     0     0     0     0     0     0
[27,]     0     0     0     0     0     0     0     0     0     0     0     0
[28,]     0     0     0     0     0     0     0     0     0     0     0     0
      [,26] [,27] [,28]
 [1,]     0     0     0
 [2,]     0     0     0
 [3,]     0     0     0
 [4,]     0     0     0
 [5,]     0     0     0
 [6,]     0     0     0
 [7,]     0     0     0
 [8,]     0     0     0
 [9,]     0     0     0
[10,]     0     0     0
[11,]     0     0     0
[12,]     0     0     0
[13,]     0     0     0
[14,]     0     0     0
[15,]     0     0     0
[16,]     0     0     0
[17,]     0     0     0
[18,]     0     0     0
[19,]     0     0     0
[20,]     0     0     0
[21,]     0     0     0
[22,]     0     0     0
[23,]     0     0     0
[24,]     0     0     0
[25,]     0     0     0
[26,]     0     0     0
[27,]     0     0     0
[28,]     0     0     0</code></pre>
</div>
<div class="sourceCode cell-code" id="cb57"><pre class="sourceCode numberSource r number-lines code-with-copy"><code class="sourceCode r"><span id="cb57-1"><a href="#cb57-1"></a><span class="co"># Target</span></span>
<span id="cb57-2"><a href="#cb57-2"></a>y_train[<span class="dv">1</span>]</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>[1] 5</code></pre>
</div>
</div>
<p>Ahora definimos una función que nos permite representar gráficamente la información contenida en cada uno de los elementos de entrenamiento.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb59"><pre class="sourceCode numberSource r number-lines code-with-copy"><code class="sourceCode r"><span id="cb59-1"><a href="#cb59-1"></a>pinta_digit <span class="ot">=</span> <span class="cf">function</span>(datos, idx)</span>
<span id="cb59-2"><a href="#cb59-2"></a>{</span>
<span id="cb59-3"><a href="#cb59-3"></a>  <span class="do">## Valores de entrada</span></span>
<span id="cb59-4"><a href="#cb59-4"></a>  <span class="co">#    datos: matriz de datos de inputs</span></span>
<span id="cb59-5"><a href="#cb59-5"></a>  <span class="co">#    idx: muestra seleccionada</span></span>
<span id="cb59-6"><a href="#cb59-6"></a>  <span class="do">## Valores de salida</span></span>
<span id="cb59-7"><a href="#cb59-7"></a>  <span class="co">#    gráfico de intensidad en escala de grises de la información contenida en la muestra idx de la matriz de inputs  </span></span>
<span id="cb59-8"><a href="#cb59-8"></a>  datos[idx, , ] <span class="sc">%&gt;%</span></span>
<span id="cb59-9"><a href="#cb59-9"></a>    <span class="co">#transformar a dataframe</span></span>
<span id="cb59-10"><a href="#cb59-10"></a>    <span class="fu">as.data.frame</span>() <span class="sc">%&gt;%</span></span>
<span id="cb59-11"><a href="#cb59-11"></a>    <span class="co"># agregar el ide de la columna</span></span>
<span id="cb59-12"><a href="#cb59-12"></a>    <span class="co"># para identificar la posición de cada pixel</span></span>
<span id="cb59-13"><a href="#cb59-13"></a>    <span class="fu">rowid_to_column</span>(<span class="at">var =</span> <span class="st">"y"</span>) <span class="sc">%&gt;%</span></span>
<span id="cb59-14"><a href="#cb59-14"></a>    <span class="co"># reshape del dataframe</span></span>
<span id="cb59-15"><a href="#cb59-15"></a>    <span class="fu">gather</span>(<span class="st">"x"</span>, <span class="st">"value"</span>, <span class="sc">-</span>y) <span class="sc">%&gt;%</span></span>
<span id="cb59-16"><a href="#cb59-16"></a>    <span class="co"># volviendo la variable x numerica</span></span>
<span id="cb59-17"><a href="#cb59-17"></a>    <span class="fu">mutate</span>(<span class="at">x =</span> <span class="fu">parse_number</span>(x)) <span class="sc">%&gt;%</span></span>
<span id="cb59-18"><a href="#cb59-18"></a>    <span class="co"># gráfico de tiles</span></span>
<span id="cb59-19"><a href="#cb59-19"></a>    <span class="fu">ggplot</span>(<span class="fu">aes</span>(<span class="at">x =</span> x, <span class="at">y =</span> y, <span class="at">fill =</span> value)) <span class="sc">+</span> </span>
<span id="cb59-20"><a href="#cb59-20"></a>      <span class="fu">geom_tile</span>(<span class="at">show.legend =</span> <span class="cn">FALSE</span>) <span class="sc">+</span></span>
<span id="cb59-21"><a href="#cb59-21"></a>      <span class="fu">scale_y_reverse</span>() <span class="sc">+</span></span>
<span id="cb59-22"><a href="#cb59-22"></a>      <span class="fu">scale_fill_gradient</span>(<span class="at">low =</span> <span class="st">"white"</span>, <span class="at">high =</span> <span class="st">"black"</span>) <span class="sc">+</span></span>
<span id="cb59-23"><a href="#cb59-23"></a>      <span class="fu">theme_void</span>() </span>
<span id="cb59-24"><a href="#cb59-24"></a>}</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>Veamos su funcionamiento sobre la primera muestra de la matriz de inputs de entrenamiento</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb60"><pre class="sourceCode numberSource r number-lines code-with-copy"><code class="sourceCode r"><span id="cb60-1"><a href="#cb60-1"></a><span class="fu">pinta_digit</span>(x_train, <span class="dv">1</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output-display">
<p><img src="30_RMDDL_files/figure-html/rmdDL-034-1.png" class="img-fluid" width="672"></p>
</div>
</div>
<p>El resultado se corresponde con el valor etiquetado en <code>ytrain[1]</code> que es un 5. Representamos la información de los 100 primeras muestras de entrenamiento</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb61"><pre class="sourceCode numberSource r number-lines code-with-copy"><code class="sourceCode r"><span id="cb61-1"><a href="#cb61-1"></a><span class="co"># Realizamos los gráficos y los cargamos en una lista</span></span>
<span id="cb61-2"><a href="#cb61-2"></a>gr <span class="ot">=</span> <span class="fu">list</span>()</span>
<span id="cb61-3"><a href="#cb61-3"></a><span class="cf">for</span>(i <span class="cf">in</span> <span class="dv">1</span><span class="sc">:</span><span class="dv">100</span>)</span>
<span id="cb61-4"><a href="#cb61-4"></a>{</span>
<span id="cb61-5"><a href="#cb61-5"></a>  gr[[i]] <span class="ot">=</span> <span class="fu">pinta_digit</span>(x_train, i)</span>
<span id="cb61-6"><a href="#cb61-6"></a>}</span>
<span id="cb61-7"><a href="#cb61-7"></a><span class="co"># Representamos todos los gráficos</span></span>
<span id="cb61-8"><a href="#cb61-8"></a><span class="fu">ggarrange</span>(<span class="at">plotlist=</span>gr, <span class="at">ncol =</span> <span class="dv">10</span>, <span class="at">nrow =</span> <span class="dv">10</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output-display">
<p><img src="30_RMDDL_files/figure-html/rmdDL-035-1.png" class="img-fluid" width="672"></p>
</div>
</div>
<p>Veamos con que dígito se corresponde cada uno de ellos:</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb62"><pre class="sourceCode numberSource r number-lines code-with-copy"><code class="sourceCode r"><span id="cb62-1"><a href="#cb62-1"></a>y_train[<span class="dv">1</span><span class="sc">:</span><span class="dv">100</span>]</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>  [1] 5 0 4 1 9 2 1 3 1 4 3 5 3 6 1 7 2 8 6 9 4 0 9 1 1 2 4 3 2 7 3 8 6 9 0 5 6
 [38] 0 7 6 1 8 7 9 3 9 8 5 9 3 3 0 7 4 9 8 0 9 4 1 4 4 6 0 4 5 6 1 0 0 1 7 1 6
 [75] 3 0 2 1 1 7 9 0 2 6 7 8 3 9 0 4 6 7 4 6 8 0 7 8 3 1</code></pre>
</div>
</div>
<section id="arquitectura-de-la-red-1" class="level4" data-number="3.2.2.1">
<h4 data-number="3.2.2.1" class="anchored" data-anchor-id="arquitectura-de-la-red-1"><span class="header-section-number">3.2.2.1</span> Arquitectura de la red</h4>
<p>Antes de comenzar a describir la arquitectura de la red neuronal para este ejemplo vamos a normalizar los inputs a la escala 0-1 para facilitar que la red converja más rápidamente.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb64"><pre class="sourceCode numberSource r number-lines code-with-copy"><code class="sourceCode r"><span id="cb64-1"><a href="#cb64-1"></a><span class="co"># Reescalamos para tener entradas en el intervalo 0-1</span></span>
<span id="cb64-2"><a href="#cb64-2"></a>x_train <span class="ot">&lt;-</span> x_train <span class="sc">/</span> <span class="dv">255</span></span>
<span id="cb64-3"><a href="#cb64-3"></a>x_test <span class="ot">&lt;-</span> x_test <span class="sc">/</span> <span class="dv">255</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>Para definir la arquitectura de la red en este caso debemos tener en cuenta que el input de cada muestra es una matriz (array) de dimensiones 28x28 y no un cevtor como en el primer ejemplo. Para facilitar el trabajo de la red neuronal lo más habitual es introducir para cada muestra un vector de inputs, por lo que es necesario reconvertir la entrada en un vector. Esto se puede hacer de dos formas:</p>
<ul>
<li>Convertir la matriz 28x28 en una vector con 784 elementos mediante la función <code>array_reshape</code>.</li>
<li>Introducir en la arquitectura una capa de preprocesado <code>layer_faltten</code> que convierte la matriz de input en un vector de forma automática.</li>
</ul>
<p>En este caso vamos a optar por esta opción para la manipulación de datos. Luego se especifican dos capas dense, en la primera se establece la cantidad de nodos o neuronas de la red y la función de activación. En este caso se usa una de las más comunes, la función de activación ReLU.</p>
<p>En la segunda capa dense, la capa del output, se especifican los nodos de salida, uno por cada categoría probable, y al tratarse de números del 0 al 9 se especifican 10, El segundo argumento de esta capa hace que el resultado del modelo sea un array con 10 valores de probabilidad que suma uno. En este caso el nodo de la categoría que tenga el mayor score termina siendo la predicción.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb65"><pre class="sourceCode numberSource r number-lines code-with-copy"><code class="sourceCode r"><span id="cb65-1"><a href="#cb65-1"></a>inicializador <span class="ot">=</span> <span class="fu">initializer_glorot_normal</span>(<span class="at">seed =</span> <span class="dv">15</span>)</span>
<span id="cb65-2"><a href="#cb65-2"></a></span>
<span id="cb65-3"><a href="#cb65-3"></a>modelo_digits <span class="ot">=</span> <span class="fu">keras_model_sequential</span>() <span class="sc">%&gt;%</span> </span>
<span id="cb65-4"><a href="#cb65-4"></a>    <span class="fu">layer_flatten</span>(<span class="at">input_shape =</span> <span class="fu">c</span>(<span class="dv">28</span>, <span class="dv">28</span>)) <span class="sc">%&gt;%</span> </span>
<span id="cb65-5"><a href="#cb65-5"></a>    <span class="fu">layer_dense</span>(<span class="at">units =</span> <span class="dv">32</span>, <span class="at">activation =</span> <span class="st">"relu"</span>, <span class="at">kernel_initializer =</span> inicializador) <span class="sc">%&gt;%</span> </span>
<span id="cb65-6"><a href="#cb65-6"></a>    <span class="fu">layer_dense</span>(<span class="dv">10</span>, <span class="at">activation =</span> <span class="st">"softmax"</span>, <span class="at">kernel_initializer =</span> inicializador)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>Veamos el número de parámetros de este modelo</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb66"><pre class="sourceCode numberSource r number-lines code-with-copy"><code class="sourceCode r"><span id="cb66-1"><a href="#cb66-1"></a><span class="fu">summary</span>(modelo_digits)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Model: "sequential_7"
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 flatten (Flatten)                  (None, 784)                     0           
 dense_15 (Dense)                   (None, 32)                      25120       
 dense_14 (Dense)                   (None, 10)                      330         
================================================================================
Total params: 25450 (99.41 KB)
Trainable params: 25450 (99.41 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________</code></pre>
</div>
</div>
<p>El número de parámetros es 25450 a pesar de la sencillez de la red.</p>
</section>
<section id="proceso-de-aprendizaje-1" class="level4" data-number="3.2.2.2">
<h4 data-number="3.2.2.2" class="anchored" data-anchor-id="proceso-de-aprendizaje-1"><span class="header-section-number">3.2.2.2</span> Proceso de aprendizaje</h4>
<p>Definimos ahora el proceso de aprendizaje con la misma configuración que en el ejemplo anterior</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb68"><pre class="sourceCode numberSource r number-lines code-with-copy"><code class="sourceCode r"><span id="cb68-1"><a href="#cb68-1"></a>modelo_digits <span class="sc">%&gt;%</span> <span class="fu">compile</span>(</span>
<span id="cb68-2"><a href="#cb68-2"></a>  <span class="at">loss =</span> <span class="st">'sparse_categorical_crossentropy'</span>,</span>
<span id="cb68-3"><a href="#cb68-3"></a>  <span class="at">optimizer =</span> <span class="fu">optimizer_sgd</span>(),</span>
<span id="cb68-4"><a href="#cb68-4"></a>  <span class="at">metrics =</span> <span class="fu">c</span>(<span class="st">'accuracy'</span>)</span>
<span id="cb68-5"><a href="#cb68-5"></a>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
</section>
<section id="entrenamiento-del-modelo-1" class="level4" data-number="3.2.2.3">
<h4 data-number="3.2.2.3" class="anchored" data-anchor-id="entrenamiento-del-modelo-1"><span class="header-section-number">3.2.2.3</span> Entrenamiento del modelo</h4>
<p>Para el proceso de entrenamiento consideramos <em>batch_size</em> de 50 y 10 <em>epochs</em>. En este caso hay un número bastante grande de muestras de entrenamiento y es necesario hacer bloques para que el algoritmo pueda estimar los parámetros de la red.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb69"><pre class="sourceCode numberSource r number-lines code-with-copy"><code class="sourceCode r"><span id="cb69-1"><a href="#cb69-1"></a>history_digits <span class="ot">=</span> modelo_digits <span class="sc">%&gt;%</span> </span>
<span id="cb69-2"><a href="#cb69-2"></a>  <span class="fu">fit</span>(x_train, y_train, <span class="at">batch_size =</span> <span class="dv">50</span>, <span class="at">epochs =</span> <span class="dv">10</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Epoch 1/10
1200/1200 - 3s - loss: 0.8719 - accuracy: 0.7737 - 3s/epoch - 2ms/step
Epoch 2/10
1200/1200 - 2s - loss: 0.4072 - accuracy: 0.8886 - 2s/epoch - 2ms/step
Epoch 3/10
1200/1200 - 2s - loss: 0.3470 - accuracy: 0.9019 - 2s/epoch - 2ms/step
Epoch 4/10
1200/1200 - 2s - loss: 0.3174 - accuracy: 0.9093 - 2s/epoch - 2ms/step
Epoch 5/10
1200/1200 - 2s - loss: 0.2978 - accuracy: 0.9153 - 2s/epoch - 2ms/step
Epoch 6/10
1200/1200 - 2s - loss: 0.2825 - accuracy: 0.9195 - 2s/epoch - 2ms/step
Epoch 7/10
1200/1200 - 2s - loss: 0.2698 - accuracy: 0.9231 - 2s/epoch - 2ms/step
Epoch 8/10
1200/1200 - 2s - loss: 0.2587 - accuracy: 0.9264 - 2s/epoch - 2ms/step
Epoch 9/10
1200/1200 - 2s - loss: 0.2487 - accuracy: 0.9297 - 2s/epoch - 2ms/step
Epoch 10/10
1200/1200 - 2s - loss: 0.2398 - accuracy: 0.9315 - 2s/epoch - 2ms/step</code></pre>
</div>
</div>
<p>Los resultados finales del entrenamiento los podemos ver con:</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb71"><pre class="sourceCode numberSource r number-lines code-with-copy"><code class="sourceCode r"><span id="cb71-1"><a href="#cb71-1"></a>history_digits</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>
Final epoch (plot to see history):
    loss: 0.2398
accuracy: 0.9315 </code></pre>
</div>
</div>
<p>El porcentaje de clasificación correcta es muy alta incluso con una red tan sencilla. Vemos los resultados del proceso iterativa gráficamente</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb73"><pre class="sourceCode numberSource r number-lines code-with-copy"><code class="sourceCode r"><span id="cb73-1"><a href="#cb73-1"></a><span class="fu">plot</span>(history_digits) <span class="sc">+</span> <span class="fu">ylim</span>(<span class="dv">0</span>,<span class="dv">1</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output-display">
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="30_RMDDL_files/figure-html/rmdDL-043-1.png" class="img-fluid figure-img" width="576"></p>
<p></p><figcaption class="figure-caption">Proceso de aprendizaje. Datos Iris</figcaption><p></p>
</figure>
</div>
</div>
</div>
<p>¿qué podemos decir?</p>
</section>
<section id="evaluación-del-modelo-1" class="level4" data-number="3.2.2.4">
<h4 data-number="3.2.2.4" class="anchored" data-anchor-id="evaluación-del-modelo-1"><span class="header-section-number">3.2.2.4</span> Evaluación del modelo</h4>
<p>Una vez entrenada la red neuronal llega el momento de evaluar como se comporta con los datos de validación. Veamos los resultados para nuestro banco de datos.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb74"><pre class="sourceCode numberSource r number-lines code-with-copy"><code class="sourceCode r"><span id="cb74-1"><a href="#cb74-1"></a>modelo_digits <span class="sc">%&gt;%</span> tensorflow<span class="sc">::</span><span class="fu">evaluate</span>(x_test, y_test)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>313/313 - 0s - loss: 0.2310 - accuracy: 0.9335 - 449ms/epoch - 1ms/step</code></pre>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>     loss  accuracy 
0.2309539 0.9335000 </code></pre>
</div>
</div>
<p>¿Cómo interpretamos el valor obtenido?</p>
<p>Obtenemos ahora las predicciones asociadas para conseguir la matriz de confusión y la métrica de interés.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb77"><pre class="sourceCode numberSource r number-lines code-with-copy"><code class="sourceCode r"><span id="cb77-1"><a href="#cb77-1"></a><span class="co"># probabilidades de clasificación de cada muestra en cada especie </span></span>
<span id="cb77-2"><a href="#cb77-2"></a>prediccion <span class="ot">=</span> modelo_digits <span class="sc">%&gt;%</span> <span class="fu">predict</span>(x_test)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>313/313 - 0s - 335ms/epoch - 1ms/step</code></pre>
</div>
<div class="sourceCode cell-code" id="cb79"><pre class="sourceCode numberSource r number-lines code-with-copy"><code class="sourceCode r"><span id="cb79-1"><a href="#cb79-1"></a><span class="co"># predicción del modelo</span></span>
<span id="cb79-2"><a href="#cb79-2"></a>pr_modelo <span class="ot">=</span> <span class="fu">factor</span>((prediccion <span class="sc">%&gt;%</span> <span class="fu">k_argmax</span>())<span class="sc">$</span><span class="fu">numpy</span>(), <span class="at">levels =</span> <span class="dv">0</span><span class="sc">:</span>(<span class="fu">length</span>(etiquetas)<span class="sc">-</span><span class="dv">1</span>))</span>
<span id="cb79-3"><a href="#cb79-3"></a>pr_test <span class="ot">=</span> <span class="fu">factor</span>(y_test, <span class="at">levels =</span> <span class="dv">0</span><span class="sc">:</span>(<span class="fu">length</span>(etiquetas)<span class="sc">-</span><span class="dv">1</span>))</span>
<span id="cb79-4"><a href="#cb79-4"></a><span class="co"># matriz de confusion</span></span>
<span id="cb79-5"><a href="#cb79-5"></a>cm <span class="ot">&lt;-</span> <span class="fu">confusion_matrix</span>(y_test, pr_modelo, <span class="at">metrics =</span> <span class="fu">list</span>(<span class="st">"Weighted Accuracy"</span> <span class="ot">=</span> <span class="cn">TRUE</span>))</span>
<span id="cb79-6"><a href="#cb79-6"></a><span class="co"># Matriz de confusión</span></span>
<span id="cb79-7"><a href="#cb79-7"></a>cm<span class="sc">$</span>Table</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>[[1]]
          Target
Prediction    0    1    2    3    4    5    6    7    8    9
         0  962    0    7    3    1   10   10    1    6   10
         1    0 1115    7    1    2    3    3   10    8    8
         2    2    2  943   24    7    5    4   27    4    1
         3    1    2   16  917    0   32    1    2   18   11
         4    0    0    9    1  922    7    9    5    8   32
         5    2    1    1   23    0  786    7    0   14    4
         6   10    4   11    2   10   21  922    0   14    1
         7    1    2   10   10    3    5    0  954   10   10
         8    1    9   25   18    4   15    2    3  888    6
         9    1    0    3   11   33    8    0   26    4  926</code></pre>
</div>
<div class="sourceCode cell-code" id="cb81"><pre class="sourceCode numberSource r number-lines code-with-copy"><code class="sourceCode r"><span id="cb81-1"><a href="#cb81-1"></a><span class="co"># Métrica global</span></span>
<span id="cb81-2"><a href="#cb81-2"></a>cm<span class="sc">$</span><span class="st">`</span><span class="at">Weighted Accuracy</span><span class="st">`</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>[1] 0.9867928</code></pre>
</div>
<div class="sourceCode cell-code" id="cb83"><pre class="sourceCode numberSource r number-lines code-with-copy"><code class="sourceCode r"><span id="cb83-1"><a href="#cb83-1"></a><span class="co"># individuales para cada clase</span></span>
<span id="cb83-2"><a href="#cb83-2"></a>cm[[<span class="dv">3</span>]][[<span class="dv">1</span>]][,<span class="fu">c</span>(<span class="st">"Class"</span>, <span class="st">"Balanced Accuracy"</span>,<span class="st">"Accuracy"</span>)]</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code># A tibble: 10 × 3
   Class `Balanced Accuracy` Accuracy
   &lt;chr&gt;               &lt;dbl&gt;    &lt;dbl&gt;
 1 0                   0.988    0.993
 2 1                   0.989    0.994
 3 2                   0.953    0.984
 4 3                   0.949    0.982
 5 4                   0.966    0.987
 6 5                   0.938    0.984
 7 6                   0.977    0.989
 8 7                   0.961    0.988
 9 8                   0.951    0.983
10 9                   0.954    0.983</code></pre>
</div>
</div>
<div class="cell">
<div class="sourceCode cell-code" id="cb85"><pre class="sourceCode numberSource r number-lines code-with-copy"><code class="sourceCode r"><span id="cb85-1"><a href="#cb85-1"></a><span class="fu">plot_confusion_matrix</span>(cm<span class="sc">$</span><span class="st">`</span><span class="at">Confusion Matrix</span><span class="st">`</span>[[<span class="dv">1</span>]])</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output-display">
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="30_RMDDL_files/figure-html/rmdDL-046-1.png" class="img-fluid figure-img" width="960"></p>
<p></p><figcaption class="figure-caption">Matriz de confusión</figcaption><p></p>
</figure>
</div>
</div>
</div>
<p>¿Qué podemos comentar de la matriz de confusión obtenida?</p>
<p>Visualizamos el análisis individual de la clasificación para las primeras muestras de test igual que hicimos con el ejemplo de iris. En primer lugar obtenemos los datos para la representación gráfica.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb86"><pre class="sourceCode numberSource r number-lines code-with-copy"><code class="sourceCode r"><span id="cb86-1"><a href="#cb86-1"></a><span class="co"># Datos</span></span>
<span id="cb86-2"><a href="#cb86-2"></a>datos_pred <span class="ot">=</span> <span class="fu">genera_dat_indiv</span>(prediccion, etiquetas, pr_test)</span>
<span id="cb86-3"><a href="#cb86-3"></a><span class="co"># datos de observaciones que no coinciden</span></span>
<span id="cb86-4"><a href="#cb86-4"></a>datos_pred[(datos_pred<span class="sc">$</span>max<span class="sc">&gt;</span><span class="dv">0</span>) <span class="sc">&amp;</span> (datos_pred<span class="sc">$</span>coincidencia <span class="sc">==</span> <span class="cn">FALSE</span>), <span class="fu">c</span>(<span class="st">"sample"</span>, <span class="st">"class"</span>, <span class="st">"probability"</span>, <span class="st">"target"</span>)]</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code># A tibble: 665 × 4
   sample class probability target
    &lt;int&gt; &lt;chr&gt;       &lt;dbl&gt; &lt;fct&gt; 
 1      9 6           0.976 5     
 2     34 6           0.664 4     
 3     64 2           0.620 3     
 4     93 4           0.396 9     
 5    125 4           0.616 7     
 6    150 9           0.574 2     
 7    194 3           0.320 9     
 8    196 8           0.292 3     
 9    212 7           0.464 5     
10    234 7           0.553 8     
# ℹ 655 more rows</code></pre>
</div>
</div>
<p>Representamos las 16 primeras muestras de tests:</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb88"><pre class="sourceCode numberSource r number-lines code-with-copy"><code class="sourceCode r"><span id="cb88-1"><a href="#cb88-1"></a>ngraf <span class="ot">=</span> <span class="dv">16</span></span>
<span id="cb88-2"><a href="#cb88-2"></a>graf <span class="ot">=</span> <span class="fu">list</span>()</span>
<span id="cb88-3"><a href="#cb88-3"></a><span class="cf">for</span> (i <span class="cf">in</span> <span class="dv">1</span><span class="sc">:</span>ngraf)</span>
<span id="cb88-4"><a href="#cb88-4"></a>{</span>
<span id="cb88-5"><a href="#cb88-5"></a>  graf[[i]] <span class="ot">=</span> <span class="fu">grafica_clf</span>(datos_pred, i)</span>
<span id="cb88-6"><a href="#cb88-6"></a>}</span>
<span id="cb88-7"><a href="#cb88-7"></a><span class="fu">ggarrange</span>(<span class="at">plotlist=</span>graf, <span class="at">ncol =</span> <span class="dv">4</span>, <span class="at">nrow =</span> <span class="dv">4</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output-display">
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="30_RMDDL_files/figure-html/rmdDL-048-1.png" class="img-fluid figure-img" width="1440"></p>
<p></p><figcaption class="figure-caption">Clasificación. Datos Iris</figcaption><p></p>
</figure>
</div>
</div>
</div>
<p>¿qué podemos decir de los gráficos obtenidos?</p>
</section>
<section id="validación-del-modelo-1" class="level4" data-number="3.2.2.5">
<h4 data-number="3.2.2.5" class="anchored" data-anchor-id="validación-del-modelo-1"><span class="header-section-number">3.2.2.5</span> Validación del modelo</h4>
<p>En este caso el proceso de validación es similar al del ejemplo anterior seleccionando los folds sobre las matrices de inputs y el vector de target combinando tanto los datos de entrenamiento como los de test. El código siguiente nos permite combinar ambos conjuntos en uno solo tanto en los inputs como en el output.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb89"><pre class="sourceCode numberSource r number-lines code-with-copy"><code class="sourceCode r"><span id="cb89-1"><a href="#cb89-1"></a><span class="co"># Calculamos dimensiones</span></span>
<span id="cb89-2"><a href="#cb89-2"></a>dm_train <span class="ot">=</span> <span class="fu">dim</span>(x_train)[<span class="dv">1</span>]</span>
<span id="cb89-3"><a href="#cb89-3"></a>dm_test <span class="ot">=</span> <span class="fu">dim</span>(x_test)[<span class="dv">1</span>]</span>
<span id="cb89-4"><a href="#cb89-4"></a>dm <span class="ot">=</span> dm_train <span class="sc">+</span> dm_test</span>
<span id="cb89-5"><a href="#cb89-5"></a><span class="co"># matriz de inputs completo</span></span>
<span id="cb89-6"><a href="#cb89-6"></a>x_digits <span class="ot">=</span> <span class="fu">array</span>(<span class="dv">0</span>, <span class="at">dim=</span> <span class="fu">c</span>(dm, <span class="dv">28</span>, <span class="dv">28</span>))</span>
<span id="cb89-7"><a href="#cb89-7"></a>x_digits[<span class="dv">1</span><span class="sc">:</span>dm_train,,] <span class="ot">=</span> x_train</span>
<span id="cb89-8"><a href="#cb89-8"></a>x_digits[(dm_train<span class="sc">+</span><span class="dv">1</span>)<span class="sc">:</span>dm,,] <span class="ot">=</span> x_test</span>
<span id="cb89-9"><a href="#cb89-9"></a><span class="co"># vector de output completo</span></span>
<span id="cb89-10"><a href="#cb89-10"></a>y_digits <span class="ot">=</span> <span class="fu">c</span>(y_train, y_test)</span>
<span id="cb89-11"><a href="#cb89-11"></a><span class="co"># Barajamos los datos: </span></span>
<span id="cb89-12"><a href="#cb89-12"></a><span class="fu">set.seed</span>(<span class="dv">123</span>)</span>
<span id="cb89-13"><a href="#cb89-13"></a>order <span class="ot">=</span> <span class="fu">slice_sample</span>(<span class="fu">as.data.frame</span>(<span class="dv">1</span><span class="sc">:</span><span class="fu">length</span>(y_digits)),<span class="at">n=</span><span class="fu">length</span>(y_digits))<span class="sc">$</span><span class="st">`</span><span class="at">1:length(y_digits)</span><span class="st">`</span></span>
<span id="cb89-14"><a href="#cb89-14"></a><span class="co"># Reordenamos los datos</span></span>
<span id="cb89-15"><a href="#cb89-15"></a>x_digits <span class="ot">=</span> x_digits[order,,]</span>
<span id="cb89-16"><a href="#cb89-16"></a>y_digits <span class="ot">=</span> y_digits[order]</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>En primer lugar generamos la función que nos permite establecer la arquitectura de la red:</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb90"><pre class="sourceCode numberSource r number-lines code-with-copy"><code class="sourceCode r"><span id="cb90-1"><a href="#cb90-1"></a><span class="co"># Función para la definición del modelo</span></span>
<span id="cb90-2"><a href="#cb90-2"></a>build_model_digits <span class="ot">=</span> <span class="cf">function</span>()</span>
<span id="cb90-3"><a href="#cb90-3"></a>{</span>
<span id="cb90-4"><a href="#cb90-4"></a>  <span class="co"># Arquitectura del modelo</span></span>
<span id="cb90-5"><a href="#cb90-5"></a>  modelo <span class="ot">=</span> <span class="fu">keras_model_sequential</span>() <span class="sc">%&gt;%</span> </span>
<span id="cb90-6"><a href="#cb90-6"></a>      <span class="fu">layer_flatten</span>(<span class="at">input_shape =</span> <span class="fu">c</span>(<span class="dv">28</span>, <span class="dv">28</span>)) <span class="sc">%&gt;%</span> </span>
<span id="cb90-7"><a href="#cb90-7"></a>      <span class="fu">layer_dense</span>(<span class="at">units =</span> <span class="dv">32</span>, <span class="at">activation =</span> <span class="st">"relu"</span>, <span class="at">kernel_initializer =</span> inicializador) <span class="sc">%&gt;%</span> </span>
<span id="cb90-8"><a href="#cb90-8"></a>      <span class="fu">layer_dense</span>(<span class="dv">10</span>, <span class="at">activation =</span> <span class="st">"softmax"</span>, <span class="at">kernel_initializer =</span> inicializador)</span>
<span id="cb90-9"><a href="#cb90-9"></a>  modelo <span class="sc">%&gt;%</span> <span class="fu">compile</span>(</span>
<span id="cb90-10"><a href="#cb90-10"></a>    <span class="at">loss =</span> <span class="st">'sparse_categorical_crossentropy'</span>,</span>
<span id="cb90-11"><a href="#cb90-11"></a>    <span class="at">optimizer =</span> <span class="fu">optimizer_sgd</span>(),</span>
<span id="cb90-12"><a href="#cb90-12"></a>    <span class="at">metrics =</span> <span class="fu">c</span>(<span class="st">'accuracy'</span>)</span>
<span id="cb90-13"><a href="#cb90-13"></a>  )</span>
<span id="cb90-14"><a href="#cb90-14"></a>  <span class="co"># Devolvemos el modelo configurado</span></span>
<span id="cb90-15"><a href="#cb90-15"></a>  <span class="fu">return</span>(modelo)</span>
<span id="cb90-16"><a href="#cb90-16"></a>}</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>Ahora debemos establecer el número de folds y el tamaño de cada uno de ellos. En este caso optamos por <span class="math inline">\(k=7\)</span> folds para mantener los tamaños de las muestras de entrenamiento y validación que hemos utilizado en el modelo de partida.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb91"><pre class="sourceCode numberSource r number-lines code-with-copy"><code class="sourceCode r"><span id="cb91-1"><a href="#cb91-1"></a><span class="co"># Inicializamos los vectores donde almacenamos las métricas de validación de los sucesivos modelos</span></span>
<span id="cb91-2"><a href="#cb91-2"></a>acc_mod <span class="ot">=</span> <span class="fu">c</span>()</span>
<span id="cb91-3"><a href="#cb91-3"></a>wacc_mod <span class="ot">=</span> <span class="fu">c</span>()</span>
<span id="cb91-4"><a href="#cb91-4"></a>metricas <span class="ot">=</span> <span class="fu">c</span>()</span>
<span id="cb91-5"><a href="#cb91-5"></a></span>
<span id="cb91-6"><a href="#cb91-6"></a><span class="co"># Establecemos número de folds</span></span>
<span id="cb91-7"><a href="#cb91-7"></a>folds <span class="ot">=</span> <span class="dv">7</span></span>
<span id="cb91-8"><a href="#cb91-8"></a><span class="co"># Tamaño de cada fold</span></span>
<span id="cb91-9"><a href="#cb91-9"></a>nfolds <span class="ot">=</span> <span class="fu">length</span>(y_digits)<span class="sc">/</span>folds</span>
<span id="cb91-10"><a href="#cb91-10"></a></span>
<span id="cb91-11"><a href="#cb91-11"></a><span class="co"># Bucle pra cada fold</span></span>
<span id="cb91-12"><a href="#cb91-12"></a><span class="cf">for</span>(i <span class="cf">in</span> <span class="dv">1</span><span class="sc">:</span>folds)</span>
<span id="cb91-13"><a href="#cb91-13"></a>{</span>
<span id="cb91-14"><a href="#cb91-14"></a>  <span class="co"># Índice para la muestra de test</span></span>
<span id="cb91-15"><a href="#cb91-15"></a>  test <span class="ot">=</span> (nfolds<span class="sc">*</span>(i<span class="dv">-1</span>) <span class="sc">+</span><span class="dv">1</span>)<span class="sc">:</span>(nfolds<span class="sc">*</span>i)</span>
<span id="cb91-16"><a href="#cb91-16"></a>  <span class="co"># Muestras de entrenamiento y test</span></span>
<span id="cb91-17"><a href="#cb91-17"></a>  xtrain <span class="ot">=</span> x_digits[<span class="sc">-</span>test,,]</span>
<span id="cb91-18"><a href="#cb91-18"></a>  xtest <span class="ot">=</span> x_digits[test,,]</span>
<span id="cb91-19"><a href="#cb91-19"></a>  ytrain <span class="ot">=</span> y_digits[<span class="sc">-</span>test]</span>
<span id="cb91-20"><a href="#cb91-20"></a>  ytest <span class="ot">=</span> y_digits[test]</span>
<span id="cb91-21"><a href="#cb91-21"></a>    <span class="co"># Modelo de red</span></span>
<span id="cb91-22"><a href="#cb91-22"></a>  modelo <span class="ot">=</span> <span class="fu">build_model_digits</span>()</span>
<span id="cb91-23"><a href="#cb91-23"></a>  <span class="fu">cat</span>(<span class="st">"Comienza el entrenamiento para el fold "</span>, i, <span class="st">"</span><span class="sc">\n</span><span class="st">"</span>)</span>
<span id="cb91-24"><a href="#cb91-24"></a>  <span class="co"># Entrenamiento del modelo</span></span>
<span id="cb91-25"><a href="#cb91-25"></a>  history <span class="ot">=</span> modelo <span class="sc">%&gt;%</span>  <span class="fu">fit</span>(xtrain, ytrain,  <span class="at">batch_size =</span> <span class="dv">50</span>, <span class="at">epochs =</span> <span class="dv">10</span>, <span class="at">verbose =</span> <span class="cn">FALSE</span>)</span>
<span id="cb91-26"><a href="#cb91-26"></a>  <span class="co"># Evaluación del modelo</span></span>
<span id="cb91-27"><a href="#cb91-27"></a>  acc_mod[i] <span class="ot">=</span> (modelo <span class="sc">%&gt;%</span> tensorflow<span class="sc">::</span><span class="fu">evaluate</span>(xtest, ytest))[<span class="dv">2</span>]</span>
<span id="cb91-28"><a href="#cb91-28"></a>  <span class="co"># Predicción con el modelo</span></span>
<span id="cb91-29"><a href="#cb91-29"></a>  prediccion <span class="ot">=</span> modelo <span class="sc">%&gt;%</span> <span class="fu">predict</span>(xtest)</span>
<span id="cb91-30"><a href="#cb91-30"></a>  <span class="co"># predicción del modelo</span></span>
<span id="cb91-31"><a href="#cb91-31"></a>  pr_modelo <span class="ot">=</span> <span class="fu">factor</span>((prediccion <span class="sc">%&gt;%</span> <span class="fu">k_argmax</span>())<span class="sc">$</span><span class="fu">numpy</span>(), <span class="at">levels =</span> <span class="dv">0</span><span class="sc">:</span>(<span class="fu">length</span>(etiquetas)<span class="sc">-</span><span class="dv">1</span>))</span>
<span id="cb91-32"><a href="#cb91-32"></a>  pr_test <span class="ot">=</span> <span class="fu">factor</span>(y_test, <span class="at">levels =</span> <span class="dv">0</span><span class="sc">:</span>(<span class="fu">length</span>(etiquetas)<span class="sc">-</span><span class="dv">1</span>))</span>
<span id="cb91-33"><a href="#cb91-33"></a>  wacc_mod[i] <span class="ot">=</span> <span class="fu">confusion_matrix</span>(pr_test, pr_modelo, <span class="at">metrics =</span> <span class="fu">list</span>(<span class="st">"Weighted Accuracy"</span> <span class="ot">=</span> <span class="cn">TRUE</span>))<span class="sc">$</span><span class="st">`</span><span class="at">Weighted Accuracy</span><span class="st">`</span></span>
<span id="cb91-34"><a href="#cb91-34"></a>  metricas <span class="ot">=</span> <span class="fu">rbind</span>(metricas, <span class="fu">c</span>(i,acc_mod[i],wacc_mod[i]))</span>
<span id="cb91-35"><a href="#cb91-35"></a>  }</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Comienza el entrenamiento para el fold  1 
313/313 - 0s - loss: 0.2513 - accuracy: 0.9276 - 411ms/epoch - 1ms/step
313/313 - 0s - 297ms/epoch - 948us/step
Comienza el entrenamiento para el fold  2 
313/313 - 0s - loss: 0.2438 - accuracy: 0.9282 - 406ms/epoch - 1ms/step
313/313 - 0s - 292ms/epoch - 933us/step
Comienza el entrenamiento para el fold  3 
313/313 - 0s - loss: 0.2468 - accuracy: 0.9261 - 443ms/epoch - 1ms/step
313/313 - 0s - 323ms/epoch - 1ms/step
Comienza el entrenamiento para el fold  4 
313/313 - 0s - loss: 0.2371 - accuracy: 0.9312 - 399ms/epoch - 1ms/step
313/313 - 0s - 289ms/epoch - 924us/step
Comienza el entrenamiento para el fold  5 
313/313 - 0s - loss: 0.2366 - accuracy: 0.9309 - 394ms/epoch - 1ms/step
313/313 - 0s - 299ms/epoch - 956us/step
Comienza el entrenamiento para el fold  6 
313/313 - 0s - loss: 0.2434 - accuracy: 0.9319 - 396ms/epoch - 1ms/step
313/313 - 0s - 294ms/epoch - 939us/step
Comienza el entrenamiento para el fold  7 
313/313 - 0s - loss: 0.2468 - accuracy: 0.9335 - 419ms/epoch - 1ms/step
313/313 - 0s - 288ms/epoch - 920us/step</code></pre>
</div>
<div class="sourceCode cell-code" id="cb93"><pre class="sourceCode numberSource r number-lines code-with-copy"><code class="sourceCode r"><span id="cb93-1"><a href="#cb93-1"></a><span class="fu">colnames</span>(metricas) <span class="ot">=</span> <span class="fu">c</span>(<span class="st">"Fold"</span>,<span class="st">"Acc"</span>,<span class="st">"WAcc"</span>)</span>
<span id="cb93-2"><a href="#cb93-2"></a>metricas</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>     Fold    Acc      WAcc
[1,]    1 0.9276 0.8199056
[2,]    2 0.9282 0.8190394
[3,]    3 0.9261 0.8193737
[4,]    4 0.9312 0.8190675
[5,]    5 0.9309 0.8186953
[6,]    6 0.9319 0.8205304
[7,]    7 0.9335 0.8204387</code></pre>
</div>
</div>
<p>Veamos los resultados:</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb95"><pre class="sourceCode numberSource r number-lines code-with-copy"><code class="sourceCode r"><span id="cb95-1"><a href="#cb95-1"></a><span class="co"># Accuracy</span></span>
<span id="cb95-2"><a href="#cb95-2"></a><span class="fu">describe</span>(metricas[,<span class="dv">2</span>])</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>     media          dt     p05    p25    p50     p75     p95
 0.9299143 0.002654191 0.92655 0.9279 0.9309 0.93155 0.93302</code></pre>
</div>
<div class="sourceCode cell-code" id="cb97"><pre class="sourceCode numberSource r number-lines code-with-copy"><code class="sourceCode r"><span id="cb97-1"><a href="#cb97-1"></a><span class="co"># WAccuracy</span></span>
<span id="cb97-2"><a href="#cb97-2"></a><span class="fu">describe</span>(metricas[,<span class="dv">3</span>])</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>     media           dt       p05       p25       p50       p75       p95
 0.8195787 0.0007218941 0.8187985 0.8190534 0.8193737 0.8201722 0.8205029</code></pre>
</div>
</div>
<p>¿Cómo interpretamos los resultados obtenidos para ambas métricas?</p>
</section>
</section>
</section>
<section id="parámetros-e-hiperparámetros-de-la-red" class="level2" data-number="3.3">
<h2 data-number="3.3" class="anchored" data-anchor-id="parámetros-e-hiperparámetros-de-la-red"><span class="header-section-number">3.3</span> Parámetros e hiperparámetros de la red</h2>
<p>¿Cuál es la diferencia entre un parámetro del modelo y un hiperparámetro? Los parámetros del modelo son internos a la red neuronal, por ejemplo, los pesos de las neuronas. Se estiman o aprenden automáticamente a partir de las muestras de entrenamiento. Estos parámetros también se utilizan para hacer predicciones en un modelo ya entrenado que se encuentra en producción.</p>
<p>En cambio, los hiperparámetros son parámetros externos al modelo en sí mismo, establecidos por el programador de la red neuronal; por ejemplo, podemos aumentar el número de <em>epochs</em> (veces que se usan todos los datos de entrenamiento), agregar más neuronas en una capa o agregar más capas, seleccionar qué función de activación usar o el tamaño de lote utilizado en el entrenamiento. Los hiperparámetros tienen un gran impacto en la precisión de una red neuronal y puede haber diferentes valores óptimos para diferentes hiperparámetros; descubrir esos valores no es algo trivial.</p>
<p>La forma más sencilla de seleccionar hiperparámetros para un modelo de red neuronal es «búsqueda manual»; en otras palabras, prueba y error. De todas maneras, están apareciendo algoritmos y métodos de optimización para descubrir los mejores hiperparámetros. Es importante mencionar que actualmente existen ya propuestas para ayudar al programador en este paso de búsqueda de hiperparámetros. En ellas se intenta automatizar este proceso: Hyperopt, Kopt, Talos o GPflowOpt. También en el escenario del Cloud Computing hay ya alguna propuesta, como Google Cloud.</p>
<p>En este apartado vamos a analizar el efecto de los hiperparámetros de la red que se establecen antes del proceso de entrenamiento de la red (antes de optimizar los pesos y sesgos), por lo que elegir sus valores adecuados deviene un paso esencial para conseguir un buen modelo. En primer lugar hacemos una revisión teórica de los conceptos más relevantes, para centrarnos más tarde es los aspectos prácticos de su aplicación y análisis.</p>
<section id="grupos-de-hiperparámetros" class="level3" data-number="3.3.1">
<h3 data-number="3.3.1" class="anchored" data-anchor-id="grupos-de-hiperparámetros"><span class="header-section-number">3.3.1</span> Grupos de hiperparámetros</h3>
<p>A grandes rasgos, los hiperparámetros de un modelo de red neuronal se pueden clasificar en dos grandes grupos:</p>
<ul>
<li>Hiperparámetros a nivel de estructura y topología de la red neuronal: número de capas, número de neuronas por capa, sus funciones de activación, inicialización de los pesos, etc.</li>
<li>Hiperparámetros a nivel de algoritmo de aprendizaje: <em>epochs</em>, <em>batch size</em>, <em>learning rate</em>, etc.</li>
</ul>
<p>Para empezar veremos el efecto que tienen sobre las métricas de evaluación del modelo los hiperpárametros del segundo punto, y posteriormente veremos de forma introductoria el efecto de los del primer grupo.</p>
<p>Para ver el efecto de los cambios de los hiperparámetros vamos a utilizar el banco de datos digits.</p>
<section id="a-nivel-de-estructura-y-topologia" class="level4" data-number="3.3.1.1">
<h4 data-number="3.3.1.1" class="anchored" data-anchor-id="a-nivel-de-estructura-y-topologia"><span class="header-section-number">3.3.1.1</span> A nivel de estructura y topologia</h4>
<p>Como el resultado del modelo obtenido en el punto anterior ya era bastante bueno vamos a considerar que la arquitectura de red mantiene el mismo número de capas pero vamos a ir modificando el tamaño de la capa intermedia y la función de activación. Analizamos el comportamiento de la red comparando el porcentaje global de clasificación correcta para cada red. Antes de mostrar el bucle de evaluación definimos una función para cargar cada modelo con parámetros el tamaño de la capa y la función de activación.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb99"><pre class="sourceCode numberSource r number-lines code-with-copy"><code class="sourceCode r"><span id="cb99-1"><a href="#cb99-1"></a>build_model_digits <span class="ot">=</span> <span class="cf">function</span>(size, factiv)</span>
<span id="cb99-2"><a href="#cb99-2"></a>{</span>
<span id="cb99-3"><a href="#cb99-3"></a><span class="co"># Función para la definición del modelo (arquitectura y proceso de aprendizaje)</span></span>
<span id="cb99-4"><a href="#cb99-4"></a></span>
<span id="cb99-5"><a href="#cb99-5"></a>  <span class="co">#  Valores de entrada</span></span>
<span id="cb99-6"><a href="#cb99-6"></a>  <span class="co">#   size: número de neuronas en la capa input</span></span>
<span id="cb99-7"><a href="#cb99-7"></a>  <span class="co">#   factiv: función de activación de la capa input  </span></span>
<span id="cb99-8"><a href="#cb99-8"></a>  </span>
<span id="cb99-9"><a href="#cb99-9"></a>  <span class="co"># Valores de salida</span></span>
<span id="cb99-10"><a href="#cb99-10"></a>  <span class="co">#   modelo: modelo configurado</span></span>
<span id="cb99-11"><a href="#cb99-11"></a>  </span>
<span id="cb99-12"><a href="#cb99-12"></a>  <span class="co"># Arquitectura del modelo</span></span>
<span id="cb99-13"><a href="#cb99-13"></a>  modelo <span class="ot">=</span> <span class="fu">keras_model_sequential</span>() <span class="sc">%&gt;%</span> </span>
<span id="cb99-14"><a href="#cb99-14"></a>      <span class="fu">layer_flatten</span>(<span class="at">input_shape =</span> <span class="fu">c</span>(<span class="dv">28</span>, <span class="dv">28</span>)) <span class="sc">%&gt;%</span> </span>
<span id="cb99-15"><a href="#cb99-15"></a>      <span class="fu">layer_dense</span>(<span class="at">units =</span> size, <span class="at">activation =</span> factiv, <span class="at">kernel_initializer =</span> inicializador) <span class="sc">%&gt;%</span> </span>
<span id="cb99-16"><a href="#cb99-16"></a>      <span class="fu">layer_dense</span>(<span class="dv">10</span>, <span class="at">activation =</span> <span class="st">'softmax'</span>, <span class="at">kernel_initializer =</span> inicializador)</span>
<span id="cb99-17"><a href="#cb99-17"></a>  <span class="co"># Proceso de aprendizaje</span></span>
<span id="cb99-18"><a href="#cb99-18"></a>  modelo <span class="sc">%&gt;%</span> <span class="fu">compile</span>(</span>
<span id="cb99-19"><a href="#cb99-19"></a>    <span class="at">loss =</span> <span class="st">'sparse_categorical_crossentropy'</span>,</span>
<span id="cb99-20"><a href="#cb99-20"></a>    <span class="at">optimizer =</span> <span class="fu">optimizer_sgd</span>(),</span>
<span id="cb99-21"><a href="#cb99-21"></a>    <span class="at">metrics =</span> <span class="fu">c</span>(<span class="st">'accuracy'</span>))</span>
<span id="cb99-22"><a href="#cb99-22"></a><span class="fu">return</span>(modelo)</span>
<span id="cb99-23"><a href="#cb99-23"></a>}</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>Para la evaluación vamos a considerar que el número de neuronas es 16, 32, 64, y que las funciones de activación son <code>relu</code>, <code>sigmoid</code>, y <code>tanh</code>. A continuación se muestra el bucle de evaluación para todas las combinaciones prediseñadas.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb100"><pre class="sourceCode numberSource r number-lines code-with-copy"><code class="sourceCode r"><span id="cb100-1"><a href="#cb100-1"></a><span class="co"># Neuronas</span></span>
<span id="cb100-2"><a href="#cb100-2"></a>neuronas <span class="ot">=</span> <span class="fu">c</span>(<span class="dv">16</span>, <span class="dv">32</span>, <span class="dv">64</span>)</span>
<span id="cb100-3"><a href="#cb100-3"></a>factiv <span class="ot">=</span> <span class="fu">c</span>(<span class="st">'relu'</span>, <span class="st">'sigmoid'</span>, <span class="st">'tanh'</span>)</span>
<span id="cb100-4"><a href="#cb100-4"></a><span class="co"># Lista donde almacenamos la accuracy de cada modelo</span></span>
<span id="cb100-5"><a href="#cb100-5"></a>comparativa <span class="ot">=</span> <span class="fu">c</span>()</span>
<span id="cb100-6"><a href="#cb100-6"></a></span>
<span id="cb100-7"><a href="#cb100-7"></a></span>
<span id="cb100-8"><a href="#cb100-8"></a><span class="co"># Bucle de evaluación</span></span>
<span id="cb100-9"><a href="#cb100-9"></a><span class="cf">for</span> (i <span class="cf">in</span> neuronas)</span>
<span id="cb100-10"><a href="#cb100-10"></a>{</span>
<span id="cb100-11"><a href="#cb100-11"></a>  <span class="cf">for</span> (j <span class="cf">in</span> factiv)</span>
<span id="cb100-12"><a href="#cb100-12"></a>  {</span>
<span id="cb100-13"><a href="#cb100-13"></a>    modelo <span class="ot">=</span> <span class="fu">build_model_digits</span>(i, j)</span>
<span id="cb100-14"><a href="#cb100-14"></a>    <span class="co"># Entrenamiento</span></span>
<span id="cb100-15"><a href="#cb100-15"></a>    history <span class="ot">=</span> modelo <span class="sc">%&gt;%</span>  <span class="fu">fit</span>(x_train, y_train, <span class="at">batch_size =</span> <span class="dv">50</span>, <span class="at">epochs =</span> <span class="dv">10</span>)  </span>
<span id="cb100-16"><a href="#cb100-16"></a>    <span class="co"># Evaluación</span></span>
<span id="cb100-17"><a href="#cb100-17"></a>    valor <span class="ot">=</span> (modelo <span class="sc">%&gt;%</span> tensorflow<span class="sc">::</span><span class="fu">evaluate</span>(x_test, y_test))[<span class="dv">2</span>]</span>
<span id="cb100-18"><a href="#cb100-18"></a>    comparativa <span class="ot">=</span> <span class="fu">rbind</span>(comparativa,<span class="fu">c</span>(i,j,valor))</span>
<span id="cb100-19"><a href="#cb100-19"></a>  }</span>
<span id="cb100-20"><a href="#cb100-20"></a>}</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Epoch 1/10
1200/1200 - 2s - loss: 0.9445 - accuracy: 0.7454 - 2s/epoch - 2ms/step
Epoch 2/10
1200/1200 - 2s - loss: 0.4372 - accuracy: 0.8816 - 2s/epoch - 2ms/step
Epoch 3/10
1200/1200 - 2s - loss: 0.3665 - accuracy: 0.8980 - 2s/epoch - 1ms/step
Epoch 4/10
1200/1200 - 2s - loss: 0.3348 - accuracy: 0.9046 - 2s/epoch - 1ms/step
Epoch 5/10
1200/1200 - 2s - loss: 0.3135 - accuracy: 0.9107 - 2s/epoch - 1ms/step
Epoch 6/10
1200/1200 - 2s - loss: 0.2981 - accuracy: 0.9147 - 2s/epoch - 2ms/step
Epoch 7/10
1200/1200 - 2s - loss: 0.2858 - accuracy: 0.9179 - 2s/epoch - 2ms/step
Epoch 8/10
1200/1200 - 2s - loss: 0.2758 - accuracy: 0.9212 - 2s/epoch - 2ms/step
Epoch 9/10
1200/1200 - 2s - loss: 0.2670 - accuracy: 0.9234 - 2s/epoch - 1ms/step
Epoch 10/10
1200/1200 - 2s - loss: 0.2592 - accuracy: 0.9258 - 2s/epoch - 2ms/step
313/313 - 0s - loss: 0.2539 - accuracy: 0.9288 - 392ms/epoch - 1ms/step
Epoch 1/10
1200/1200 - 2s - loss: 1.9313 - accuracy: 0.5092 - 2s/epoch - 2ms/step
Epoch 2/10
1200/1200 - 2s - loss: 1.3834 - accuracy: 0.6990 - 2s/epoch - 2ms/step
Epoch 3/10
1200/1200 - 2s - loss: 1.0529 - accuracy: 0.7770 - 2s/epoch - 2ms/step
Epoch 4/10
1200/1200 - 2s - loss: 0.8528 - accuracy: 0.8195 - 2s/epoch - 2ms/step
Epoch 5/10
1200/1200 - 2s - loss: 0.7269 - accuracy: 0.8416 - 2s/epoch - 2ms/step
Epoch 6/10
1200/1200 - 2s - loss: 0.6422 - accuracy: 0.8566 - 2s/epoch - 2ms/step
Epoch 7/10
1200/1200 - 2s - loss: 0.5816 - accuracy: 0.8663 - 2s/epoch - 2ms/step
Epoch 8/10
1200/1200 - 2s - loss: 0.5360 - accuracy: 0.8735 - 2s/epoch - 1ms/step
Epoch 9/10
1200/1200 - 2s - loss: 0.5006 - accuracy: 0.8801 - 2s/epoch - 2ms/step
Epoch 10/10
1200/1200 - 2s - loss: 0.4723 - accuracy: 0.8845 - 2s/epoch - 2ms/step
313/313 - 0s - loss: 0.4483 - accuracy: 0.8912 - 403ms/epoch - 1ms/step
Epoch 1/10
1200/1200 - 3s - loss: 1.0311 - accuracy: 0.7459 - 3s/epoch - 3ms/step
Epoch 2/10
1200/1200 - 2s - loss: 0.5428 - accuracy: 0.8727 - 2s/epoch - 2ms/step
Epoch 3/10
1200/1200 - 2s - loss: 0.4302 - accuracy: 0.8912 - 2s/epoch - 2ms/step
Epoch 4/10
1200/1200 - 2s - loss: 0.3788 - accuracy: 0.9004 - 2s/epoch - 2ms/step
Epoch 5/10
1200/1200 - 2s - loss: 0.3485 - accuracy: 0.9060 - 2s/epoch - 2ms/step
Epoch 6/10
1200/1200 - 2s - loss: 0.3272 - accuracy: 0.9101 - 2s/epoch - 2ms/step
Epoch 7/10
1200/1200 - 2s - loss: 0.3116 - accuracy: 0.9143 - 2s/epoch - 2ms/step
Epoch 8/10
1200/1200 - 2s - loss: 0.2990 - accuracy: 0.9169 - 2s/epoch - 2ms/step
Epoch 9/10
1200/1200 - 2s - loss: 0.2886 - accuracy: 0.9198 - 2s/epoch - 2ms/step
Epoch 10/10
1200/1200 - 2s - loss: 0.2796 - accuracy: 0.9224 - 2s/epoch - 2ms/step
313/313 - 0s - loss: 0.2758 - accuracy: 0.9248 - 405ms/epoch - 1ms/step
Epoch 1/10
1200/1200 - 2s - loss: 0.8705 - accuracy: 0.7729 - 2s/epoch - 2ms/step
Epoch 2/10
1200/1200 - 2s - loss: 0.4073 - accuracy: 0.8877 - 2s/epoch - 2ms/step
Epoch 3/10
1200/1200 - 2s - loss: 0.3472 - accuracy: 0.9023 - 2s/epoch - 2ms/step
Epoch 4/10
1200/1200 - 2s - loss: 0.3177 - accuracy: 0.9095 - 2s/epoch - 2ms/step
Epoch 5/10
1200/1200 - 2s - loss: 0.2981 - accuracy: 0.9153 - 2s/epoch - 2ms/step
Epoch 6/10
1200/1200 - 2s - loss: 0.2830 - accuracy: 0.9188 - 2s/epoch - 2ms/step
Epoch 7/10
1200/1200 - 2s - loss: 0.2706 - accuracy: 0.9230 - 2s/epoch - 2ms/step
Epoch 8/10
1200/1200 - 2s - loss: 0.2595 - accuracy: 0.9266 - 2s/epoch - 2ms/step
Epoch 9/10
1200/1200 - 2s - loss: 0.2495 - accuracy: 0.9292 - 2s/epoch - 2ms/step
Epoch 10/10
1200/1200 - 2s - loss: 0.2404 - accuracy: 0.9318 - 2s/epoch - 2ms/step
313/313 - 0s - loss: 0.2324 - accuracy: 0.9322 - 447ms/epoch - 1ms/step
Epoch 1/10
1200/1200 - 2s - loss: 1.8485 - accuracy: 0.5701 - 2s/epoch - 2ms/step
Epoch 2/10
1200/1200 - 2s - loss: 1.1923 - accuracy: 0.7631 - 2s/epoch - 2ms/step
Epoch 3/10
1200/1200 - 2s - loss: 0.8613 - accuracy: 0.8284 - 2s/epoch - 2ms/step
Epoch 4/10
1200/1200 - 2s - loss: 0.6939 - accuracy: 0.8503 - 2s/epoch - 2ms/step
Epoch 5/10
1200/1200 - 2s - loss: 0.5967 - accuracy: 0.8639 - 2s/epoch - 2ms/step
Epoch 6/10
1200/1200 - 2s - loss: 0.5333 - accuracy: 0.8729 - 2s/epoch - 2ms/step
Epoch 7/10
1200/1200 - 2s - loss: 0.4886 - accuracy: 0.8800 - 2s/epoch - 2ms/step
Epoch 8/10
1200/1200 - 2s - loss: 0.4554 - accuracy: 0.8852 - 2s/epoch - 2ms/step
Epoch 9/10
1200/1200 - 2s - loss: 0.4297 - accuracy: 0.8896 - 2s/epoch - 2ms/step
Epoch 10/10
1200/1200 - 2s - loss: 0.4092 - accuracy: 0.8929 - 2s/epoch - 2ms/step
313/313 - 0s - loss: 0.3851 - accuracy: 0.8993 - 408ms/epoch - 1ms/step
Epoch 1/10
1200/1200 - 2s - loss: 0.8926 - accuracy: 0.7859 - 2s/epoch - 2ms/step
Epoch 2/10
1200/1200 - 2s - loss: 0.4658 - accuracy: 0.8809 - 2s/epoch - 2ms/step
Epoch 3/10
1200/1200 - 2s - loss: 0.3829 - accuracy: 0.8974 - 2s/epoch - 2ms/step
Epoch 4/10
1200/1200 - 2s - loss: 0.3422 - accuracy: 0.9061 - 2s/epoch - 2ms/step
Epoch 5/10
1200/1200 - 2s - loss: 0.3160 - accuracy: 0.9119 - 2s/epoch - 2ms/step
Epoch 6/10
1200/1200 - 2s - loss: 0.2968 - accuracy: 0.9172 - 2s/epoch - 2ms/step
Epoch 7/10
1200/1200 - 2s - loss: 0.2819 - accuracy: 0.9207 - 2s/epoch - 2ms/step
Epoch 8/10
1200/1200 - 2s - loss: 0.2693 - accuracy: 0.9249 - 2s/epoch - 2ms/step
Epoch 9/10
1200/1200 - 2s - loss: 0.2583 - accuracy: 0.9271 - 2s/epoch - 2ms/step
Epoch 10/10
1200/1200 - 2s - loss: 0.2489 - accuracy: 0.9302 - 2s/epoch - 2ms/step
313/313 - 0s - loss: 0.2414 - accuracy: 0.9319 - 412ms/epoch - 1ms/step
Epoch 1/10
1200/1200 - 3s - loss: 0.8202 - accuracy: 0.7931 - 3s/epoch - 2ms/step
Epoch 2/10
1200/1200 - 2s - loss: 0.3919 - accuracy: 0.8924 - 2s/epoch - 2ms/step
Epoch 3/10
1200/1200 - 2s - loss: 0.3318 - accuracy: 0.9065 - 2s/epoch - 2ms/step
Epoch 4/10
1200/1200 - 2s - loss: 0.3002 - accuracy: 0.9152 - 2s/epoch - 2ms/step
Epoch 5/10
1200/1200 - 2s - loss: 0.2779 - accuracy: 0.9215 - 2s/epoch - 2ms/step
Epoch 6/10
1200/1200 - 2s - loss: 0.2603 - accuracy: 0.9265 - 2s/epoch - 2ms/step
Epoch 7/10
1200/1200 - 2s - loss: 0.2457 - accuracy: 0.9315 - 2s/epoch - 2ms/step
Epoch 8/10
1200/1200 - 2s - loss: 0.2333 - accuracy: 0.9343 - 2s/epoch - 2ms/step
Epoch 9/10
1200/1200 - 2s - loss: 0.2222 - accuracy: 0.9379 - 2s/epoch - 2ms/step
Epoch 10/10
1200/1200 - 2s - loss: 0.2124 - accuracy: 0.9407 - 2s/epoch - 2ms/step
313/313 - 0s - loss: 0.2070 - accuracy: 0.9402 - 432ms/epoch - 1ms/step
Epoch 1/10
1200/1200 - 3s - loss: 1.7629 - accuracy: 0.6190 - 3s/epoch - 2ms/step
Epoch 2/10
1200/1200 - 2s - loss: 1.0283 - accuracy: 0.7999 - 2s/epoch - 2ms/step
Epoch 3/10
1200/1200 - 2s - loss: 0.7349 - accuracy: 0.8404 - 2s/epoch - 2ms/step
Epoch 4/10
1200/1200 - 2s - loss: 0.6013 - accuracy: 0.8596 - 2s/epoch - 2ms/step
Epoch 5/10
1200/1200 - 2s - loss: 0.5253 - accuracy: 0.8713 - 2s/epoch - 2ms/step
Epoch 6/10
1200/1200 - 2s - loss: 0.4760 - accuracy: 0.8797 - 2s/epoch - 2ms/step
Epoch 7/10
1200/1200 - 2s - loss: 0.4413 - accuracy: 0.8863 - 2s/epoch - 2ms/step
Epoch 8/10
1200/1200 - 2s - loss: 0.4156 - accuracy: 0.8911 - 2s/epoch - 2ms/step
Epoch 9/10
1200/1200 - 2s - loss: 0.3957 - accuracy: 0.8946 - 2s/epoch - 2ms/step
Epoch 10/10
1200/1200 - 2s - loss: 0.3798 - accuracy: 0.8974 - 2s/epoch - 2ms/step
313/313 - 0s - loss: 0.3563 - accuracy: 0.9030 - 452ms/epoch - 1ms/step
Epoch 1/10
1200/1200 - 3s - loss: 0.8045 - accuracy: 0.7999 - 3s/epoch - 2ms/step
Epoch 2/10
1200/1200 - 2s - loss: 0.4242 - accuracy: 0.8869 - 2s/epoch - 2ms/step
Epoch 3/10
1200/1200 - 2s - loss: 0.3590 - accuracy: 0.9007 - 2s/epoch - 2ms/step
Epoch 4/10
1200/1200 - 2s - loss: 0.3253 - accuracy: 0.9083 - 2s/epoch - 2ms/step
Epoch 5/10
1200/1200 - 2s - loss: 0.3022 - accuracy: 0.9141 - 2s/epoch - 2ms/step
Epoch 6/10
1200/1200 - 2s - loss: 0.2844 - accuracy: 0.9195 - 2s/epoch - 2ms/step
Epoch 7/10
1200/1200 - 2s - loss: 0.2698 - accuracy: 0.9233 - 2s/epoch - 2ms/step
Epoch 8/10
1200/1200 - 2s - loss: 0.2573 - accuracy: 0.9265 - 2s/epoch - 2ms/step
Epoch 9/10
1200/1200 - 2s - loss: 0.2461 - accuracy: 0.9298 - 2s/epoch - 2ms/step
Epoch 10/10
1200/1200 - 2s - loss: 0.2364 - accuracy: 0.9331 - 2s/epoch - 2ms/step
313/313 - 0s - loss: 0.2269 - accuracy: 0.9345 - 447ms/epoch - 1ms/step</code></pre>
</div>
<div class="sourceCode cell-code" id="cb102"><pre class="sourceCode numberSource r number-lines code-with-copy"><code class="sourceCode r"><span id="cb102-1"><a href="#cb102-1"></a><span class="co"># Data Frame de resultados</span></span>
<span id="cb102-2"><a href="#cb102-2"></a><span class="fu">colnames</span>(comparativa) <span class="ot">=</span> <span class="fu">c</span>(<span class="st">"Size"</span>, <span class="st">"Factiv"</span>, <span class="st">"Accuracy"</span>)</span>
<span id="cb102-3"><a href="#cb102-3"></a>comparativa</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>      Size Factiv    Accuracy           
 [1,] "16" "relu"    "0.928799986839294"
 [2,] "16" "sigmoid" "0.891200006008148"
 [3,] "16" "tanh"    "0.924799978733063"
 [4,] "32" "relu"    "0.932200014591217"
 [5,] "32" "sigmoid" "0.8992999792099"  
 [6,] "32" "tanh"    "0.931900024414062"
 [7,] "64" "relu"    "0.940199971199036"
 [8,] "64" "sigmoid" "0.902999997138977"
 [9,] "64" "tanh"    "0.934499979019165"</code></pre>
</div>
</div>
<p>Aunque hay que tomar los resultados con cautela, ya que solo entrenamos cada red una única vez, parece claro que las funciones de activación <code>sigmoid</code> y <code>tanh</code> proporcionan mejores resultados que la utilizada inicialmente. No se aprecian muchas diferencias en cuanto al número de neuronas, ya que incluso con 16 neuronas el modelo parece funcionar bastante bien.</p>
</section>
<section id="a-nivel-de-algoritmo-de-aprendizaje" class="level4" data-number="3.3.1.2">
<h4 data-number="3.3.1.2" class="anchored" data-anchor-id="a-nivel-de-algoritmo-de-aprendizaje"><span class="header-section-number">3.3.1.2</span> A nivel de algoritmo de aprendizaje</h4>
<p>En este punto vamos a estudiar el efecto del número de <em>epochs</em>, el <em>batch size</em> y el <em>learning rate</em> sobre las métricas de evaluación de la red neuronal utilizada para modelizar los dos bancos de datos propuestos.</p>
<p><strong>Número de epochs</strong></p>
<p>El número de épocas (<em>epochs</em>) nos indica el número de veces que los datos de entrenamiento han pasado por la red neuronal en el proceso de entrenamiento. Es importante determinar un valor adecuado de este hiperparámentro. Un número alto de épocas provoca que el modelo se ajuste en exceso a los datos y puede tener problemas de generalización en el conjunto de datos de prueba y validación, como veremos más adelante, así como problemas de vanishing gradients y exploding gradient.</p>
<p>Un valor menor al óptimo de épocas puede limitar el potencial del modelo, en el sentido de que este no llegue a entrenarse lo suficiente por no haber visto suficientes datos y, por tanto, no haga buenas predicciones.</p>
<p>Normalmente, se prueban diferentes valores en función del tiempo y los recursos computacionales que se tenga. Una buena pista es incrementar el número de <em>epochs</em> hasta que la métrica de precisión con los datos de validación empiece a decrecer, incluso cuando la precisión de los datos de entrenamiento continúe incrementándose (es cuando detectamos un potencial sobreajuste u <em>overfitting</em>).</p>
<p><strong>Batch size</strong></p>
<p>Ya hemos explicado anteriormente que podemos particionar los datos de entrenamiento en lotes (<em>batches</em>) para pasarlos por la red. En Keras, como hemos visto, el <code>batch_size</code> es argumento en el método <code>fit()</code>, que indica el tamaño de estos lotes en una iteración del entrenamiento para actualizar el gradiente. El tamaño óptimo dependerá de muchos factores, entre ellos de la capacidad de memoria del ordenador que usemos para hacer los cálculos. Como ocurre con el número de <em>epochs</em> deberemos buscar sobre un rango de posibles valores. Lo habitual es comenzar con un valor grande e ir reduciéndolo. Podemos considerar por ejemplo los valores 128, 64, 32, 16, 8, 4, 2 y evaluar los modelos correspondientes.</p>
<p><strong>Learnig rate</strong></p>
<p>Como ya vimos anteriormente los algoritmos de optimización usados en el proceso de configuración del aprendizaje de la red neuronal multiplican la magnitud del gradiente por un escalar conocido como <em>learning rate</em>. Por ejemplo, si la magnitud del gradiente es 1.5 y el <em>learning rate</em> es 0.01, entonces el algoritmo del gradiente descendiente seleccionará el siguiente punto a 0.015 de distancia del punto anterior.</p>
<p>El valor adecuado de este hiperparámetro es muy dependiente del problema en cuestión. En general, si este es demasiado grande, se están dando pasos enormes que podrían ser buenos para ir rápido en el proceso de aprendizaje, pero sus actualizaciones pueden terminar llevándolo a ubicaciones completamente aleatorias en la curva, saltándose el mínimo. Esto podría dificultar el proceso de aprendizaje porque al buscar el siguiente punto perpetuamente rebota al azar en el fondo del «pozo» sin llegar a encontrar el valor mínimo deseado.</p>
<p>Contrariamente, si la tasa de aprendizaje es demasiado pequeña, se harán avances constantes pero pequeños, generando así una mejor oportunidad de llegar a un mínimo local de la función de pérdida. Sin embargo, esto puede provocar que el proceso de aprendizaje sea extremadamente lento. En general, una buena regla es -si nuestro modelo de aprendizaje no funciona- disminuir la <em>learning rate</em>. Si sabemos que el gradiente de la función de pérdida (<em>loss</em>) es pequeño, es más seguro probar con <em>learning rates</em> que compensen el gradiente.</p>
<p>Ahora bien, la mejor tasa de aprendizaje en general es aquella que disminuye a medida que el modelo se acerca a una solución. Para conseguir este efecto, disponemos de otro hiperparámetro, el <em>weight_decay</em>, una especie de decaimiento del rango de aprendizaje que se usa para disminuir el <em>learning rate</em> a medida que van pasando <em>epochs</em>. Esto permite que el aprendizaje avance más rápido al principio con <em>learning rates</em> más grandes y, a medida que se avanza, se vayan haciendo ajustes cada vez más pequeños para facilitar que converja el proceso de entrenamiento al mínimo de la función de pérdida.</p>
<p>El valor de la tasa de aprendizaje depende también del optimizador utilizado. Por poner algún ejemplo, para el optimizador de descenso del gradiente estocástico, un <em>learning rate</em> de 0.1 generalmente funciona bien, mientras que para el optimizador Adam es mejor un <em>learning rate</em> entre 0.001 y 0.01. Pero se recomienda probar siempre varios valores. También puede usar el parámetro de <em>weight_decay</em> para lograr la convergencia.</p>
<p><strong>Aplicación al banco de datos digits</strong></p>
<p>Como el banco de datos es tan grande (y para no ralentizar mucho el proceso de computación) vamos a mantener fijo el número de epochs, pero probaremos diferentes configuraciones del algoritmo de aprendizaje y el learning rate.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb104"><pre class="sourceCode numberSource r number-lines code-with-copy"><code class="sourceCode r"><span id="cb104-1"><a href="#cb104-1"></a><span class="co"># Configuraciones de búsqueda</span></span>
<span id="cb104-2"><a href="#cb104-2"></a>tasa <span class="ot">=</span> <span class="fu">c</span>(<span class="fl">0.001</span>, <span class="fl">0.01</span>, <span class="fl">0.1</span>)</span>
<span id="cb104-3"><a href="#cb104-3"></a>bloque <span class="ot">=</span> <span class="fu">c</span>(<span class="dv">16</span>, <span class="dv">32</span>, <span class="dv">64</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>En cuanto a los algoritmos de aprendizaje consideramos: <code>SGD</code>, <code>ADAM</code>, y <code>RMSprop</code>. Para cada uno de los algoritmos deberemos definir una función de configuración del modelo diferente. Comenzamos con `SGD pero vamos a reducir el número de neuronas en la capa oculta para facilitar el tiempo de computación. Tengamos en cuenta que solamente estamos probando configuraciones para ver el efecto que tiene sobre el resultado fina y no en la búsqueda de la mejor solución, ya que este ejemplo se ha estuado con mucho de talle y se encuentran publicadas las soluciones óptimasl.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb105"><pre class="sourceCode numberSource r number-lines code-with-copy"><code class="sourceCode r"><span id="cb105-1"><a href="#cb105-1"></a>build_model_digits_2 <span class="ot">=</span> <span class="cf">function</span>(tasa)</span>
<span id="cb105-2"><a href="#cb105-2"></a>{</span>
<span id="cb105-3"><a href="#cb105-3"></a><span class="co"># Función para la definición del modelo (arquitectura y proceso de aprendizaje)</span></span>
<span id="cb105-4"><a href="#cb105-4"></a></span>
<span id="cb105-5"><a href="#cb105-5"></a>  <span class="co">#  Valores de entrada</span></span>
<span id="cb105-6"><a href="#cb105-6"></a>  <span class="co">#   tasa: tasa de aprendizaje</span></span>
<span id="cb105-7"><a href="#cb105-7"></a>  </span>
<span id="cb105-8"><a href="#cb105-8"></a>  <span class="co"># Valores de salida</span></span>
<span id="cb105-9"><a href="#cb105-9"></a>  <span class="co">#   modelo: modelo configurado</span></span>
<span id="cb105-10"><a href="#cb105-10"></a>  </span>
<span id="cb105-11"><a href="#cb105-11"></a>  <span class="co"># Arquitectura del modelo</span></span>
<span id="cb105-12"><a href="#cb105-12"></a>  modelo <span class="ot">=</span> <span class="fu">keras_model_sequential</span>() <span class="sc">%&gt;%</span> </span>
<span id="cb105-13"><a href="#cb105-13"></a>      <span class="fu">layer_flatten</span>(<span class="at">input_shape =</span> <span class="fu">c</span>(<span class="dv">28</span>, <span class="dv">28</span>)) <span class="sc">%&gt;%</span> </span>
<span id="cb105-14"><a href="#cb105-14"></a>      <span class="fu">layer_dense</span>(<span class="at">units =</span> <span class="dv">8</span>, <span class="at">activation =</span> <span class="st">'relu'</span>, <span class="at">kernel_initializer =</span> inicializador) <span class="sc">%&gt;%</span> </span>
<span id="cb105-15"><a href="#cb105-15"></a>      <span class="fu">layer_dense</span>(<span class="dv">10</span>, <span class="at">activation =</span> <span class="st">'softmax'</span>, <span class="at">kernel_initializer =</span> inicializador)</span>
<span id="cb105-16"><a href="#cb105-16"></a>  <span class="co"># Proceso de aprendizaje</span></span>
<span id="cb105-17"><a href="#cb105-17"></a>  modelo <span class="sc">%&gt;%</span> <span class="fu">compile</span>(</span>
<span id="cb105-18"><a href="#cb105-18"></a>    <span class="at">loss =</span> <span class="st">'sparse_categorical_crossentropy'</span>,</span>
<span id="cb105-19"><a href="#cb105-19"></a>    <span class="at">optimizer =</span> <span class="fu">optimizer_sgd</span>(<span class="at">learning_rate =</span> tasa),</span>
<span id="cb105-20"><a href="#cb105-20"></a>    <span class="at">metrics =</span> <span class="fu">c</span>(<span class="st">'accuracy'</span>))</span>
<span id="cb105-21"><a href="#cb105-21"></a><span class="fu">return</span>(modelo)</span>
<span id="cb105-22"><a href="#cb105-22"></a>}</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>Ahora planteamos el bucle para este algoritmo</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb106"><pre class="sourceCode numberSource r number-lines code-with-copy"><code class="sourceCode r"><span id="cb106-1"><a href="#cb106-1"></a><span class="co"># Lista donde almacenamos la accuracy de cada modelo</span></span>
<span id="cb106-2"><a href="#cb106-2"></a>comparativa <span class="ot">=</span> <span class="fu">c</span>()</span>
<span id="cb106-3"><a href="#cb106-3"></a></span>
<span id="cb106-4"><a href="#cb106-4"></a><span class="co"># Bucle de evaluación</span></span>
<span id="cb106-5"><a href="#cb106-5"></a><span class="cf">for</span> (i <span class="cf">in</span> tasa)</span>
<span id="cb106-6"><a href="#cb106-6"></a>{</span>
<span id="cb106-7"><a href="#cb106-7"></a>  <span class="cf">for</span> (j <span class="cf">in</span> bloque)</span>
<span id="cb106-8"><a href="#cb106-8"></a>  {</span>
<span id="cb106-9"><a href="#cb106-9"></a>    modelo <span class="ot">=</span> <span class="fu">build_model_digits_2</span>(i)</span>
<span id="cb106-10"><a href="#cb106-10"></a>    <span class="co"># Entrenamiento</span></span>
<span id="cb106-11"><a href="#cb106-11"></a>    history <span class="ot">=</span> modelo <span class="sc">%&gt;%</span>  <span class="fu">fit</span>(x_train, y_train, <span class="at">batch_size =</span> j, <span class="at">epochs =</span> <span class="dv">10</span>)  </span>
<span id="cb106-12"><a href="#cb106-12"></a>    <span class="co"># Evaluación</span></span>
<span id="cb106-13"><a href="#cb106-13"></a>    valor <span class="ot">=</span> (modelo <span class="sc">%&gt;%</span> tensorflow<span class="sc">::</span><span class="fu">evaluate</span>(x_test, y_test))[<span class="dv">2</span>]</span>
<span id="cb106-14"><a href="#cb106-14"></a>    comparativa <span class="ot">=</span> <span class="fu">rbind</span>(comparativa, <span class="fu">c</span>(i,j,valor))</span>
<span id="cb106-15"><a href="#cb106-15"></a>  }</span>
<span id="cb106-16"><a href="#cb106-16"></a>}</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Epoch 1/10
3750/3750 - 6s - loss: 1.8871 - accuracy: 0.3396 - 6s/epoch - 2ms/step
Epoch 2/10
3750/3750 - 5s - loss: 1.3594 - accuracy: 0.5942 - 5s/epoch - 1ms/step
Epoch 3/10
3750/3750 - 5s - loss: 1.0800 - accuracy: 0.6814 - 5s/epoch - 1ms/step
Epoch 4/10
3750/3750 - 5s - loss: 0.8668 - accuracy: 0.7338 - 5s/epoch - 1ms/step
Epoch 5/10
3750/3750 - 5s - loss: 0.7075 - accuracy: 0.7836 - 5s/epoch - 1ms/step
Epoch 6/10
3750/3750 - 6s - loss: 0.6127 - accuracy: 0.8178 - 6s/epoch - 1ms/step
Epoch 7/10
3750/3750 - 5s - loss: 0.5526 - accuracy: 0.8371 - 5s/epoch - 1ms/step
Epoch 8/10
3750/3750 - 5s - loss: 0.5116 - accuracy: 0.8509 - 5s/epoch - 1ms/step
Epoch 9/10
3750/3750 - 5s - loss: 0.4820 - accuracy: 0.8597 - 5s/epoch - 1ms/step
Epoch 10/10
3750/3750 - 5s - loss: 0.4596 - accuracy: 0.8671 - 5s/epoch - 1ms/step
313/313 - 0s - loss: 0.4343 - accuracy: 0.8711 - 418ms/epoch - 1ms/step
Epoch 1/10
1875/1875 - 3s - loss: 2.0874 - accuracy: 0.2335 - 3s/epoch - 2ms/step
Epoch 2/10
1875/1875 - 3s - loss: 1.6877 - accuracy: 0.4426 - 3s/epoch - 1ms/step
Epoch 3/10
1875/1875 - 3s - loss: 1.4358 - accuracy: 0.5670 - 3s/epoch - 1ms/step
Epoch 4/10
1875/1875 - 3s - loss: 1.2769 - accuracy: 0.6283 - 3s/epoch - 1ms/step
Epoch 5/10
1875/1875 - 3s - loss: 1.1642 - accuracy: 0.6579 - 3s/epoch - 1ms/step
Epoch 6/10
1875/1875 - 3s - loss: 1.0653 - accuracy: 0.6839 - 3s/epoch - 2ms/step
Epoch 7/10
1875/1875 - 3s - loss: 0.9689 - accuracy: 0.7086 - 3s/epoch - 1ms/step
Epoch 8/10
1875/1875 - 3s - loss: 0.8799 - accuracy: 0.7328 - 3s/epoch - 1ms/step
Epoch 9/10
1875/1875 - 3s - loss: 0.7943 - accuracy: 0.7620 - 3s/epoch - 1ms/step
Epoch 10/10
1875/1875 - 3s - loss: 0.7204 - accuracy: 0.7867 - 3s/epoch - 1ms/step
313/313 - 0s - loss: 0.6713 - accuracy: 0.8012 - 391ms/epoch - 1ms/step
Epoch 1/10
938/938 - 2s - loss: 2.2144 - accuracy: 0.1432 - 2s/epoch - 2ms/step
Epoch 2/10
938/938 - 1s - loss: 1.9638 - accuracy: 0.3133 - 1s/epoch - 2ms/step
Epoch 3/10
938/938 - 1s - loss: 1.7713 - accuracy: 0.4136 - 1s/epoch - 2ms/step
Epoch 4/10
938/938 - 2s - loss: 1.6156 - accuracy: 0.4683 - 2s/epoch - 2ms/step
Epoch 5/10
938/938 - 2s - loss: 1.4894 - accuracy: 0.5404 - 2s/epoch - 2ms/step
Epoch 6/10
938/938 - 2s - loss: 1.3912 - accuracy: 0.5914 - 2s/epoch - 2ms/step
Epoch 7/10
938/938 - 1s - loss: 1.3128 - accuracy: 0.6170 - 1s/epoch - 2ms/step
Epoch 8/10
938/938 - 1s - loss: 1.2478 - accuracy: 0.6359 - 1s/epoch - 2ms/step
Epoch 9/10
938/938 - 1s - loss: 1.1921 - accuracy: 0.6512 - 1s/epoch - 2ms/step
Epoch 10/10
938/938 - 1s - loss: 1.1432 - accuracy: 0.6635 - 1s/epoch - 2ms/step
313/313 - 0s - loss: 1.0998 - accuracy: 0.6783 - 440ms/epoch - 1ms/step
Epoch 1/10
3750/3750 - 5s - loss: 0.8675 - accuracy: 0.7259 - 5s/epoch - 1ms/step
Epoch 2/10
3750/3750 - 5s - loss: 0.4062 - accuracy: 0.8837 - 5s/epoch - 1ms/step
Epoch 3/10
3750/3750 - 6s - loss: 0.3594 - accuracy: 0.8977 - 6s/epoch - 1ms/step
Epoch 4/10
3750/3750 - 5s - loss: 0.3393 - accuracy: 0.9037 - 5s/epoch - 1ms/step
Epoch 5/10
3750/3750 - 5s - loss: 0.3273 - accuracy: 0.9069 - 5s/epoch - 1ms/step
Epoch 6/10
3750/3750 - 5s - loss: 0.3187 - accuracy: 0.9090 - 5s/epoch - 1ms/step
Epoch 7/10
3750/3750 - 5s - loss: 0.3120 - accuracy: 0.9115 - 5s/epoch - 1ms/step
Epoch 8/10
3750/3750 - 5s - loss: 0.3059 - accuracy: 0.9139 - 5s/epoch - 1ms/step
Epoch 9/10
3750/3750 - 5s - loss: 0.3017 - accuracy: 0.9142 - 5s/epoch - 1ms/step
Epoch 10/10
3750/3750 - 5s - loss: 0.2978 - accuracy: 0.9164 - 5s/epoch - 1ms/step
313/313 - 0s - loss: 0.2975 - accuracy: 0.9142 - 384ms/epoch - 1ms/step
Epoch 1/10
1875/1875 - 3s - loss: 1.2226 - accuracy: 0.6165 - 3s/epoch - 2ms/step
Epoch 2/10
1875/1875 - 3s - loss: 0.5586 - accuracy: 0.8367 - 3s/epoch - 1ms/step
Epoch 3/10
1875/1875 - 3s - loss: 0.4303 - accuracy: 0.8764 - 3s/epoch - 1ms/step
Epoch 4/10
1875/1875 - 3s - loss: 0.3878 - accuracy: 0.8897 - 3s/epoch - 1ms/step
Epoch 5/10
1875/1875 - 3s - loss: 0.3657 - accuracy: 0.8962 - 3s/epoch - 1ms/step
Epoch 6/10
1875/1875 - 3s - loss: 0.3517 - accuracy: 0.9000 - 3s/epoch - 1ms/step
Epoch 7/10
1875/1875 - 3s - loss: 0.3421 - accuracy: 0.9029 - 3s/epoch - 1ms/step
Epoch 8/10
1875/1875 - 3s - loss: 0.3348 - accuracy: 0.9050 - 3s/epoch - 1ms/step
Epoch 9/10
1875/1875 - 3s - loss: 0.3291 - accuracy: 0.9064 - 3s/epoch - 1ms/step
Epoch 10/10
1875/1875 - 3s - loss: 0.3238 - accuracy: 0.9079 - 3s/epoch - 1ms/step
313/313 - 0s - loss: 0.3224 - accuracy: 0.9072 - 403ms/epoch - 1ms/step
Epoch 1/10
938/938 - 2s - loss: 1.5042 - accuracy: 0.5091 - 2s/epoch - 2ms/step
Epoch 2/10
938/938 - 1s - loss: 0.7718 - accuracy: 0.7615 - 1s/epoch - 2ms/step
Epoch 3/10
938/938 - 1s - loss: 0.5538 - accuracy: 0.8367 - 1s/epoch - 2ms/step
Epoch 4/10
938/938 - 2s - loss: 0.4696 - accuracy: 0.8638 - 2s/epoch - 2ms/step
Epoch 5/10
938/938 - 2s - loss: 0.4272 - accuracy: 0.8770 - 2s/epoch - 2ms/step
Epoch 6/10
938/938 - 1s - loss: 0.4017 - accuracy: 0.8848 - 1s/epoch - 2ms/step
Epoch 7/10
938/938 - 1s - loss: 0.3842 - accuracy: 0.8901 - 1s/epoch - 2ms/step
Epoch 8/10
938/938 - 2s - loss: 0.3716 - accuracy: 0.8933 - 2s/epoch - 2ms/step
Epoch 9/10
938/938 - 2s - loss: 0.3615 - accuracy: 0.8966 - 2s/epoch - 2ms/step
Epoch 10/10
938/938 - 2s - loss: 0.3540 - accuracy: 0.8994 - 2s/epoch - 2ms/step
313/313 - 0s - loss: 0.3441 - accuracy: 0.8995 - 412ms/epoch - 1ms/step
Epoch 1/10
3750/3750 - 6s - loss: 0.5623 - accuracy: 0.8305 - 6s/epoch - 2ms/step
Epoch 2/10
3750/3750 - 5s - loss: 0.4304 - accuracy: 0.8753 - 5s/epoch - 1ms/step
Epoch 3/10
3750/3750 - 5s - loss: 0.3732 - accuracy: 0.8928 - 5s/epoch - 1ms/step
Epoch 4/10
3750/3750 - 5s - loss: 0.3284 - accuracy: 0.9047 - 5s/epoch - 1ms/step
Epoch 5/10
3750/3750 - 5s - loss: 0.3144 - accuracy: 0.9097 - 5s/epoch - 1ms/step
Epoch 6/10
3750/3750 - 5s - loss: 0.3026 - accuracy: 0.9129 - 5s/epoch - 1ms/step
Epoch 7/10
3750/3750 - 5s - loss: 0.2952 - accuracy: 0.9151 - 5s/epoch - 1ms/step
Epoch 8/10
3750/3750 - 5s - loss: 0.2928 - accuracy: 0.9157 - 5s/epoch - 1ms/step
Epoch 9/10
3750/3750 - 5s - loss: 0.2881 - accuracy: 0.9152 - 5s/epoch - 1ms/step
Epoch 10/10
3750/3750 - 5s - loss: 0.2852 - accuracy: 0.9172 - 5s/epoch - 1ms/step
313/313 - 0s - loss: 0.2921 - accuracy: 0.9146 - 408ms/epoch - 1ms/step
Epoch 1/10
1875/1875 - 3s - loss: 0.4974 - accuracy: 0.8501 - 3s/epoch - 2ms/step
Epoch 2/10
1875/1875 - 3s - loss: 0.3529 - accuracy: 0.8969 - 3s/epoch - 1ms/step
Epoch 3/10
1875/1875 - 3s - loss: 0.3295 - accuracy: 0.9049 - 3s/epoch - 1ms/step
Epoch 4/10
1875/1875 - 3s - loss: 0.3184 - accuracy: 0.9075 - 3s/epoch - 1ms/step
Epoch 5/10
1875/1875 - 3s - loss: 0.3091 - accuracy: 0.9090 - 3s/epoch - 2ms/step
Epoch 6/10
1875/1875 - 3s - loss: 0.2907 - accuracy: 0.9153 - 3s/epoch - 1ms/step
Epoch 7/10
1875/1875 - 3s - loss: 0.2763 - accuracy: 0.9197 - 3s/epoch - 2ms/step
Epoch 8/10
1875/1875 - 3s - loss: 0.2639 - accuracy: 0.9228 - 3s/epoch - 1ms/step
Epoch 9/10
1875/1875 - 3s - loss: 0.2559 - accuracy: 0.9262 - 3s/epoch - 2ms/step
Epoch 10/10
1875/1875 - 3s - loss: 0.2505 - accuracy: 0.9261 - 3s/epoch - 1ms/step
313/313 - 0s - loss: 0.2580 - accuracy: 0.9252 - 398ms/epoch - 1ms/step
Epoch 1/10
938/938 - 2s - loss: 0.5808 - accuracy: 0.8199 - 2s/epoch - 2ms/step
Epoch 2/10
938/938 - 1s - loss: 0.3552 - accuracy: 0.8968 - 1s/epoch - 2ms/step
Epoch 3/10
938/938 - 1s - loss: 0.3301 - accuracy: 0.9065 - 1s/epoch - 2ms/step
Epoch 4/10
938/938 - 2s - loss: 0.3194 - accuracy: 0.9095 - 2s/epoch - 2ms/step
Epoch 5/10
938/938 - 1s - loss: 0.3118 - accuracy: 0.9115 - 1s/epoch - 2ms/step
Epoch 6/10
938/938 - 2s - loss: 0.3051 - accuracy: 0.9141 - 2s/epoch - 2ms/step
Epoch 7/10
938/938 - 2s - loss: 0.3000 - accuracy: 0.9147 - 2s/epoch - 2ms/step
Epoch 8/10
938/938 - 2s - loss: 0.2972 - accuracy: 0.9168 - 2s/epoch - 2ms/step
Epoch 9/10
938/938 - 1s - loss: 0.2939 - accuracy: 0.9160 - 1s/epoch - 2ms/step
Epoch 10/10
938/938 - 2s - loss: 0.2897 - accuracy: 0.9181 - 2s/epoch - 2ms/step
313/313 - 0s - loss: 0.3008 - accuracy: 0.9097 - 396ms/epoch - 1ms/step</code></pre>
</div>
<div class="sourceCode cell-code" id="cb108"><pre class="sourceCode numberSource r number-lines code-with-copy"><code class="sourceCode r"><span id="cb108-1"><a href="#cb108-1"></a><span class="co"># Data Frame de resultados</span></span>
<span id="cb108-2"><a href="#cb108-2"></a><span class="fu">colnames</span>(comparativa) <span class="ot">=</span> <span class="fu">c</span>(<span class="st">"lr"</span>, <span class="st">"Factiv"</span>, <span class="st">"Accuracy"</span>)</span>
<span id="cb108-3"><a href="#cb108-3"></a>comparativa</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>         lr Factiv Accuracy
 [1,] 0.001     16   0.8711
 [2,] 0.001     32   0.8012
 [3,] 0.001     64   0.6783
 [4,] 0.010     16   0.9142
 [5,] 0.010     32   0.9072
 [6,] 0.010     64   0.8995
 [7,] 0.100     16   0.9146
 [8,] 0.100     32   0.9252
 [9,] 0.100     64   0.9097</code></pre>
</div>
</div>
<p>¿qué conclusiones podemos extraer de este estudio? Se deja para el lector en completar los estudios para los otros dos algoritmos de aprendizaje.</p>
</section>
</section>
</section>
<section id="sobreajuste-e-infraajuste" class="level2" data-number="3.4">
<h2 data-number="3.4" class="anchored" data-anchor-id="sobreajuste-e-infraajuste"><span class="header-section-number">3.4</span> Sobreajuste e infraajuste</h2>
<p>El concepto de sobreajuste de un modelo (overfitting en inglés) se produce cuando el modelo obtenido se ajusta tanto a los ejemplos etiquetados de entrenamiento que no puede realizar las predicciones correctas en ejemplos de datos nuevos que nunca ha visto antes.</p>
<p>En resumen, con overfitting o sobreajuste nos referimos a lo que le sucede a un modelo cuando este modela los datos de entrenamiento demasiado bien, aprendiendo detalles de estos que no son generales. Esto es debido a que sobreentrenamos nuestro modelo y este estará considerando como válidos solo los datos idénticos a los de nuestro conjunto de entrenamiento, incluidos sus defectos (también llamado ruido en nuestro contexto). Es decir, nos encontramos en la situación de que el modelo puede tener una baja tasa de error de clasificación para los datos de entrenamiento, pero no se generaliza bien a la población general de datos en los que estamos interesados.</p>
<p>Es evidente que, en general, esta situación presenta un impacto negativo en la eficiencia del modelo cuando este se usa para inferencia con datos nuevos. Por ello, es muy importante evitar estar en esta situación; de aquí la utilidad de reservar una parte de datos de entrenamiento como datos de validación.</p>
<p>Podemos añadir el porcentaje de datos de validación dentro de la muestra de entrenamiento dentro del ajuste del modelo con el parámetro <code>validation_split</code> mediante:</p>
<p><code>model.fit(train_data, train_labels, epochs=epochs, validation_split=0.2)</code></p>
<p>de forma que cada época reservamos el 20% de los datos de entrenamiento para validar el modelo.</p>
<p>Los datos de validación del modelo se usan para probar y evaluar diferentes opciones de hiperparámetros para minimizar la situación de <em>overfitting</em>, como el número de <em>epochs</em> con las que entrenar el modelo, el ratio de aprendizaje o la mejor arquitectura de red, por poner algunos ejemplos.</p>
<p>Entrenamos por ejemplo el modelo de digits reservando un 20% para validación:</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb110"><pre class="sourceCode numberSource r number-lines code-with-copy"><code class="sourceCode r"><span id="cb110-1"><a href="#cb110-1"></a><span class="co"># Arquitectura del modelo</span></span>
<span id="cb110-2"><a href="#cb110-2"></a>modelo_digits <span class="ot">=</span> <span class="fu">keras_model_sequential</span>() <span class="sc">%&gt;%</span> </span>
<span id="cb110-3"><a href="#cb110-3"></a>      <span class="fu">layer_flatten</span>(<span class="at">input_shape =</span> <span class="fu">c</span>(<span class="dv">28</span>, <span class="dv">28</span>)) <span class="sc">%&gt;%</span> </span>
<span id="cb110-4"><a href="#cb110-4"></a>      <span class="fu">layer_dense</span>(<span class="at">units =</span> <span class="dv">32</span>, <span class="at">activation =</span> <span class="st">'relu'</span>, <span class="at">kernel_initializer =</span> inicializador) <span class="sc">%&gt;%</span> </span>
<span id="cb110-5"><a href="#cb110-5"></a>      <span class="fu">layer_dense</span>(<span class="dv">10</span>, <span class="at">activation =</span> <span class="st">'softmax'</span>, <span class="at">kernel_initializer =</span> inicializador)</span>
<span id="cb110-6"><a href="#cb110-6"></a><span class="co"># Proceso de aprendizaje</span></span>
<span id="cb110-7"><a href="#cb110-7"></a>  modelo_digits <span class="sc">%&gt;%</span> <span class="fu">compile</span>(</span>
<span id="cb110-8"><a href="#cb110-8"></a>    <span class="at">loss =</span> <span class="st">'sparse_categorical_crossentropy'</span>,</span>
<span id="cb110-9"><a href="#cb110-9"></a>    <span class="at">optimizer =</span> <span class="fu">optimizer_sgd</span>(),</span>
<span id="cb110-10"><a href="#cb110-10"></a>    <span class="at">metrics =</span> <span class="fu">c</span>(<span class="st">'accuracy'</span>))</span>
<span id="cb110-11"><a href="#cb110-11"></a><span class="co"># Entrenamiento</span></span>
<span id="cb110-12"><a href="#cb110-12"></a>history_digits <span class="ot">=</span> modelo_digits <span class="sc">%&gt;%</span> </span>
<span id="cb110-13"><a href="#cb110-13"></a>  <span class="fu">fit</span>(x_train, y_train, <span class="at">batch_size =</span> <span class="dv">50</span>, <span class="at">epochs =</span> <span class="dv">10</span>, <span class="at">validation_split =</span> <span class="fl">0.2</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Epoch 1/10
960/960 - 2s - loss: 0.9715 - accuracy: 0.7476 - val_loss: 0.4797 - val_accuracy: 0.8804 - 2s/epoch - 3ms/step
Epoch 2/10
960/960 - 2s - loss: 0.4447 - accuracy: 0.8802 - val_loss: 0.3678 - val_accuracy: 0.9001 - 2s/epoch - 2ms/step
Epoch 3/10
960/960 - 2s - loss: 0.3725 - accuracy: 0.8956 - val_loss: 0.3290 - val_accuracy: 0.9093 - 2s/epoch - 2ms/step
Epoch 4/10
960/960 - 2s - loss: 0.3387 - accuracy: 0.9039 - val_loss: 0.3066 - val_accuracy: 0.9147 - 2s/epoch - 2ms/step
Epoch 5/10
960/960 - 2s - loss: 0.3168 - accuracy: 0.9094 - val_loss: 0.2910 - val_accuracy: 0.9182 - 2s/epoch - 2ms/step
Epoch 6/10
960/960 - 2s - loss: 0.3009 - accuracy: 0.9141 - val_loss: 0.2815 - val_accuracy: 0.9207 - 2s/epoch - 2ms/step
Epoch 7/10
960/960 - 2s - loss: 0.2877 - accuracy: 0.9183 - val_loss: 0.2697 - val_accuracy: 0.9237 - 2s/epoch - 2ms/step
Epoch 8/10
960/960 - 2s - loss: 0.2763 - accuracy: 0.9209 - val_loss: 0.2608 - val_accuracy: 0.9265 - 2s/epoch - 2ms/step
Epoch 9/10
960/960 - 2s - loss: 0.2662 - accuracy: 0.9245 - val_loss: 0.2547 - val_accuracy: 0.9268 - 2s/epoch - 2ms/step
Epoch 10/10
960/960 - 2s - loss: 0.2571 - accuracy: 0.9273 - val_loss: 0.2474 - val_accuracy: 0.9294 - 2s/epoch - 2ms/step</code></pre>
</div>
<div class="sourceCode cell-code" id="cb112"><pre class="sourceCode numberSource r number-lines code-with-copy"><code class="sourceCode r"><span id="cb112-1"><a href="#cb112-1"></a><span class="co"># Evaluación</span></span>
<span id="cb112-2"><a href="#cb112-2"></a>modelo_digits <span class="sc">%&gt;%</span> tensorflow<span class="sc">::</span><span class="fu">evaluate</span>(x_test, y_test)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>313/313 - 0s - loss: 0.2477 - accuracy: 0.9300 - 413ms/epoch - 1ms/step</code></pre>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>     loss  accuracy 
0.2477478 0.9300000 </code></pre>
</div>
</div>
<p>Veamos gráficamente al evolución del proceso iterativo:</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb115"><pre class="sourceCode numberSource r number-lines code-with-copy"><code class="sourceCode r"><span id="cb115-1"><a href="#cb115-1"></a><span class="fu">plot</span>(history_digits) <span class="sc">+</span> <span class="fu">ylim</span>(<span class="dv">0</span>,<span class="dv">1</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output-display">
<p><img src="30_RMDDL_files/figure-html/rmdDL-59-1.png" class="img-fluid" width="672"></p>
</div>
</div>
<p>Los resultados con la muestra reservada para validación son comparables con los resultados de entrenamiento indicando que no parece producirse sobreajuste ni infrajuste. A continuación vemos diferentes modificaciones que se pueden introducir en el modelo para reducir cualquiera de esos dos efectos, aunque los estudiaremos con más detalle en el tema siguiente donde introduciremos diferentes casos prácticos de redes neuronales densas aplicadas a otro problemas de clasificación y regresión.</p>
<section id="reduciendo-el-tamaño-de-la-red" class="level3" data-number="3.4.1">
<h3 data-number="3.4.1" class="anchored" data-anchor-id="reduciendo-el-tamaño-de-la-red"><span class="header-section-number">3.4.1</span> Reduciendo el tamaño de la red</h3>
<p>La forma más sencilla de evitar el sobreajuste es reducir el tamaño del modelo: el número de parámetros aprendibles en el modelo (que viene determinado por el número de capas y el número de unidades por capa). En el aprendizaje profundo, el número de parámetros aprendibles en un modelo suele denominarse capacidad del modelo.</p>
<p>Intuitivamente, un modelo con más parámetros tiene más capacidad de memorización y, por lo tanto, puede aprender fácilmente y obtener un modelo perfecto entre las muestras de entrenamiento y sus objetivos, pero sin ningún poder de generalización. Por ejemplo, un modelo con 500.000 parámetros binarios podría aprender fácilmente la clase de cada dígito del conjunto de entrenamiento MNIST sólo necesitaríamos 10 parámetros binarios para cada uno de los 50.000 dígitos. Pero un modelo así sería inútil para clasificar nuevas muestras de dígitos.</p>
<p>Por otro lado, si la red tiene recursos de memorización limitados, no podrá aprender fácilmente; por tanto, para minimizar su pérdida, tendrá que recurrir al aprendizaje de modelos más complejos. Al mismo tiempo, hay que tener en cuenta que hay que utilizar modelos que tengan suficientes parámetros para que no se ajusten mal.</p>
<p>Desgraciadamente, no existe una fórmula mágica para determinar el número correcto de capas o el tamaño adecuado de cada capa. Se deben evaluar una serie de arquitecturas diferentes (en su conjunto de validación, no en su conjunto de prueba, por supuesto) con el fin de encontrar el tamaño correcto del modelo para los datos. El flujo de trabajo general para encontrar un tamaño de modelo adecuado consiste en empezar con relativamente pocas capas y parámetros, e ir aumentando el tamaño de las capas o añadiendo nuevas capas hasta que se observe una disminución del rendimiento con respecto a la pérdida de validación.</p>
</section>
<section id="regularización-de-parámetros" class="level3" data-number="3.4.2">
<h3 data-number="3.4.2" class="anchored" data-anchor-id="regularización-de-parámetros"><span class="header-section-number">3.4.2</span> Regularización de parámetros</h3>
<p>Dados unos datos de entrenamiento y una arquitectura de red, múltiples conjuntos de valores de los pesos (múltiples modelos) podrían explicar los datos. Un modelo simple en este contexto es un modelo en el que la distribución de los valores de los parámetros tiene menos entropía (o un modelo con menos parámetros). Por tanto, una forma común de mitigar el sobreajuste es poner restricciones a la complejidad de una red obligando a sus pesos a tomar sólo valores pequeños, lo que hace que la distribución de los valores de los pesos sea más regular. Esto se llama regularización de pesos, y se hace añadiendo a la función de pérdida de la red un coste asociado a tener pesos grandes.</p>
<p>Este coste puede ser de dos tipos:</p>
<ul>
<li>Regularización L1. El coste añadido es proporcional al valor absoluto de los coeficientes de peso (la norma L1 de los pesos).</li>
<li>Regularización L2. El coste añadido es proporcional al cuadrado del valor de los coeficientes de peso (la norma L2 de los pesos). En el contexto de las redes neuronales, la regularización L2 también se denomina decaimiento de los pesos.</li>
</ul>
<p>En Keras, la regularización de peso se añade pasando instancias de regularizador de peso a las capas como argumentos de palabra clave. Más concretamente debemos definir un regularizador de pesos con las funciones <code>kernel_regularizer=regularizer_l2(value)</code> y <code>kernel_regularizer=regularizer_l1(value)</code>, donde si <code>value</code> toma el valor 0.001 implica que cada coeficiente de la matriz de pesos de la capa sumará <code>0.001*weight_coefficient_value</code> a la pérdida total de la red.</p>
<p>Tenga en cuenta que como esta penalización sólo se añade en el momento del entrenamiento, la pérdida de esta red será mucho mayor durante el entrenamiento que en el momento de la validación.</p>
</section>
<section id="añadiendo-abandono-dropout" class="level3" data-number="3.4.3">
<h3 data-number="3.4.3" class="anchored" data-anchor-id="añadiendo-abandono-dropout"><span class="header-section-number">3.4.3</span> Añadiendo abandono (dropout)</h3>
<p>El <em>dropout</em> es una de las técnicas de regularización de redes neuronales más eficaces y utilizadas, desarrollada por Geoff Hinton y sus alumnos de la Universidad de Toronto. El <em>dropout</em>, aplicado a una capa, consiste en eliminar aleatoriamente (poner a cero) un número de características de salida de la capa durante el entrenamiento. Supongamos que una capa determinada devuelve normalmente un vector [0.2, 0.5, 1.3, 0.8, 1.1] para una determinada muestra de entrada durante el entrenamiento. Después de aplicar el abandono, este vector tendrá algunas entradas cero distribuidas al azar: por ejemplo, [0, 0.5, 1.3, 0, 1.1]. La tasa de abandono es la fracción de las características que se reducen a cero; normalmente se establece entre 0,2 y 0,5. En el momento de la prueba, no se eliminan las unidades; en su lugar, los valores de salida de la capa se reducen en un factor igual a la tasa de eliminación, para equilibrar el hecho de que hay más unidades activas que en el momento del entrenamiento.</p>
<p>En Keras, puedes introducir <em>dropout</em> en una red a través de la capa Dropout, que se aplica a la salida de la capa justo antes de ella:</p>
<pre><code>model.add(layers.Dropout(0.5))</code></pre>
<p>En este caso no pasamos por el 50% de las neuronas consideradas. Vamos a ver el efecto de esta capa sobre la red para el banco de datos digits. Como solo tenemos una capa intermedia dense colocamos ahí la capa dropout. para comparar los resultados vamos a justar un modelo sin dropout y otro con un dropout del 50% y comparemos la evolución de la pérdida entre ambos modelos.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb117"><pre class="sourceCode numberSource r number-lines code-with-copy"><code class="sourceCode r"><span id="cb117-1"><a href="#cb117-1"></a>inicializador <span class="ot">=</span> <span class="fu">initializer_glorot_normal</span>(<span class="at">seed =</span> <span class="dv">15</span>)</span>
<span id="cb117-2"><a href="#cb117-2"></a><span class="co"># Arquitectura del modelo sin dropout</span></span>
<span id="cb117-3"><a href="#cb117-3"></a>modelo_digits_sdr <span class="ot">=</span> <span class="fu">keras_model_sequential</span>() <span class="sc">%&gt;%</span> </span>
<span id="cb117-4"><a href="#cb117-4"></a>      <span class="fu">layer_flatten</span>(<span class="at">input_shape =</span> <span class="fu">c</span>(<span class="dv">28</span>, <span class="dv">28</span>)) <span class="sc">%&gt;%</span> </span>
<span id="cb117-5"><a href="#cb117-5"></a>      <span class="fu">layer_dense</span>(<span class="at">units =</span> <span class="dv">32</span>, <span class="at">activation =</span> <span class="st">'relu'</span>, <span class="at">kernel_initializer =</span> inicializador) <span class="sc">%&gt;%</span> </span>
<span id="cb117-6"><a href="#cb117-6"></a>      <span class="fu">layer_dense</span>(<span class="dv">10</span>, <span class="at">activation =</span> <span class="st">'softmax'</span>, <span class="at">kernel_initializer =</span> inicializador)</span>
<span id="cb117-7"><a href="#cb117-7"></a><span class="co"># Proceso de aprendizaje</span></span>
<span id="cb117-8"><a href="#cb117-8"></a>  modelo_digits_sdr <span class="sc">%&gt;%</span> <span class="fu">compile</span>(</span>
<span id="cb117-9"><a href="#cb117-9"></a>    <span class="at">loss =</span> <span class="st">'sparse_categorical_crossentropy'</span>,</span>
<span id="cb117-10"><a href="#cb117-10"></a>    <span class="at">optimizer =</span> <span class="fu">optimizer_sgd</span>(),</span>
<span id="cb117-11"><a href="#cb117-11"></a>    <span class="at">metrics =</span> <span class="fu">c</span>(<span class="st">'accuracy'</span>))</span>
<span id="cb117-12"><a href="#cb117-12"></a><span class="co"># Entrenamiento</span></span>
<span id="cb117-13"><a href="#cb117-13"></a>history_digits_sdr <span class="ot">=</span> modelo_digits_sdr <span class="sc">%&gt;%</span> </span>
<span id="cb117-14"><a href="#cb117-14"></a>  <span class="fu">fit</span>(x_train, y_train, <span class="at">batch_size =</span> <span class="dv">50</span>, <span class="at">epochs =</span> <span class="dv">10</span>, <span class="at">validation_split=</span><span class="fl">0.2</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Epoch 1/10
960/960 - 2s - loss: 0.9752 - accuracy: 0.7448 - val_loss: 0.4816 - val_accuracy: 0.8821 - 2s/epoch - 3ms/step
Epoch 2/10
960/960 - 2s - loss: 0.4460 - accuracy: 0.8796 - val_loss: 0.3688 - val_accuracy: 0.8986 - 2s/epoch - 2ms/step
Epoch 3/10
960/960 - 2s - loss: 0.3730 - accuracy: 0.8950 - val_loss: 0.3294 - val_accuracy: 0.9086 - 2s/epoch - 2ms/step
Epoch 4/10
960/960 - 2s - loss: 0.3391 - accuracy: 0.9035 - val_loss: 0.3099 - val_accuracy: 0.9134 - 2s/epoch - 2ms/step
Epoch 5/10
960/960 - 2s - loss: 0.3174 - accuracy: 0.9098 - val_loss: 0.2916 - val_accuracy: 0.9191 - 2s/epoch - 2ms/step
Epoch 6/10
960/960 - 2s - loss: 0.3011 - accuracy: 0.9136 - val_loss: 0.2802 - val_accuracy: 0.9213 - 2s/epoch - 2ms/step
Epoch 7/10
960/960 - 2s - loss: 0.2879 - accuracy: 0.9180 - val_loss: 0.2703 - val_accuracy: 0.9237 - 2s/epoch - 2ms/step
Epoch 8/10
960/960 - 2s - loss: 0.2763 - accuracy: 0.9213 - val_loss: 0.2618 - val_accuracy: 0.9260 - 2s/epoch - 2ms/step
Epoch 9/10
960/960 - 2s - loss: 0.2664 - accuracy: 0.9245 - val_loss: 0.2537 - val_accuracy: 0.9280 - 2s/epoch - 2ms/step
Epoch 10/10
960/960 - 2s - loss: 0.2572 - accuracy: 0.9272 - val_loss: 0.2468 - val_accuracy: 0.9302 - 2s/epoch - 2ms/step</code></pre>
</div>
</div>
<p>Modelo con Dropout</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb119"><pre class="sourceCode numberSource r number-lines code-with-copy"><code class="sourceCode r"><span id="cb119-1"><a href="#cb119-1"></a>inicializador <span class="ot">=</span> <span class="fu">initializer_glorot_normal</span>(<span class="at">seed =</span> <span class="dv">15</span>)</span>
<span id="cb119-2"><a href="#cb119-2"></a><span class="co"># Arquitectura del modelo sin dropout</span></span>
<span id="cb119-3"><a href="#cb119-3"></a>modelo_digits_dr <span class="ot">=</span> <span class="fu">keras_model_sequential</span>() <span class="sc">%&gt;%</span> </span>
<span id="cb119-4"><a href="#cb119-4"></a>      <span class="fu">layer_flatten</span>(<span class="at">input_shape =</span> <span class="fu">c</span>(<span class="dv">28</span>, <span class="dv">28</span>)) <span class="sc">%&gt;%</span> </span>
<span id="cb119-5"><a href="#cb119-5"></a>      <span class="fu">layer_dense</span>(<span class="at">units =</span> <span class="dv">32</span>, <span class="at">activation =</span> <span class="st">'relu'</span>, <span class="at">kernel_initializer =</span> inicializador) <span class="sc">%&gt;%</span> </span>
<span id="cb119-6"><a href="#cb119-6"></a>      <span class="fu">layer_dropout</span>(<span class="fl">0.5</span>) <span class="sc">%&gt;%</span></span>
<span id="cb119-7"><a href="#cb119-7"></a>      <span class="fu">layer_dense</span>(<span class="dv">10</span>, <span class="at">activation =</span> <span class="st">'softmax'</span>, <span class="at">kernel_initializer =</span> inicializador)</span>
<span id="cb119-8"><a href="#cb119-8"></a><span class="co"># Proceso de aprendizaje</span></span>
<span id="cb119-9"><a href="#cb119-9"></a>  modelo_digits_dr <span class="sc">%&gt;%</span> <span class="fu">compile</span>(</span>
<span id="cb119-10"><a href="#cb119-10"></a>    <span class="at">loss =</span> <span class="st">'sparse_categorical_crossentropy'</span>,</span>
<span id="cb119-11"><a href="#cb119-11"></a>    <span class="at">optimizer =</span> <span class="fu">optimizer_sgd</span>(),</span>
<span id="cb119-12"><a href="#cb119-12"></a>    <span class="at">metrics =</span> <span class="fu">c</span>(<span class="st">'accuracy'</span>))</span>
<span id="cb119-13"><a href="#cb119-13"></a><span class="co"># Entrenamiento</span></span>
<span id="cb119-14"><a href="#cb119-14"></a>history_digits_dr <span class="ot">=</span> modelo_digits_dr <span class="sc">%&gt;%</span> </span>
<span id="cb119-15"><a href="#cb119-15"></a>  <span class="fu">fit</span>(x_train, y_train, <span class="at">batch_size =</span> <span class="dv">50</span>, <span class="at">epochs =</span> <span class="dv">10</span>, <span class="at">validation_split=</span><span class="fl">0.2</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Epoch 1/10
960/960 - 3s - loss: 1.4090 - accuracy: 0.5387 - val_loss: 0.6724 - val_accuracy: 0.8639 - 3s/epoch - 3ms/step
Epoch 2/10
960/960 - 2s - loss: 0.8923 - accuracy: 0.7176 - val_loss: 0.4855 - val_accuracy: 0.8867 - 2s/epoch - 2ms/step
Epoch 3/10
960/960 - 2s - loss: 0.7631 - accuracy: 0.7626 - val_loss: 0.4153 - val_accuracy: 0.8947 - 2s/epoch - 2ms/step
Epoch 4/10
960/960 - 2s - loss: 0.7004 - accuracy: 0.7809 - val_loss: 0.3762 - val_accuracy: 0.9029 - 2s/epoch - 2ms/step
Epoch 5/10
960/960 - 2s - loss: 0.6590 - accuracy: 0.7948 - val_loss: 0.3491 - val_accuracy: 0.9068 - 2s/epoch - 2ms/step
Epoch 6/10
960/960 - 2s - loss: 0.6342 - accuracy: 0.8020 - val_loss: 0.3323 - val_accuracy: 0.9107 - 2s/epoch - 2ms/step
Epoch 7/10
960/960 - 2s - loss: 0.6082 - accuracy: 0.8120 - val_loss: 0.3181 - val_accuracy: 0.9149 - 2s/epoch - 2ms/step
Epoch 8/10
960/960 - 2s - loss: 0.5894 - accuracy: 0.8162 - val_loss: 0.3070 - val_accuracy: 0.9163 - 2s/epoch - 2ms/step
Epoch 9/10
960/960 - 2s - loss: 0.5801 - accuracy: 0.8188 - val_loss: 0.2970 - val_accuracy: 0.9195 - 2s/epoch - 2ms/step
Epoch 10/10
960/960 - 2s - loss: 0.5631 - accuracy: 0.8236 - val_loss: 0.2866 - val_accuracy: 0.9204 - 2s/epoch - 2ms/step</code></pre>
</div>
</div>
<p>Comparamos ahora los valores de la muestra de validación durante el proceso de entrenamiento para ambos modelos.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb121"><pre class="sourceCode numberSource r number-lines code-with-copy"><code class="sourceCode r"><span id="cb121-1"><a href="#cb121-1"></a><span class="fu">par</span>(<span class="at">mfrow=</span><span class="fu">c</span>(<span class="dv">1</span>, <span class="dv">2</span>))</span>
<span id="cb121-2"><a href="#cb121-2"></a>vl1 <span class="ot">=</span> history_digits_sdr<span class="sc">$</span>metrics<span class="sc">$</span>val_accuracy</span>
<span id="cb121-3"><a href="#cb121-3"></a>vl2 <span class="ot">=</span> history_digits_dr<span class="sc">$</span>metrics<span class="sc">$</span>val_accuracy </span>
<span id="cb121-4"><a href="#cb121-4"></a><span class="fu">plot</span>(vl1, <span class="at">type =</span><span class="st">"l"</span></span>
<span id="cb121-5"><a href="#cb121-5"></a>     ,<span class="at">xlab =</span> <span class="st">"Epoch"</span>, <span class="at">ylab =</span> <span class="st">"Validation Accuracy"</span>, <span class="at">col =</span> <span class="dv">1</span>, <span class="at">ylim =</span><span class="fu">c</span>(<span class="fu">min</span>(vl1,vl2), <span class="fu">max</span>(vl1,vl2)))</span>
<span id="cb121-6"><a href="#cb121-6"></a><span class="fu">lines</span>(vl2, <span class="at">col =</span> <span class="dv">2</span>)</span>
<span id="cb121-7"><a href="#cb121-7"></a><span class="fu">legend</span>(<span class="st">"topleft"</span>, <span class="at">legend=</span><span class="fu">c</span>(<span class="st">"Sin Dropout"</span>, <span class="st">"50% Dropout"</span>), <span class="at">lty =</span> <span class="fu">c</span>(<span class="dv">1</span>,<span class="dv">1</span>), <span class="at">col =</span> <span class="fu">c</span>(<span class="dv">1</span>,<span class="dv">2</span>))</span>
<span id="cb121-8"><a href="#cb121-8"></a></span>
<span id="cb121-9"><a href="#cb121-9"></a>vl1 <span class="ot">=</span> history_digits_sdr<span class="sc">$</span>metrics<span class="sc">$</span>val_loss</span>
<span id="cb121-10"><a href="#cb121-10"></a>vl2 <span class="ot">=</span> history_digits_dr<span class="sc">$</span>metrics<span class="sc">$</span>val_loss </span>
<span id="cb121-11"><a href="#cb121-11"></a><span class="fu">plot</span>(vl1, <span class="at">type =</span><span class="st">"l"</span></span>
<span id="cb121-12"><a href="#cb121-12"></a>     ,<span class="at">xlab =</span> <span class="st">"Epoch"</span>, <span class="at">ylab =</span> <span class="st">"Validation loss"</span>, <span class="at">col =</span> <span class="dv">1</span>,</span>
<span id="cb121-13"><a href="#cb121-13"></a>     <span class="at">ylim =</span> <span class="fu">c</span>(<span class="dv">0</span>, <span class="fu">max</span>(vl1, vl2)))</span>
<span id="cb121-14"><a href="#cb121-14"></a><span class="fu">lines</span>(vl2, <span class="at">col =</span> <span class="dv">2</span>)</span>
<span id="cb121-15"><a href="#cb121-15"></a><span class="fu">legend</span>(<span class="st">"topright"</span>, <span class="at">legend=</span><span class="fu">c</span>(<span class="st">"Sin Dropout"</span>, <span class="st">"50% Dropout"</span>), <span class="at">lty =</span> <span class="fu">c</span>(<span class="dv">1</span>,<span class="dv">1</span>), <span class="at">col =</span> <span class="fu">c</span>(<span class="dv">1</span>,<span class="dv">2</span>))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output-display">
<p><img src="30_RMDDL_files/figure-html/rmdDL-61-1.png" class="img-fluid" width="768"></p>
</div>
</div>
<p>En este caso el dropout no mejora los resultados del modelo completo, ya que la red tiene mucha información de entrada y es capaz de aprender con gran precisión. Más adelante veremos otros ejemplos donde la red contiene menos información de entrenamiento y el efecto del dropout si resulta relevante.</p>
</section>
<section id="parada-temprana-early-stopping" class="level3" data-number="3.4.4">
<h3 data-number="3.4.4" class="anchored" data-anchor-id="parada-temprana-early-stopping"><span class="header-section-number">3.4.4</span> Parada temprana (early stopping)</h3>
<p>En general, uno de los motivos del sobreajuste es que realizamos más <em>epochs</em> de las requeridas. Keras nos permite controlar que no nos excedemos de <em>epochs</em> de manera automática mediante <em>callbacks</em>.</p>
<p>Básicamente consiste en añadir un <em>callback</em> <code>EarlyStopping</code> como argumento en el método <code>fit()</code> que, automáticamente, para el entrenamiento cuando las métricas de la función de pérdida, para los datos de validación no mejoran. Al <em>callback</em> <code>EarlyStopping</code> le indicamos con el argumento <code>monitor</code> qué métrica debe tener en cuenta y, con el argumento <code>patience</code>, cuántas <em>epochs</em> se deben considerar para verificar la mejora. Por ejemplo si deseamos usar la pérdida con 3 epochs debemos escribir:</p>
<pre><code>early_stop = callback_early_stoppingg(monitor = 'loss', patience = 3)
history = model.fit(train_data, train_labels, epochs,
    validation_split, callbacks=list(early_stop))</code></pre>
<p>Si definimos la validacíón durante el entrenamiento (lo que es habitual) podemos usar como métrica <code>val_loss</code>. tambien podemos obviar el parámetro <code>patience</code> para que el entrenamiento se detenga entre dos iteraciones consecutivas.</p>
<p>En el tema siguiente nos enfrentamos a diferentes bancos de datos donde utilizaremos redes densas para problemas de clasificación y regresión, y pondremos en práctica todos los conceptos vistos en este tema.</p>


</section>
</section>

</main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const clipboard = new window.ClipboardJS('.code-copy-button', {
    target: function(trigger) {
      return trigger.previousElementSibling;
    }
  });
  clipboard.on('success', function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Copied!");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  });
  function tippyHover(el, contentFn) {
    const config = {
      allowHTML: true,
      content: contentFn,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start'
    };
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      return note.innerHTML;
    });
  }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
});
</script>
<nav class="page-navigation">
  <div class="nav-page nav-page-previous">
      <a href="./20_TrainDL.html" class="pagination-link">
        <i class="bi bi-arrow-left-short"></i> <span class="nav-page-text"><span class="chapter-number">2</span>&nbsp; <span class="chapter-title">Entrenamiento de la red neuronal</span></span>
      </a>          
  </div>
  <div class="nav-page nav-page-next">
      <a href="./40_AplMD.html" class="pagination-link">
        <span class="nav-page-text"><span class="chapter-number">4</span>&nbsp; <span class="chapter-title">Aplicaciones Redes multicapa densas</span></span> <i class="bi bi-arrow-right-short"></i>
      </a>
  </div>
</nav>
</div> <!-- /content -->
<footer class="footer">
  <div class="nav-footer">
    <div class="nav-footer-left">Copyright 2023, IA4LEGOS. Universidad Miguel Hernández de Elche</div>   
  </div>
</footer>



</body></html>